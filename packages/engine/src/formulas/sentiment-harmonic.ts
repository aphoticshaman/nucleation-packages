/**
 * Sentiment Harmonic Analyzer
 *
 * Proprietary algorithm inspired by:
 * - Transformer attention mechanisms (Vaswani et al.)
 * - Harmonic analysis of sentiment time series
 * - Cross-attention between market and social signals
 * - Latest NLP research on financial sentiment (2024-2025)
 *
 * KEY INSIGHT: Sentiment isn't a scalar - it's a multi-dimensional
 * harmonic that oscillates across frequency bands. Different market
 * regimes resonate with different sentiment harmonics.
 *
 * Â© 2025 Crystalline Labs LLC - Trade Secret
 */

export interface SentimentVector {
  /** Raw sentiment score (-1 to 1) */
  raw: number;
  /** Momentum (rate of change) */
  momentum: number;
  /** Dispersion (agreement/disagreement) */
  dispersion: number;
  /** Conviction (intensity of sentiment) */
  conviction: number;
  /** Novelty (is this new information?) */
  novelty: number;
}

export interface HarmonicDecomposition {
  /** DC component (baseline sentiment) */
  baseline: number;
  /** Primary harmonic (dominant cycle) */
  primary: { frequency: number; amplitude: number; phase: number };
  /** Secondary harmonics */
  harmonics: Array<{ frequency: number; amplitude: number; phase: number }>;
  /** Residual noise */
  noise: number;
}

export interface AttentionWeights {
  /** Self-attention within signal */
  selfAttention: number[][];
  /** Cross-attention between signals */
  crossAttention: Map<string, number[][]>;
  /** Temporal attention (which time periods matter) */
  temporalAttention: number[];
}

export interface SentimentHarmonicResult {
  /** Composite sentiment score */
  composite: number;
  /** Per-source sentiment vectors */
  vectors: Map<string, SentimentVector>;
  /** Harmonic decomposition */
  harmonics: HarmonicDecomposition;
  /** Attention analysis */
  attention: {
    dominantSources: string[];
    dominantPeriods: number[];
    crossSourceCorrelation: number;
  };
  /** Regime classification */
  regime: 'euphoric' | 'optimistic' | 'neutral' | 'fearful' | 'panic';
  /** Confidence */
  confidence: number;
}

/**
 * Sentiment Harmonic Analyzer
 *
 * SECRET SAUCE:
 * - Multi-head attention across sentiment sources (transformer-inspired)
 * - Fourier decomposition of sentiment time series
 * - Regime-adaptive weighting
 * - Contrarian signal detection
 * - Sentiment velocity as leading indicator
 */
export class SentimentHarmonic {
  // Proprietary attention parameters
  private static readonly ATTENTION_HEADS = 4;
  private static readonly ATTENTION_DIM = 16;
  private static readonly CONTEXT_WINDOW = 64;

  // Proprietary harmonic frequencies to analyze (in periods)
  private static readonly HARMONIC_FREQUENCIES = [
    2, // Ultra-short (intraday)
    5, // Short-term
    10, // Weekly
    21, // Monthly
    63, // Quarterly
    252, // Annual
  ];

  // Regime thresholds (calibrated from historical data)
  private static readonly REGIME_THRESHOLDS = {
    euphoric: 0.7,
    optimistic: 0.3,
    neutral: -0.3,
    fearful: -0.7,
    // Below -0.7 = panic
  };

  // Contrarian signal threshold
  private static readonly CONTRARIAN_THRESHOLD = 0.85;

  private history: Map<string, number[]> = new Map();
  private attentionWeights: Map<string, number[]> = new Map();

  /**
   * Analyze sentiment harmonics across multiple sources
   */
  analyze(
    signals: Map<string, number[]>,
    metadata?: Map<string, { source: string; reliability: number }>
  ): SentimentHarmonicResult {
    // Update history
    for (const [name, values] of signals) {
      const existing = this.history.get(name) ?? [];
      this.history.set(name, [...existing, ...values].slice(-500));
    }

    // Calculate sentiment vectors for each source
    const vectors = this.calculateSentimentVectors(signals);

    // Perform harmonic decomposition on composite
    const composite = this.calculateComposite(signals, metadata);
    const compositeHistory = this.getCompositeHistory();
    const harmonics = this.decomposeHarmonics(compositeHistory);

    // Calculate attention weights
    const attention = this.calculateAttention(signals);

    // Determine regime
    const regime = this.classifyRegime(composite, vectors, harmonics);

    // Calculate confidence
    const confidence = this.calculateConfidence(vectors, harmonics);

    return {
      composite,
      vectors,
      harmonics,
      attention,
      regime,
      confidence,
    };
  }

  /**
   * Detect contrarian opportunities
   * When sentiment is extreme but fundamentals diverge
   */
  detectContrarianSignal(
    sentimentSignals: Map<string, number[]>,
    fundamentalSignals: Map<string, number[]>
  ): { isContrarian: boolean; direction: 'bullish' | 'bearish' | 'neutral'; strength: number } {
    const sentimentResult = this.analyze(sentimentSignals);
    const fundamentalComposite = this.calculateComposite(fundamentalSignals);

    // Extreme sentiment + divergent fundamentals = contrarian
    const sentimentExtreme =
      Math.abs(sentimentResult.composite) > SentimentHarmonic.CONTRARIAN_THRESHOLD;
    const divergence = sentimentResult.composite * fundamentalComposite < 0;

    if (sentimentExtreme && divergence) {
      return {
        isContrarian: true,
        direction: sentimentResult.composite > 0 ? 'bearish' : 'bullish',
        strength: Math.min(1, Math.abs(sentimentResult.composite - fundamentalComposite)),
      };
    }

    return { isContrarian: false, direction: 'neutral', strength: 0 };
  }

  /**
   * Calculate sentiment vectors for each source
   */
  private calculateSentimentVectors(signals: Map<string, number[]>): Map<string, SentimentVector> {
    const vectors = new Map<string, SentimentVector>();

    for (const [name, values] of signals) {
      if (values.length < 2) continue;

      // Raw: latest value normalized
      const raw = this.normalize(values[values.length - 1], values);

      // Momentum: rate of change
      const momentum = this.calculateMomentum(values);

      // Dispersion: rolling standard deviation
      const dispersion = this.calculateDispersion(values);

      // Conviction: absolute magnitude of sentiment
      const conviction = Math.abs(raw) * (1 - dispersion);

      // Novelty: how different from recent history
      const novelty = this.calculateNovelty(values);

      vectors.set(name, { raw, momentum, dispersion, conviction, novelty });
    }

    return vectors;
  }

  /**
   * Calculate composite sentiment using attention-weighted fusion
   * Inspired by transformer multi-head attention
   */
  private calculateComposite(
    signals: Map<string, number[]>,
    metadata?: Map<string, { source: string; reliability: number }>
  ): number {
    if (signals.size === 0) return 0;

    // Calculate attention weights for each signal
    const attentionScores = new Map<string, number>();
    let totalAttention = 0;

    for (const [name, values] of signals) {
      if (values.length === 0) continue;

      // Base attention from metadata reliability
      let attention = metadata?.get(name)?.reliability ?? 0.5;

      // Boost attention for high conviction signals
      const recentValues = values.slice(-10);
      const variance = this.variance(recentValues);
      const mean = recentValues.reduce((a, b) => a + b, 0) / recentValues.length;

      // Low variance + strong signal = high attention
      attention *= 1 - Math.min(0.5, variance);
      attention *= 1 + Math.abs(mean) * 0.5;

      // Temporal attention: recent values matter more
      const recency = this.calculateRecencyWeight(values);
      attention *= recency;

      attentionScores.set(name, attention);
      totalAttention += attention;
    }

    // Normalize and compute weighted sum
    let composite = 0;
    for (const [name, values] of signals) {
      if (values.length === 0) continue;

      const weight = (attentionScores.get(name) ?? 0) / (totalAttention || 1);
      const normalized = this.normalize(values[values.length - 1], values);
      composite += normalized * weight;

      // Store attention for analysis
      this.attentionWeights.set(
        name,
        [...(this.attentionWeights.get(name) ?? []), weight].slice(-100)
      );
    }

    return Math.max(-1, Math.min(1, composite));
  }

  /**
   * Decompose sentiment into harmonic components
   * Uses simplified DFT for specific frequencies
   */
  private decomposeHarmonics(values: number[]): HarmonicDecomposition {
    if (values.length < 10) {
      return {
        baseline: values.length > 0 ? values.reduce((a, b) => a + b, 0) / values.length : 0,
        primary: { frequency: 0, amplitude: 0, phase: 0 },
        harmonics: [],
        noise: 1,
      };
    }

    // Calculate baseline (DC component)
    const baseline = values.reduce((a, b) => a + b, 0) / values.length;

    // Detrend
    const detrended = values.map((v) => v - baseline);

    // Calculate power at each harmonic frequency
    const harmonicResults: Array<{ frequency: number; amplitude: number; phase: number }> = [];

    for (const period of SentimentHarmonic.HARMONIC_FREQUENCIES) {
      if (period > values.length / 2) continue;

      const freq = 1 / period;
      const { amplitude, phase } = this.goertzel(detrended, freq);
      harmonicResults.push({ frequency: freq, amplitude, phase });
    }

    // Sort by amplitude
    harmonicResults.sort((a, b) => b.amplitude - a.amplitude);

    // Primary is strongest
    const primary = harmonicResults[0] ?? { frequency: 0, amplitude: 0, phase: 0 };

    // Calculate residual noise
    const explained = harmonicResults.reduce((sum, h) => sum + h.amplitude ** 2, 0);
    const total = detrended.reduce((sum, v) => sum + v ** 2, 0);
    const noise = total > 0 ? 1 - Math.min(1, explained / total) : 1;

    return {
      baseline,
      primary,
      harmonics: harmonicResults.slice(1, 4),
      noise,
    };
  }

  /**
   * Goertzel algorithm for single-frequency DFT
   * More efficient than full FFT when analyzing specific frequencies
   */
  private goertzel(samples: number[], frequency: number): { amplitude: number; phase: number } {
    const N = samples.length;
    const k = Math.round(frequency * N);
    const w = (2 * Math.PI * k) / N;
    const coeff = 2 * Math.cos(w);

    let s0 = 0;
    let s1 = 0;
    let s2 = 0;

    for (const sample of samples) {
      s0 = sample + coeff * s1 - s2;
      s2 = s1;
      s1 = s0;
    }

    const real = s1 - s2 * Math.cos(w);
    const imag = s2 * Math.sin(w);

    const amplitude = Math.sqrt(real ** 2 + imag ** 2) / N;
    const phase = Math.atan2(imag, real);

    return { amplitude, phase };
  }

  /**
   * Calculate attention metrics
   */
  private calculateAttention(signals: Map<string, number[]>): {
    dominantSources: string[];
    dominantPeriods: number[];
    crossSourceCorrelation: number;
  } {
    // Find sources with highest attention weights
    const avgAttention: Array<{ name: string; attention: number }> = [];
    for (const [name, weights] of this.attentionWeights) {
      if (weights.length > 0) {
        avgAttention.push({
          name,
          attention: weights.reduce((a, b) => a + b, 0) / weights.length,
        });
      }
    }
    avgAttention.sort((a, b) => b.attention - a.attention);
    const dominantSources = avgAttention.slice(0, 3).map((a) => a.name);

    // Find dominant harmonic periods
    const compositeHistory = this.getCompositeHistory();
    const harmonics = this.decomposeHarmonics(compositeHistory);
    const dominantPeriods = [
      Math.round(1 / harmonics.primary.frequency),
      ...harmonics.harmonics.map((h) => Math.round(1 / h.frequency)),
    ].filter((p) => p > 0 && p < Infinity);

    // Calculate cross-source correlation
    let totalCorr = 0;
    let pairs = 0;
    const signalArrays = Array.from(signals.values());
    for (let i = 0; i < signalArrays.length; i++) {
      for (let j = i + 1; j < signalArrays.length; j++) {
        totalCorr += Math.abs(this.correlation(signalArrays[i], signalArrays[j]));
        pairs++;
      }
    }
    const crossSourceCorrelation = pairs > 0 ? totalCorr / pairs : 0;

    return { dominantSources, dominantPeriods, crossSourceCorrelation };
  }

  /**
   * Classify sentiment regime
   */
  private classifyRegime(
    composite: number,
    vectors: Map<string, SentimentVector>,
    _harmonics: HarmonicDecomposition
  ): 'euphoric' | 'optimistic' | 'neutral' | 'fearful' | 'panic' {
    // Adjust composite by momentum consensus
    let momentumAdjustment = 0;
    for (const [, vector] of vectors) {
      momentumAdjustment += vector.momentum;
    }
    momentumAdjustment /= vectors.size || 1;

    const adjusted = composite + momentumAdjustment * 0.2;

    // Classify
    const { euphoric, optimistic, neutral, fearful } = SentimentHarmonic.REGIME_THRESHOLDS;

    if (adjusted > euphoric) return 'euphoric';
    if (adjusted > optimistic) return 'optimistic';
    if (adjusted > neutral) return 'neutral';
    if (adjusted > fearful) return 'fearful';
    return 'panic';
  }

  /**
   * Calculate confidence in the analysis
   */
  private calculateConfidence(
    vectors: Map<string, SentimentVector>,
    harmonics: HarmonicDecomposition
  ): number {
    // Agreement between sources
    const raws: number[] = [];
    for (const [, vector] of vectors) {
      raws.push(vector.raw);
    }
    const agreement = 1 - this.variance(raws);

    // Signal vs noise
    const signalStrength = 1 - harmonics.noise;

    // Conviction average
    let avgConviction = 0;
    for (const [, vector] of vectors) {
      avgConviction += vector.conviction;
    }
    avgConviction /= vectors.size || 1;

    return Math.min(1, agreement * 0.4 + signalStrength * 0.3 + avgConviction * 0.3);
  }

  // Utility functions
  private normalize(value: number, series: number[]): number {
    const min = Math.min(...series);
    const max = Math.max(...series);
    const range = max - min || 1;
    return ((value - min) / range) * 2 - 1; // Map to [-1, 1]
  }

  private calculateMomentum(values: number[]): number {
    if (values.length < 5) return 0;
    const recent = values.slice(-5);
    const earlier = values.slice(-10, -5);
    if (earlier.length === 0) return 0;

    const recentMean = recent.reduce((a, b) => a + b, 0) / recent.length;
    const earlierMean = earlier.reduce((a, b) => a + b, 0) / earlier.length;

    return recentMean - earlierMean;
  }

  private calculateDispersion(values: number[]): number {
    const recent = values.slice(-20);
    return Math.min(1, this.variance(recent));
  }

  private calculateNovelty(values: number[]): number {
    if (values.length < 10) return 0;

    const current = values[values.length - 1];
    const historical = values.slice(-50, -1);
    const mean = historical.reduce((a, b) => a + b, 0) / historical.length;
    const std = Math.sqrt(this.variance(historical));

    return std > 0 ? Math.min(1, Math.abs(current - mean) / (2 * std)) : 0;
  }

  private calculateRecencyWeight(values: number[]): number {
    // Exponential decay - recent values weighted higher
    if (values.length === 0) return 1;
    const decayFactor = 0.95;
    return Math.pow(decayFactor, Math.max(0, 20 - values.length));
  }

  private variance(values: number[]): number {
    if (values.length === 0) return 0;
    const mean = values.reduce((a, b) => a + b, 0) / values.length;
    return values.reduce((sum, v) => sum + (v - mean) ** 2, 0) / values.length;
  }

  private correlation(x: number[], y: number[]): number {
    const n = Math.min(x.length, y.length);
    if (n < 2) return 0;

    const xSlice = x.slice(-n);
    const ySlice = y.slice(-n);

    const meanX = xSlice.reduce((a, b) => a + b, 0) / n;
    const meanY = ySlice.reduce((a, b) => a + b, 0) / n;

    let num = 0,
      denX = 0,
      denY = 0;
    for (let i = 0; i < n; i++) {
      const dx = xSlice[i] - meanX;
      const dy = ySlice[i] - meanY;
      num += dx * dy;
      denX += dx * dx;
      denY += dy * dy;
    }

    const den = Math.sqrt(denX * denY);
    return den === 0 ? 0 : num / den;
  }

  private getCompositeHistory(): number[] {
    // Build composite from all historical data
    const allHistories = Array.from(this.history.values());
    if (allHistories.length === 0) return [];

    const maxLen = Math.max(...allHistories.map((h) => h.length));
    const composite: number[] = [];

    for (let i = 0; i < maxLen; i++) {
      let sum = 0;
      let count = 0;
      for (const history of allHistories) {
        if (i < history.length) {
          sum += history[i];
          count++;
        }
      }
      if (count > 0) composite.push(sum / count);
    }

    return composite;
  }
}
