# LatticeForge Inference Server Dependencies
# Minimal set for GPU inference

# Core ML
torch>=2.1.0
transformers>=4.36.0
peft>=0.7.0
accelerate>=0.25.0

# Server
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
pydantic>=2.0.0

# Cognitive module deps
numpy>=1.24.0
scipy>=1.11.0

# HuggingFace
huggingface_hub>=0.19.0

# Optional: faster tokenization
# tokenizers>=0.15.0
