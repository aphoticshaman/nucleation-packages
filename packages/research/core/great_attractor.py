"""
Great Attractor Basin Theory for Socio-Informational Systems.

NOVEL MATHEMATICS - PATENT-GRADE FORMALIZATION

This module implements the mathematical framework for understanding humans
as "Great Attractors" in high-dimensional possibility space - entities whose
coherent intentions create measurable curvature in probability distributions.

Key novel quantities (not in any prior art):
- Intentionality Gradient (‚àáùìò): Coherent agency shaping system trajectories
- Attractor Basin Curvature (Œ∫_ùíú): Sharpness of basin boundaries
- Human Causal Mass (M_agent): Gravitational pull on possibility space
- Macro-Micro Predictive Gain (Œ®): Intentional emergence measure
- Downward Causal Power (Œî): Force of intention on the system
- Attractor Dominance Ratio (ùîá_ùíú): Regime partitioning

Mathematical Foundation:
- Informational manifold ùìú ‚äÇ ‚Ñù^d where d >> 10¬≥
- Humans modeled as macro-causal attractors
- Intentions create curvature in probability space
- Phase transitions = basin boundary crossings
"""

import numpy as np
from numpy.typing import NDArray
from typing import Tuple, List, Optional, Dict, Callable
from dataclasses import dataclass
from scipy.spatial.distance import cdist
from scipy.ndimage import gaussian_filter
from scipy.stats import entropy
from scipy.linalg import eigh

from .types import (
    SourceSignal,
    CausalGraph,
    CausalEmergence,
    PhaseTransitionSignal,
    RegimeState,
)


@dataclass
class AttractorBasin:
    """
    Representation of a human attractor basin in the informational manifold.

    ùíú_i = { x ‚àà ùìú : lim_{t‚Üí‚àû} œÜ_t(x) = M_i* }

    where M_i* is the fixed point defined by agent's coherent intentions.
    """
    agent_id: str
    center: NDArray[np.float64]  # M_i* - the attractor fixed point
    influence_radius: float  # Effective reach in manifold
    curvature: float  # Œ∫_ùíú - basin boundary sharpness
    causal_mass: float  # M_agent - gravitational pull
    dominance_ratio: float  # ùîá_ùíú - share of total system influence


@dataclass
class IntentionalityField:
    """
    The intentionality field ùìò(x,t) over the manifold.

    Encodes strength and coherence of purposeful influence at each point.
    """
    values: NDArray[np.float64]  # Shape: (N_points,) or grid
    gradient: NDArray[np.float64]  # ‚àáùìò - shape: (N_points, D)
    gradient_magnitude: NDArray[np.float64]  # |‚àáùìò|
    timestamp: float


@dataclass
class GreatAttractorState:
    """Complete state of the Great Attractor system at time t."""
    timestamp: float
    basins: List[AttractorBasin]
    intentionality_field: IntentionalityField
    total_causal_mass: float
    dominant_basin_idx: int
    psi: float  # Macro-Micro Predictive Gain
    delta: float  # Downward Causal Power
    phase_transition_probability: float


def compute_intentionality_field(
    positions: NDArray[np.float64],
    agent_centers: NDArray[np.float64],
    agent_strengths: NDArray[np.float64],
    kernel_bandwidth: float = 1.0
) -> IntentionalityField:
    """
    Compute the intentionality field ùìò(x,t) over the manifold.

    ùìò(x,t): ùìú ‚Üí ‚Ñù

    Models the strength and coherence of purposeful influence at each point.
    Uses kernel density estimation from agent positions weighted by strength.

    Args:
        positions: Points in manifold to evaluate, shape (N, D)
        agent_centers: Agent macrostate positions, shape (K, D)
        agent_strengths: Agent influence strengths, shape (K,)
        kernel_bandwidth: RBF kernel bandwidth Œ∑

    Returns:
        IntentionalityField with values and gradient
    """
    N, D = positions.shape
    K = len(agent_centers)

    # Compute intentionality as weighted sum of Gaussian kernels
    # ùìò(x) = Œ£_i s_i ¬∑ exp(-||x - c_i||¬≤ / 2Œ∑¬≤)

    distances_sq = cdist(positions, agent_centers, 'sqeuclidean')  # (N, K)
    kernels = np.exp(-distances_sq / (2 * kernel_bandwidth**2))  # (N, K)

    # Weighted sum
    values = kernels @ agent_strengths  # (N,)

    # Compute gradient ‚àáùìò
    # ‚àÇùìò/‚àÇx = Œ£_i s_i ¬∑ K_i(x) ¬∑ (c_i - x) / Œ∑¬≤
    gradient = np.zeros((N, D))

    for i in range(K):
        diff = agent_centers[i] - positions  # (N, D)
        kernel_i = kernels[:, i:i+1]  # (N, 1)
        gradient += agent_strengths[i] * kernel_i * diff / kernel_bandwidth**2

    gradient_magnitude = np.linalg.norm(gradient, axis=1)

    return IntentionalityField(
        values=values,
        gradient=gradient,
        gradient_magnitude=gradient_magnitude,
        timestamp=0.0  # To be set by caller
    )


def compute_basin_curvature(
    intentionality_field: IntentionalityField,
    positions: NDArray[np.float64],
    eps: float = 1e-4
) -> NDArray[np.float64]:
    """
    Compute attractor basin boundary curvature Œ∫_ùíú.

    Œ∫_ùíú(x) = |‚àá ¬∑ nÃÇ(x)|

    where nÃÇ(x) is the outward normal (normalized gradient).

    Sharp increases in Œ∫_ùíú indicate emerging attractors.

    Args:
        intentionality_field: The intentionality field
        positions: Points to evaluate, shape (N, D)
        eps: Numerical differentiation epsilon

    Returns:
        Curvature values, shape (N,)
    """
    gradient = intentionality_field.gradient
    grad_mag = intentionality_field.gradient_magnitude

    # Normalized gradient (unit normal)
    n_hat = np.zeros_like(gradient)
    nonzero = grad_mag > eps
    n_hat[nonzero] = gradient[nonzero] / grad_mag[nonzero, None]

    # Compute divergence of nÃÇ via finite differences
    # This is an approximation - for production, use proper differential geometry
    N, D = positions.shape

    # Estimate local divergence via neighbor differences
    curvature = np.zeros(N)

    if N < 10:
        return curvature

    # Build k-NN graph for local divergence estimation
    from scipy.spatial import KDTree
    tree = KDTree(positions)

    for i in range(N):
        # Find neighbors
        dists, indices = tree.query(positions[i], k=min(10, N))
        indices = indices[1:]  # Exclude self

        if len(indices) < 3:
            continue

        # Local divergence as sum of directional derivatives
        for j in indices:
            diff = positions[j] - positions[i]
            dist = np.linalg.norm(diff)
            if dist > eps:
                direction = diff / dist
                # Directional derivative of nÃÇ
                n_diff = n_hat[j] - n_hat[i]
                curvature[i] += np.dot(n_diff, direction) / dist

        curvature[i] = np.abs(curvature[i]) / len(indices)

    return curvature


def compute_causal_mass(
    intentionality_field: IntentionalityField,
    basin_membership: NDArray[np.int64],
    positions: NDArray[np.float64],
    n_agents: int
) -> NDArray[np.float64]:
    """
    Compute human causal mass M_agent for each agent.

    M_{agent,i}(t) = ‚à´_{ùíú_i} |‚àáùìò(x,t)| dx

    Interpretation: High causal mass = strong pull on possibility space.
    Equivalent to gravitational mass in spacetime.

    Args:
        intentionality_field: The intentionality field
        basin_membership: Which basin each point belongs to, shape (N,)
        positions: Points in manifold, shape (N, D)
        n_agents: Number of agents/basins

    Returns:
        Causal mass for each agent, shape (n_agents,)
    """
    gradient_magnitude = intentionality_field.gradient_magnitude
    N = len(positions)

    # Approximate integral as sum over points in each basin
    causal_masses = np.zeros(n_agents)

    for i in range(n_agents):
        mask = basin_membership == i
        if mask.sum() > 0:
            # Volume element approximation (uniform for simplicity)
            causal_masses[i] = np.sum(gradient_magnitude[mask]) / N

    return causal_masses


def compute_attractor_dominance(
    causal_masses: NDArray[np.float64]
) -> NDArray[np.float64]:
    """
    Compute attractor dominance ratio ùîá_ùíú for each agent.

    ùîá_{ùíú_i}(t) = M_{agent,i}(t) / Œ£_j M_{agent,j}(t)

    Interpretation:
    - Dominance > 0.5 ‚Üí single-agent driven regime
    - Dominance < 0.2 ‚Üí distributed swarm-driven regime

    Args:
        causal_masses: Causal mass for each agent

    Returns:
        Dominance ratios, shape (n_agents,)
    """
    total_mass = causal_masses.sum()

    if total_mass < 1e-10:
        return np.ones_like(causal_masses) / len(causal_masses)

    return causal_masses / total_mass


def compute_predictive_gain_psi(
    macro_states: NDArray[np.float64],
    micro_states: NDArray[np.float64],
    actions: NDArray[np.float64],
    tau: int = 1
) -> float:
    """
    Compute Macro-Micro Predictive Gain Œ®.

    Œ®_i(t) = I(M_i(t); a_i(t+œÑ)) - I(m_i(t); a_i(t+œÑ))

    If Œ® > 0: macrostate explains more of future than microstate.
    Meaning: Intentions matter more than chemistry ‚Üí true downward causation.

    NOVEL: This is a patentable measure of intentional emergence.

    Args:
        macro_states: Macrostates (beliefs, intentions), shape (T, D_M)
        micro_states: Microstates (detailed signals), shape (T, D_m)
        actions: Observed actions/outcomes, shape (T, D_a)
        tau: Time lag

    Returns:
        Predictive gain Œ® (positive indicates emergence)
    """
    from .transfer_entropy import _kraskov_mi

    T = len(macro_states) - tau

    # I(M(t); a(t+œÑ))
    M_t = macro_states[:T]
    a_future = actions[tau:tau+T]

    I_macro = _kraskov_mi(M_t, a_future, k=4)

    # I(m(t); a(t+œÑ))
    m_t = micro_states[:T]
    I_micro = _kraskov_mi(m_t, a_future, k=4)

    psi = I_macro - I_micro

    return psi


def compute_downward_causal_power_delta(
    macro_states: NDArray[np.float64],
    actions: NDArray[np.float64],
    tau: int = 1,
    n_bins: int = 20
) -> float:
    """
    Compute Downward Causal Power Œî.

    Œî_i(t,œÑ) = D_KL(P(a(t+œÑ)|M(t)) || P(a(t+œÑ)))

    Interpretation: How much the agent's intentions deform the action distribution.
    Peaks exactly where your platform flags phase transitions.

    This functional signals WHEN WILL ENTERS THE SYSTEM.

    Args:
        macro_states: Macrostates shape (T, D_M)
        actions: Actions shape (T, D_a)
        tau: Time lag
        n_bins: Bins for discretization

    Returns:
        Downward causal power Œî
    """
    T = len(macro_states) - tau

    M_t = macro_states[:T]
    a_future = actions[tau:tau+T]

    # Discretize for KL computation
    if a_future.ndim == 1:
        a_future = a_future.reshape(-1, 1)

    # Marginal distribution P(a)
    a_flat = a_future[:, 0]  # Use first dimension
    hist_marginal, bin_edges = np.histogram(a_flat, bins=n_bins, density=True)
    hist_marginal = hist_marginal + 1e-10
    hist_marginal = hist_marginal / hist_marginal.sum()

    # Conditional distribution P(a|M) - approximate via quantiles of M
    if M_t.ndim == 1:
        M_t = M_t.reshape(-1, 1)

    M_quantile = np.digitize(M_t[:, 0], np.quantile(M_t[:, 0], np.linspace(0, 1, 5)))

    # Compute conditional distributions for each M quantile
    kl_terms = []

    for q in np.unique(M_quantile):
        mask = M_quantile == q
        if mask.sum() < 5:
            continue

        a_given_M = a_flat[mask]
        hist_cond, _ = np.histogram(a_given_M, bins=bin_edges, density=True)
        hist_cond = hist_cond + 1e-10
        hist_cond = hist_cond / hist_cond.sum()

        # KL divergence
        kl = entropy(hist_cond, hist_marginal)
        kl_terms.append(kl * mask.sum() / T)  # Weight by frequency

    delta = np.sum(kl_terms) if kl_terms else 0.0

    return delta


def compute_phase_transition_probability(
    basin_probabilities: NDArray[np.float64],
    window_size: int = 10
) -> float:
    """
    Compute probability of imminent phase transition.

    Based on basin-crossing probability - the likelihood that
    the system will transition from one attractor basin to another.

    INSIGHT: Early warning = high basin-crossing probability

    Args:
        basin_probabilities: Time series of basin membership probs, shape (T, K)
        window_size: Window for trend analysis

    Returns:
        Phase transition probability in [0, 1]
    """
    if len(basin_probabilities) < window_size:
        return 0.0

    recent = basin_probabilities[-window_size:]

    # Entropy of basin probabilities (uncertainty = transition risk)
    mean_probs = recent.mean(axis=0)
    current_entropy = entropy(mean_probs + 1e-10)
    max_entropy = np.log(len(mean_probs))

    normalized_entropy = current_entropy / max_entropy if max_entropy > 0 else 0

    # Trend: are probabilities converging or diverging?
    first_half = recent[:window_size//2].mean(axis=0)
    second_half = recent[window_size//2:].mean(axis=0)

    # Jensen-Shannon divergence between halves
    m = (first_half + second_half) / 2
    js = (entropy(first_half + 1e-10, m + 1e-10) +
          entropy(second_half + 1e-10, m + 1e-10)) / 2

    # Combine entropy (uncertainty) with JS divergence (change)
    transition_prob = 0.5 * normalized_entropy + 0.5 * min(js * 2, 1.0)

    return float(np.clip(transition_prob, 0, 1))


class GreatAttractorAnalyzer:
    """
    Complete Great Attractor analysis system.

    Integrates all novel measures:
    - Intentionality field computation
    - Basin curvature detection
    - Causal mass quantification
    - Predictive gain (Œ®) and downward causation (Œî)
    - Attractor dominance tracking
    - Phase transition forecasting
    """

    def __init__(
        self,
        n_agents: int,
        manifold_dim: int,
        kernel_bandwidth: float = 1.0
    ):
        self.n_agents = n_agents
        self.manifold_dim = manifold_dim
        self.kernel_bandwidth = kernel_bandwidth

        # History
        self.state_history: List[GreatAttractorState] = []
        self.basin_membership_history: List[NDArray] = []

    def analyze(
        self,
        positions: NDArray[np.float64],
        agent_centers: NDArray[np.float64],
        agent_strengths: NDArray[np.float64],
        macro_states: Optional[NDArray[np.float64]] = None,
        micro_states: Optional[NDArray[np.float64]] = None,
        actions: Optional[NDArray[np.float64]] = None,
        timestamp: float = 0.0
    ) -> GreatAttractorState:
        """
        Perform complete Great Attractor analysis.

        Args:
            positions: Points in manifold, shape (N, D)
            agent_centers: Agent macrostate positions, shape (K, D)
            agent_strengths: Agent influence strengths, shape (K,)
            macro_states: For Œ®/Œî computation, shape (T, D_M)
            micro_states: For Œ® computation, shape (T, D_m)
            actions: For Œ®/Œî computation, shape (T, D_a)
            timestamp: Current time

        Returns:
            Complete GreatAttractorState
        """
        # 1. Compute intentionality field
        intent_field = compute_intentionality_field(
            positions, agent_centers, agent_strengths, self.kernel_bandwidth
        )
        intent_field.timestamp = timestamp

        # 2. Compute basin membership (assign to nearest agent)
        distances = cdist(positions, agent_centers)
        basin_membership = np.argmin(distances, axis=1)

        # 3. Compute basin curvature
        curvatures = compute_basin_curvature(intent_field, positions)
        avg_curvature = curvatures.mean()

        # 4. Compute causal masses
        causal_masses = compute_causal_mass(
            intent_field, basin_membership, positions, self.n_agents
        )

        # 5. Compute dominance ratios
        dominance_ratios = compute_attractor_dominance(causal_masses)
        dominant_idx = int(np.argmax(dominance_ratios))

        # 6. Compute Œ® and Œî if data available
        if macro_states is not None and actions is not None:
            if micro_states is not None:
                psi = compute_predictive_gain_psi(macro_states, micro_states, actions)
            else:
                psi = 0.0
            delta = compute_downward_causal_power_delta(macro_states, actions)
        else:
            psi = 0.0
            delta = 0.0

        # 7. Compute phase transition probability
        if len(self.basin_membership_history) > 0:
            # Convert membership to probabilities
            recent_memberships = np.array(self.basin_membership_history[-20:])
            basin_probs = np.zeros((len(recent_memberships), self.n_agents))
            for t, mem in enumerate(recent_memberships):
                for k in range(self.n_agents):
                    basin_probs[t, k] = (mem == k).mean()
            phase_trans_prob = compute_phase_transition_probability(basin_probs)
        else:
            phase_trans_prob = 0.0

        # 8. Build attractor basin objects
        basins = []
        for i in range(self.n_agents):
            mask = basin_membership == i
            if mask.sum() > 0:
                basin_curvature = curvatures[mask].mean()
            else:
                basin_curvature = 0.0

            basins.append(AttractorBasin(
                agent_id=f"agent_{i}",
                center=agent_centers[i],
                influence_radius=self.kernel_bandwidth * 2,
                curvature=float(basin_curvature),
                causal_mass=float(causal_masses[i]),
                dominance_ratio=float(dominance_ratios[i])
            ))

        # Build complete state
        state = GreatAttractorState(
            timestamp=timestamp,
            basins=basins,
            intentionality_field=intent_field,
            total_causal_mass=float(causal_masses.sum()),
            dominant_basin_idx=dominant_idx,
            psi=float(psi),
            delta=float(delta),
            phase_transition_probability=phase_trans_prob
        )

        # Update history
        self.state_history.append(state)
        self.basin_membership_history.append(basin_membership)

        return state

    def get_attractor_genesis_events(
        self,
        curvature_threshold: float = 0.5
    ) -> List[Tuple[float, int]]:
        """
        NOVEL INSIGHT #8: Detect attractor genesis events.

        Returns moments when basin curvature sharply increases,
        indicating a new attractor is forming.

        Returns:
            List of (timestamp, basin_idx) for genesis events
        """
        events = []

        for i, state in enumerate(self.state_history[1:], 1):
            prev_state = self.state_history[i-1]

            for j, basin in enumerate(state.basins):
                if j < len(prev_state.basins):
                    prev_curvature = prev_state.basins[j].curvature
                    if basin.curvature - prev_curvature > curvature_threshold:
                        events.append((state.timestamp, j))

        return events

    def get_gravity_gradient_field(self) -> NDArray[np.float64]:
        """
        NOVEL INSIGHT #10: Compute gravity gradient field.

        The temporal derivative of basin dominance ratios.
        Shows which attractors are gaining/losing influence.

        Returns:
            Gradient field, shape (T-1, n_agents)
        """
        if len(self.state_history) < 2:
            return np.array([])

        dominances = np.array([
            [b.dominance_ratio for b in state.basins]
            for state in self.state_history
        ])

        return np.gradient(dominances, axis=0)

    def modulate_ds_fusion_reliability(
        self,
        base_reliabilities: NDArray[np.float64],
        source_basin_affiliations: NDArray[np.int64]
    ) -> NDArray[np.float64]:
        """
        Integration: Modulate DS fusion reliabilities by attractor dominance.

        r'_j = r_j ¬∑ ùîá_{ùíú_k}

        where k is the basin that source j is affiliated with.

        Args:
            base_reliabilities: Original source reliabilities, shape (J,)
            source_basin_affiliations: Which basin each source belongs to, shape (J,)

        Returns:
            Modulated reliabilities
        """
        if len(self.state_history) == 0:
            return base_reliabilities

        current_state = self.state_history[-1]
        modulated = base_reliabilities.copy()

        for j, affiliation in enumerate(source_basin_affiliations):
            if 0 <= affiliation < len(current_state.basins):
                dominance = current_state.basins[affiliation].dominance_ratio
                modulated[j] *= (0.5 + dominance)  # Boost by dominance, baseline 0.5

        return modulated

    def modulate_laplacian_weights(
        self,
        adjacency: NDArray[np.float64],
        node_positions: NDArray[np.float64]
    ) -> NDArray[np.float64]:
        """
        Integration: Modulate graph Laplacian edge weights by basin curvature.

        Edges crossing high-curvature regions get lower weight
        (representing basin boundaries).

        Args:
            adjacency: Original adjacency matrix, shape (N, N)
            node_positions: Node positions in manifold, shape (N, D)

        Returns:
            Modulated adjacency matrix
        """
        if len(self.state_history) == 0:
            return adjacency

        current_state = self.state_history[-1]
        curvatures = np.zeros(len(node_positions))

        # Get curvature at each node position
        for i, pos in enumerate(node_positions):
            # Find nearest point in intentionality field
            # (simplified - in production, interpolate properly)
            curvatures[i] = current_state.basins[0].curvature  # Placeholder

        # Modulate edges: high curvature = lower weight
        modulated = adjacency.copy()
        N = len(adjacency)

        for i in range(N):
            for j in range(i+1, N):
                if adjacency[i, j] > 0:
                    avg_curvature = (curvatures[i] + curvatures[j]) / 2
                    # Decrease weight exponentially with curvature
                    modulated[i, j] *= np.exp(-avg_curvature)
                    modulated[j, i] = modulated[i, j]

        return modulated
