{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# RYANAIMO v0.3.0 - AIMO3 Competition Solver\n\n**Smart Swap Ensemble with Budget Enforcement**\n\n---\n\n## Model Strategy\n- **Primary: Fast-Math-R1-14B-AWQ** - Proven 9th place AIMO2, 63% AIME\n- **Secondary: 14B-GRPO-Merged-AWQ** - Competition-tuned, different approach\n- **Swap on demand** - Only swap when needed (~25s per swap)\n\n## Smart Swap Logic\n```\nFast-Math runs on EVERY problem first\n         \u2502\n         \u25bc\nConfidence \u2265 0.5? \u2500\u2500\u2500YES\u2500\u2500\u2192 ACCEPT (no swap)\n         \u2502\n         NO\n         \u2502\n         \u25bc\nCode failed 3+ times? \u2500\u2500OR\u2500\u2500 Confidence < 0.5?\n         \u2502\n         YES\n         \u2502\n         \u25bc\nSWAP TO GRPO \u2192 Get second opinion \u2192 Vote/Combine \u2192 SWAP BACK\n```\n\n## Budget Enforcement\n- **5-hour total** with 4-4.5hr target finish\n- **Per-problem stopwatch** with hard budget enforcement\n- **Bayesian calibration** from AIMO 2023/2024 historical data\n- **Adaptive pacing** - learns from overage/underage\n\n## Second Pass Review\n- After all problems: review low-confidence answers with GRPO\n- Only if time permits (last 30-60 minutes)\n- Can correct mistakes caught by second model\n\n## Key Features\n- Extended `<think>` prompting for deep reasoning\n- Value clustering (88% error reduction)\n- CIC-aware answer selection\n- Math-specific heuristics (Fibonacci, Catalan, nice numbers)\n- Problem type classification with tailored strategies\n\n---\n\n**Author**: Ryan J Cardwell (Archer Phoenix)  \n**Target**: $1.59M Grand Prize"
  },
  {
   "cell_type": "code",
   "id": "9aedok8f4g5",
   "source": "# CELL 0: Quick startup check (runs first, proves kernel is alive)\nprint(\"=\" * 60)\nprint(\"KAGGLE NOTEBOOK STARTING...\")\nprint(\"=\" * 60)\n\nimport sys\nprint(f\"Python: {sys.version}\")\n\nimport os\nprint(\"\\nInputs attached:\")\nfor d in sorted(os.listdir(\"/kaggle/input\")):\n    print(f\"  - {d}\")\n\nprint(\"\\nKernel is alive. Proceeding to setup...\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-setup",
   "metadata": {},
   "outputs": [],
   "source": "# CELL 1: Install Dependencies (purge torch from memory!)\nimport sys\nimport os\nimport subprocess\n\nprint(\"=\" * 60)\nprint(\"RYANAIMO v0.3.0 - Setup\")\nprint(\"=\" * 60)\n\n# Paths\nLIBS_PATH = \"/kaggle/input/libraries\"\nTORCH26_PATH = \"/kaggle/input/torch-2-6-0\"\nDEPS_PATH = \"/kaggle/input/aimo3-dependency-dataset\"\nRYANSTREAM_PATH = \"/kaggle/input/aimo3-prometheus-deps\"\n\n# Model paths\nFAST_MATH_PATH = \"/kaggle/input/fast_math_r1_14b/transformers/fast_math_r1_14b_awq/1\"\nGRPO_PATH = \"/kaggle/input/14b-grpo-v2-12288/transformers/merged-awq/3\"\n\n# ============================================================================\n# STEP 0: Purge any pre-loaded torch from memory\n# Kaggle/Papermill might have imported torch before our code runs\n# ============================================================================\nprint(\"\\nStep 0: Purging torch from memory...\")\ntorch_modules = [key for key in sys.modules.keys() if 'torch' in key.lower()]\nfor mod in torch_modules:\n    del sys.modules[mod]\nprint(f\"  Purged {len(torch_modules)} torch-related modules from sys.modules\")\n\nprint(\"\\nStep 1: Uninstalling Kaggle's torch stack...\")\nfor pkg in ['torchvision', 'torchaudio', 'torch']:\n    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"-q\", pkg],\n                   capture_output=True)\n    print(f\"  Uninstalled {pkg}\")\n\nprint(\"\\nStep 2: Installing torch 2.7.1 stack...\")\n\ndef install_wheel(path, prefix, desc):\n    if not os.path.exists(path):\n        print(f\"  {desc}: PATH NOT FOUND\")\n        return\n    for f in os.listdir(path):\n        if f.lower().startswith(prefix.lower()) and f.endswith('.whl'):\n            print(f\"  {desc}: {f}\")\n            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--no-deps\", \n                           os.path.join(path, f)], capture_output=True, timeout=120)\n            return\n    print(f\"  {desc}: NOT FOUND\")\n\ninstall_wheel(LIBS_PATH, \"torch-2.7\", \"torch 2.7.1\")\ninstall_wheel(TORCH26_PATH, \"nvidia_nccl_cu12-2.26\", \"nccl 2.26\")  # For torch 2.7.1\ninstall_wheel(TORCH26_PATH, \"torchvision-0.22\", \"torchvision 0.22.1\")\ninstall_wheel(TORCH26_PATH, \"pillow-11\", \"pillow 11.2.1\")  # For torchvision\ninstall_wheel(TORCH26_PATH, \"triton-3.3\", \"triton 3.3.1\")\ninstall_wheel(LIBS_PATH, \"xform\", \"xformers\")\ninstall_wheel(LIBS_PATH, \"vllm\", \"vLLM 0.10.0\")\ninstall_wheel(LIBS_PATH, \"transformers\", \"transformers\")\ninstall_wheel(LIBS_PATH, \"tokenizers\", \"tokenizers\")\ninstall_wheel(LIBS_PATH, \"bitsandbytes\", \"bitsandbytes\")\n\n# Install deps from ermecan\nif os.path.exists(DEPS_PATH):\n    print(\"\\nStep 3: Installing additional deps...\")\n    SKIP = {'torch', 'torchvision', 'torchaudio', 'nvidia', 'cuda', 'triton',\n            'xformers', 'flash_attn', 'flashinfer', 'vllm', 'transformers', 'tokenizers'}\n    installed = 0\n    for wf in sorted(os.listdir(DEPS_PATH)):\n        if not wf.endswith('.whl') or any(wf.lower().startswith(s) for s in SKIP):\n            continue\n        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--no-deps\",\n                       os.path.join(DEPS_PATH, wf)], capture_output=True, timeout=30)\n        installed += 1\n    print(f\"  Installed {installed} wheels\")\n\nif os.path.exists(RYANSTREAM_PATH):\n    sys.path.insert(0, RYANSTREAM_PATH)\n    print(\"\\nRYANSTREAM path added\")\n\nprint(\"\\nSetup complete! torch 2.7.1 + vLLM 0.10.0 installed\")\nprint(\"(Fresh import will happen in next cell)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-models",
   "metadata": {},
   "outputs": [],
   "source": "# CELL 2: Load Models with Smart Swap Strategy\nfrom vllm import LLM, SamplingParams\nfrom transformers import AutoTokenizer\nimport gc\n\nprint(\"=\" * 60)\nprint(\"RYANAIMO v0.3.0 - SMART SWAP ENSEMBLE\")\nprint(\"=\" * 60)\n\n# =============================================================================\n# MODEL CONFIGURATION - Two AWQ Models\n# =============================================================================\n\n# Primary: Fast-Math (proven 9th place AIMO2, 63% AIME)\nFAST_MATH_PATH = \"/kaggle/input/fast_math_r1_14b/transformers/fast_math_r1_14b_awq/1\"\n\n# Secondary: GRPO (competition-tuned, different training approach)\nGRPO_PATH = \"/kaggle/input/14b-grpo-v2-12288/transformers/merged-awq/3\"\n\n# Model registry\nMODELS = {\n    \"fast_math\": {\n        \"path\": FAST_MATH_PATH,\n        \"name\": \"Fast-Math-R1-14B-AWQ\",\n        \"quantization\": \"awq\",\n    },\n    \"grpo\": {\n        \"path\": GRPO_PATH,\n        \"name\": \"14B-GRPO-Merged-AWQ\",\n        \"quantization\": \"awq\",\n    },\n}\n\n# =============================================================================\n# MODEL MANAGER - Handles loading and swapping\n# =============================================================================\n\nclass ModelManager:\n    \"\"\"\n    Manages model loading and swapping with smart caching.\n    \n    Strategy:\n    - Fast-Math as primary (stays loaded)\n    - GRPO for low-confidence second opinions\n    - Swap only when needed (~25s per swap)\n    \"\"\"\n    \n    def __init__(self):\n        self.current_model_id = None\n        self.llm = None\n        self.tokenizer = None\n        self.swap_count = 0\n        self.swap_time_total = 0\n    \n    def load_model(self, model_id: str):\n        \"\"\"Load a model, swapping out current if necessary.\"\"\"\n        if model_id == self.current_model_id:\n            return  # Already loaded\n        \n        config = MODELS[model_id]\n        swap_start = time.time()\n        \n        # Unload current model if exists\n        if self.llm is not None:\n            print(f\"\\n  [SWAP] Unloading {MODELS[self.current_model_id]['name']}...\")\n            del self.llm\n            del self.tokenizer\n            torch.cuda.empty_cache()\n            gc.collect()\n            self.swap_count += 1\n        \n        # Load new model\n        print(f\"  [SWAP] Loading {config['name']}...\")\n        \n        self.llm = LLM(\n            model=config['path'],\n            quantization=config['quantization'],\n            max_model_len=16384,\n            gpu_memory_utilization=0.92,\n            trust_remote_code=True,\n            enforce_eager=True,\n        )\n        \n        self.tokenizer = AutoTokenizer.from_pretrained(\n            config['path'], \n            trust_remote_code=True\n        )\n        \n        self.current_model_id = model_id\n        swap_time = time.time() - swap_start\n        self.swap_time_total += swap_time\n        \n        print(f\"  [SWAP] Loaded in {swap_time:.1f}s | Total swaps: {self.swap_count} | Total swap time: {self.swap_time_total:.0f}s\")\n        print(f\"  [SWAP] VRAM: {torch.cuda.memory_allocated()/1e9:.1f}GB\")\n    \n    def get_llm(self):\n        return self.llm\n    \n    def get_tokenizer(self):\n        return self.tokenizer\n    \n    def get_current_model_name(self) -> str:\n        if self.current_model_id:\n            return MODELS[self.current_model_id]['name']\n        return \"None\"\n    \n    def get_swap_stats(self) -> str:\n        return f\"Swaps: {self.swap_count} | Swap time: {self.swap_time_total:.0f}s\"\n\n# =============================================================================\n# INITIALIZE - Load primary model (Fast-Math)\n# =============================================================================\n\nprint(\"\\nInitializing Model Manager...\")\nmodel_manager = ModelManager()\n\nprint(\"\\nLoading PRIMARY model (Fast-Math-R1-14B-AWQ)...\")\nload_start = time.time()\nmodel_manager.load_model(\"fast_math\")\nprint(f\"\\nPrimary model ready in {time.time() - load_start:.1f}s\")\n\n# Quick reference for solver\nllm = model_manager.get_llm()\ntokenizer = model_manager.get_tokenizer()\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SMART SWAP STRATEGY:\")\nprint(\"  Primary: Fast-Math (runs on every problem)\")\nprint(\"  Swap to GRPO when:\")\nprint(\"    - Confidence < 0.5 after sampling\")\nprint(\"    - Code execution failed 3+ times\")\nprint(\"  Second pass: Review low-conf with GRPO if time permits\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-cic",
   "metadata": {},
   "outputs": [],
   "source": "# CELL 3: GRAND SYNTHESIS - CIC + UIPT + NCD + LatticeForge + Grokking + Toroidal\n# =============================================================================\n# THE COMPLETE RYANAIMO WEAPON SYSTEM\n# Integrates: CIC Theory, UIPT Entropy, Extended NCD, LatticeForge Phase Detection,\n#             Micro-Grokking, Toroidal Voting, Entropic Gravity, Value Clustering\n# =============================================================================\n\nimport lzma\nimport math\nimport struct\nimport statistics\nimport re\nimport time\nfrom dataclasses import dataclass, field\nfrom typing import Optional, List, Tuple, Dict, Any, Deque\nfrom collections import Counter, deque\nimport heapq\n\n# Constants\nANSWER_MIN = 0\nANSWER_MAX = 99999\nFALLBACK_ANSWER = 0\nTOTAL_BUDGET_SECONDS = 5 * 60 * 60  # 5 hours\n\n# =============================================================================\n# SECTION 1: UIPT (Universal Information Phase Transition) - Entropy Tracking\n# From prometheus_kaggle.py\n# =============================================================================\n\nclass UIPTEntropyWindow:\n    \"\"\"\n    Rolling entropy tracker for detecting phase transitions in token generation.\n\n    Low entropy = Crystallized Logic (High confidence) - CRYSTALLINE phase\n    High entropy = Gas Phase (Hallucination/exploration) - PLASMA phase\n\n    This is the core UIPT insight: Intelligence emerges at the phase transition\n    where compression forces balance integration forces.\n    \"\"\"\n\n    def __init__(self, window: int = 32):\n        self.window = window\n        self.buf: Deque[int] = deque(maxlen=self.window)\n        self.counts: Counter = Counter()\n        self.entropy_history: List[float] = []\n\n    def add(self, token_id: int) -> None:\n        \"\"\"Add a new token and update entropy calculation.\"\"\"\n        if len(self.buf) == self.window:\n            old = self.buf.popleft()\n            self.counts[old] -= 1\n            if self.counts[old] <= 0:\n                del self.counts[old]\n        self.buf.append(token_id)\n        self.counts[token_id] += 1\n        self.entropy_history.append(self.normalized())\n\n    def raw_entropy_bits(self) -> float:\n        \"\"\"Calculate raw Shannon entropy in bits.\"\"\"\n        total = sum(self.counts.values())\n        if total <= 0:\n            return 0.0\n        probs = [c / total for c in self.counts.values() if c > 0]\n        H = -sum(p * math.log2(p) for p in probs)\n        return H\n\n    def normalized(self) -> float:\n        \"\"\"Normalized entropy (0-1). 0=crystallized, 1=max entropy.\"\"\"\n        H = self.raw_entropy_bits()\n        alph = max(1, len(self.counts))\n        maxH = math.log2(alph) if alph > 1 else 1.0\n        return float(H / maxH) if maxH > 0 else 0.0\n\n    def is_crystallized(self, threshold: float = 0.3) -> bool:\n        \"\"\"Check if entropy has crystallized below threshold.\"\"\"\n        return self.normalized() < threshold\n\n    def is_gas_phase(self, threshold: float = 0.85) -> bool:\n        \"\"\"Check if entropy is in gas phase (hallucination mode).\"\"\"\n        return self.normalized() > threshold\n\n    def get_phase(self) -> str:\n        \"\"\"Get current phase based on entropy.\"\"\"\n        h = self.normalized()\n        if h < 0.3:\n            return \"CRYSTALLINE\"\n        elif h < 0.5:\n            return \"SUPERCOOLED\"\n        elif h < 0.7:\n            return \"NUCLEATING\"\n        elif h < 0.85:\n            return \"ANNEALING\"\n        else:\n            return \"PLASMA\"\n\n\n# =============================================================================\n# SECTION 2: MICRO-GROKKING DETECTION\n# From entropy_voting.py - The KEY insight\n# =============================================================================\n\n@dataclass\nclass GrokkingSignal:\n    \"\"\"Result of micro-grokking analysis.\"\"\"\n    detected: bool\n    score: float\n    d2_min: float  # Minimum second derivative (negative = grokking)\n    final_entropy: float\n    convergence_point: int  # Token position where grokking occurred\n\ndef detect_micro_grokking(\n    entropies: List[float],\n    window_size: int = 5,\n    d2_threshold: float = -0.05\n) -> GrokkingSignal:\n    \"\"\"\n    Detect micro-grokking via entropy second derivative.\n\n    THE KEY INSIGHT: A sharp negative second derivative in entropy indicates\n    the model has \"clicked\" - switching from exploration to exploitation.\n    This is the moment of understanding, the \"aha\" signal.\n\n    Args:\n        entropies: Per-token entropy values\n        window_size: Window for derivative smoothing\n        d2_threshold: Threshold for grokking detection (default -0.05)\n\n    Returns:\n        GrokkingSignal with detection result and score\n    \"\"\"\n    if len(entropies) < window_size * 3:\n        return GrokkingSignal(False, 0.0, 0.0, 1.0, -1)\n\n    arr = [float(e) for e in entropies]\n\n    # Smooth entropies with moving average\n    kernel_size = min(window_size, len(arr) // 3)\n    smooth = []\n    for i in range(len(arr) - kernel_size + 1):\n        smooth.append(sum(arr[i:i+kernel_size]) / kernel_size)\n\n    if len(smooth) < 3:\n        return GrokkingSignal(False, 0.0, 0.0, arr[-1] if arr else 1.0, -1)\n\n    # First derivative (rate of confusion change)\n    d1 = [smooth[i+1] - smooth[i] for i in range(len(smooth)-1)]\n\n    # Second derivative (acceleration of convergence)\n    d2 = [d1[i+1] - d1[i] for i in range(len(d1)-1)] if len(d1) > 1 else [0.0]\n\n    # Find minimum d2 (most negative = sharpest convergence)\n    min_d2 = min(d2) if d2 else 0.0\n    min_d2_idx = d2.index(min_d2) if d2 and min_d2 in d2 else -1\n\n    # Final entropy (last window_size tokens)\n    final_entropy = sum(arr[-window_size:]) / window_size if len(arr) >= window_size else arr[-1]\n\n    # Score: favors low final entropy AND sharp convergence\n    final_stability = 1.0 / (1.0 + final_entropy)\n    convergence_bonus = max(0, -min_d2 * 10)\n    score = final_stability + convergence_bonus\n\n    grokking_detected = min_d2 < d2_threshold\n\n    return GrokkingSignal(\n        detected=grokking_detected,\n        score=score,\n        d2_min=min_d2,\n        final_entropy=final_entropy,\n        convergence_point=min_d2_idx + kernel_size if min_d2_idx >= 0 else -1\n    )\n\n\n# =============================================================================\n# SECTION 3: EXTENDED NCD - The Nobel-Worthy Improvement\n# From final_nobel_synthesis.py\n# =============================================================================\n\ndef int_to_extended_bytes(n: int) -> bytes:\n    \"\"\"\n    Convert integer to extended byte representation for better NCD discrimination.\n\n    Multiple representations concatenated:\n    1. Raw bytes (8 bytes, big-endian)\n    2. Digit string (repeated 3x for weight)\n    3. Binary string\n    4. Residues mod [2,3,5,7,11,13,17,19,23,29] (prime fingerprint)\n    5. Digit histogram\n\n    This is THE BREAKTHROUGH: NCD on short numeric strings doesn't differentiate.\n    Extended representation captures structural similarity.\n    \"\"\"\n    parts = []\n\n    # Raw 8-byte representation\n    try:\n        parts.append(struct.pack('>q', n))\n    except struct.error:\n        parts.append(str(n).encode()[:8].ljust(8, b'\\x00'))\n\n    # Digit string (repeated 3x for weight)\n    digit_str = str(abs(n))\n    parts.append((digit_str * 3).encode())\n\n    # Binary string\n    bin_str = bin(abs(n))[2:]\n    parts.append(bin_str.encode())\n\n    # Prime residue fingerprint - captures number-theoretic structure\n    primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n    residues = ''.join([str(abs(n) % p) for p in primes])\n    parts.append((residues * 2).encode())\n\n    # Digit histogram (frequency of each digit 0-9)\n    hist = [0] * 10\n    for d in digit_str:\n        if d.isdigit():\n            hist[int(d)] += 1\n    parts.append(bytes(hist))\n\n    return b''.join(parts)\n\n\ndef ncd_basic(x: bytes, y: bytes) -> float:\n    \"\"\"Basic NCD - Normalized Compression Distance.\"\"\"\n    if not x or not y:\n        return 1.0\n    cx = len(lzma.compress(x))\n    cy = len(lzma.compress(y))\n    cxy = len(lzma.compress(x + y))\n    return (cxy - min(cx, cy)) / max(cx, cy) if max(cx, cy) > 0 else 0.0\n\n\ndef ncd_extended(x: int, y: int) -> float:\n    \"\"\"Extended NCD using rich integer representation.\"\"\"\n    x_bytes = int_to_extended_bytes(x)\n    y_bytes = int_to_extended_bytes(y)\n    return ncd_basic(x_bytes, y_bytes)\n\n\n# =============================================================================\n# SECTION 4: LATTICEFORGE PHASE DETECTION\n# From LATTICEFORGE_MATHEMATICAL_FOUNDATIONS.md\n# =============================================================================\n\n@dataclass\nclass LatticeForgeState:\n    \"\"\"LatticeForge phase state for answer ensemble.\"\"\"\n    temperature: float      # T - variance-based energy\n    order_parameter: float  # \u03a8 - consensus measure (Fourier harmonics)\n    critical_exponent: float  # \u03bd - distance from phase transition\n    phase: str              # Current phase\n    nucleation_count: int   # Number of nucleation sites\n    confidence: float       # Epistemic confidence bound\n\n# Fibonacci-derived weights for harmonic analysis (from LatticeForge patent)\nFIBONACCI_WEIGHTS = [0.382, 0.236, 0.146, 0.090, 0.056]\n\ndef compute_temperature(samples: List[int]) -> float:\n    \"\"\"\n    System temperature T from LatticeForge.\n    T = (variance / n) \u00d7 (1 + (1 - avg_correlation))\n\n    High variance + low correlation = HIGH temperature (chaotic/PLASMA)\n    Low variance = LOW temperature (stable/CRYSTALLINE)\n    \"\"\"\n    if len(samples) < 2:\n        return 0.0\n\n    mean_val = statistics.mean(samples) if samples else 1\n    if mean_val == 0:\n        mean_val = 1\n\n    # Normalize and compute variance\n    normalized = [s / abs(mean_val) for s in samples]\n    variance = statistics.variance(normalized)\n\n    # For simplicity, estimate correlation from clustering\n    # High agreement = high correlation\n    counter = Counter(samples)\n    max_agreement = counter.most_common(1)[0][1] / len(samples)\n    avg_correlation = max_agreement  # Proxy\n\n    T = variance * (1 + (1 - avg_correlation))\n    return min(1.0, T)\n\n\ndef compute_order_parameter(samples: List[int]) -> float:\n    \"\"\"\n    Order parameter \u03a8 from LatticeForge.\n    Measures system structure via consensus.\n\n    High \u03a8 = crystalline structure (consensus)\n    Low \u03a8 = disordered (no consensus)\n    \"\"\"\n    if not samples:\n        return 0.0\n\n    counter = Counter(samples)\n    most_common_count = counter.most_common(1)[0][1]\n\n    # Basic order from consensus\n    basic_order = most_common_count / len(samples)\n\n    # Bonus for tight clustering (multiple answers within 5%)\n    def rel_dist(a, b):\n        if a == b: return 0.0\n        if a == 0 or b == 0: return 1.0\n        return abs(a - b) / max(abs(a), abs(b))\n\n    n = len(samples)\n    close_pairs = sum(1 for i in range(n) for j in range(i+1, n)\n                      if rel_dist(samples[i], samples[j]) < 0.05)\n    total_pairs = n * (n - 1) // 2 if n > 1 else 1\n    cluster_bonus = close_pairs / total_pairs * 0.3\n\n    return min(1.0, basic_order + cluster_bonus)\n\n\ndef compute_critical_exponent(T: float, psi: float, T_c: float = 0.5) -> float:\n    \"\"\"\n    Critical exponent \u03bd - distance from phase transition.\n    \u03bd \u2192 0 means imminent phase transition (solution crystallizing)\n    \u03bd \u2192 1 means far from transition\n\n    From Landau-Ginzburg theory adapted for algorithm space.\n    \"\"\"\n    return math.sqrt((T - T_c)**2 + (psi - 0.5)**2) / math.sqrt(2)\n\n\ndef detect_nucleation_sites(samples: List[int], threshold: float = 0.05) -> int:\n    \"\"\"\n    Detect nucleation sites - clusters that could trigger cascade.\n    From LatticeForge: regions of high local correlation.\n    \"\"\"\n    if len(samples) < 3:\n        return 0\n\n    # Find tight clusters\n    def rel_dist(a, b):\n        if a == b: return 0.0\n        if a == 0 or b == 0: return 1.0\n        return abs(a - b) / max(abs(a), abs(b))\n\n    visited = [False] * len(samples)\n    nucleation_count = 0\n\n    for i in range(len(samples)):\n        if visited[i]:\n            continue\n\n        # Find cluster around samples[i]\n        cluster = [i]\n        for j in range(i+1, len(samples)):\n            if not visited[j] and rel_dist(samples[i], samples[j]) < threshold:\n                cluster.append(j)\n                visited[j] = True\n\n        # Nucleation site if cluster has 3+ members\n        if len(cluster) >= 3:\n            nucleation_count += 1\n\n        visited[i] = True\n\n    return nucleation_count\n\n\ndef classify_phase(T: float, psi: float, nu: float, nucleation: int) -> str:\n    \"\"\"\n    Classify system phase from LatticeForge.\n\n    CRYSTALLINE: Stable equilibrium, low volatility\n    SUPERCOOLED: Appears stable but susceptible to perturbation\n    NUCLEATING: Rapid regime change in progress\n    PLASMA: High energy chaotic state\n    ANNEALING: Post-transition settling\n    \"\"\"\n    if nu < 0.1 and nucleation > 2:\n        return \"NUCLEATING\"\n    elif T > 0.8 and psi < 0.3:\n        return \"PLASMA\"\n    elif T < 0.3 and psi > 0.7:\n        return \"CRYSTALLINE\"\n    elif T < 0.5 and psi > 0.5 and nucleation > 0:\n        return \"SUPERCOOLED\"\n    else:\n        return \"ANNEALING\"\n\n\ndef compute_latticeforge_state(samples: List[int]) -> LatticeForgeState:\n    \"\"\"Compute full LatticeForge phase state for answer ensemble.\"\"\"\n    T = compute_temperature(samples)\n    psi = compute_order_parameter(samples)\n    nu = compute_critical_exponent(T, psi)\n    nucleation = detect_nucleation_sites(samples)\n    phase = classify_phase(T, psi, nu, nucleation)\n\n    # Confidence from LatticeForge: high order + low temperature + low nu\n    raw_confidence = psi * (1 - T) * (1 - nu)\n    confidence = min(0.95, max(0.05, raw_confidence))\n\n    return LatticeForgeState(\n        temperature=T,\n        order_parameter=psi,\n        critical_exponent=nu,\n        phase=phase,\n        nucleation_count=nucleation,\n        confidence=confidence\n    )\n\n\n# =============================================================================\n# SECTION 5: CIC THEORY - Compression-Integration-Causality\n# The unified functional F[T] = \u03a6 - \u03bbH + \u03b3C\n# =============================================================================\n\ndef representation_entropy(samples: List[int]) -> float:\n    \"\"\"H(T|X) - entropy of representations (compression term).\"\"\"\n    if len(samples) < 2:\n        return 0.0\n    mean_val = statistics.mean(samples) if samples else 1\n    if mean_val == 0:\n        mean_val = 1\n    normalized = [s / abs(mean_val) for s in samples]\n    variance = statistics.variance(normalized)\n    return min(1.0, variance)\n\n\ndef integrated_information_phi(samples: List[int]) -> float:\n    \"\"\"\n    \u03a6 (Phi) - Integrated Information for ensemble answers.\n    High \u03a6 = answers are structurally related (same reasoning path)\n    Low \u03a6 = answers are independent (different reasoning paths)\n\n    Uses extended NCD for better discrimination.\n    \"\"\"\n    if len(samples) < 2:\n        return 0.0\n\n    # Measure mutual compression across all pairs\n    total_mi = 0.0\n    pairs = 0\n    for i in range(len(samples)):\n        for j in range(i+1, len(samples)):\n            # Mutual information approximation via NCD\n            mi = 1.0 - ncd_extended(samples[i], samples[j])\n            total_mi += mi\n            pairs += 1\n\n    return total_mi / pairs if pairs > 0 else 0.0\n\n\ndef causal_power_multiscale(samples: List[int]) -> float:\n    \"\"\"C_multi(T) - multi-scale causal power.\"\"\"\n    if not samples:\n        return 0.0\n    n = len(samples)\n\n    # Scale 1: Exact consensus\n    counter = Counter(samples)\n    exact_power = counter.most_common(1)[0][1] / n\n\n    # Scale 2: Cluster coherence\n    def rel_dist(a, b):\n        if a == b: return 0.0\n        if a == 0 or b == 0: return 1.0\n        return abs(a - b) / max(abs(a), abs(b))\n\n    close_pairs = sum(1 for i in range(n) for j in range(i+1, n)\n                      if rel_dist(samples[i], samples[j]) < 0.05)\n    total_pairs = n * (n - 1) // 2\n    cluster_power = close_pairs / total_pairs if total_pairs > 0 else 0\n\n    # Scale 3: Range constraint\n    spread = max(samples) - min(samples) if samples else 0\n    center = abs(statistics.mean(samples)) if samples else 1\n    range_power = 1.0 / (1.0 + spread / center) if center > 0 else 0\n\n    return 0.5 * exact_power + 0.3 * cluster_power + 0.2 * range_power\n\n\n@dataclass\nclass CICState:\n    \"\"\"Full CIC state with all components.\"\"\"\n    phi: float              # Integrated information\n    entropy: float          # Representation entropy H\n    causal_power: float     # Multi-scale causal power C\n    F: float                # CIC functional value\n    confidence: float       # Derived confidence\n\n\ndef compute_cic(samples: List[int], lambda_c: float = 0.5, gamma_c: float = 0.3) -> CICState:\n    \"\"\"\n    Compute CIC functional: F[T] = \u03a6 - \u03bbH + \u03b3C\n\n    This is THE EQUATION of intelligence under CIC theory.\n    Intelligence emerges at the fixed point where integration + causality balance compression.\n    \"\"\"\n    phi = integrated_information_phi(samples)\n    H = representation_entropy(samples)\n    C = causal_power_multiscale(samples)\n\n    F = phi - lambda_c * H + gamma_c * C\n    confidence = max(0.05, min(0.95, 0.5 + 0.5 * F))\n\n    return CICState(phi=phi, entropy=H, causal_power=C, F=F, confidence=confidence)\n\n\n# =============================================================================\n# SECTION 6: TOROIDAL VOTING - For mod-N answers\n# From prometheus_kaggle.py - S\u00b9 clustering\n# =============================================================================\n\ndef toroidal_distance(a: int, b: int, mod: int) -> float:\n    \"\"\"\n    Distance on circle S\u00b9 for modular arithmetic.\n    Handles wrap-around: 999 is close to 0 under mod 1000.\n    \"\"\"\n    diff = abs(a - b)\n    return min(diff, mod - diff) / (mod / 2)  # Normalized to [0, 1]\n\n\ndef toroidal_clustering(samples: List[int], mod: int, threshold: float = 0.1) -> Dict:\n    \"\"\"\n    Cluster answers on torus S\u00b9 for mod-N problems.\n\n    Key insight: In mod-1000 problems, 999 and 1 are close!\n    Standard Euclidean clustering fails here.\n    \"\"\"\n    if not samples:\n        return {\"clusters\": [], \"best\": None}\n\n    n = len(samples)\n    if n == 1:\n        return {\n            \"clusters\": [{\"members\": samples, \"center\": samples[0] % mod, \"size\": 1}],\n            \"best\": {\"members\": samples, \"center\": samples[0] % mod, \"size\": 1}\n        }\n\n    # Normalize to mod range\n    normalized = [s % mod for s in samples]\n\n    # Union-Find clustering on torus\n    parent = list(range(n))\n    def find(i):\n        if parent[i] != i:\n            parent[i] = find(parent[i])\n        return parent[i]\n    def union(i, j):\n        pi, pj = find(i), find(j)\n        if pi != pj:\n            parent[pi] = pj\n\n    for i in range(n):\n        for j in range(i+1, n):\n            if toroidal_distance(normalized[i], normalized[j], mod) < threshold:\n                union(i, j)\n\n    # Extract clusters\n    clusters_dict = {}\n    for i in range(n):\n        root = find(i)\n        if root not in clusters_dict:\n            clusters_dict[root] = []\n        clusters_dict[root].append(normalized[i])\n\n    clusters = []\n    for members in clusters_dict.values():\n        size = len(members)\n        # Toroidal center: use circular mean\n        angles = [2 * math.pi * m / mod for m in members]\n        sin_sum = sum(math.sin(a) for a in angles)\n        cos_sum = sum(math.cos(a) for a in angles)\n        mean_angle = math.atan2(sin_sum, cos_sum)\n        center = int(round(mean_angle * mod / (2 * math.pi))) % mod\n\n        clusters.append({\"members\": members, \"center\": center, \"size\": size})\n\n    clusters.sort(key=lambda c: -c[\"size\"])\n    return {\"clusters\": clusters, \"best\": clusters[0] if clusters else None}\n\n\n# =============================================================================\n# SECTION 7: ENTROPIC GRAVITY VOTING\n# From prometheus_kaggle.py - Mass \u00d7 Density^0.15 \u00d7 Solomonoff\n# =============================================================================\n\ndef solomonoff_prior(n: int) -> float:\n    \"\"\"\n    Solomonoff prior: simpler numbers more likely correct.\n    Based on Kolmogorov complexity approximation.\n    \"\"\"\n    if n == 0:\n        return 1.0\n\n    # Approximate complexity by description length\n    digit_len = len(str(abs(n)))\n\n    # Bonus for \"nice\" numbers\n    nice_bonus = 1.0\n    if n % 10 == 0:  # Ends in 0\n        nice_bonus *= 1.2\n    if n % 100 == 0:  # Ends in 00\n        nice_bonus *= 1.3\n    if n in [1, 2, 3, 4, 5, 10, 12, 15, 20, 24, 25, 30, 36, 42, 48, 50, 60, 72, 100, 120, 144]:\n        nice_bonus *= 1.5  # Common competition answers\n\n    # Prior inversely proportional to complexity\n    return nice_bonus / (1 + digit_len * 0.3)\n\n\ndef entropic_gravity_vote(\n    samples: List[int],\n    entropies: Optional[List[float]] = None,\n    grokking_scores: Optional[List[float]] = None\n) -> Tuple[int, float, Dict]:\n    \"\"\"\n    Entropic Gravity Voting: Mass \u00d7 Density^0.15 \u00d7 Solomonoff\n\n    Combines:\n    - Mass: Number of votes for answer\n    - Density: Tightness of cluster (from extended NCD)\n    - Solomonoff: Prior probability from simplicity\n    - Grokking: Bonus for answers with micro-grokking signal\n    \"\"\"\n    if not samples:\n        return FALLBACK_ANSWER, 0.05, {}\n\n    counter = Counter(samples)\n    n = len(samples)\n\n    # Compute score for each unique answer\n    answer_scores = {}\n    for ans, count in counter.items():\n        # Mass term\n        mass = count / n\n\n        # Density term: how tight is the cluster around this answer?\n        cluster_members = [s for s in samples if abs(s - ans) < max(1, abs(ans) * 0.05)]\n        density = len(cluster_members) / n\n\n        # Solomonoff prior\n        prior = solomonoff_prior(ans)\n\n        # Grokking bonus\n        grok_bonus = 1.0\n        if grokking_scores:\n            # Find indices of this answer\n            indices = [i for i, s in enumerate(samples) if s == ans]\n            if indices:\n                avg_grok = sum(grokking_scores[i] for i in indices if i < len(grokking_scores)) / len(indices)\n                grok_bonus = 1.0 + avg_grok * 0.5\n\n        # Entropy penalty (lower entropy = higher confidence)\n        entropy_factor = 1.0\n        if entropies:\n            indices = [i for i, s in enumerate(samples) if s == ans]\n            if indices:\n                avg_entropy = sum(entropies[i] for i in indices if i < len(entropies)) / len(indices)\n                entropy_factor = 1.0 / (1.0 + avg_entropy)\n\n        # Final score: Mass \u00d7 Density^0.15 \u00d7 Prior \u00d7 Grokking \u00d7 Entropy\n        score = mass * (density ** 0.15) * prior * grok_bonus * entropy_factor\n        answer_scores[ans] = score\n\n    # Select best answer\n    best_answer = max(answer_scores.keys(), key=lambda a: answer_scores[a])\n    best_score = answer_scores[best_answer]\n\n    # Confidence from score distribution\n    total_score = sum(answer_scores.values())\n    confidence = best_score / total_score if total_score > 0 else 0.1\n    confidence = min(0.95, max(0.05, confidence))\n\n    return best_answer, confidence, {\"scores\": answer_scores, \"method\": \"entropic_gravity\"}\n\n\n# =============================================================================\n# SECTION 8: VALUE CLUSTERING (88% Error Reduction)\n# =============================================================================\n\ndef relative_distance(a: int, b: int) -> float:\n    \"\"\"Relative distance between two integers.\"\"\"\n    if a == b: return 0.0\n    if a == 0 or b == 0:\n        return 1.0 if max(abs(a), abs(b)) > 1000 else abs(a-b) / 1000\n    return abs(a - b) / max(abs(a), abs(b))\n\n\ndef value_clustering(samples: List[int], threshold: float = 0.05) -> Dict:\n    \"\"\"Cluster by value proximity - the 88% error reduction method.\"\"\"\n    n = len(samples)\n    if n == 0:\n        return {\"clusters\": [], \"best\": None}\n    if n == 1:\n        return {\n            \"clusters\": [{\"members\": samples, \"center\": samples[0], \"size\": 1, \"tightness\": 1.0, \"score\": 1.0}],\n            \"best\": {\"members\": samples, \"center\": samples[0], \"size\": 1, \"tightness\": 1.0, \"score\": 1.0}\n        }\n\n    # Union-Find clustering\n    parent = list(range(n))\n    def find(i):\n        if parent[i] != i:\n            parent[i] = find(parent[i])\n        return parent[i]\n    def union(i, j):\n        pi, pj = find(i), find(j)\n        if pi != pj:\n            parent[pi] = pj\n\n    for i in range(n):\n        for j in range(i+1, n):\n            if relative_distance(samples[i], samples[j]) < threshold:\n                union(i, j)\n\n    clusters_dict = {}\n    for i in range(n):\n        root = find(i)\n        if root not in clusters_dict:\n            clusters_dict[root] = []\n        clusters_dict[root].append(samples[i])\n\n    clusters = []\n    for members in clusters_dict.values():\n        size = len(members)\n        center = int(statistics.median(members))\n        spread = statistics.stdev(members) if size > 1 else 0\n        center_abs = abs(statistics.mean(members)) if members else 1\n        tightness = max(0.0, min(1.0, 1.0 - (spread / center_abs if center_abs > 0 else 0)))\n        score = size * (tightness ** 0.5)\n        clusters.append({\"members\": members, \"center\": center, \"size\": size, \"tightness\": tightness, \"score\": score})\n\n    clusters.sort(key=lambda c: -c[\"score\"])\n    return {\"clusters\": clusters, \"best\": clusters[0] if clusters else None}\n\n\ndef extended_ncd_basin_detection(samples: List[int], threshold: float = 0.25) -> Dict:\n    \"\"\"\n    Basin detection using extended NCD representation.\n    From final_nobel_synthesis.py - uses prime fingerprint for better discrimination.\n    \"\"\"\n    n = len(samples)\n    if n == 0:\n        return {\"found\": False, \"clusters\": []}\n    if n == 1:\n        return {\"found\": True, \"clusters\": [{\"members\": samples, \"center\": samples[0]}], \"best\": samples[0]}\n\n    # Build extended NCD matrix\n    ncd_matrix = [[0.0] * n for _ in range(n)]\n    for i in range(n):\n        for j in range(i+1, n):\n            d = ncd_extended(samples[i], samples[j])\n            ncd_matrix[i][j] = d\n            ncd_matrix[j][i] = d\n\n    # Simple clustering: group if NCD < threshold\n    parent = list(range(n))\n    def find(i):\n        if parent[i] != i:\n            parent[i] = find(parent[i])\n        return parent[i]\n    def union(i, j):\n        pi, pj = find(i), find(j)\n        if pi != pj:\n            parent[pi] = pj\n\n    for i in range(n):\n        for j in range(i+1, n):\n            if ncd_matrix[i][j] < threshold:\n                union(i, j)\n\n    # Extract clusters\n    clusters_dict = {}\n    for i in range(n):\n        root = find(i)\n        if root not in clusters_dict:\n            clusters_dict[root] = []\n        clusters_dict[root].append(samples[i])\n\n    clusters = []\n    for members in clusters_dict.values():\n        # Internal cohesion\n        if len(members) > 1:\n            indices = [samples.index(m) for m in members]\n            internal_ncds = [ncd_matrix[i][j] for i in indices for j in indices if i < j]\n            cohesion = 1.0 - statistics.mean(internal_ncds) if internal_ncds else 0.5\n        else:\n            cohesion = 0.5\n\n        clusters.append({\n            \"members\": members,\n            \"size\": len(members),\n            \"center\": int(statistics.median(members)),\n            \"cohesion\": cohesion,\n            \"score\": len(members) * cohesion\n        })\n\n    clusters.sort(key=lambda c: -c[\"score\"])\n    best = clusters[0][\"center\"] if clusters else samples[0]\n\n    return {\"found\": True, \"clusters\": clusters, \"best\": best}\n\n\n# =============================================================================\n# SECTION 9: THE GRAND SYNTHESIS - UNIFIED ANSWER SELECTION\n# =============================================================================\n\n@dataclass\nclass GrandSynthesisResult:\n    \"\"\"Complete result from grand synthesis answer selection.\"\"\"\n    answer: int\n    confidence: float\n    method: str\n    cic_state: CICState\n    lattice_state: LatticeForgeState\n    grokking: Optional[GrokkingSignal]\n    value_clusters: Dict\n    ncd_basins: Dict\n    toroidal_result: Optional[Dict]\n    debug: Dict\n\n\ndef grand_synthesis_select(\n    samples: List[int],\n    entropies: Optional[List[float]] = None,\n    problem_text: str = \"\",\n    mod_hint: Optional[int] = None\n) -> GrandSynthesisResult:\n    \"\"\"\n    THE GRAND SYNTHESIS: Unified answer selection combining ALL methods.\n\n    Pipeline:\n    1. Value-based clustering (88% error reduction)\n    2. Extended NCD basin detection (prime fingerprint)\n    3. LatticeForge phase analysis (T, \u03a8, \u03bd)\n    4. CIC functional computation\n    5. Micro-grokking detection (if entropies provided)\n    6. Toroidal voting (if mod problem detected)\n    7. Entropic gravity voting\n    8. Final weighted selection\n    \"\"\"\n    if not samples:\n        return GrandSynthesisResult(\n            answer=FALLBACK_ANSWER, confidence=0.05, method=\"fallback\",\n            cic_state=CICState(0,0,0,0,0.05), lattice_state=LatticeForgeState(0,0,0,\"UNKNOWN\",0,0.05),\n            grokking=None, value_clusters={}, ncd_basins={}, toroidal_result=None, debug={}\n        )\n\n    # 1. Value clustering\n    value_result = value_clustering(samples, threshold=0.05)\n\n    # 2. Extended NCD basin detection\n    ncd_result = extended_ncd_basin_detection(samples, threshold=0.25)\n\n    # 3. LatticeForge phase analysis\n    lattice_state = compute_latticeforge_state(samples)\n\n    # 4. CIC functional\n    cic_state = compute_cic(samples)\n\n    # 5. Micro-grokking detection\n    grokking = None\n    grokking_scores = None\n    if entropies and len(entropies) >= 10:\n        grokking = detect_micro_grokking(entropies)\n        if grokking.detected:\n            # Create grokking scores for each sample (simplified)\n            grokking_scores = [grokking.score] * len(samples)\n\n    # 6. Toroidal voting (detect mod problems)\n    toroidal_result = None\n    detected_mod = mod_hint\n    if not detected_mod:\n        # Try to detect mod from problem text\n        mod_match = re.search(r'modulo?\\s*(\\d+)', problem_text, re.IGNORECASE)\n        if mod_match:\n            detected_mod = int(mod_match.group(1))\n\n    if detected_mod and detected_mod > 1:\n        toroidal_result = toroidal_clustering(samples, detected_mod, threshold=0.1)\n\n    # 7. Entropic gravity voting\n    gravity_answer, gravity_conf, gravity_debug = entropic_gravity_vote(\n        samples, entropies, grokking_scores\n    )\n\n    # 8. FINAL WEIGHTED SELECTION\n    candidates = {}\n\n    # Value cluster candidate\n    if value_result[\"best\"]:\n        vc = value_result[\"best\"]\n        vc_answer = vc[\"center\"]\n        vc_weight = vc[\"size\"] / len(samples) * vc[\"tightness\"] * 1.5  # Boost value clustering\n        candidates[vc_answer] = candidates.get(vc_answer, 0) + vc_weight\n\n    # NCD basin candidate\n    if ncd_result.get(\"best\"):\n        ncd_answer = ncd_result[\"best\"]\n        ncd_weight = 0.8  # Good but not as reliable as value clustering\n        candidates[ncd_answer] = candidates.get(ncd_answer, 0) + ncd_weight\n\n    # LatticeForge influence\n    if lattice_state.phase == \"CRYSTALLINE\":\n        # High confidence in consensus\n        counter = Counter(samples)\n        lf_answer = counter.most_common(1)[0][0]\n        lf_weight = lattice_state.confidence * 1.2\n        candidates[lf_answer] = candidates.get(lf_answer, 0) + lf_weight\n\n    # CIC influence\n    if cic_state.F > 0.3:\n        # Good CIC score - trust the consensus\n        counter = Counter(samples)\n        cic_answer = counter.most_common(1)[0][0]\n        cic_weight = cic_state.confidence\n        candidates[cic_answer] = candidates.get(cic_answer, 0) + cic_weight\n\n    # Toroidal candidate (for mod problems)\n    if toroidal_result and toroidal_result.get(\"best\"):\n        tor_answer = toroidal_result[\"best\"][\"center\"]\n        tor_weight = 0.7 if detected_mod else 0.3\n        candidates[tor_answer] = candidates.get(tor_answer, 0) + tor_weight\n\n    # Entropic gravity candidate\n    candidates[gravity_answer] = candidates.get(gravity_answer, 0) + gravity_conf\n\n    # Grokking bonus\n    if grokking and grokking.detected:\n        # Boost answers that had grokking signal\n        counter = Counter(samples)\n        grok_answer = counter.most_common(1)[0][0]\n        grok_weight = grokking.score * 0.5\n        candidates[grok_answer] = candidates.get(grok_answer, 0) + grok_weight\n\n    # Select best candidate\n    if candidates:\n        final_answer = max(candidates.keys(), key=lambda a: candidates[a])\n        total_weight = sum(candidates.values())\n        final_confidence = candidates[final_answer] / total_weight if total_weight > 0 else 0.1\n    else:\n        final_answer = Counter(samples).most_common(1)[0][0]\n        final_confidence = 0.3\n\n    # Determine method used\n    if candidates:\n        method_weights = {\n            \"value_cluster\": candidates.get(value_result[\"best\"][\"center\"], 0) if value_result[\"best\"] else 0,\n            \"ncd_basin\": candidates.get(ncd_result.get(\"best\", -1), 0),\n            \"latticeforge\": candidates.get(Counter(samples).most_common(1)[0][0], 0) if lattice_state.phase == \"CRYSTALLINE\" else 0,\n            \"entropic_gravity\": candidates.get(gravity_answer, 0),\n        }\n        primary_method = max(method_weights.keys(), key=lambda m: method_weights[m])\n    else:\n        primary_method = \"majority\"\n\n    # Bound confidence\n    final_confidence = min(0.95, max(0.05, final_confidence))\n\n    return GrandSynthesisResult(\n        answer=final_answer,\n        confidence=final_confidence,\n        method=primary_method,\n        cic_state=cic_state,\n        lattice_state=lattice_state,\n        grokking=grokking,\n        value_clusters=value_result,\n        ncd_basins=ncd_result,\n        toroidal_result=toroidal_result,\n        debug={\"candidates\": candidates, \"gravity_debug\": gravity_debug}\n    )\n\n\n# =============================================================================\n# SECTION 10: CONVENIENCE FUNCTION\n# =============================================================================\n\ndef select_answer(samples: List[int], threshold: float = 0.05, fallback: int = 0) -> Tuple[int, float, Dict]:\n    \"\"\"\n    Main answer selection function - uses grand synthesis.\n\n    Returns: (answer, confidence, debug_info)\n    \"\"\"\n    result = grand_synthesis_select(samples, problem_text=\"\")\n    return result.answer, result.confidence, {\n        \"method\": result.method,\n        \"phase\": result.lattice_state.phase,\n        \"cic_F\": result.cic_state.F,\n        \"grokking\": result.grokking.detected if result.grokking else False\n    }\n\n\n# =============================================================================\n# SECTION 11: MATH-SPECIFIC HEURISTICS (Kept from original)\n# =============================================================================\n\nFIBONACCI = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, 4181, 6765, 10946, 17711, 28657, 46368, 75025]\nCATALAN = [1, 1, 2, 5, 14, 42, 132, 429, 1430, 4862, 16796, 58786]\nFACTORIALS = [1, 1, 2, 6, 24, 120, 720, 5040, 40320]\nPOWERS_OF_2 = [2**i for i in range(17)]\nPOWERS_OF_10 = [10**i for i in range(6)]\nTRIANGULAR = [n*(n+1)//2 for n in range(200)]\nPERFECT_SQUARES = [n*n for n in range(317)]\nPRIMES_100 = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97]\n\ndef is_math_special_number(n: int) -> Tuple[bool, str]:\n    \"\"\"Check if number is 'special' in competition math.\"\"\"\n    if n in FIBONACCI: return True, \"fibonacci\"\n    if n in CATALAN: return True, \"catalan\"\n    if n in FACTORIALS: return True, \"factorial\"\n    if n in POWERS_OF_2: return True, \"power_of_2\"\n    if n in POWERS_OF_10: return True, \"power_of_10\"\n    if n in TRIANGULAR: return True, \"triangular\"\n    if n in PERFECT_SQUARES: return True, \"perfect_square\"\n    if n in PRIMES_100: return True, \"small_prime\"\n    for p in PRIMES_100:\n        if p * p > n: break\n        if n % p == 0 and n // p in PRIMES_100:\n            return True, \"semiprime\"\n    return False, \"\"\n\n\n# =============================================================================\n# SECTION 12: TIME BUDGET MANAGEMENT (Kept from original)\n# =============================================================================\n\n@dataclass\nclass TimeBudgetManager:\n    \"\"\"Sophisticated time budget management.\"\"\"\n    total_budget: float\n    num_problems: int\n    start_time: float = field(default_factory=time.time)\n    problem_times: Dict[str, float] = field(default_factory=dict)\n    problem_difficulties: Dict[str, float] = field(default_factory=dict)\n\n    def __post_init__(self):\n        self.base_time_per_problem = self.total_budget / self.num_problems\n        self.time_bank = 0.0\n        self.problems_solved = 0\n\n    def elapsed(self) -> float:\n        return time.time() - self.start_time\n\n    def remaining(self) -> float:\n        return max(0, self.total_budget - self.elapsed())\n\n    def get_budget_for_problem(self, difficulty: float, problem_idx: int) -> float:\n        remaining = self.remaining()\n        remaining_problems = max(1, self.num_problems - self.problems_solved)\n        base_budget = remaining / remaining_problems\n        difficulty_multiplier = 0.6 + 0.8 * difficulty\n        bank_contribution = 0\n        if difficulty > 0.6 and self.time_bank > 0:\n            bank_contribution = min(self.time_bank * 0.3, base_budget * 0.5)\n        budget = base_budget * difficulty_multiplier + bank_contribution\n        return max(60, min(600, budget))\n\n    def record_problem(self, problem_id: str, difficulty: float, actual_time: float):\n        self.problem_times[problem_id] = actual_time\n        self.problem_difficulties[problem_id] = difficulty\n        self.problems_solved += 1\n        expected_time = self.base_time_per_problem * (0.6 + 0.8 * difficulty)\n        time_saved = expected_time - actual_time\n        if time_saved > 0:\n            self.time_bank += time_saved * 0.5\n        elif time_saved < 0:\n            self.time_bank = max(0, self.time_bank + time_saved)\n\n\n# =============================================================================\n# INITIALIZATION MESSAGE\n# =============================================================================\n\nprint(\"=\" * 70)\nprint(\"GRAND SYNTHESIS LOADED - THE COMPLETE RYANAIMO WEAPON SYSTEM\")\nprint(\"=\" * 70)\nprint(\"Components:\")\nprint(\"  \u2713 UIPT Entropy Window (Phase transition detection)\")\nprint(\"  \u2713 Micro-Grokking Detection (Entropy 2nd derivative)\")\nprint(\"  \u2713 Extended NCD (Prime residue fingerprint)\")\nprint(\"  \u2713 LatticeForge Phase Analysis (T, \u03a8, \u03bd)\")\nprint(\"  \u2713 CIC Functional (\u03a6 - \u03bbH + \u03b3C)\")\nprint(\"  \u2713 Toroidal Voting (S\u00b9 clustering for mod-N)\")\nprint(\"  \u2713 Entropic Gravity (Mass \u00d7 Density \u00d7 Solomonoff)\")\nprint(\"  \u2713 Value Clustering (88% error reduction)\")\nprint(\"=\" * 70)\n"
  },
  {
   "cell_type": "code",
   "id": "qsjr3l1891g",
   "source": "# CELL 3B: Historical Calibration + Dynamic Time Optimization\n# Uses AIMO 2023/2024 data to predict this year's distribution\n\n# =============================================================================\n# HISTORICAL AIMO DATA (Empirical from AIMO1 & AIMO2)\n# =============================================================================\n\n# AIMO1 (2023) - 50 problems, 4hr limit\n# Source: Competition retrospectives and public discussions\nAIMO1_STATS = {\n    \"year\": 2023,\n    \"num_problems\": 50,\n    \"time_limit_hours\": 4,\n    \"difficulty_distribution\": {\n        \"easy\": 0.30,    # ~15 problems - solvable in <2 min avg\n        \"medium\": 0.45,  # ~22 problems - 3-5 min avg\n        \"hard\": 0.25,    # ~13 problems - 5+ min or unsolvable\n    },\n    \"winning_score\": 29,  # Top score was 29/50 (58%)\n    \"median_score\": 12,   # Rough estimate\n    \"problem_types\": {\n        \"counting\": 0.22,\n        \"number_theory\": 0.20,\n        \"algebra\": 0.18,\n        \"geometry\": 0.15,\n        \"modular\": 0.12,\n        \"sequence\": 0.08,\n        \"probability\": 0.05,\n    },\n    \"avg_time_by_difficulty\": {\n        \"easy\": 90,      # 1.5 minutes\n        \"medium\": 210,   # 3.5 minutes\n        \"hard\": 420,     # 7 minutes (or timeout)\n    }\n}\n\n# AIMO2 (2024) - 50 problems, 5hr limit\nAIMO2_STATS = {\n    \"year\": 2024,\n    \"num_problems\": 50,\n    \"time_limit_hours\": 5,\n    \"difficulty_distribution\": {\n        \"easy\": 0.28,    # Slightly harder than AIMO1\n        \"medium\": 0.44,\n        \"hard\": 0.28,\n    },\n    \"winning_score\": 38,  # Top score was 38/50 (76%)\n    \"median_score\": 18,\n    \"problem_types\": {\n        \"counting\": 0.24,\n        \"number_theory\": 0.22,\n        \"modular\": 0.16,\n        \"algebra\": 0.14,\n        \"geometry\": 0.10,\n        \"sequence\": 0.08,\n        \"probability\": 0.06,\n    },\n    \"avg_time_by_difficulty\": {\n        \"easy\": 100,     # Slightly longer than AIMO1\n        \"medium\": 240,\n        \"hard\": 480,\n    }\n}\n\n# AIMO3 (2025) - Our predictions based on trends\nAIMO3_PREDICTED = {\n    \"year\": 2025,\n    \"num_problems\": 50,\n    \"time_limit_hours\": 5,\n    \"difficulty_distribution\": {\n        \"easy\": 0.26,    # Trend: getting harder each year\n        \"medium\": 0.46,\n        \"hard\": 0.28,\n    },\n    \"target_score\": 47,  # What we need to win\n    \"problem_types\": {\n        \"counting\": 0.25,\n        \"number_theory\": 0.22,\n        \"modular\": 0.18,\n        \"algebra\": 0.12,\n        \"geometry\": 0.08,\n        \"sequence\": 0.08,\n        \"probability\": 0.07,\n    },\n    \"avg_time_by_difficulty\": {\n        \"easy\": 110,     # Budget: slightly more than AIMO2\n        \"medium\": 270,\n        \"hard\": 500,\n    }\n}\n\n# =============================================================================\n# BAYESIAN DIFFICULTY CALIBRATOR\n# Updates predictions based on observed performance\n# =============================================================================\n\nclass DifficultyCalibrator:\n    \"\"\"Bayesian calibrator that updates difficulty estimates based on observed performance.\"\"\"\n    \n    def __init__(self, prior_stats: Dict = AIMO3_PREDICTED):\n        self.prior = prior_stats\n        self.observed_difficulties = []  # (problem_id, estimated_difficulty, actual_time, got_correct)\n        self.difficulty_bins = {\"easy\": [], \"medium\": [], \"hard\": []}\n        \n        # Prior beliefs (will be updated)\n        self.expected_distribution = prior_stats[\"difficulty_distribution\"].copy()\n        self.expected_times = prior_stats[\"avg_time_by_difficulty\"].copy()\n        \n        # Calibration state\n        self.calibration_factor = 1.0  # >1 = problems harder than expected\n        self.time_factor = 1.0  # >1 = taking longer than expected\n    \n    def observe(self, problem_id: str, estimated_difficulty: float, actual_time: float, \n                got_correct: bool, confidence: float):\n        \"\"\"Record an observation and update beliefs.\"\"\"\n        \n        # Bin the difficulty\n        if estimated_difficulty < 0.4:\n            diff_bin = \"easy\"\n        elif estimated_difficulty < 0.7:\n            diff_bin = \"medium\"\n        else:\n            diff_bin = \"hard\"\n        \n        self.difficulty_bins[diff_bin].append({\n            \"id\": problem_id,\n            \"est_diff\": estimated_difficulty,\n            \"time\": actual_time,\n            \"correct\": got_correct,\n            \"confidence\": confidence\n        })\n        \n        self.observed_difficulties.append((problem_id, estimated_difficulty, actual_time, got_correct))\n        \n        # Update calibration factors\n        self._update_calibration()\n    \n    def _update_calibration(self):\n        \"\"\"Bayesian update of calibration factors.\"\"\"\n        if len(self.observed_difficulties) < 3:\n            return  # Need enough data\n        \n        # Calculate observed vs expected times\n        total_expected_time = 0\n        total_actual_time = 0\n        \n        for pid, est_diff, actual_time, correct in self.observed_difficulties:\n            if est_diff < 0.4:\n                expected = self.expected_times[\"easy\"]\n            elif est_diff < 0.7:\n                expected = self.expected_times[\"medium\"]\n            else:\n                expected = self.expected_times[\"hard\"]\n            \n            total_expected_time += expected\n            total_actual_time += actual_time\n        \n        if total_expected_time > 0:\n            # Smooth update (don't overreact to small samples)\n            new_time_factor = total_actual_time / total_expected_time\n            alpha = min(0.5, len(self.observed_difficulties) / 20)  # Blend rate\n            self.time_factor = (1 - alpha) * self.time_factor + alpha * new_time_factor\n        \n        # Calculate difficulty calibration from success rate\n        correct_count = sum(1 for _, _, _, c in self.observed_difficulties if c)\n        success_rate = correct_count / len(self.observed_difficulties)\n        \n        # Expected success rate based on our target (47/50 = 94%)\n        target_success = 0.94\n        \n        # If we're succeeding less than expected, problems are harder\n        if success_rate > 0:\n            new_diff_factor = target_success / success_rate\n            alpha = min(0.3, len(self.observed_difficulties) / 30)\n            self.calibration_factor = (1 - alpha) * self.calibration_factor + alpha * new_diff_factor\n        \n        # Clamp to reasonable bounds\n        self.time_factor = max(0.5, min(2.0, self.time_factor))\n        self.calibration_factor = max(0.7, min(1.5, self.calibration_factor))\n    \n    def get_adjusted_difficulty(self, raw_difficulty: float) -> float:\n        \"\"\"Get calibrated difficulty estimate.\"\"\"\n        adjusted = raw_difficulty * self.calibration_factor\n        return max(0.0, min(1.0, adjusted))\n    \n    def get_adjusted_time_budget(self, raw_budget: float, difficulty: float) -> float:\n        \"\"\"Get calibrated time budget.\"\"\"\n        adjusted = raw_budget * self.time_factor\n        \n        # Extra buffer for hard problems if we're running behind\n        if difficulty > 0.7 and self.time_factor > 1.2:\n            adjusted *= 1.1\n        \n        return adjusted\n    \n    def get_status(self) -> str:\n        \"\"\"Get calibration status string.\"\"\"\n        n = len(self.observed_difficulties)\n        if n == 0:\n            return \"No data yet\"\n        \n        correct = sum(1 for _, _, _, c in self.observed_difficulties if c)\n        return f\"n={n} | acc={100*correct/n:.0f}% | time_factor={self.time_factor:.2f} | diff_factor={self.calibration_factor:.2f}\"\n\n# =============================================================================\n# DYNAMIC TIME OPTIMIZER\n# Aims to finish in 4-4.5 hours (optimal range)\n# =============================================================================\n\nclass DynamicTimeOptimizer:\n    \"\"\"\n    Optimizes time usage to hit the 4-4.5 hour sweet spot.\n    \n    Why 4-4.5 hours?\n    - Finishing too early (< 4hr): Wasted potential, could have done more verification\n    - Finishing too late (> 4.5hr): Risk running out of time, rushing final problems\n    - Sweet spot: Full use of time without panic\n    \"\"\"\n    \n    def __init__(self, total_budget: float = 5 * 3600, num_problems: int = 50,\n                 target_finish_low: float = 4 * 3600, target_finish_high: float = 4.5 * 3600):\n        self.total_budget = total_budget\n        self.num_problems = num_problems\n        self.target_low = target_finish_low\n        self.target_high = target_finish_high\n        self.target_mid = (target_finish_low + target_finish_high) / 2\n        \n        self.start_time = time.time()\n        self.problem_history = []  # (problem_idx, time_spent, difficulty, got_answer)\n        \n        # Pace tracking\n        self.expected_pace = self.target_mid / num_problems  # seconds per problem\n        self.current_pace = self.expected_pace\n        \n        # Reserve time for second pass\n        self.review_reserve = 300  # 5 minutes reserved for review\n    \n    def elapsed(self) -> float:\n        return time.time() - self.start_time\n    \n    def remaining(self) -> float:\n        return max(0, self.total_budget - self.elapsed())\n    \n    def problems_remaining(self) -> int:\n        return max(0, self.num_problems - len(self.problem_history))\n    \n    def record_problem(self, time_spent: float, difficulty: float, got_answer: bool):\n        \"\"\"Record problem completion.\"\"\"\n        self.problem_history.append((len(self.problem_history), time_spent, difficulty, got_answer))\n        self._update_pace()\n    \n    def _update_pace(self):\n        \"\"\"Update pace estimate based on history.\"\"\"\n        if not self.problem_history:\n            return\n        \n        total_time = sum(t for _, t, _, _ in self.problem_history)\n        n_done = len(self.problem_history)\n        n_remaining = self.problems_remaining()\n        \n        if n_remaining == 0:\n            return\n        \n        # Current pace\n        self.current_pace = total_time / n_done\n        \n        # Projected finish time\n        projected_finish = total_time + (n_remaining * self.current_pace)\n        \n        # How far off are we from target?\n        self.pace_delta = projected_finish - self.target_mid\n    \n    def get_time_budget(self, difficulty: float) -> float:\n        \"\"\"Get time budget for next problem.\"\"\"\n        n_remaining = self.problems_remaining()\n        if n_remaining == 0:\n            return 60  # Minimum\n        \n        # Base budget from remaining time\n        usable_time = self.remaining() - self.review_reserve\n        base_budget = usable_time / n_remaining\n        \n        # Adjust for difficulty\n        difficulty_mult = 0.6 + 0.8 * difficulty\n        budget = base_budget * difficulty_mult\n        \n        # Pace adjustment\n        if hasattr(self, 'pace_delta'):\n            if self.pace_delta > 600:  # More than 10 min ahead of target\n                # Slow down slightly - spend more time on verification\n                budget *= 1.1\n            elif self.pace_delta < -600:  # More than 10 min behind\n                # Speed up - be more aggressive with early stopping\n                budget *= 0.9\n        \n        # Hard limits\n        return max(60, min(600, budget))\n    \n    def get_early_stop_threshold(self) -> float:\n        \"\"\"Get confidence threshold for early stopping.\"\"\"\n        n_remaining = self.problems_remaining()\n        \n        # Early in the test: be thorough\n        if n_remaining > 40:\n            return 0.85\n        \n        # Middle of test: standard\n        if n_remaining > 20:\n            return 0.75\n        \n        # Late in test: more aggressive\n        if n_remaining > 10:\n            return 0.65\n        \n        # Very late: accept lower confidence\n        return 0.55\n    \n    def should_do_verification(self, confidence: float, time_in_budget: float) -> bool:\n        \"\"\"Decide if we should run verification pass.\"\"\"\n        # Always verify if plenty of time\n        if time_in_budget < 0.5:\n            return True\n        \n        # Skip verification if behind schedule and confident\n        if hasattr(self, 'pace_delta') and self.pace_delta < -300:\n            if confidence > 0.7:\n                return False\n        \n        # Generally verify if not confident\n        return confidence < 0.8\n    \n    def should_do_second_pass(self) -> bool:\n        \"\"\"Decide if we should do a second pass review.\"\"\"\n        remaining = self.remaining()\n        \n        # Must have enough time\n        if remaining < 180:  # Less than 3 minutes\n            return False\n        \n        # Check if we have low-confidence answers worth reviewing\n        low_conf = sum(1 for _, _, _, got in self.problem_history if not got)\n        \n        return low_conf > 0 and remaining > 120 * low_conf\n    \n    def get_pace_status(self) -> str:\n        \"\"\"Get human-readable pace status.\"\"\"\n        elapsed = self.elapsed()\n        n_done = len(self.problem_history)\n        n_remaining = self.problems_remaining()\n        \n        if n_done == 0:\n            return \"Starting...\"\n        \n        current_pace_min = self.current_pace / 60\n        projected_finish = elapsed + (n_remaining * self.current_pace)\n        projected_finish_hr = projected_finish / 3600\n        \n        target_hr = self.target_mid / 3600\n        delta_min = (projected_finish - self.target_mid) / 60\n        \n        if abs(delta_min) < 5:\n            status = \"ON TARGET\"\n        elif delta_min > 0:\n            status = f\"+{delta_min:.0f}min (slow down)\"\n        else:\n            status = f\"{delta_min:.0f}min (speed up)\"\n        \n        return f\"Pace: {current_pace_min:.1f}m/prob | ETA: {projected_finish_hr:.1f}hr | {status}\"\n\n# =============================================================================\n# INTEGRATED CALIBRATED SOLVER CONFIG\n# =============================================================================\n\nclass CalibratedSolverConfig:\n    \"\"\"Combines historical calibration with dynamic optimization.\"\"\"\n    \n    def __init__(self, prior_stats: Dict = AIMO3_PREDICTED):\n        self.calibrator = DifficultyCalibrator(prior_stats)\n        self.optimizer = DynamicTimeOptimizer(\n            total_budget=prior_stats[\"time_limit_hours\"] * 3600,\n            num_problems=prior_stats[\"num_problems\"],\n            target_finish_low=4 * 3600,\n            target_finish_high=4.5 * 3600\n        )\n        self.prior = prior_stats\n    \n    def get_problem_budget(self, estimated_difficulty: float) -> float:\n        \"\"\"Get fully calibrated time budget for a problem.\"\"\"\n        # Start with optimizer's budget\n        base_budget = self.optimizer.get_time_budget(estimated_difficulty)\n        \n        # Apply calibrator's time factor\n        adjusted_difficulty = self.calibrator.get_adjusted_difficulty(estimated_difficulty)\n        calibrated_budget = self.calibrator.get_adjusted_time_budget(base_budget, adjusted_difficulty)\n        \n        return calibrated_budget\n    \n    def record_result(self, problem_id: str, estimated_difficulty: float, \n                      actual_time: float, got_correct: bool, confidence: float):\n        \"\"\"Record result for calibration.\"\"\"\n        self.calibrator.observe(problem_id, estimated_difficulty, actual_time, got_correct, confidence)\n        self.optimizer.record_problem(actual_time, estimated_difficulty, got_correct)\n    \n    def get_status(self) -> str:\n        \"\"\"Get combined status.\"\"\"\n        cal = self.calibrator.get_status()\n        pace = self.optimizer.get_pace_status()\n        return f\"Cal: {cal}\\nPace: {pace}\"\n\nprint(\"Historical Calibration + Dynamic Optimization: OK\")\nprint(f\"  Prior: AIMO1 winner {AIMO1_STATS['winning_score']}/50, AIMO2 winner {AIMO2_STATS['winning_score']}/50\")\nprint(f\"  Target: {AIMO3_PREDICTED['target_score']}/50 in 4-4.5 hours\")\nprint(f\"  Distribution: Easy {AIMO3_PREDICTED['difficulty_distribution']['easy']*100:.0f}% | Med {AIMO3_PREDICTED['difficulty_distribution']['medium']*100:.0f}% | Hard {AIMO3_PREDICTED['difficulty_distribution']['hard']*100:.0f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "gp1p66kusvn",
   "source": "# CELL 3C: Competition Clock & Timer Display System\n\n# =============================================================================\n# VISUAL TIMER DISPLAY\n# Comprehensive timing information during the competition\n# =============================================================================\n\nclass CompetitionClock:\n    \"\"\"\n    Visual timer/clock for competition monitoring.\n    Shows elapsed, remaining, pace, and projections.\n    \"\"\"\n    \n    def __init__(self, total_budget: float = 5 * 3600, num_problems: int = 50):\n        self.total_budget = total_budget\n        self.num_problems = num_problems\n        self.start_time = None\n        self.problem_times = []  # (problem_id, start_time, end_time, duration)\n        self.current_problem = None\n        self.current_problem_start = None\n        \n        # Milestones\n        self.milestones = {\n            \"quarter\": (0.25, False),\n            \"half\": (0.50, False),\n            \"three_quarter\": (0.75, False),\n            \"final_stretch\": (0.90, False),\n        }\n        \n        # Alerts\n        self.alerts = []\n    \n    def start(self):\n        \"\"\"Start the competition clock.\"\"\"\n        self.start_time = time.time()\n        return self._format_time_display(\"COMPETITION STARTED\")\n    \n    def start_problem(self, problem_id: str):\n        \"\"\"Mark the start of a problem.\"\"\"\n        self.current_problem = problem_id\n        self.current_problem_start = time.time()\n    \n    def end_problem(self, problem_id: str):\n        \"\"\"Mark the end of a problem.\"\"\"\n        if self.current_problem_start:\n            duration = time.time() - self.current_problem_start\n            self.problem_times.append((problem_id, self.current_problem_start, time.time(), duration))\n            self.current_problem = None\n            self.current_problem_start = None\n            return duration\n        return 0\n    \n    def elapsed(self) -> float:\n        \"\"\"Get elapsed time in seconds.\"\"\"\n        if not self.start_time:\n            return 0\n        return time.time() - self.start_time\n    \n    def remaining(self) -> float:\n        \"\"\"Get remaining time in seconds.\"\"\"\n        return max(0, self.total_budget - self.elapsed())\n    \n    def elapsed_on_current(self) -> float:\n        \"\"\"Get time spent on current problem.\"\"\"\n        if not self.current_problem_start:\n            return 0\n        return time.time() - self.current_problem_start\n    \n    def problems_done(self) -> int:\n        \"\"\"Get number of completed problems.\"\"\"\n        return len(self.problem_times)\n    \n    def _format_time(self, seconds: float) -> str:\n        \"\"\"Format seconds as H:MM:SS.\"\"\"\n        h = int(seconds // 3600)\n        m = int((seconds % 3600) // 60)\n        s = int(seconds % 60)\n        return f\"{h}:{m:02d}:{s:02d}\"\n    \n    def _format_time_short(self, seconds: float) -> str:\n        \"\"\"Format seconds as Xh Ym or Ym Zs.\"\"\"\n        if seconds >= 3600:\n            h = int(seconds // 3600)\n            m = int((seconds % 3600) // 60)\n            return f\"{h}h {m}m\"\n        else:\n            m = int(seconds // 60)\n            s = int(seconds % 60)\n            return f\"{m}m {s}s\"\n    \n    def _progress_bar(self, progress: float, width: int = 30) -> str:\n        \"\"\"Create a text progress bar.\"\"\"\n        filled = int(progress * width)\n        empty = width - filled\n        bar = \"\u2588\" * filled + \"\u2591\" * empty\n        return f\"[{bar}]\"\n    \n    def get_display(self) -> str:\n        \"\"\"Get the full timer display.\"\"\"\n        if not self.start_time:\n            return \"Clock not started\"\n        \n        elapsed = self.elapsed()\n        remaining = self.remaining()\n        done = self.problems_done()\n        total = self.num_problems\n        \n        # Progress\n        time_progress = elapsed / self.total_budget\n        problem_progress = done / total if total > 0 else 0\n        \n        # Pace calculation\n        if done > 0:\n            avg_time = elapsed / done\n            projected_total = avg_time * total\n            eta = projected_total - elapsed\n        else:\n            avg_time = 0\n            projected_total = self.total_budget\n            eta = remaining\n        \n        # Target comparison (4-4.5hr sweet spot)\n        target_mid = 4.25 * 3600\n        if projected_total < 4 * 3600:\n            pace_status = \"FAST (slow down for verification)\"\n        elif projected_total < 4.5 * 3600:\n            pace_status = \"ON TARGET\"\n        elif projected_total < 5 * 3600:\n            pace_status = \"SLIGHTLY BEHIND (acceptable)\"\n        else:\n            pace_status = \"BEHIND (need to speed up!)\"\n        \n        # Build display\n        lines = [\n            \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\",\n            \"\u2551                    COMPETITION CLOCK                     \u2551\",\n            \"\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\",\n            f\"\u2551  Elapsed:  {self._format_time(elapsed):>10}  \u2502  Remaining: {self._format_time(remaining):>10}  \u2551\",\n            \"\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\",\n            f\"\u2551  Problems: {done:>3}/{total:<3}  {self._progress_bar(problem_progress, 25)} {problem_progress*100:>5.1f}%  \u2551\",\n            f\"\u2551  Time:            {self._progress_bar(time_progress, 25)} {time_progress*100:>5.1f}%  \u2551\",\n            \"\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\",\n        ]\n        \n        if done > 0:\n            lines.append(f\"\u2551  Avg/problem: {avg_time/60:>5.1f}m  \u2502  ETA: {self._format_time_short(eta):>12}       \u2551\")\n            lines.append(f\"\u2551  Projected:   {self._format_time(projected_total):>10}  \u2502  Status: {pace_status:<14} \u2551\")\n        else:\n            lines.append(f\"\u2551  Avg/problem:   ---   \u2502  ETA:          ---       \u2551\")\n            lines.append(f\"\u2551  Projected:        ---  \u2502  Status: Starting...     \u2551\")\n        \n        if self.current_problem:\n            current_elapsed = self.elapsed_on_current()\n            lines.append(\"\u2560\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2563\")\n            lines.append(f\"\u2551  Current: {self.current_problem:<12}  \u2502  Time: {self._format_time_short(current_elapsed):>12}       \u2551\")\n        \n        lines.append(\"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\")\n        \n        return \"\\n\".join(lines)\n    \n    def get_compact_display(self) -> str:\n        \"\"\"Get a one-line timer display.\"\"\"\n        elapsed = self.elapsed()\n        remaining = self.remaining()\n        done = self.problems_done()\n        \n        # Emoji indicators\n        if remaining < 600:  # Less than 10 min\n            time_emoji = \"\ud83d\udd34\"\n        elif remaining < 1800:  # Less than 30 min\n            time_emoji = \"\ud83d\udfe1\"\n        else:\n            time_emoji = \"\ud83d\udfe2\"\n        \n        current = \"\"\n        if self.current_problem:\n            current_elapsed = self.elapsed_on_current()\n            current = f\" | Current: {current_elapsed:.0f}s\"\n        \n        return f\"{time_emoji} [{self._format_time(elapsed)} / {self._format_time(remaining)}] Problems: {done}/{self.num_problems}{current}\"\n    \n    def check_milestones(self) -> List[str]:\n        \"\"\"Check and return any new milestones reached.\"\"\"\n        progress = self.problems_done() / self.num_problems\n        new_milestones = []\n        \n        for name, (threshold, triggered) in self.milestones.items():\n            if progress >= threshold and not triggered:\n                self.milestones[name] = (threshold, True)\n                if name == \"quarter\":\n                    new_milestones.append(\"\ud83d\udccd 25% COMPLETE - Quarter mark reached!\")\n                elif name == \"half\":\n                    new_milestones.append(\"\ud83d\udccd 50% COMPLETE - Halfway there!\")\n                elif name == \"three_quarter\":\n                    new_milestones.append(\"\ud83d\udccd 75% COMPLETE - Final quarter!\")\n                elif name == \"final_stretch\":\n                    new_milestones.append(\"\ud83c\udfc1 90% COMPLETE - Final stretch!\")\n        \n        return new_milestones\n    \n    def check_time_alerts(self) -> List[str]:\n        \"\"\"Check and return any time-based alerts.\"\"\"\n        remaining = self.remaining()\n        alerts = []\n        \n        alert_thresholds = [\n            (3600, \"\u23f0 1 HOUR REMAINING\"),\n            (1800, \"\u23f0 30 MINUTES REMAINING\"),\n            (600, \"\u26a0\ufe0f 10 MINUTES REMAINING - WRAP UP!\"),\n            (300, \"\ud83d\udea8 5 MINUTES REMAINING - FINISH CURRENT!\"),\n            (60, \"\ud83d\udd25 1 MINUTE REMAINING!!!\"),\n        ]\n        \n        for threshold, message in alert_thresholds:\n            if remaining <= threshold and threshold not in self.alerts:\n                self.alerts.append(threshold)\n                alerts.append(message)\n        \n        return alerts\n\n# =============================================================================\n# PROBLEM STOPWATCH\n# Individual problem timing with warnings\n# =============================================================================\n\nclass ProblemStopwatch:\n    \"\"\"Stopwatch for individual problem timing with alerts.\"\"\"\n    \n    def __init__(self, problem_id: str, budget: float = 360):\n        self.problem_id = problem_id\n        self.budget = budget\n        self.start_time = time.time()\n        self.checkpoints = []  # (name, time)\n        self.warnings_issued = set()\n    \n    def elapsed(self) -> float:\n        return time.time() - self.start_time\n    \n    def remaining(self) -> float:\n        return max(0, self.budget - self.elapsed())\n    \n    def is_over_budget(self) -> bool:\n        return self.elapsed() > self.budget\n    \n    def budget_usage(self) -> float:\n        \"\"\"Return fraction of budget used (can be > 1.0).\"\"\"\n        return self.elapsed() / self.budget\n    \n    def checkpoint(self, name: str):\n        \"\"\"Add a timing checkpoint.\"\"\"\n        self.checkpoints.append((name, self.elapsed()))\n    \n    def get_warnings(self) -> List[str]:\n        \"\"\"Get any new warnings based on time.\"\"\"\n        warnings = []\n        usage = self.budget_usage()\n        \n        if usage > 0.5 and \"half\" not in self.warnings_issued:\n            self.warnings_issued.add(\"half\")\n            warnings.append(f\"\u23f1\ufe0f Problem {self.problem_id}: 50% of budget used\")\n        \n        if usage > 0.75 and \"three_quarter\" not in self.warnings_issued:\n            self.warnings_issued.add(\"three_quarter\")\n            warnings.append(f\"\u23f1\ufe0f Problem {self.problem_id}: 75% of budget - consider wrapping up\")\n        \n        if usage > 0.9 and \"ninety\" not in self.warnings_issued:\n            self.warnings_issued.add(\"ninety\")\n            warnings.append(f\"\u26a0\ufe0f Problem {self.problem_id}: 90% of budget - make a decision!\")\n        \n        if usage > 1.0 and \"over\" not in self.warnings_issued:\n            self.warnings_issued.add(\"over\")\n            warnings.append(f\"\ud83d\udd34 Problem {self.problem_id}: OVER BUDGET - move on!\")\n        \n        return warnings\n    \n    def summary(self) -> str:\n        \"\"\"Get timing summary.\"\"\"\n        elapsed = self.elapsed()\n        usage = self.budget_usage()\n        status = \"\u2705\" if usage <= 1.0 else \"\u26a0\ufe0f\"\n        \n        checkpoint_str = \"\"\n        if self.checkpoints:\n            checkpoint_str = \" | \" + \", \".join(f\"{n}:{t:.1f}s\" for n, t in self.checkpoints[-3:])\n        \n        return f\"{status} {self.problem_id}: {elapsed:.1f}s ({usage*100:.0f}% of {self.budget:.0f}s budget){checkpoint_str}\"\n\n# =============================================================================\n# TIMER SINGLETON\n# Global timer for easy access\n# =============================================================================\n\n# Global competition clock\nCOMPETITION_CLOCK = None\n\ndef init_clock(total_budget: float = 5 * 3600, num_problems: int = 50) -> CompetitionClock:\n    \"\"\"Initialize the global competition clock.\"\"\"\n    global COMPETITION_CLOCK\n    COMPETITION_CLOCK = CompetitionClock(total_budget, num_problems)\n    return COMPETITION_CLOCK\n\ndef get_clock() -> CompetitionClock:\n    \"\"\"Get the global competition clock.\"\"\"\n    global COMPETITION_CLOCK\n    if COMPETITION_CLOCK is None:\n        COMPETITION_CLOCK = CompetitionClock()\n    return COMPETITION_CLOCK\n\ndef display_clock():\n    \"\"\"Print the current clock display.\"\"\"\n    clock = get_clock()\n    print(clock.get_display())\n\ndef compact_clock() -> str:\n    \"\"\"Get compact clock string.\"\"\"\n    return get_clock().get_compact_display()\n\nprint(\"Competition Clock & Timer: OK\")\nprint(\"  - Full clock display with progress bars\")\nprint(\"  - Per-problem stopwatch with budget warnings\")\nprint(\"  - Milestone and time alerts\")\nprint(\"  - Pace tracking and ETA projection\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6vp7f5h3nht",
   "source": "# CELL 3D: Multi-Pass Solving Strategy\n# Classic test-taking: Quick pass on all, then revisit by difficulty\n\n# =============================================================================\n# ADAPTIVE TIME TRACKER\n# Tracks overage/underage and adjusts budgets in real-time\n# =============================================================================\n\nclass AdaptiveTimeTracker:\n    \"\"\"\n    Tracks time usage and dynamically adjusts future budgets.\n    \n    Key insight: If we're running under budget, we have more time for hard problems.\n    If we're running over, we need to be more aggressive.\n    \"\"\"\n    \n    def __init__(self, total_budget: float = 5 * 3600, num_problems: int = 50):\n        self.total_budget = total_budget\n        self.num_problems = num_problems\n        self.start_time = time.time()\n        \n        # Tracking\n        self.problem_records = []  # (id, difficulty, budget, actual, answer, confidence)\n        self.cumulative_budget = 0  # What we expected to spend\n        self.cumulative_actual = 0  # What we actually spent\n        \n        # Running calculations\n        self.time_delta = 0  # Positive = ahead, negative = behind\n        self.budget_efficiency = 1.0  # actual/budget ratio\n    \n    def record(self, problem_id: str, difficulty: float, budget: float, \n               actual: float, answer: int, confidence: float):\n        \"\"\"Record a problem completion.\"\"\"\n        self.problem_records.append({\n            \"id\": problem_id,\n            \"difficulty\": difficulty,\n            \"budget\": budget,\n            \"actual\": actual,\n            \"answer\": answer,\n            \"confidence\": confidence,\n            \"over_under\": budget - actual  # Positive = under budget\n        })\n        \n        self.cumulative_budget += budget\n        self.cumulative_actual += actual\n        self.time_delta = self.cumulative_budget - self.cumulative_actual\n        \n        if self.cumulative_budget > 0:\n            self.budget_efficiency = self.cumulative_actual / self.cumulative_budget\n    \n    def get_adjusted_budget(self, base_budget: float, difficulty: float) -> float:\n        \"\"\"Get adjusted budget based on historical performance.\"\"\"\n        if len(self.problem_records) < 3:\n            return base_budget  # Not enough data yet\n        \n        # Start with base\n        adjusted = base_budget\n        \n        # Apply efficiency correction\n        # If we've been finishing early, we can afford more time\n        if self.budget_efficiency < 0.8:  # Using less than 80% of budgets\n            adjusted *= 1.2  # Give 20% more time\n        elif self.budget_efficiency > 1.2:  # Using more than 120%\n            adjusted *= 0.85  # Cut 15%\n        \n        # If we have banked time (ahead of schedule), use it on hard problems\n        if self.time_delta > 120 and difficulty > 0.6:\n            # Use up to 30% of banked time on hard problems\n            bonus = min(self.time_delta * 0.3, base_budget * 0.5)\n            adjusted += bonus\n        \n        return max(60, min(600, adjusted))  # Keep within bounds\n    \n    def get_status(self) -> str:\n        \"\"\"Get current status string.\"\"\"\n        n = len(self.problem_records)\n        if n == 0:\n            return \"No problems solved yet\"\n        \n        avg_actual = self.cumulative_actual / n\n        avg_budget = self.cumulative_budget / n\n        \n        if self.time_delta > 0:\n            delta_str = f\"+{self.time_delta:.0f}s ahead\"\n        else:\n            delta_str = f\"{self.time_delta:.0f}s behind\"\n        \n        return f\"n={n} | avg={avg_actual:.0f}s (budget {avg_budget:.0f}s) | {delta_str} | efficiency={self.budget_efficiency:.2f}\"\n    \n    def get_review_candidates(self) -> List[Dict]:\n        \"\"\"Get problems that should be reviewed (low confidence).\"\"\"\n        return sorted(\n            [p for p in self.problem_records if p[\"confidence\"] < 0.6],\n            key=lambda p: p[\"confidence\"]\n        )\n\n# =============================================================================\n# MULTI-PASS SOLVING STRATEGY\n# =============================================================================\n\nclass MultiPassStrategy:\n    \"\"\"\n    Implements the classic test-taking strategy:\n    1. QUICK PASS: 60-90 seconds per problem, get easy wins\n    2. MEDIUM PASS: Revisit uncertain problems with more time\n    3. HARD PASS: Tackle remaining hard problems with full budget\n    4. REVIEW PASS: Verify low-confidence answers if time permits\n    \n    This ONLY works if we have access to all problems at once (batch mode).\n    For streaming mode (API), we fall back to single-pass.\n    \"\"\"\n    \n    def __init__(self, problems: List[Tuple[str, str]], total_budget: float = 5 * 3600):\n        \"\"\"\n        Args:\n            problems: List of (problem_id, problem_text) tuples\n            total_budget: Total time budget in seconds\n        \"\"\"\n        self.problems = problems\n        self.total_budget = total_budget\n        self.num_problems = len(problems)\n        \n        # Analyze all problems upfront\n        self.profiles = self._analyze_problems()\n        \n        # Time allocation per pass\n        self.pass_budgets = {\n            \"quick\": 0.20,    # 20% of total time for quick pass\n            \"medium\": 0.35,   # 35% for medium pass\n            \"hard\": 0.35,     # 35% for hard pass\n            \"review\": 0.10,   # 10% for review\n        }\n        \n        # Results tracking\n        self.results = {}  # problem_id -> {\"answer\": int, \"confidence\": float, \"pass\": str, \"time\": float}\n        self.pass_order = [\"quick\", \"medium\", \"hard\", \"review\"]\n    \n    def _analyze_problems(self) -> Dict[str, Dict]:\n        \"\"\"Analyze all problems and estimate difficulty.\"\"\"\n        profiles = {}\n        for idx, (pid, text) in enumerate(self.problems):\n            ptype = classify_problem(text)\n            difficulty = estimate_difficulty(text, ptype, idx, self.num_problems)\n            profiles[pid] = {\n                \"id\": pid,\n                \"text\": text,\n                \"type\": ptype,\n                \"difficulty\": difficulty,\n                \"index\": idx\n            }\n        return profiles\n    \n    def get_quick_pass_order(self) -> List[str]:\n        \"\"\"Get order for quick pass: easiest first.\"\"\"\n        return sorted(\n            self.profiles.keys(),\n            key=lambda pid: self.profiles[pid][\"difficulty\"]\n        )\n    \n    def get_medium_pass_candidates(self) -> List[str]:\n        \"\"\"Get candidates for medium pass: uncertain from quick pass, medium difficulty.\"\"\"\n        return [\n            pid for pid in self.profiles.keys()\n            if pid in self.results and self.results[pid][\"confidence\"] < 0.7\n            and self.profiles[pid][\"difficulty\"] < 0.7\n        ]\n    \n    def get_hard_pass_candidates(self) -> List[str]:\n        \"\"\"Get candidates for hard pass: still uncertain or skipped.\"\"\"\n        return [\n            pid for pid in self.profiles.keys()\n            if pid not in self.results or self.results[pid][\"confidence\"] < 0.5\n        ]\n    \n    def get_review_candidates(self) -> List[str]:\n        \"\"\"Get candidates for review: lowest confidence answers.\"\"\"\n        return sorted(\n            [pid for pid in self.results.keys() if self.results[pid][\"confidence\"] < 0.6],\n            key=lambda pid: self.results[pid][\"confidence\"]\n        )\n    \n    def record_result(self, problem_id: str, answer: int, confidence: float, \n                      pass_name: str, time_spent: float):\n        \"\"\"Record a result.\"\"\"\n        self.results[problem_id] = {\n            \"answer\": answer,\n            \"confidence\": confidence,\n            \"pass\": pass_name,\n            \"time\": time_spent\n        }\n    \n    def get_pass_time_budget(self, pass_name: str, elapsed: float) -> float:\n        \"\"\"Get remaining time budget for a pass.\"\"\"\n        remaining = self.total_budget - elapsed\n        pass_fraction = self.pass_budgets.get(pass_name, 0.25)\n        return remaining * pass_fraction\n    \n    def get_problem_budget(self, pass_name: str, pass_time_budget: float, \n                           num_problems_in_pass: int) -> float:\n        \"\"\"Get per-problem budget for a pass.\"\"\"\n        if num_problems_in_pass == 0:\n            return 0\n        \n        base = pass_time_budget / num_problems_in_pass\n        \n        # Different strategies per pass\n        if pass_name == \"quick\":\n            return min(90, base)  # Max 90 seconds in quick pass\n        elif pass_name == \"medium\":\n            return min(180, base)  # Max 3 minutes in medium pass\n        elif pass_name == \"hard\":\n            return min(360, base)  # Max 6 minutes in hard pass\n        else:  # review\n            return min(120, base)  # Max 2 minutes in review\n    \n    def get_summary(self) -> str:\n        \"\"\"Get summary of multi-pass strategy.\"\"\"\n        total = self.num_problems\n        solved = len(self.results)\n        high_conf = sum(1 for r in self.results.values() if r[\"confidence\"] >= 0.7)\n        low_conf = sum(1 for r in self.results.values() if r[\"confidence\"] < 0.5)\n        \n        by_pass = Counter(r[\"pass\"] for r in self.results.values())\n        \n        return f\"Solved: {solved}/{total} | High conf: {high_conf} | Low conf: {low_conf} | By pass: {dict(by_pass)}\"\n\n# =============================================================================\n# PASS EXECUTION CONTROLLER\n# =============================================================================\n\nclass PassController:\n    \"\"\"Controls execution of multi-pass strategy.\"\"\"\n    \n    def __init__(self, strategy: MultiPassStrategy):\n        self.strategy = strategy\n        self.current_pass = None\n        self.pass_start_time = None\n        self.pass_problems = []\n        self.pass_index = 0\n    \n    def start_pass(self, pass_name: str, problems: List[str], time_budget: float):\n        \"\"\"Start a new pass.\"\"\"\n        self.current_pass = pass_name\n        self.pass_start_time = time.time()\n        self.pass_problems = problems\n        self.pass_budget = time_budget\n        self.pass_index = 0\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"STARTING {pass_name.upper()} PASS\")\n        print(f\"Problems: {len(problems)} | Budget: {time_budget/60:.1f} min\")\n        print(f\"{'='*60}\")\n    \n    def get_next_problem(self) -> Optional[str]:\n        \"\"\"Get next problem in current pass.\"\"\"\n        if self.pass_index >= len(self.pass_problems):\n            return None\n        \n        pid = self.pass_problems[self.pass_index]\n        self.pass_index += 1\n        return pid\n    \n    def pass_time_elapsed(self) -> float:\n        \"\"\"Time elapsed in current pass.\"\"\"\n        if not self.pass_start_time:\n            return 0\n        return time.time() - self.pass_start_time\n    \n    def pass_time_remaining(self) -> float:\n        \"\"\"Time remaining in current pass.\"\"\"\n        return max(0, self.pass_budget - self.pass_time_elapsed())\n    \n    def should_continue_pass(self) -> bool:\n        \"\"\"Check if we should continue current pass or move on.\"\"\"\n        # Out of problems\n        if self.pass_index >= len(self.pass_problems):\n            return False\n        \n        # Out of time for this pass\n        if self.pass_time_remaining() < 30:\n            return False\n        \n        return True\n    \n    def end_pass(self) -> Dict:\n        \"\"\"End current pass and return summary.\"\"\"\n        elapsed = self.pass_time_elapsed()\n        completed = self.pass_index\n        total = len(self.pass_problems)\n        \n        summary = {\n            \"pass\": self.current_pass,\n            \"completed\": completed,\n            \"total\": total,\n            \"time\": elapsed,\n            \"budget\": self.pass_budget\n        }\n        \n        print(f\"\\n{self.current_pass.upper()} PASS COMPLETE\")\n        print(f\"  Completed: {completed}/{total}\")\n        print(f\"  Time: {elapsed/60:.1f}m (budget: {self.pass_budget/60:.1f}m)\")\n        \n        return summary\n\n# =============================================================================\n# STREAMING VS BATCH MODE DETECTOR\n# =============================================================================\n\ndef detect_solving_mode(competition_path: str) -> str:\n    \"\"\"\n    Detect whether we're in streaming or batch mode.\n    \n    Streaming (API): Problems come one at a time via predict() function\n    Batch (CSV): All problems available at once in test.csv\n    \n    In AIMO3, it's likely streaming for the actual competition but\n    batch for local testing.\n    \"\"\"\n    # Check if test.csv exists and has problems\n    test_csv = f\"{competition_path}/test.csv\"\n    if os.path.exists(test_csv):\n        return \"batch\"  # Can use multi-pass\n    \n    return \"streaming\"  # Must use single-pass\n\nprint(\"Multi-Pass Solving Strategy: OK\")\nprint(\"  - Quick pass: 60-90s per problem, easy first\")\nprint(\"  - Medium pass: Revisit uncertain, medium difficulty\")\nprint(\"  - Hard pass: Tackle remaining with full budget\")\nprint(\"  - Review pass: Verify low-confidence answers\")\nprint(\"  - Adaptive time tracking with overage/underage adjustment\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: Code Execution Engine\n",
    "import re\n",
    "import signal\n",
    "import traceback\n",
    "from io import StringIO\n",
    "import contextlib\n",
    "\n",
    "MATH_STDLIB = '''\n",
    "import math\n",
    "from math import gcd, factorial, comb, isqrt, sqrt, ceil, floor, log, exp, sin, cos, tan, pi, e\n",
    "from itertools import permutations, combinations, product, combinations_with_replacement\n",
    "from functools import reduce, lru_cache\n",
    "from collections import Counter, defaultdict, deque\n",
    "from fractions import Fraction\n",
    "from decimal import Decimal\n",
    "\n",
    "try:\n",
    "    from sympy import *\n",
    "    from sympy.ntheory import factorint, divisors, totient, isprime, primerange, prime\n",
    "    from sympy.ntheory.modular import crt\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "def lcm(a, b): return abs(a * b) // gcd(a, b)\n",
    "def is_prime(n):\n",
    "    if n < 2: return False\n",
    "    if n < 4: return True\n",
    "    if n % 2 == 0: return False\n",
    "    for i in range(3, isqrt(n) + 1, 2):\n",
    "        if n % i == 0: return False\n",
    "    return True\n",
    "def C(n, k): return comb(n, k) if 0 <= k <= n else 0\n",
    "def P(n, k): return factorial(n) // factorial(n - k) if 0 <= k <= n else 0\n",
    "def modinv(a, m): return pow(a, -1, m)\n",
    "'''\n",
    "\n",
    "ANSWER_SNIFFER = '''\n",
    "for _vname in [\"answer\", \"ans\", \"result\", \"res\", \"total\", \"count\", \"final\"]:\n",
    "    if _vname in dir() and isinstance(eval(_vname), (int, float)):\n",
    "        _val = int(eval(_vname))\n",
    "        if 0 <= _val <= 99999:\n",
    "            print(f\"EXTRACTED_ANSWER:{_val}\")\n",
    "            break\n",
    "'''\n",
    "\n",
    "def execute_code(code: str, timeout: int = 30) -> Tuple[Optional[int], str]:\n",
    "    \"\"\"Execute Python code with timeout.\"\"\"\n",
    "    full_code = MATH_STDLIB + '\\n' + code + '\\n' + ANSWER_SNIFFER\n",
    "    stdout_capture = StringIO()\n",
    "    \n",
    "    def timeout_handler(signum, frame):\n",
    "        raise TimeoutError(\"Timeout\")\n",
    "    \n",
    "    old_handler = signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    \n",
    "    try:\n",
    "        signal.alarm(timeout)\n",
    "        with contextlib.redirect_stdout(stdout_capture):\n",
    "            exec(full_code, {'__builtins__': __builtins__})\n",
    "        signal.alarm(0)\n",
    "        \n",
    "        output = stdout_capture.getvalue()\n",
    "        match = re.search(r'EXTRACTED_ANSWER:(\\d+)', output)\n",
    "        if match:\n",
    "            return int(match.group(1)), \"\"\n",
    "        \n",
    "        numbers = re.findall(r'\\b(\\d+)\\b', output)\n",
    "        if numbers:\n",
    "            val = int(numbers[-1])\n",
    "            if 0 <= val <= 99999:\n",
    "                return val, \"\"\n",
    "        \n",
    "        return None, \"No answer found\"\n",
    "    except TimeoutError:\n",
    "        return None, \"Timeout\"\n",
    "    except Exception as e:\n",
    "        return None, f\"{type(e).__name__}: {str(e)[:50]}\"\n",
    "    finally:\n",
    "        signal.alarm(0)\n",
    "        signal.signal(signal.SIGALRM, old_handler)\n",
    "\n",
    "def extract_code(text: str) -> Optional[str]:\n",
    "    for pattern in [r'```python\\n(.*?)```', r'```py\\n(.*?)```', r'```\\n(.*?)```']:\n",
    "        matches = re.findall(pattern, text, re.DOTALL)\n",
    "        if matches:\n",
    "            return matches[0].strip()\n",
    "    return None\n",
    "\n",
    "def extract_text_answer(text: str) -> Optional[int]:\n",
    "    for pattern in [r'\\\\boxed\\{(\\d+)\\}', r'answer\\s*(?:is|=)\\s*(\\d+)', r'=\\s*(\\d+)\\s*$']:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            try:\n",
    "                val = int(match.group(1))\n",
    "                if 0 <= val <= 99999:\n",
    "                    return val\n",
    "            except ValueError:\n",
    "                pass\n",
    "    \n",
    "    numbers = re.findall(r'\\b(\\d+)\\b', text[-500:])\n",
    "    if numbers:\n",
    "        try:\n",
    "            val = int(numbers[-1])\n",
    "            if 0 <= val <= 99999:\n",
    "                return val\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "print(\"Code Execution: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "s524pja4w1",
   "source": "# CELL 4B: Loop Detection and Intervention\n# Detects when LLMs get stuck repeating themselves and intervenes\n\nfrom collections import Counter\nfrom typing import Tuple, Optional, List\nimport hashlib\n\n# =============================================================================\n# LOOP DETECTOR\n# Detects repetitive patterns in LLM output\n# =============================================================================\n\nclass LoopDetector:\n    \"\"\"\n    Detects when an LLM is stuck in a repetition loop.\n    \n    Common loop patterns:\n    - \"Let me reconsider...\" repeated 10x\n    - Same reasoning block copy-pasted\n    - Infinite \"Step 1: ... Step 1: ... Step 1: ...\"\n    \"\"\"\n    \n    def __init__(self, \n                 min_chunk_size: int = 30,      # Minimum chars to consider a \"chunk\"\n                 max_chunk_size: int = 200,     # Maximum chunk size to check\n                 repeat_threshold: int = 3,      # How many repeats = loop\n                 line_repeat_threshold: int = 4  # How many identical lines = loop\n                 ):\n        self.min_chunk_size = min_chunk_size\n        self.max_chunk_size = max_chunk_size\n        self.repeat_threshold = repeat_threshold\n        self.line_repeat_threshold = line_repeat_threshold\n    \n    def _hash_chunk(self, text: str) -> str:\n        \"\"\"Hash a text chunk for fast comparison.\"\"\"\n        return hashlib.md5(text.encode()).hexdigest()[:8]\n    \n    def check_ngram_loops(self, text: str) -> Tuple[bool, int, str]:\n        \"\"\"\n        Check for repeated n-gram chunks.\n        Returns: (is_looping, truncate_position, repeated_chunk)\n        \"\"\"\n        if len(text) < self.min_chunk_size * self.repeat_threshold:\n            return False, -1, \"\"\n        \n        # Try different chunk sizes, larger first\n        for chunk_size in range(self.max_chunk_size, self.min_chunk_size - 1, -10):\n            if len(text) < chunk_size * self.repeat_threshold:\n                continue\n            \n            # Sliding window to find repeated chunks\n            chunk_hashes = {}\n            \n            for i in range(0, len(text) - chunk_size + 1, chunk_size // 2):\n                chunk = text[i:i + chunk_size]\n                chunk_hash = self._hash_chunk(chunk)\n                \n                if chunk_hash in chunk_hashes:\n                    chunk_hashes[chunk_hash].append(i)\n                else:\n                    chunk_hashes[chunk_hash] = [i]\n            \n            # Check for repeated chunks\n            for chunk_hash, positions in chunk_hashes.items():\n                if len(positions) >= self.repeat_threshold:\n                    # Found a loop! Return first occurrence position\n                    first_pos = positions[0]\n                    repeated_chunk = text[first_pos:first_pos + min(50, chunk_size)]\n                    return True, first_pos, repeated_chunk\n        \n        return False, -1, \"\"\n    \n    def check_line_loops(self, text: str) -> Tuple[bool, int, str]:\n        \"\"\"\n        Check for repeated lines.\n        Returns: (is_looping, truncate_position, repeated_line)\n        \"\"\"\n        lines = text.split('\\n')\n        if len(lines) < self.line_repeat_threshold:\n            return False, -1, \"\"\n        \n        # Count line occurrences\n        line_counts = Counter(lines)\n        \n        for line, count in line_counts.most_common(5):\n            # Skip empty or very short lines\n            if len(line.strip()) < 10:\n                continue\n            \n            if count >= self.line_repeat_threshold:\n                # Find first occurrence\n                char_pos = text.find(line)\n                return True, char_pos, line[:50]\n        \n        return False, -1, \"\"\n    \n    def check_think_loops(self, text: str) -> Tuple[bool, int, str]:\n        \"\"\"\n        Check for loops specific to <think> blocks.\n        Common patterns: \"Wait, let me...\" \"Actually...\" \"Hmm...\" repeated.\n        \"\"\"\n        think_starters = [\n            \"let me reconsider\",\n            \"wait, i need to\",\n            \"actually, let me\",\n            \"hmm, let me think\",\n            \"i should reconsider\",\n            \"let me try again\",\n            \"let me re-examine\",\n        ]\n        \n        text_lower = text.lower()\n        \n        for starter in think_starters:\n            count = text_lower.count(starter)\n            if count >= self.repeat_threshold:\n                pos = text_lower.find(starter)\n                return True, pos, starter\n        \n        return False, -1, \"\"\n    \n    def check(self, text: str) -> Tuple[bool, int, str, str]:\n        \"\"\"\n        Full loop check.\n        Returns: (is_looping, truncate_position, loop_type, sample)\n        \"\"\"\n        # Check n-gram loops (most common)\n        is_loop, pos, sample = self.check_ngram_loops(text)\n        if is_loop:\n            return True, pos, \"ngram\", sample\n        \n        # Check line loops\n        is_loop, pos, sample = self.check_line_loops(text)\n        if is_loop:\n            return True, pos, \"line\", sample\n        \n        # Check think-specific loops\n        is_loop, pos, sample = self.check_think_loops(text)\n        if is_loop:\n            return True, pos, \"think\", sample\n        \n        return False, -1, \"\", \"\"\n    \n    def clean(self, text: str) -> Tuple[str, bool]:\n        \"\"\"\n        Clean looped output by truncating before loop starts.\n        Returns: (cleaned_text, was_truncated)\n        \"\"\"\n        is_loop, pos, loop_type, sample = self.check(text)\n        \n        if is_loop and pos > 100:  # Keep at least 100 chars\n            # Find a good truncation point (end of sentence before loop)\n            truncate_region = text[max(0, pos - 200):pos]\n            \n            # Try to find sentence end\n            for end_marker in ['. ', '.\\n', '```\\n', '\\n\\n']:\n                last_end = truncate_region.rfind(end_marker)\n                if last_end != -1:\n                    final_pos = max(0, pos - 200) + last_end + len(end_marker)\n                    return text[:final_pos], True\n            \n            # No good sentence end, just truncate\n            return text[:pos], True\n        \n        return text, False\n\n\n# =============================================================================\n# LOOP INTERVENOR\n# Takes action when loops are detected\n# =============================================================================\n\nclass LoopIntervenor:\n    \"\"\"\n    Intervenes when LLM loops are detected.\n    \n    Strategies:\n    1. Truncate and extract what we can\n    2. Retry with higher temperature (more randomness breaks loops)\n    3. Retry with presence penalty (discourages repetition)\n    4. Retry with different prompt framing\n    \"\"\"\n    \n    def __init__(self, detector: LoopDetector = None):\n        self.detector = detector or LoopDetector()\n        self.loop_stats = {\n            \"total_detected\": 0,\n            \"truncated\": 0,\n            \"retried\": 0,\n            \"by_type\": Counter(),\n        }\n    \n    def check_and_clean(self, text: str) -> Tuple[str, bool, Optional[str]]:\n        \"\"\"\n        Check for loops and clean if found.\n        Returns: (cleaned_text, had_loop, loop_type)\n        \"\"\"\n        is_loop, pos, loop_type, sample = self.detector.check(text)\n        \n        if is_loop:\n            self.loop_stats[\"total_detected\"] += 1\n            self.loop_stats[\"by_type\"][loop_type] += 1\n            \n            cleaned, was_truncated = self.detector.clean(text)\n            if was_truncated:\n                self.loop_stats[\"truncated\"] += 1\n                print(f\"    LOOP DETECTED ({loop_type}): '{sample[:30]}...' - truncated\")\n            \n            return cleaned, True, loop_type\n        \n        return text, False, None\n    \n    def get_retry_params(self, original_temp: float, loop_type: str, attempt: int) -> dict:\n        \"\"\"\n        Get modified sampling params for retry after loop.\n        Each retry gets progressively more aggressive anti-loop measures.\n        \"\"\"\n        # Base modifications\n        new_temp = min(1.0, original_temp + 0.2 * attempt)  # Increase temp\n        presence_penalty = 0.5 * attempt  # Discourage repetition\n        frequency_penalty = 0.3 * attempt\n        \n        # Type-specific adjustments\n        if loop_type == \"think\":\n            # Think loops often need more aggressive intervention\n            presence_penalty += 0.3\n            new_temp = min(1.2, new_temp + 0.1)\n        \n        self.loop_stats[\"retried\"] += 1\n        \n        return {\n            \"temperature\": new_temp,\n            \"presence_penalty\": min(2.0, presence_penalty),\n            \"frequency_penalty\": min(2.0, frequency_penalty),\n        }\n    \n    def get_intervention_prompt(self, original_prompt: str, loop_type: str) -> str:\n        \"\"\"\n        Modify prompt to help break loops.\n        Adds explicit anti-loop instructions.\n        \"\"\"\n        anti_loop_suffix = \"\"\"\n\nIMPORTANT: Give a direct, concise answer. Do not repeat yourself or reconsider multiple times. \nState your solution clearly and move forward. If unsure, make your best guess and explain briefly.\"\"\"\n        \n        return original_prompt + anti_loop_suffix\n    \n    def get_stats(self) -> str:\n        \"\"\"Get intervention statistics.\"\"\"\n        s = self.loop_stats\n        if s[\"total_detected\"] == 0:\n            return \"No loops detected\"\n        \n        by_type = \", \".join(f\"{t}:{c}\" for t, c in s[\"by_type\"].items())\n        return f\"Loops: {s['total_detected']} detected, {s['truncated']} truncated, {s['retried']} retried | Types: {by_type}\"\n\n\n# =============================================================================\n# GLOBAL INSTANCES\n# =============================================================================\n\nloop_detector = LoopDetector()\nloop_intervenor = LoopIntervenor(loop_detector)\n\nprint(\"Loop Detection & Intervention: OK\")\nprint(\"  - N-gram repetition detection (30-200 char chunks)\")\nprint(\"  - Line repetition detection\")  \nprint(\"  - Think-block loop detection\")\nprint(\"  - Auto-truncation and retry with modified params\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-solver",
   "metadata": {},
   "outputs": [],
   "source": "# CELL 5: BUDGET-ENFORCED SOLVER with Smart Swap Strategy\n\n# =============================================================================\n# PROMPTS\n# =============================================================================\n\nSYSTEM_PROMPT = \"\"\"You are an expert olympiad mathematician solving IMO-level problems.\n\nCRITICAL: Before writing ANY code, you MUST think deeply in a <think> block.\n\nFORMAT YOUR RESPONSE EXACTLY LIKE THIS:\n\n<think>\n[Your extended reasoning here - at least 10 lines of deep analysis]\n- What type of problem is this? (Number theory, combinatorics, algebra, geometry)\n- What are the key constraints and conditions?\n- What mathematical techniques apply? (Modular arithmetic, generating functions, etc.)\n- What are potential edge cases?\n- Can I verify my approach before coding?\n- What is my solution strategy?\n</think>\n\n```python\n# Your code here\nanswer = ...\n```\n\nRULES:\n1. ALWAYS include a <think> block with detailed reasoning\n2. Store the final answer in a variable called 'answer'\n3. Answer MUST be an integer from 0 to 99999\n4. Any modulo is EXPLICITLY stated in the problem (no implicit mod 1000)\n5. Double-check your arithmetic and edge cases\n\nTake your time. Think deeply. Get it right.\"\"\"\n\nSYSTEM_PROMPT_FAST = \"\"\"You are an expert olympiad mathematician.\nWrite Python code to solve this problem.\nStore the answer in 'answer' (integer 0-99999).\nAny modulo is explicitly stated.\"\"\"\n\nVERIFICATION_PROMPT = \"\"\"You solved this problem and got answer = {answer}.\n\nProblem: {problem}\n\nVERIFY this answer:\n1. Does it satisfy ALL constraints in the problem?\n2. Check edge cases\n3. Is the arithmetic correct?\n4. Does the answer \"make sense\" for this problem type?\n\nIf CORRECT, respond: VERIFIED:{answer}\nIf WRONG, respond: WRONG:[your corrected answer]\"\"\"\n\n# =============================================================================\n# SWAP THRESHOLDS\n# =============================================================================\n\nCONFIDENCE_SWAP_THRESHOLD = 0.5  # Swap to GRPO if confidence below this\nCODE_FAIL_SWAP_THRESHOLD = 3     # Swap if code fails this many times\nSECOND_PASS_CONFIDENCE = 0.6    # Review answers below this in second pass\n\n# =============================================================================\n# BUDGET-ENFORCED SOLVER WITH SMART SWAP\n# =============================================================================\n\nclass BudgetEnforcedSolver:\n    \"\"\"\n    Main solver with budget enforcement and smart model swapping.\n    \n    Swap Strategy:\n    1. Run Fast-Math on every problem first\n    2. If confidence < 0.5 OR code failed 3+ times \u2192 swap to GRPO\n    3. GRPO gives second opinion, combine with voting\n    4. Second pass: Review all conf < 0.6 with GRPO if time permits\n    \"\"\"\n    \n    def __init__(self, model_manager, \n                 total_budget: float = TOTAL_BUDGET_SECONDS,\n                 num_problems: int = 50,\n                 use_extended_thinking: bool = True):\n        self.model_manager = model_manager\n        self.use_extended_thinking = use_extended_thinking\n        \n        # Initialize all timing systems\n        self.clock = init_clock(total_budget, num_problems)\n        self.clock.start()\n        \n        self.config = CalibratedSolverConfig(AIMO3_PREDICTED)\n        self.tracker = AdaptiveTimeTracker(total_budget, num_problems)\n        self.review_queue = ReviewQueue()\n        \n        # State\n        self.num_problems = num_problems\n        self.problems_solved = 0\n        self.all_answers = {}  # problem_id -> (answer, confidence, model_used)\n        self.swap_triggers = []  # Track why we swapped\n        \n        print(self.clock.get_display())\n    \n    def generate(self, problem: str, temperature: float = 0.7, \n                 max_tokens: int = 8192, max_loop_retries: int = 2) -> Optional[str]:\n        \"\"\"Generate using current model with loop detection and intervention.\"\"\"\n        llm = self.model_manager.get_llm()\n        tokenizer = self.model_manager.get_tokenizer()\n        \n        # Select prompt based on time remaining\n        if self.use_extended_thinking and self.clock.remaining() > 3600:\n            system_prompt = SYSTEM_PROMPT\n            tokens = max_tokens\n        else:\n            system_prompt = SYSTEM_PROMPT_FAST\n            tokens = 4096\n        \n        messages = [\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": problem}\n        ]\n        \n        prompt = tokenizer.apply_chat_template(\n            messages, tokenize=False, add_generation_prompt=True\n        )\n        \n        current_temp = temperature\n        presence_penalty = 0.0\n        frequency_penalty = 0.0\n        \n        for attempt in range(max_loop_retries + 1):\n            sampling_params = SamplingParams(\n                temperature=current_temp,\n                top_p=0.90,\n                min_p=0.05,\n                max_tokens=tokens,\n                presence_penalty=presence_penalty,\n                frequency_penalty=frequency_penalty,\n            )\n            \n            try:\n                outputs = llm.generate([prompt], sampling_params)\n                response = outputs[0].outputs[0].text\n                \n                # Check for loops\n                cleaned, had_loop, loop_type = loop_intervenor.check_and_clean(response)\n                \n                if had_loop and attempt < max_loop_retries:\n                    # Loop detected - retry with modified params\n                    retry_params = loop_intervenor.get_retry_params(temperature, loop_type, attempt + 1)\n                    current_temp = retry_params[\"temperature\"]\n                    presence_penalty = retry_params[\"presence_penalty\"]\n                    frequency_penalty = retry_params[\"frequency_penalty\"]\n                    print(f\"    Loop retry {attempt + 1}: temp={current_temp:.2f}, presence={presence_penalty:.1f}\")\n                    continue\n                \n                # Return cleaned response (truncated if loop was found on final attempt)\n                return cleaned\n                \n            except Exception as e:\n                print(f\"    Generation error: {e}\")\n                return None\n        \n        return None\n    \n    def _run_sampling_paths(self, problem: str, problem_type: str, \n                            budget: float, start_time: float) -> Tuple[List[int], List[Tuple], int]:\n        \"\"\"Run sampling paths with current model. Returns (candidates, scores, code_failures).\"\"\"\n        candidates = []\n        candidate_scores = []\n        code_failures = 0\n        \n        # Temperature schedule\n        if problem_type in [\"modular\", \"number_theory\"]:\n            temperatures = [0.3, 0.5, 0.7, 0.2, 0.4, 0.6]\n        elif problem_type in [\"counting\"]:\n            temperatures = [0.5, 0.7, 0.3, 0.6, 0.4, 0.8]\n        else:\n            temperatures = [0.6, 0.4, 0.7, 0.3, 0.5, 0.2]\n        \n        for i, temp in enumerate(temperatures):\n            elapsed = time.time() - start_time\n            \n            # Budget check\n            if elapsed > budget * 0.9:\n                break\n            \n            # Early stop on consensus\n            if not should_continue_sampling(candidates, elapsed, budget):\n                print(f\"  Good consensus - stopping early\")\n                break\n            \n            remaining = budget - elapsed\n            print(f\"  Path {i+1}/{len(temperatures)} @ temp={temp:.1f} | {remaining:.0f}s left\")\n            \n            try:\n                response = self.generate(problem, temperature=temp)\n                if response is None:\n                    continue\n                \n                # Check thinking block\n                if '<think>' in response:\n                    think_match = re.search(r'<think>(.*?)</think>', response, re.DOTALL)\n                    if think_match:\n                        print(f\"    Think: {len(think_match.group(1).split(chr(10)))} lines\")\n                \n                # Extract and execute code\n                code = extract_code(response)\n                if code:\n                    result, err = execute_code(code, timeout=30)\n                    if result is not None:\n                        sanity = answer_sanity_score(result, problem)\n                        math_score = math_answer_heuristics(result, problem, problem_type)\n                        combined_score = sanity * math_score\n                        candidates.append(result)\n                        candidate_scores.append((result, combined_score, 'code'))\n                        print(f\"    Code: {result} (score={combined_score:.2f})\")\n                    else:\n                        code_failures += 1\n                        print(f\"    Code FAILED ({code_failures}x): {err[:30]}\")\n                        text_ans = extract_text_answer(response)\n                        if text_ans:\n                            sanity = answer_sanity_score(text_ans, problem)\n                            candidates.append(text_ans)\n                            candidate_scores.append((text_ans, sanity, 'fallback'))\n                            print(f\"    Fallback: {text_ans}\")\n                else:\n                    text_ans = extract_text_answer(response)\n                    if text_ans:\n                        sanity = answer_sanity_score(text_ans, problem)\n                        candidates.append(text_ans)\n                        candidate_scores.append((text_ans, sanity, 'text'))\n                        print(f\"    Text: {text_ans}\")\n                        \n            except Exception as e:\n                print(f\"    Error: {e}\")\n        \n        return candidates, candidate_scores, code_failures\n    \n    def solve(self, problem: str, problem_id: str = \"unknown\") -> int:\n        \"\"\"\n        Solve with smart swap strategy:\n        1. Try Fast-Math first\n        2. If low confidence OR code failed 3+ times \u2192 swap to GRPO\n        3. Combine results with voting\n        \"\"\"\n        # Start timing\n        self.clock.start_problem(problem_id)\n        stopwatch = ProblemStopwatch(problem_id)\n        start_time = time.time()\n        \n        # Classify problem\n        problem_type = classify_problem(problem)\n        difficulty = estimate_difficulty(problem, problem_type, self.problems_solved, self.num_problems)\n        type_fallback = get_fallback_for_type(problem_type)\n        \n        # Get calibrated budget\n        base_budget = self.config.get_problem_budget(difficulty)\n        adjusted_budget = self.tracker.get_adjusted_budget(base_budget, difficulty)\n        stopwatch.budget = adjusted_budget\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"Problem: {problem_id} | Type: {problem_type} | Diff: {difficulty:.2f}\")\n        print(f\"Budget: {adjusted_budget:.0f}s | {self.clock.get_compact_display()}\")\n        print(f\"Model: {self.model_manager.get_current_model_name()}\")\n        print(f\"{'='*60}\")\n        \n        # ============ PHASE 1: Fast-Math (Primary) ============\n        print(f\"\\n  PHASE 1: Fast-Math\")\n        \n        # Ensure Fast-Math is loaded\n        self.model_manager.load_model(\"fast_math\")\n        \n        # Run sampling\n        phase1_budget = adjusted_budget * 0.6  # 60% budget for phase 1\n        candidates, candidate_scores, code_failures = self._run_sampling_paths(\n            problem, problem_type, phase1_budget, start_time\n        )\n        \n        # Compute initial answer and confidence\n        if not candidates:\n            answer = type_fallback\n            confidence = 0.05\n            print(f\"  No candidates from Fast-Math - fallback {type_fallback}\")\n        else:\n            answer, confidence, cluster_result = select_answer(\n                candidates, threshold=0.05, fallback=type_fallback\n            )\n            # Adjust by scores\n            matching_scores = [s for a, s, _ in candidate_scores if a == answer]\n            if matching_scores:\n                confidence = min(0.95, confidence * statistics.mean(matching_scores))\n            \n            cic = compute_cic(candidates)\n            print(f\"  Fast-Math: answer={answer}, conf={confidence:.2f}, CIC.F={cic.F:.2f}\")\n        \n        # ============ PHASE 2: GRPO (if needed) ============\n        elapsed = time.time() - start_time\n        remaining_budget = adjusted_budget - elapsed\n        \n        need_swap = False\n        swap_reason = None\n        \n        if confidence < CONFIDENCE_SWAP_THRESHOLD and remaining_budget > 60:\n            need_swap = True\n            swap_reason = f\"low_confidence ({confidence:.2f})\"\n        elif code_failures >= CODE_FAIL_SWAP_THRESHOLD and remaining_budget > 60:\n            need_swap = True\n            swap_reason = f\"code_failures ({code_failures}x)\"\n        \n        grpo_candidates = []\n        if need_swap:\n            print(f\"\\n  PHASE 2: GRPO (reason: {swap_reason})\")\n            self.swap_triggers.append((problem_id, swap_reason))\n            \n            # Swap to GRPO\n            self.model_manager.load_model(\"grpo\")\n            \n            # Run sampling with GRPO\n            phase2_budget = remaining_budget * 0.8\n            grpo_candidates, grpo_scores, _ = self._run_sampling_paths(\n                problem, problem_type, phase2_budget, time.time()\n            )\n            \n            if grpo_candidates:\n                grpo_answer, grpo_conf, _ = select_answer(\n                    grpo_candidates, threshold=0.05, fallback=type_fallback\n                )\n                print(f\"  GRPO: answer={grpo_answer}, conf={grpo_conf:.2f}\")\n                \n                # Combine results via voting\n                all_candidates = candidates + grpo_candidates\n                all_scores = candidate_scores + grpo_scores\n                \n                final_answer, final_conf, final_cluster = select_answer(\n                    all_candidates, threshold=0.05, fallback=type_fallback\n                )\n                \n                # Update with combined result\n                if final_conf > confidence:\n                    answer = final_answer\n                    confidence = final_conf\n                    print(f\"  Combined: answer={answer}, conf={confidence:.2f}\")\n                else:\n                    # Keep Fast-Math answer but note disagreement\n                    if grpo_answer != answer:\n                        print(f\"  Models disagree: Fast-Math={answer}, GRPO={grpo_answer}\")\n                        print(f\"  Keeping Fast-Math (higher conf)\")\n            \n            # Swap back to Fast-Math for next problem\n            self.model_manager.load_model(\"fast_math\")\n        else:\n            print(f\"\\n  PHASE 2: Skipped (conf={confidence:.2f} >= {CONFIDENCE_SWAP_THRESHOLD})\")\n        \n        # ============ VERIFICATION (if budget allows) ============\n        elapsed = time.time() - start_time\n        remaining = adjusted_budget - elapsed\n        \n        if remaining > 30 and confidence < 0.8 and len(candidates) >= 2:\n            print(f\"  Verifying...\")\n            llm = self.model_manager.get_llm()\n            tokenizer = self.model_manager.get_tokenizer()\n            verify_params = SamplingParams(temperature=0.1, max_tokens=1024, top_p=0.9)\n            try:\n                verified, changed = verify_answer(llm, tokenizer, problem, answer, verify_params)\n                if changed:\n                    print(f\"  Verification corrected: {answer} -> {verified}\")\n                    answer = verified\n                else:\n                    confidence = min(0.95, confidence * 1.15)\n            except:\n                pass\n        \n        # ============ RECORD & FINALIZE ============\n        answer = max(ANSWER_MIN, min(ANSWER_MAX, answer))\n        total_time = time.time() - start_time\n        \n        # Record in all tracking systems\n        self.clock.end_problem(problem_id)\n        self.tracker.record(problem_id, difficulty, adjusted_budget, total_time, answer, confidence)\n        self.config.record_result(problem_id, difficulty, total_time, confidence > 0.5, confidence)\n        self.review_queue.add(problem_id, problem, answer, confidence, total_time)\n        \n        model_used = \"fast_math+grpo\" if need_swap else \"fast_math\"\n        self.all_answers[problem_id] = (answer, confidence, model_used)\n        \n        self.problems_solved += 1\n        \n        # Print summary\n        print(f\"\\n  {stopwatch.summary()}\")\n        print(f\"  Tracker: {self.tracker.get_status()}\")\n        print(f\"  {self.model_manager.get_swap_stats()}\")\n        print(f\"  ANSWER: {answer}\")\n        \n        # Check milestones and alerts\n        for milestone in self.clock.check_milestones():\n            print(f\"\\n  {milestone}\")\n        for alert in self.clock.check_time_alerts():\n            print(f\"\\n  {alert}\")\n        \n        return answer\n    \n    def run_second_pass(self) -> Dict[str, int]:\n        \"\"\"\n        Second pass: Review low-confidence problems with GRPO.\n        Only runs if time permits.\n        \"\"\"\n        remaining = self.clock.remaining()\n        review_budget = self.config.optimizer.get_review_time_budget()\n        \n        if review_budget < 120:\n            print(\"Insufficient time for second pass\")\n            return {}\n        \n        candidates = self.review_queue.get_review_candidates(review_budget)\n        if not candidates:\n            print(\"No low-confidence problems to review\")\n            return {}\n        \n        print(f\"\\n{'='*60}\")\n        print(f\"SECOND PASS: GRPO REVIEW\")\n        print(f\"Reviewing {len(candidates)} problems | Budget: {review_budget/60:.1f}min\")\n        print(f\"{'='*60}\")\n        \n        # Swap to GRPO for review\n        self.model_manager.load_model(\"grpo\")\n        \n        corrections = {}\n        for problem_id, problem_text, old_answer, old_conf, _ in candidates:\n            if self.clock.remaining() < 60:\n                break\n            \n            print(f\"\\nReview: {problem_id} (was {old_answer}, conf={old_conf:.2f})\")\n            \n            new_candidates = [old_answer]  # Include original\n            for temp in [0.3, 0.5]:\n                try:\n                    response = self.generate(problem_text, temperature=temp)\n                    if response:\n                        code = extract_code(response)\n                        if code:\n                            result, _ = execute_code(code, timeout=20)\n                            if result is not None:\n                                new_candidates.append(result)\n                        else:\n                            text_ans = extract_text_answer(response)\n                            if text_ans:\n                                new_candidates.append(text_ans)\n                except:\n                    pass\n            \n            if len(new_candidates) > 1:\n                new_answer, new_conf, _ = select_answer(new_candidates, threshold=0.05)\n                if new_answer != old_answer and new_conf > old_conf:\n                    print(f\"  Correcting: {old_answer} -> {new_answer}\")\n                    corrections[problem_id] = new_answer\n                    self.all_answers[problem_id] = (new_answer, new_conf, \"grpo_review\")\n        \n        # Swap back to Fast-Math\n        self.model_manager.load_model(\"fast_math\")\n        \n        return corrections\n    \n    def get_final_summary(self) -> str:\n        \"\"\"Get final competition summary.\"\"\"\n        # Count by confidence\n        high_conf = sum(1 for a, c, m in self.all_answers.values() if c >= 0.7)\n        med_conf = sum(1 for a, c, m in self.all_answers.values() if 0.5 <= c < 0.7)\n        low_conf = sum(1 for a, c, m in self.all_answers.values() if c < 0.5)\n        \n        # Count by model\n        fast_math_only = sum(1 for a, c, m in self.all_answers.values() if m == \"fast_math\")\n        with_grpo = sum(1 for a, c, m in self.all_answers.values() if \"grpo\" in m)\n        \n        lines = [\n            \"\\n\" + \"=\" * 60,\n            \"FINAL COMPETITION SUMMARY\",\n            \"=\" * 60,\n            self.clock.get_display(),\n            \"\",\n            f\"Problems solved: {self.problems_solved}/{self.num_problems}\",\n            f\"  High confidence (\u22650.7): {high_conf}\",\n            f\"  Medium confidence (0.5-0.7): {med_conf}\",\n            f\"  Low confidence (<0.5): {low_conf}\",\n            \"\",\n            f\"Model usage:\",\n            f\"  Fast-Math only: {fast_math_only}\",\n            f\"  With GRPO assist: {with_grpo}\",\n            f\"  {self.model_manager.get_swap_stats()}\",\n            \"\",\n            f\"Swap triggers: {len(self.swap_triggers)}\",\n            \"\",\n            f\"Loop intervention: {loop_intervenor.get_stats()}\",\n        ]\n        \n        if self.swap_triggers:\n            for pid, reason in self.swap_triggers[:5]:\n                lines.append(f\"  - {pid}: {reason}\")\n            if len(self.swap_triggers) > 5:\n                lines.append(f\"  ... and {len(self.swap_triggers) - 5} more\")\n        \n        lines.extend([\n            \"\",\n            self.tracker.get_status(),\n            self.config.get_status(),\n            \"=\" * 60\n        ])\n        \n        return \"\\n\".join(lines)\n\n# Initialize solver with model manager\nsolver = BudgetEnforcedSolver(model_manager, use_extended_thinking=True)\n\nprint(\"\\nSmart Swap Solver: OK\")\nprint(f\"  Primary: Fast-Math-R1-14B-AWQ\")\nprint(f\"  Secondary: 14B-GRPO-Merged-AWQ\")\nprint(f\"  Swap threshold: confidence < {CONFIDENCE_SWAP_THRESHOLD}\")\nprint(f\"  Code fail threshold: {CODE_FAIL_SWAP_THRESHOLD}+ failures\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-api",
   "metadata": {},
   "outputs": [],
   "source": "# CELL 6: Kaggle API Interface with Budget Tracking\nimport polars as pl\n\ndef predict(id_: pl.DataFrame, question: pl.DataFrame) -> pl.DataFrame:\n    \"\"\"Kaggle API predict function with full budget tracking.\"\"\"\n    problem_id = str(id_.item())\n    problem_text = question.item()\n    \n    try:\n        answer = solver.solve(problem_text, problem_id)\n    except Exception as e:\n        print(f\"  CRITICAL ERROR: {e}\")\n        traceback.print_exc()\n        answer = FALLBACK_ANSWER\n    \n    answer = max(ANSWER_MIN, min(ANSWER_MAX, int(answer)))\n    \n    return pl.DataFrame({'id': problem_id, 'answer': answer})\n\nprint(\"API Interface: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-server",
   "metadata": {},
   "outputs": [],
   "source": "# CELL 7: Start Server with Full Budget Management\nimport kaggle_evaluation.aimo_3_inference_server\nimport json\nimport csv\n\n# ============================================================================\n# TEST MODE TOGGLE\n# ============================================================================\nRUN_REFERENCE = False   # Official 10 reference problems\nRUN_TRIAD_DEV = False   # Your 50 custom problems from triad-dev\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"RYANAIMO v0.3.0 - BUDGET ENFORCED MAXIMUM POWER MODE\")\nprint(\"=\" * 60)\nprint(f\"Model: Fast-Math-R1-14B-AWQ\")\nprint(f\"Total Budget: 5 hours | Target: 4-4.5 hours\")\nprint(f\"Strategy: Bayesian calibration + Adaptive pacing\")\nprint(\"=\" * 60)\n\n# Display initial clock\ndisplay_clock()\n\nserver = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    # === COMPETITION MODE (Private Set) ===\n    print(\"\\nMODE: Competition (private set)\")\n    print(\"Starting solver...\")\n    server.serve()\n    \n    # After serving, run second pass if time permits\n    corrections = solver.run_second_pass()\n    if corrections:\n        print(f\"\\nSecond pass made {len(corrections)} corrections\")\n    \n    # Print final summary\n    print(solver.get_final_summary())\n\nelif RUN_TRIAD_DEV:\n    # === YOUR 50 AIMO-CALIBER PROBLEMS FROM TRIAD-DEV ===\n    print(\"\\nMODE: Triad-Dev Test (50 problems)\")\n    \n    test_file = f\"{TRIAD_DEV_PATH}/test_dataset/test.jsonl\"\n    answers_file = f\"{TRIAD_DEV_PATH}/test_dataset/answers.json\"\n    \n    with open(answers_file, 'r') as f:\n        answers = json.load(f)\n    \n    problems = []\n    with open(test_file, 'r') as f:\n        for line in f:\n            problems.append(json.loads(line))\n    \n    correct = 0\n    total = len(problems)\n    \n    for prob in problems:\n        pid = prob['id']\n        expected = answers.get(pid, -1)\n        \n        answer = solver.solve(prob['problem'], pid)\n        \n        is_correct = answer == expected\n        if is_correct:\n            correct += 1\n            print(f\"  CORRECT\")\n        else:\n            print(f\"  WRONG (expected {expected})\")\n    \n    # Run second pass\n    corrections = solver.run_second_pass()\n    \n    # Recalculate with corrections\n    for pid, new_answer in corrections.items():\n        expected = answers.get(pid, -1)\n        old_answer = solver.all_answers.get(pid, (0, 0))[0]\n        if new_answer == expected and old_answer != expected:\n            correct += 1\n        elif new_answer != expected and old_answer == expected:\n            correct -= 1\n    \n    print(solver.get_final_summary())\n    print(f\"\\nTRIAD-DEV SCORE: {correct}/{total} ({100*correct/total:.0f}%)\")\n\nelif RUN_REFERENCE:\n    # === OFFICIAL 10 REFERENCE PROBLEMS ===\n    print(\"\\nMODE: Reference Test (10 official problems)\")\n    reference_csv = f\"{COMPETITION_PATH}/reference.csv\"\n    \n    with open(reference_csv, 'r') as f:\n        reader = csv.DictReader(f)\n        problems = list(reader)\n    \n    correct = 0\n    total = len(problems)\n    \n    for prob in problems:\n        expected = int(prob['answer'])\n        answer = solver.solve(prob['problem'], prob['id'])\n        \n        if answer == expected:\n            correct += 1\n            print(f\"  CORRECT\")\n        else:\n            print(f\"  WRONG (expected {expected})\")\n    \n    print(solver.get_final_summary())\n    print(f\"\\nREFERENCE SCORE: {correct}/{total} ({100*correct/total:.0f}%)\")\n\nelse:\n    # === DEFAULT: Quick test (3 problems from test.csv) ===\n    print(\"\\nMODE: Quick Test (3 problems from test.csv)\")\n    test_csv = f\"{COMPETITION_PATH}/test.csv\"\n    server.run_local_gateway((test_csv,))\n    \n    print(solver.get_final_summary())"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}