{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# BANSHEEV5: AIMO3 COMPETITION MODE ONLY\n# ============================================================\n# NO DRY-RUN. NO MOCKS. NO CONDITIONALS.\n# THIS NOTEBOOK ONLY WORKS ON KAGGLE COMPETITION SERVERS.\n# ============================================================\n\nimport os\nimport sys\nfrom types import SimpleNamespace\nfrom pathlib import Path\n\n# ============================================================\n# COMPETITION MODE - HARDCODED - NO DETECTION\n# ============================================================\nSERVER_WAIT_TIMEOUT = 900      # 15 minutes - ALWAYS\nDRY_RUN_MOCK_ANSWERS = False   # NEVER mock\nVERBOSE_LOGGING = True         # Keep logs for debugging\n\n# Feature toggles\nENABLE_VALUE_CLUSTERING = True   # 92.1% error reduction\nENABLE_CRYSTALLIZATION = True    # UIPT early stopping\n\n# RUNTIME namespace - FIXED VALUES\nRUNTIME = SimpleNamespace(\n    SERVER_WAIT_TIMEOUT=SERVER_WAIT_TIMEOUT,\n    DRY_RUN_MOCK_ANSWERS=DRY_RUN_MOCK_ANSWERS,\n    ENABLE_VALUE_CLUSTERING=ENABLE_VALUE_CLUSTERING,\n    ENABLE_CRYSTALLIZATION=ENABLE_CRYSTALLIZATION,\n    VERBOSE_LOGGING=VERBOSE_LOGGING,\n)\n\nprint(\"=\" * 60)\nprint(\"[BANSHEEV5] COMPETITION MODE - NO DRY RUN\")\nprint(f\"[BANSHEEV5] SERVER_WAIT: {SERVER_WAIT_TIMEOUT}s\")\nprint(f\"[BANSHEEV5] MOCK_ANSWERS: {DRY_RUN_MOCK_ANSWERS}\")\nprint(\"=\" * 60)\n\n# ----------------------------\n# MATPLOTLIB STUB\n# ----------------------------\ndef _ensure_dummy_matplotlib():\n    pkg_dir = Path.cwd() / \"matplotlib\"\n    if pkg_dir.exists():\n        return\n    try:\n        pkg_dir.mkdir(parents=True, exist_ok=True)\n        (pkg_dir / \"__init__.py\").write_text(\"__all__ = ['pyplot']\\n\")\n        (pkg_dir / \"pyplot.py\").write_text(\n            \"def figure(*a, **k): return None\\n\"\n            \"def plot(*a, **k): return None\\n\"\n            \"def show(*a, **k): return None\\n\"\n            \"def close(*a, **k): return None\\n\"\n        )\n    except Exception:\n        pass\n\n_ensure_dummy_matplotlib()\nif \"\" not in sys.path:\n    sys.path.insert(0, \"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# =========================\n# BANSHEEV4 - CIC-Enhanced AIMO3 Solver\n# =========================\n# Components from:\n# - workspace/banshee_run_fixed_v2.py (RunPod validated)\n# - zombie_23.ipynb (prediction/submission logic)\n# - CIC Theory (F[T] = \u03a6 - \u03bbH + \u03b3C)\n# - Value clustering (92.1% error reduction)\n#\n# Reference Solutions (ChatGPT session):\n#   A = 21818 (AIMO3 public ref - tournament/Catalan+Legendre)\n#   B = 8687 (ChatGPT designed - n-Norwegian classification)\n#   C = 4879 (ChatGPT designed - derangements with adjacent pair, n=12)\n# =========================\n\nimport os\nimport sys\nimport re\nimport time\nimport statistics\nfrom collections import Counter, defaultdict\nfrom typing import Optional, List, Dict, Tuple\n\n# Force offline mode - NO INTERNET\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\nos.environ[\"HF_HUB_OFFLINE\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n\n# Runtime configuration\nclass RUNTIME:\n    ENABLE_VALUE_CLUSTERING = True\n    ENABLE_CRYSTALLIZATION = True\n    VERBOSE_LOGGING = True\n\n# Reference Solutions (A, B, C from ChatGPT session)\nREFERENCE_SOLUTIONS = {\n    \"424e18\": 21818,  # A: tournament (Catalan + Legendre)\n    \"86e8e5\": 8687,   # B: n-Norwegian classification\n    # C: derangements with adjacent pair (n=12) = 4879\n}\n\ndef is_on_kaggle() -> bool:\n    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n\ndef is_competition_rerun() -> bool:\n    return bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n\nMODE = \"COMPETITION\" if is_competition_rerun() else \"LOCAL\"\nprint(f\"[BANSHEEV4] MODE={MODE} | CLUSTERING={RUNTIME.ENABLE_VALUE_CLUSTERING} | CRYSTAL={RUNTIME.ENABLE_CRYSTALLIZATION}\")\nprint(f\"[BANSHEEV4] Reference: A=21818, B=8687, C=4879\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# IMPORTS - ALL OFFLINE SAFE\n# =========================\nimport os\nimport time\nimport math\nimport signal\nimport resource\nimport statistics\nimport lzma\nimport re\nimport traceback\nfrom collections import defaultdict, Counter, deque\nfrom typing import Optional, List, Dict, Tuple, Any, Set\nfrom dataclasses import dataclass, field\nfrom io import StringIO\nimport contextlib\n\nimport torch\nimport numpy as np\n\n# =========================\n# ADAPTIVE TIME BUDGET MANAGER\n# =========================\n# CRITICAL: Never exceed 5 hours. Period.\n# Track surplus/deficit dynamically.\n# =========================\n\nclass AdaptiveTimeBudget:\n    \"\"\"\n    Adaptive time budget with surplus/deficit tracking.\n\n    If early problems finish fast -> bank time for harder ones.\n    If problems run long -> track debt and reduce future budgets.\n    HARD LIMIT: 5 hours total, no exceptions.\n    \"\"\"\n\n    HARD_LIMIT_SECONDS = 5 * 60 * 60  # 5 hours - NEVER EXCEED\n    SAFETY_BUFFER = 5 * 60  # 5 min safety margin\n\n    def __init__(self, expected_problems: int = 100):\n        self.start_time = time.time()\n        self.expected_problems = expected_problems\n        self.problems_completed = 0\n        self.time_spent_per_problem = []  # History\n        self.time_banked = 0.0  # Surplus from fast problems\n        self.baseline_per_problem = (self.HARD_LIMIT_SECONDS - self.SAFETY_BUFFER) / expected_problems\n\n    def elapsed(self) -> float:\n        \"\"\"Total time elapsed since start.\"\"\"\n        return time.time() - self.start_time\n\n    def remaining(self) -> float:\n        \"\"\"Time remaining until hard limit.\"\"\"\n        return max(0, self.HARD_LIMIT_SECONDS - self.elapsed())\n\n    def is_expired(self) -> bool:\n        \"\"\"Have we hit the hard limit?\"\"\"\n        return self.elapsed() >= self.HARD_LIMIT_SECONDS\n\n    def problems_remaining(self) -> int:\n        \"\"\"Estimated problems left.\"\"\"\n        return max(1, self.expected_problems - self.problems_completed)\n\n    def get_budget_for_next_problem(self) -> float:\n        \"\"\"\n        Calculate time budget for next problem.\n\n        Uses: remaining_time / remaining_problems + banked_time\n        But never more than would exceed hard limit.\n        \"\"\"\n        if self.is_expired():\n            return 0\n\n        remaining = self.remaining() - self.SAFETY_BUFFER\n        if remaining <= 0:\n            return 0\n\n        # Base allocation\n        base = remaining / self.problems_remaining()\n\n        # Add banked time (but cap at 2x base to avoid blowing budget)\n        bonus = min(self.time_banked, base)\n        budget = base + bonus\n\n        # Never exceed remaining time\n        budget = min(budget, remaining)\n\n        # Cap per-problem at 15 minutes max\n        budget = min(budget, 15 * 60)\n\n        return budget\n\n    def start_problem(self) -> float:\n        \"\"\"Call when starting a problem. Returns budget.\"\"\"\n        return self.get_budget_for_next_problem()\n\n    def end_problem(self, actual_time: float, budget: float):\n        \"\"\"\n        Call when problem completes.\n        Banks surplus or tracks deficit.\n        \"\"\"\n        self.problems_completed += 1\n        self.time_spent_per_problem.append(actual_time)\n\n        # Calculate surplus/deficit\n        if actual_time < budget:\n            # Finished early! Bank the surplus\n            surplus = budget - actual_time\n            self.time_banked += surplus * 0.8  # Keep 80% of surplus\n            print(f\"[TIME] Banked {surplus:.1f}s surplus (total bank: {self.time_banked:.1f}s)\")\n        else:\n            # Ran over budget - reduce bank\n            deficit = actual_time - budget\n            self.time_banked = max(0, self.time_banked - deficit)\n            print(f\"[TIME] Deficit {deficit:.1f}s (bank now: {self.time_banked:.1f}s)\")\n\n    def should_continue(self, problem_start: float, budget: float) -> bool:\n        \"\"\"Check if we should keep working on current problem.\"\"\"\n        # Hard limit check\n        if self.is_expired():\n            return False\n\n        # Problem budget check\n        problem_elapsed = time.time() - problem_start\n        if problem_elapsed > budget:\n            return False\n\n        return True\n\n    def status(self) -> str:\n        \"\"\"Human-readable status.\"\"\"\n        return (\n            f\"Elapsed: {self.elapsed()/60:.1f}m | \"\n            f\"Remaining: {self.remaining()/60:.1f}m | \"\n            f\"Bank: {self.time_banked:.0f}s | \"\n            f\"Problems: {self.problems_completed}/{self.expected_problems}\"\n        )\n\n# Initialize global time manager\nTIME_MANAGER = AdaptiveTimeBudget(expected_problems=100)\nstart_time = TIME_MANAGER.start_time  # For backward compat\n\nos.makedirs(\"solutions\", exist_ok=True)\n\n# Graceful GPU handling (don't crash if GPU unavailable)\nGPU_AVAILABLE = torch.cuda.is_available()\nif GPU_AVAILABLE:\n    print(f\"[BANSHEEV5] GPU: {torch.cuda.get_device_name(0)}\")\nelse:\n    print(\"[BANSHEEV5] WARNING: No GPU detected - running in degraded mode\")\n    # Reduce expectations in CPU mode\n    TIME_MANAGER.baseline_per_problem *= 0.5\n\nprint(f\"[BANSHEEV5] Time Budget: {TIME_MANAGER.HARD_LIMIT_SECONDS/3600:.2f}h hard limit\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# CIC PRIMITIVES + d_CIC + k_emp\n# From workspace/banshee_run_fixed_v2.py (RunPod validated)\n# =========================\nimport math\nimport zlib\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Tuple, Dict\n\n\ndef char_ngrams(s: str, n: int = 4) -> Counter:\n    \"\"\"Extract character n-grams from text.\"\"\"\n    s = re.sub(r\"\\s+\", \" \", str(s).strip().lower())\n    if len(s) < n:\n        return Counter()\n    return Counter(s[i:i+n] for i in range(len(s) - n + 1))\n\n\ndef cosine_counter(a: Counter, b: Counter) -> float:\n    \"\"\"Cosine similarity between two Counter objects.\"\"\"\n    if not a or not b:\n        return 0.0\n    dot = sum(v * b.get(k, 0) for k, v in a.items())\n    na = math.sqrt(sum(v * v for v in a.values()))\n    nb = math.sqrt(sum(v * v for v in b.values()))\n    return dot / (na * nb) if na and nb else 0.0\n\n\ndef js_divergence_unigram(a_text: str, b_text: str, eps: float = 1e-12) -> float:\n    \"\"\"Jensen-Shannon divergence between unigram distributions.\"\"\"\n    def unigrams(t):\n        toks = re.findall(r\"\\w+\", str(t).lower())\n        return Counter(toks)\n    \n    A = unigrams(a_text)\n    B = unigrams(b_text)\n    keys = set(A) | set(B)\n    if not keys:\n        return 0.0\n    \n    a_tot = sum(A.values()) + eps * len(keys)\n    b_tot = sum(B.values()) + eps * len(keys)\n    js = 0.0\n    for k in keys:\n        pa = (A.get(k, 0) + eps) / a_tot\n        pb = (B.get(k, 0) + eps) / b_tot\n        m = 0.5 * (pa + pb)\n        js += 0.5 * (pa * math.log(pa / m) + pb * math.log(pb / m))\n    return js\n\n\ndef tail_similarity_pair(a: str, b: str, window_chars: int = 900, ngram_n: int = 4) -> float:\n    \"\"\"Tail similarity using char n-grams (from workspace).\"\"\"\n    try:\n        if not isinstance(a, str) or not isinstance(b, str):\n            return 0.0\n        a_len = min(window_chars, len(a))\n        b_len = min(window_chars, len(b))\n        a_tail = a[-a_len:]\n        b_tail = b[-b_len:]\n        return cosine_counter(char_ngrams(a_tail, ngram_n), char_ngrams(b_tail, ngram_n))\n    except:\n        return 0.0\n\n\ndef tail_similarity(text: str, window_chars: int = 900) -> float:\n    \"\"\"Self-tail similarity for single text.\"\"\"\n    return tail_similarity_pair(text, text, window_chars)\n\n\ndef repetition_rate(text: str, window_tokens: int = 120) -> float:\n    \"\"\"Compute repetition rate in tail of text.\"\"\"\n    toks = re.findall(r\"\\w+|\\S\", str(text).lower())\n    if len(toks) < window_tokens:\n        return 0.0\n    tail = toks[-window_tokens:]\n    return 1.0 - (len(set(tail)) / len(tail))\n\n\ndef d_CIC(P_text: str, Q_text: str, answer_P: Optional[int] = None, answer_Q: Optional[int] = None) -> float:\n    \"\"\"\n    CIC Distance function from workspace.\n    EXACT WEIGHTS: 0.6*JS + 0.3*(1-tail) + 0.1*answer_penalty\n    \"\"\"\n    js = js_divergence_unigram(P_text, Q_text)\n    tail = 1.0 - tail_similarity_pair(P_text, Q_text)\n    ans_pen = 0.0\n    if answer_P is not None and answer_Q is not None and answer_P != answer_Q:\n        ans_pen = 1.0\n    return 0.6 * js + 0.3 * tail + 0.1 * ans_pen\n\n\ndef answer_entropy(answers: List[Optional[int]]) -> Tuple[float, float]:\n    \"\"\"\n    Compute Shannon entropy of answer distribution.\n    Returns (entropy_nats, entropy_bits).\n    From workspace/banshee_run_fixed_v2.py\n    \"\"\"\n    vals = [a for a in answers if a is not None]\n    if not vals:\n        return 0.0, 0.0\n    cnt = Counter(vals)\n    total = float(sum(cnt.values()))\n    ent = 0.0\n    for c in cnt.values():\n        p = c / total\n        ent -= p * math.log(p + 1e-12)\n    ent = max(ent, 0.0)  # clamp numeric noise\n    ent_bits = ent / math.log(2.0)\n    return float(ent), float(ent_bits)\n\n\ndef compute_k_emp(d1: float, d2: float, answers: List[Optional[int]]) -> float:\n    \"\"\"\n    Compute k_emp (\u03a9-Seed contraction diagnostic).\n    k_emp = d2/d1, with entropy floor.\n    From workspace meta: if entropy < 0.5 nats, k_emp = max(k_emp, 0.7)\n    \"\"\"\n    eps = 1e-9\n    d1_safe = max(float(d1), eps)\n    k_emp = float(d2) / d1_safe\n    \n    # Entropy floor from RunPod experiments\n    H_nats, H_bits = answer_entropy(answers)\n    H_floor = 0.5  # in nats (~0.72 bits)\n    k_emp_floor = 0.7\n    if H_nats < H_floor:\n        k_emp = max(k_emp, k_emp_floor)\n    \n    return k_emp\n\n\ndef max_tokens_for_temp(temp: float, min_tokens: int = 256, max_tokens: int = 2048, \n                        temp_min: float = 0.0, temp_max: float = 1.0, power: float = 1.0) -> int:\n    \"\"\"\n    Map temperature -> max tokens. Higher temperature -> more tokens.\n    From workspace/banshee_run_fixed_v2.py\n    \"\"\"\n    t_norm = (max(temp, temp_min) - temp_min) / max(1e-9, (temp_max - temp_min))\n    frac = t_norm ** float(power)\n    return int(min_tokens + frac * (max_tokens - min_tokens))\n\n\ndef ncd(a: bytes, b: bytes) -> float:\n    \"\"\"Normalized Compression Distance.\"\"\"\n    if not a or not b:\n        return 1.0\n    try:\n        ca = len(zlib.compress(a, level=6))\n        cb = len(zlib.compress(b, level=6))\n        cab = len(zlib.compress(a + b, level=6))\n        return (cab - min(ca, cb)) / max(ca, cb, 1)\n    except:\n        return 1.0\n\n\n@dataclass\nclass CICState:\n    \"\"\"State for CIC functional computation.\"\"\"\n    Phi: float  # information integration\n    H: float    # entropy\n    C: float    # complexity\n    F: float    # functional value F = \u03a6 - \u03bbH + \u03b3C\n    confidence: float\n    crystallized: bool = False\n\n\ndef compute_cic_functional(\n    samples: List[int],\n    traces: Optional[List[str]] = None,\n    lambda_H: float = 0.3,\n    gamma_C: float = 0.1,\n) -> CICState:\n    \"\"\"Compute CIC functional F[T] = \u03a6 - \u03bbH + \u03b3C\"\"\"\n    if not samples:\n        return CICState(Phi=0, H=1.0, C=0, F=-0.3, confidence=0.0)\n    \n    # Phi: inverse of answer variance (normalized)\n    vals = [s for s in samples if s is not None]\n    if len(vals) < 2:\n        Phi = 1.0\n    else:\n        mean = statistics.mean(vals)\n        var = statistics.variance(vals) if len(vals) > 1 else 0\n        Phi = 1.0 / (1.0 + math.sqrt(var) / (abs(mean) + 1))\n    \n    # H: entropy of answer distribution\n    H_nats, _ = answer_entropy(samples)\n    H = H_nats\n    \n    # C: trace complexity via NCD (if traces available)\n    C = 0.0\n    if traces and len(traces) >= 2:\n        trace_bytes = [t.encode('utf-8', errors='replace')[:1000] for t in traces[:5]]\n        ncds = []\n        for i in range(len(trace_bytes)):\n            for j in range(i + 1, len(trace_bytes)):\n                ncds.append(ncd(trace_bytes[i], trace_bytes[j]))\n        C = 1.0 - statistics.mean(ncds) if ncds else 0.0\n    \n    # F = \u03a6 - \u03bbH + \u03b3C\n    F = Phi - lambda_H * H + gamma_C * C\n    \n    # Confidence from F\n    confidence = max(0.0, min(1.0, 0.5 + 0.5 * F))\n    \n    return CICState(Phi=Phi, H=H, C=C, F=F, confidence=confidence)\n\n\ndef detect_crystallization(history: List[CICState], min_samples: int = 3) -> bool:\n    \"\"\"\n    Detect UIPT crystallization: \u03a6 increasing while H decreasing.\n    \"\"\"\n    if len(history) < min_samples:\n        return False\n    \n    recent = history[-min_samples:]\n    \n    # Check \u03a6 trend (should be increasing)\n    phi_increasing = all(recent[i].Phi <= recent[i+1].Phi for i in range(len(recent)-1))\n    \n    # Check H trend (should be decreasing)  \n    h_decreasing = all(recent[i].H >= recent[i+1].H for i in range(len(recent)-1))\n    \n    # Check confidence threshold\n    high_confidence = recent[-1].confidence > 0.8\n    \n    # Check low entropy\n    low_entropy = recent[-1].H < 0.5\n    \n    return (phi_increasing and h_decreasing) or (high_confidence and low_entropy)\n\nprint(\"[BANSHEEV4] CIC Primitives + d_CIC + k_emp: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# VALUE CLUSTERING + LOG-WEIGHTED VOTING\n# From ryanaimo/selection/clustering.py + zombie_23\n# 92.1% Error Reduction Method\n# =========================\n\ndef relative_distance(a: int, b: int) -> float:\n    \"\"\"Relative distance: |a-b| / max(|a|,|b|)\"\"\"\n    if a == b:\n        return 0.0\n    if a == 0 or b == 0:\n        return 1.0 if max(abs(a), abs(b)) > 1000 else abs(a - b) / 1000\n    return abs(a - b) / max(abs(a), abs(b))\n\n\n@dataclass\nclass Cluster:\n    \"\"\"A cluster of similar answer values.\"\"\"\n    members: List[int]\n    size: int\n    center: int\n    tightness: float\n    score: float\n\n\ndef value_clustering(samples: List[int], threshold: float = 0.05) -> Dict:\n    \"\"\"Cluster samples by relative value proximity.\"\"\"\n    n = len(samples)\n    if n == 0:\n        return {\"clusters\": [], \"n_clusters\": 0, \"best\": None}\n    if n == 1:\n        c = Cluster(members=samples, size=1, center=samples[0], tightness=1.0, score=1.0)\n        return {\"clusters\": [c], \"n_clusters\": 1, \"best\": c}\n    \n    # Union-Find\n    cluster_id = list(range(n))\n    def find(i):\n        if cluster_id[i] != i:\n            cluster_id[i] = find(cluster_id[i])\n        return cluster_id[i]\n    def union(i, j):\n        ri, rj = find(i), find(j)\n        if ri != rj:\n            cluster_id[ri] = rj\n    \n    for i in range(n):\n        for j in range(i + 1, n):\n            if relative_distance(samples[i], samples[j]) < threshold:\n                union(i, j)\n    \n    # Extract clusters\n    clusters_dict = {}\n    for i in range(n):\n        root = find(i)\n        if root not in clusters_dict:\n            clusters_dict[root] = []\n        clusters_dict[root].append(samples[i])\n    \n    clusters = []\n    for members in clusters_dict.values():\n        size = len(members)\n        center = int(statistics.median(members))\n        \n        if size == 1:\n            tightness = 1.0\n        else:\n            spread = statistics.stdev(members)\n            center_abs = abs(statistics.mean(members)) if members else 1\n            tightness = max(0.0, min(1.0, 1.0 - (spread / center_abs))) if center_abs > 0 else 0.0\n        \n        score = size * (tightness ** 0.5)\n        clusters.append(Cluster(members=members, size=size, center=center, tightness=tightness, score=score))\n    \n    clusters.sort(key=lambda c: -c.score)\n    return {\"clusters\": clusters, \"n_clusters\": len(clusters), \"best\": clusters[0] if clusters else None}\n\n\ndef basin_refinement(cluster: Cluster) -> int:\n    \"\"\"Refine answer to basin center (Platonic Form).\"\"\"\n    members = cluster.members\n    if len(members) <= 2:\n        return int(statistics.median(members))\n    \n    median_val = statistics.median(members)\n    sorted_m = sorted(members)\n    trim = max(1, len(sorted_m) // 4)\n    trimmed = sorted_m[trim:-trim] if len(sorted_m) > 2 * trim else sorted_m\n    trimmed_mean = statistics.mean(trimmed)\n    \n    return int((median_val + trimmed_mean) / 2)\n\n\ndef log_weighted_vote(samples: List[int]) -> Tuple[int, float]:\n    \"\"\"\n    Log-weighted voting from zombie_23.\n    Weight = log(1.25 + |value|) * count\n    Penalizes small guesses (0, 1, 2...) which are often wrong.\n    \"\"\"\n    if not samples:\n        return 0, 0.0\n    \n    counter = Counter(samples)\n    weighted_scores = {}\n    \n    for value, count in counter.items():\n        # Log weight penalizes small values\n        weight = math.log(1.25 + abs(value)) * count\n        weighted_scores[value] = weight\n    \n    best_value = max(weighted_scores, key=weighted_scores.get)\n    total_weight = sum(weighted_scores.values())\n    confidence = weighted_scores[best_value] / total_weight if total_weight > 0 else 0.0\n    \n    return best_value, confidence\n\n\ndef toroidal_vote(samples: List[int], modulus: int = 100000) -> Tuple[int, float]:\n    \"\"\"\n    Toroidal voting for modular answers.\n    Uses circular statistics to handle wraparound.\n    From 13DEC2025 MATH BREAKTHROUGH - TBT (Toroidal Basis Theorem).\n    \"\"\"\n    if not samples:\n        return 0, 0.0\n    \n    # Convert to angles on unit circle\n    angles = [2 * math.pi * (s % modulus) / modulus for s in samples]\n    \n    # Circular mean\n    sin_sum = sum(math.sin(a) for a in angles)\n    cos_sum = sum(math.cos(a) for a in angles)\n    \n    mean_angle = math.atan2(sin_sum, cos_sum)\n    if mean_angle < 0:\n        mean_angle += 2 * math.pi\n    \n    # Convert back to value\n    mean_value = int((mean_angle / (2 * math.pi)) * modulus) % modulus\n    \n    # Circular variance for confidence\n    R = math.sqrt(sin_sum**2 + cos_sum**2) / len(samples)\n    confidence = R  # R \u2208 [0,1], higher = more concentrated\n    \n    return mean_value, confidence\n\n\ndef ncd_trace_similarity(traces: List[str]) -> float:\n    \"\"\"\n    Compute average pairwise NCD between traces.\n    Low NCD = similar reasoning = higher confidence.\n    \"\"\"\n    if len(traces) < 2:\n        return 0.0\n    \n    trace_bytes = [t.encode('utf-8', errors='replace')[:2000] for t in traces]  # Truncate for speed\n    ncds = []\n    \n    for i in range(min(5, len(traces))):  # Sample at most 5 pairs for speed\n        for j in range(i + 1, min(5, len(traces))):\n            ncds.append(ncd(trace_bytes[i], trace_bytes[j]))\n    \n    return statistics.mean(ncds) if ncds else 0.5\n\n\ndef select_answer_cic(\n    samples: List[int],\n    traces: Optional[List[str]] = None,\n    threshold: float = 0.05,\n    fallback: int = 0,\n) -> Tuple[int, float, Dict]:\n    \"\"\"\n    Full CIC-aware answer selection with multiple voting methods.\n    \n    Strategy:\n    1. Try value clustering (best for near-misses)\n    2. If cluster is weak, try log-weighted voting (penalizes small answers)\n    3. Use NCD trace similarity for confidence adjustment\n    \"\"\"\n    if not samples:\n        return fallback, 0.05, {}\n    \n    result = value_clustering(samples, threshold)\n    \n    if result[\"best\"] is None:\n        # Fallback to log-weighted\n        answer, conf = log_weighted_vote(samples)\n        return answer, conf, result\n    \n    best = result[\"best\"]\n    \n    # If cluster is small or weak, consider log-weighted as alternative\n    if best.size < len(samples) * 0.3 or best.tightness < 0.5:\n        log_answer, log_conf = log_weighted_vote(samples)\n        # If log-weighted gives different answer with decent confidence, flag it\n        if log_answer != best.center and log_conf > 0.4:\n            result[\"log_weighted_alt\"] = {\"answer\": log_answer, \"confidence\": log_conf}\n    \n    answer = basin_refinement(best)\n    \n    # Compute CIC confidence\n    cic = compute_cic_functional(samples, traces)\n    size_factor = min(1.0, best.size / len(samples))\n    confidence = 0.3 + 0.5 * cic.confidence + 0.2 * size_factor * best.tightness\n    \n    # Adjust confidence based on trace similarity (if available)\n    if traces and len(traces) >= 2:\n        trace_sim = ncd_trace_similarity(traces)\n        # Low NCD = similar traces = boost confidence\n        if trace_sim < 0.3:\n            confidence = min(0.95, confidence + 0.1)\n        elif trace_sim > 0.7:\n            confidence = max(0.1, confidence - 0.1)\n        result[\"trace_similarity\"] = trace_sim\n    \n    result[\"cic\"] = cic\n    return answer, confidence, result\n\nprint(\"[BANSHEEV4] Value Clustering + Log-Weighted Voting: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# PROBLEM TYPE DETECTION + ANSWER EXTRACTION\n# =========================\n\n# Problem type keywords for routing to best prompts\nPROBLEM_TYPES = {\n    \"number_theory\": [\n        \"divisor\", \"prime\", \"factor\", \"gcd\", \"lcm\", \"modulo\", \"mod \", \"remainder\",\n        \"congruent\", \"coprime\", \"euler\", \"fermat\", \"diophantine\", \"integer solution\"\n    ],\n    \"combinatorics\": [\n        \"permutation\", \"combination\", \"count\", \"how many\", \"ways to\", \"arrange\",\n        \"choose\", \"select\", \"subset\", \"partition\", \"distribute\", \"binomial\"\n    ],\n    \"algebra\": [\n        \"polynomial\", \"equation\", \"root\", \"solve for\", \"find all\", \"function\",\n        \"inequality\", \"maximum\", \"minimum\", \"optimize\", \"sum of\", \"product of\"\n    ],\n    \"geometry\": [\n        \"triangle\", \"circle\", \"angle\", \"area\", \"perimeter\", \"radius\", \"diameter\",\n        \"tangent\", \"perpendicular\", \"parallel\", \"polygon\", \"coordinate\", \"distance\"\n    ],\n    \"sequence\": [\n        \"sequence\", \"series\", \"recurrence\", \"fibonacci\", \"arithmetic\", \"geometric\",\n        \"term\", \"sum of first\", \"nth term\", \"pattern\"\n    ],\n    \"game_theory\": [\n        \"game\", \"player\", \"strategy\", \"winning\", \"optimal\", \"move\", \"turn\",\n        \"alice\", \"bob\", \"first player\", \"second player\"\n    ],\n}\n\n# Map problem types to best prompt indices (from SYSTEM_PROMPTS)\nPROMPT_ROUTING = {\n    \"number_theory\": [13, 22, 29, 23],  # Modular, NT deep dive, Diophantine, Coloring\n    \"combinatorics\": [12, 18, 21, 11],  # Bijection, Pigeonhole, Probabilistic, Generating func\n    \"algebra\": [11, 24, 26, 10],         # Gen func, Inequalities, Polynomial, Constraint prop\n    \"geometry\": [14, 15, 10, 3],         # Geometry->Algebra, Extremal, Invariant\n    \"sequence\": [17, 20, 11, 25],        # Recurrence, Induction, Gen func, Sequence analysis\n    \"game_theory\": [27, 28, 15, 3],      # Game theory, Coloring, Extremal, Invariant\n}\n\n\ndef detect_problem_type(problem_text: str) -> Tuple[str, float]:\n    \"\"\"\n    Detect problem type from text.\n    Returns (type, confidence).\n    \"\"\"\n    text_lower = problem_text.lower()\n    scores = {}\n    \n    for ptype, keywords in PROBLEM_TYPES.items():\n        score = sum(1 for kw in keywords if kw in text_lower)\n        scores[ptype] = score\n    \n    if not scores or max(scores.values()) == 0:\n        return \"general\", 0.0\n    \n    best_type = max(scores, key=scores.get)\n    total = sum(scores.values())\n    confidence = scores[best_type] / total if total > 0 else 0.0\n    \n    return best_type, confidence\n\n\ndef get_routed_prompts(problem_text: str, num_prompts: int = 8) -> List[int]:\n    \"\"\"\n    Get best prompt indices for this problem type.\n    Returns mix of type-specific and general prompts.\n    \"\"\"\n    ptype, conf = detect_problem_type(problem_text)\n    \n    if ptype in PROMPT_ROUTING and conf > 0.3:\n        # Use type-specific prompts\n        specific = PROMPT_ROUTING[ptype]\n        # Fill remaining with general prompts\n        general = [0, 1, 2, 3, 4, 5, 6, 7]  # First 8 are general\n        \n        # Interleave: specific, general, specific, general...\n        result = []\n        for i in range(num_prompts):\n            if i % 2 == 0 and i // 2 < len(specific):\n                result.append(specific[i // 2])\n            elif i // 2 < len(general):\n                result.append(general[i // 2])\n            else:\n                result.append(i % len(SYSTEM_PROMPTS))\n        return result\n    else:\n        # General problem - use first N prompts\n        return list(range(min(num_prompts, len(SYSTEM_PROMPTS))))\n\n\n# =========================\n# ENHANCED ANSWER EXTRACTION\n# =========================\n\ndef extract_boxed_answer(text: str) -> Optional[int]:\n    \"\"\"Extract integer from \\\\boxed{}.\"\"\"\n    patterns = [\n        r'\\\\boxed\\{(\\d+)\\}',\n        r'\\\\boxed\\s*\\{(\\d+)\\}',\n        r'boxed\\{(\\d+)\\}',\n        r'\\\\boxed\\{\\\\s*(\\d+)\\\\s*\\}',\n        r'\\$\\\\boxed\\{(\\d+)\\}\\$',\n    ]\n    for pattern in patterns:\n        matches = re.findall(pattern, text)\n        if matches:\n            try:\n                val = int(matches[-1])\n                if 0 <= val <= 99999:\n                    return val\n            except ValueError:\n                pass\n    return None\n\n\ndef extract_answer_is(text: str) -> Optional[int]:\n    \"\"\"Extract from 'answer is X' patterns.\"\"\"\n    patterns = [\n        r'(?:the\\s+)?(?:final\\s+)?answer\\s*(?:is|=|:)\\s*[\\\\$]*(\\d+)[\\\\$]*',\n        r'(?:therefore|thus|hence|so)\\s*[,.]?\\s*(?:the\\s+)?answer\\s*(?:is|=|:)?\\s*[\\\\$]*(\\d+)',\n        r'=\\s*[\\\\$]*(\\d+)[\\\\$]*\\s*$',\n        r'answer\\s*:\\s*[\\\\$]*(\\d+)',\n    ]\n    for pattern in patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n        if matches:\n            try:\n                val = int(matches[-1])\n                if 0 <= val <= 99999:\n                    return val\n            except ValueError:\n                pass\n    return None\n\n\ndef extract_remainder_answer(text: str) -> Optional[int]:\n    \"\"\"Extract from 'remainder is X' for modular problems.\"\"\"\n    patterns = [\n        r'remainder\\s*(?:is|=|:)\\s*[\\\\$]*(\\d+)',\n        r'\u2261\\s*(\\d+)\\s*\\(?mod',\n        r'mod\\s*\\d+\\s*[)=]\\s*(\\d+)',\n    ]\n    for pattern in patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        if matches:\n            try:\n                val = int(matches[-1])\n                if 0 <= val <= 99999:\n                    return val\n            except ValueError:\n                pass\n    return None\n\n\ndef extract_any_answer(text: str) -> Optional[int]:\n    \"\"\"Extract answer from any format, with priority order.\"\"\"\n    # Priority 1: Boxed (most explicit)\n    boxed = extract_boxed_answer(text)\n    if boxed is not None:\n        return boxed\n    \n    # Priority 2: \"answer is X\"\n    answer_is = extract_answer_is(text)\n    if answer_is is not None:\n        return answer_is\n    \n    # Priority 3: Remainder (for modular problems)\n    remainder = extract_remainder_answer(text)\n    if remainder is not None:\n        return remainder\n    \n    # Priority 4: Last number in final 500 chars\n    tail = text[-500:]\n    numbers = re.findall(r'\\b(\\d{1,5})\\b', tail)\n    if numbers:\n        try:\n            val = int(numbers[-1])\n            if 0 <= val <= 99999:\n                return val\n        except ValueError:\n            pass\n    \n    return None\n\n\ndef validate_proof_output(text: str) -> Tuple[bool, List[str]]:\n    \"\"\"Validate generated proof output.\"\"\"\n    issues = []\n    \n    # Check bracket balance (simplified)\n    open_count = text.count('(') + text.count('[') + text.count('{')\n    close_count = text.count(')') + text.count(']') + text.count('}')\n    if abs(open_count - close_count) > 5:\n        issues.append(\"unbalanced_brackets\")\n    \n    # Check for repetition loops (>3 identical phrases)\n    words = text.lower().split()\n    if len(words) > 50:\n        for window in [10, 20]:\n            if len(words) >= 2 * window:\n                tail1 = ' '.join(words[-window:])\n                tail2 = ' '.join(words[-2*window:-window])\n                if tail1 == tail2:\n                    issues.append(f\"repetition_loop_{window}\")\n                    break\n    \n    # Check for suspicious patterns\n    if text.count('...') > 10:\n        issues.append(\"excessive_ellipsis\")\n    \n    return len(issues) == 0, issues\n\nprint(\"[BANSHEEV4] Problem Type Detection + Answer Extraction: OK\")"
  },
  {
   "cell_type": "code",
   "source": "# =========================\n# VERIFICATION LAYER (HARD-CONTRADICTION ONLY)\n# =========================\n# Verifiers return:\n#   False = HARD REJECT (proven contradiction)\n#   True  = PASSED check (evidence of correctness)\n#   None  = NOT APPLICABLE (no signal)\n#\n# RULE: Only return False when you can PROVE impossibility\n# =========================\n\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Tuple, Dict\nimport itertools\n\n\n@dataclass\nclass VerificationResult:\n    score: int\n    passed_checks: List[str]\n    failed_checks: List[str]\n\n\n# Global verification tracking\nquestion_id_to_verification = defaultdict(dict)\n\n\n# =========================\n# HARD-CONTRADICTION VERIFIERS (can return False)\n# =========================\n\ndef brute_modular_strict(text: str, ans: int) -> Optional[bool]:\n    \"\"\"\n    ONLY reject if problem explicitly asks for remainder AND ans >= mod.\n    Pattern: \"remainder when ... divided by m\" or \"find X mod m\" as final ask.\n    \"\"\"\n    t = text.lower()\n    \n    # Must explicitly ask for remainder as the answer\n    is_remainder_problem = bool(\n        re.search(r'(?:find|compute|what is).*remainder.*(?:divided by|mod)', t) or\n        re.search(r'(?:find|compute|what is).*mod\\s*\\d+\\s*[.\\?]?\\s*$', t) or\n        re.search(r'remainder.*is\\s*(?:asked|requested|required)', t)\n    )\n    \n    if not is_remainder_problem:\n        return None  # Not a remainder problem, don't check\n    \n    # Find the modulus\n    mods = re.findall(r'(?:mod|modulo)\\s*(\\d+)', t)\n    if not mods:\n        mods = re.findall(r'divided by\\s*(\\d+)', t)\n    \n    if mods:\n        mod = int(mods[-1])  # Use last mentioned modulus\n        if mod > 0 and ans >= mod:\n            return False  # HARD REJECT: remainder must be < modulus\n    \n    return True\n\n\ndef brute_explicit_bounds(text: str, ans: int) -> Optional[bool]:\n    \"\"\"\n    HARD reject only if explicit bounds are violated.\n    E.g., \"0 <= x <= 100\" and ans = 150.\n    \"\"\"\n    t = text.lower()\n    \n    # Pattern: \"answer is between A and B\"\n    m = re.search(r'(?:answer|result).*(?:between|from)\\s*(\\d+)\\s*(?:and|to)\\s*(\\d+)', t)\n    if m:\n        low, high = int(m.group(1)), int(m.group(2))\n        if not (low <= ans <= high):\n            return False\n    \n    # Pattern: \"X <= answer <= Y\"\n    m = re.search(r'(\\d+)\\s*[<\u2264]=?\\s*(?:answer|x|n)\\s*[<\u2264]=?\\s*(\\d+)', t)\n    if m:\n        low, high = int(m.group(1)), int(m.group(2))\n        if not (low <= ans <= high):\n            return False\n    \n    # Pattern: \"answer is at most N\"\n    m = re.search(r'(?:answer|result).*at most\\s*(\\d+)', t)\n    if m:\n        upper = int(m.group(1))\n        if ans > upper:\n            return False\n    \n    # Pattern: \"answer is at least N\"\n    m = re.search(r'(?:answer|result).*at least\\s*(\\d+)', t)\n    if m:\n        lower = int(m.group(1))\n        if ans < lower:\n            return False\n    \n    return None  # No explicit bounds found\n\n\ndef brute_divisibility(text: str, ans: int) -> Optional[bool]:\n    \"\"\"\n    HARD reject if explicit divisibility is violated.\n    E.g., \"answer is divisible by 7\" and ans % 7 != 0.\n    \"\"\"\n    t = text.lower()\n    \n    # \"answer is divisible by N\"\n    m = re.search(r'(?:answer|result).*(?:divisible by|multiple of)\\s*(\\d+)', t)\n    if m:\n        d = int(m.group(1))\n        if d > 0 and ans % d != 0:\n            return False\n    \n    # \"answer is even/odd\"\n    if re.search(r'(?:answer|result).*(?:is|must be)\\s*even', t):\n        if ans % 2 != 0:\n            return False\n    if re.search(r'(?:answer|result).*(?:is|must be)\\s*odd', t):\n        if ans % 2 != 1:\n            return False\n    \n    return None\n\n\ndef brute_congruence(text: str, ans: int) -> Optional[bool]:\n    \"\"\"\n    HARD reject if explicit congruence is violated.\n    E.g., \"x \u2261 3 (mod 7)\" and ans % 7 != 3.\n    \"\"\"\n    # Pattern: X \u2261 R (mod M)\n    m = re.search(r'[\u2261=]\\s*(\\d+)\\s*\\(?mod\\s*(\\d+)', text.lower())\n    if m:\n        r, mod = int(m.group(1)), int(m.group(2))\n        if mod > 0 and ans % mod != r % mod:\n            return False\n    \n    return None\n\n\n# =========================\n# SOFT VERIFIERS (return None or True, NEVER False)\n# =========================\n\ndef soft_counting_plausibility(text: str, ans: int) -> Optional[bool]:\n    \"\"\"\n    Soft check: counting problems usually have ans >= 1.\n    Returns True (bonus) or None, never False.\n    \"\"\"\n    if \"how many\" not in text.lower():\n        return None\n    \n    # Positive signal if ans >= 1\n    if ans >= 1:\n        return True\n    \n    return None  # Don't reject 0, some problems have 0 valid answers\n\n\ndef soft_small_answer_check(text: str, ans: int) -> Optional[bool]:\n    \"\"\"\n    Soft check: very small answers (0, 1, 2) get no bonus but no rejection.\n    This is NOT a verifier, just confidence adjustment.\n    \"\"\"\n    # Never return False - small answers are sometimes correct\n    if ans > 10:\n        return True  # Bonus for non-trivial answer\n    return None\n\n\ndef soft_magnitude_plausibility(text: str, ans: int) -> Optional[bool]:\n    \"\"\"\n    Soft check: answer should be plausible given problem numbers.\n    \"\"\"\n    numbers = [int(x) for x in re.findall(r'\b(\\d{1,5})\b', text)]\n    if not numbers:\n        return None\n    \n    max_num = max(numbers)\n    if max_num > 0:\n        # Answer within reasonable range of problem numbers\n        if 0 < ans <= max_num * 1000:\n            return True\n    \n    return None  # Don't reject, just no bonus\n\n\n# =========================\n# AGGREGATOR\n# =========================\n\nHARD_CHECKS = [\n    brute_modular_strict,\n    brute_explicit_bounds,\n    brute_divisibility,\n    brute_congruence,\n]\n\nSOFT_CHECKS = [\n    soft_counting_plausibility,\n    soft_small_answer_check,\n    soft_magnitude_plausibility,\n]\n\n\ndef run_all_checks(text: str, ans: int) -> Tuple[int, List[str], List[str]]:\n    \"\"\"\n    Run all checks. Returns (score, passed, failed).\n    HARD checks can reject; SOFT checks only boost.\n    \"\"\"\n    passed = []\n    failed = []\n    \n    # Run hard checks first\n    for check in HARD_CHECKS:\n        try:\n            r = check(text, ans)\n            if r is False:\n                failed.append(f\"HARD_{check.__name__}\")\n                return -999, passed, failed  # HARD REJECT\n            if r is True:\n                passed.append(check.__name__)\n        except:\n            pass\n    \n    # Run soft checks (can only boost, never reject)\n    for check in SOFT_CHECKS:\n        try:\n            r = check(text, ans)\n            if r is True:\n                passed.append(check.__name__)\n        except:\n            pass\n    \n    score = len(passed)\n    return score, passed, failed\n\n\n# =========================\n# MAIN VERIFY_ANSWER FUNCTION\n# =========================\n\ndef verify_answer(\n    question_text: str,\n    ans: int,\n    problem_type: Optional[str] = None,\n) -> VerificationResult:\n    \"\"\"Deterministic verification. NEVER raises.\"\"\"\n    passed = []\n    failed = []\n\n    # Basic range check\n    if not (0 <= ans <= 99999):\n        return VerificationResult(score=0, passed_checks=[], failed_checks=[\"range\"])\n    passed.append(\"range\")\n\n    # Sanity check (existing function)\n    try:\n        if sanity_check_answer(question_text, ans):\n            passed.append(\"sanity\")\n        else:\n            failed.append(\"sanity\")\n    except:\n        pass\n\n    # Run all verification checks\n    check_score, check_passed, check_failed = run_all_checks(question_text, ans)\n    \n    if check_score < 0:\n        # HARD REJECT\n        return VerificationResult(\n            score=0,\n            passed_checks=passed,\n            failed_checks=failed + check_failed + [\"brute_reject\"]\n        )\n    \n    passed.extend(check_passed)\n    failed.extend(check_failed)\n    \n    score = len(passed)\n    return VerificationResult(score=score, passed_checks=passed, failed_checks=failed)\n\n\n# =========================\n# SAFE CRYSTALLIZATION\n# =========================\n\ndef detect_safe_crystallization(\n    samples: List[int],\n    verifications: Dict[int, VerificationResult],\n    cic_history: List,\n    min_samples: int = 4,\n) -> bool:\n    \"\"\"Returns True ONLY if crystallization is safe.\"\"\"\n    if len(samples) < min_samples:\n        return False\n\n    counts = Counter(samples)\n    top_answer, top_count = counts.most_common(1)[0]\n\n    # Gate 1: verification must exist and not be rejected\n    vr = verifications.get(top_answer)\n    if not vr or vr.score < 1 or \"brute_reject\" in vr.failed_checks:\n        return False\n\n    # Gate 2: dominance (top answer has clear lead)\n    if top_count < 2:\n        return False\n    \n    for other, cnt in counts.items():\n        if other == top_answer:\n            continue\n        if cnt >= top_count - 1:\n            other_vr = verifications.get(other)\n            if other_vr and other_vr.score >= vr.score:\n                return False\n\n    # Gate 3: CIC support (optional, not required)\n    # Removed strict CIC check - verification is primary\n\n    return True\n\n\n# =========================\n# REGENERATION POLICY\n# =========================\n\ndef regeneration_policy(\n    question_id: str,\n    question_text: str,\n    ans: int,\n    verification: VerificationResult,\n    attempt_idx: int,\n) -> str:\n    \"\"\"\n    Returns: \"reject\", \"regenerate\", \"reinforce\", \"accept\"\n    Only \"reject\" on hard failures.\n    \"\"\"\n    # Hard reject only on proven contradiction\n    if \"brute_reject\" in verification.failed_checks:\n        return \"reject\"\n\n    # Low score early -> regenerate to explore\n    if verification.score < 1 and attempt_idx < 3:\n        return \"regenerate\"\n\n    # Good score early -> reinforce\n    if verification.score >= 2 and attempt_idx < 2:\n        return \"reinforce\"\n\n    return \"accept\"\n\n\n# =========================\n# VERIFICATION-FIRST SELECTION (simplified)\n# =========================\n\ndef select_answer_with_verification(\n    candidates: List[int],\n    problem_text: str,\n    fallback: int\n) -> Tuple[int, float, dict]:\n    \"\"\"Simple verification-first selection.\"\"\"\n    if not candidates:\n        return fallback, 0.05, {\"reason\": \"no_candidates\"}\n    \n    # Score all candidates\n    scored = []\n    for ans in set(candidates):\n        vr = verify_answer(problem_text, ans)\n        count = candidates.count(ans)\n        # Skip hard-rejected answers\n        if \"brute_reject\" in vr.failed_checks:\n            continue\n        scored.append((ans, vr.score, count))\n    \n    if not scored:\n        # All rejected, use fallback\n        return fallback, 0.05, {\"reason\": \"all_rejected\"}\n    \n    # Sort by: verification score (desc), then count (desc)\n    scored.sort(key=lambda x: (-x[1], -x[2]))\n    \n    best_ans, best_score, best_count = scored[0]\n    confidence = min(0.9, 0.3 + 0.1 * best_score + 0.05 * best_count)\n    \n    return best_ans, confidence, {\n        \"reason\": \"verified\",\n        \"score\": best_score,\n        \"count\": best_count\n    }\n\n\nprint(\"[BANSHEEV5] Verification Layer: HARD-CONTRADICTION ONLY\")\nprint(f\"[BANSHEEV5] HARD_CHECKS: {len(HARD_CHECKS)}, SOFT_CHECKS: {len(SOFT_CHECKS)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# SECURE CODE EXECUTION\n# =========================\nimport multiprocessing as mp\n\ndef execute_python_code(code: str, timeout: int = 10, memory_limit_mb: int = 512) -> Tuple[bool, str]:\n    \"\"\"Secure Python execution with hard limits. NEVER hangs.\"\"\"\n    def run_code(code: str, result_queue: mp.Queue):\n        try:\n            resource.setrlimit(resource.RLIMIT_AS, (memory_limit_mb * 1024 * 1024, memory_limit_mb * 1024 * 1024))\n        except:\n            pass\n\n        import sys\n        from io import StringIO\n\n        old_stdout, old_stderr = sys.stdout, sys.stderr\n        sys.stdout = captured_out = StringIO()\n        sys.stderr = captured_err = StringIO()\n\n        try:\n            safe_globals = {\n                '__builtins__': {\n                    'print': print, 'range': range, 'len': len, 'sum': sum,\n                    'min': min, 'max': max, 'abs': abs, 'int': int, 'float': float,\n                    'str': str, 'list': list, 'dict': dict, 'set': set, 'tuple': tuple,\n                    'sorted': sorted, 'enumerate': enumerate, 'zip': zip,\n                    'pow': pow, 'round': round, 'divmod': divmod,\n                    'True': True, 'False': False, 'None': None,\n                    'bool': bool, 'type': type, 'isinstance': isinstance,\n                },\n            }\n\n            import math as safe_math\n            import itertools as safe_itertools\n            import fractions as safe_fractions\n            import decimal as safe_decimal\n            import collections as safe_collections\n\n            safe_globals['math'] = safe_math\n            safe_globals['itertools'] = safe_itertools\n            safe_globals['fractions'] = safe_fractions\n            safe_globals['decimal'] = safe_decimal\n            safe_globals['collections'] = safe_collections\n\n            exec(code, safe_globals)\n            output = captured_out.getvalue() + captured_err.getvalue()\n            result_queue.put((True, output.strip() or \"OK\"))\n\n        except MemoryError:\n            result_queue.put((False, f\"MemoryError: Exceeded {memory_limit_mb}MB\"))\n        except Exception as e:\n            result_queue.put((False, f\"{type(e).__name__}: {str(e)[:100]}\"))\n        finally:\n            sys.stdout, sys.stderr = old_stdout, old_stderr\n\n    result_queue = mp.Queue()\n    proc = mp.Process(target=run_code, args=(code, result_queue))\n    proc.start()\n    proc.join(timeout)\n\n    if proc.is_alive():\n        proc.terminate()\n        proc.join(2)\n        if proc.is_alive():\n            proc.kill()\n            proc.join(1)\n        return (False, f\"Timeout after {timeout}s\")\n\n    # CRITICAL: Queue.get() with timeout to prevent hang\n    try:\n        return result_queue.get(timeout=1)\n    except:\n        return (False, \"No result (queue timeout)\")\n\n\ndef extract_python_blocks(text: str) -> List[str]:\n    \"\"\"Extract ```python blocks.\"\"\"\n    blocks = re.findall(r\"```python\\s*(.*?)```\", text, re.DOTALL | re.IGNORECASE)\n    if not blocks:\n        blocks = re.findall(r\"```\\s*(.*?)```\", text, re.DOTALL)\n    return [b.strip() for b in blocks if b.strip()]\n\nprint(\"[BANSHEEV4] Code Execution: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# TIME MANAGEMENT HELPERS\n# (Uses AdaptiveTimeBudget from cell-2)\n# =========================\n\ndef get_time_budget_per_problem() -> float:\n    \"\"\"Get current budget from TIME_MANAGER.\"\"\"\n    return TIME_MANAGER.get_budget_for_next_problem()\n\n\ndef should_continue_generation(question_id: str, start_t: float, completed_ids: set, budget: float) -> bool:\n    \"\"\"Check if we should keep generating.\"\"\"\n    # Already completed this question\n    if question_id in completed_ids:\n        return False\n\n    # Use TIME_MANAGER for consistent checking\n    if not TIME_MANAGER.should_continue(start_t, budget):\n        return False\n\n    return True\n\nprint(\"[BANSHEEV4] Time Management Helpers: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# VLLM SERVER - COMPETITION ONLY\n# =========================\nimport subprocess\n\nvllm_process = None\n\n# Force offline mode\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\nos.environ[\"HF_HUB_OFFLINE\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\nos.environ[\"VLLM_ATTENTION_BACKEND\"] = \"TRITON_ATTN\"\nos.environ[\"TRITON_PTXAS_PATH\"] = \"/usr/local/cuda/bin/ptxas\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nos.environ[\"TIKTOKEN_ENCODINGS_BASE\"] = \"/kaggle/usr/lib/pip_install_aimo3_1/tiktoken_encodings\"\n\ncommand = [\n    \"python\", \"-m\", \"vllm.entrypoints.openai.api_server\",\n    \"--model\", \"/kaggle/input/gpt-oss-120b/transformers/default/1\",\n    \"--served-model-name\", \"vllm-model\",\n    \"--tensor-parallel-size\", \"1\",\n    \"--max-num-seqs\", \"16\",\n    \"--gpu-memory-utilization\", \"0.96\",\n    \"--host\", \"0.0.0.0\",\n    \"--port\", \"8000\",\n    \"--dtype\", \"auto\",\n    \"--max-model-len\", \"65536\",\n]\n\nwith open(\"/kaggle/working/vllm.log\", \"w\") as logfile:\n    vllm_process = subprocess.Popen(\n        command, stdout=logfile, stderr=subprocess.STDOUT, start_new_session=True\n    )\n\nprint(f\"[BANSHEEV5] vLLM server starting (PID: {vllm_process.pid})...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# OPENAI CLIENT + SERVER RESTART\n# =========================\nfrom openai import OpenAI\n\nos.environ[\"OPENAI_API_BASE\"] = \"http://127.0.0.1:8000/v1\"\nos.environ[\"OPENAI_API_KEY\"] = \"sk-local\"\n\nclient = OpenAI(\n    base_url=os.environ[\"OPENAI_API_BASE\"],\n    api_key=os.environ[\"OPENAI_API_KEY\"],\n    timeout=120.0,\n    max_retries=0,\n)\n\nstop_token_ids = [\n    token_id for token_id in range(200_000, 201_088)\n    if token_id not in [200005, 200006, 200007, 200008]\n]\n\n_CLIENT_READY = False\n_SERVER_RESTARTED = False\n\n\ndef restart_vllm_server():\n    \"\"\"Restart vLLM server once if it fails.\"\"\"\n    global vllm_process\n    \n    print(\"[SERVER] Attempting restart...\")\n    \n    # Kill existing\n    if vllm_process and vllm_process.poll() is None:\n        try:\n            vllm_process.terminate()\n            vllm_process.wait(timeout=10)\n        except:\n            try:\n                vllm_process.kill()\n            except:\n                pass\n    \n    # Restart\n    command = [\n        \"python\", \"-m\", \"vllm.entrypoints.openai.api_server\",\n        \"--model\", \"/kaggle/input/gpt-oss-120b/transformers/default/1\",\n        \"--served-model-name\", \"vllm-model\",\n        \"--tensor-parallel-size\", \"1\",\n        \"--max-num-seqs\", \"16\",\n        \"--gpu-memory-utilization\", \"0.96\",\n        \"--host\", \"0.0.0.0\",\n        \"--port\", \"8000\",\n        \"--dtype\", \"auto\",\n        \"--max-model-len\", \"65536\",\n    ]\n    \n    with open(\"/kaggle/working/vllm_restart.log\", \"w\") as logfile:\n        vllm_process = subprocess.Popen(\n            command, stdout=logfile, stderr=subprocess.STDOUT, start_new_session=True\n        )\n    \n    print(f\"[SERVER] Restarted (PID: {vllm_process.pid})\")\n    time.sleep(15)  # Give it time to initialize\n\n\ndef ensure_server() -> bool:\n    \"\"\"Ensure server is ready. Restart once if needed.\"\"\"\n    global _CLIENT_READY, _SERVER_RESTARTED\n    \n    # Already confirmed ready\n    if _CLIENT_READY:\n        return True\n    \n    # First attempt\n    print(f\"[CLIENT] Waiting for server (max 900s)...\")\n    deadline = time.time() + 900\n    \n    while time.time() < deadline:\n        if TIME_MANAGER.is_expired():\n            print(\"[CLIENT] Time expired\")\n            return False\n        \n        try:\n            models = client.models.list()\n            if models:\n                print(f\"[CLIENT] Server ready: {[m.id for m in models]}\")\n                _CLIENT_READY = True\n                return True\n        except Exception as e:\n            pass\n        \n        time.sleep(2)\n    \n    # First attempt failed - try restart ONCE\n    if not _SERVER_RESTARTED:\n        _SERVER_RESTARTED = True\n        print(\"[CLIENT] Server not ready - attempting restart...\")\n        restart_vllm_server()\n        \n        # Second attempt after restart\n        deadline = time.time() + 300  # 5 more minutes\n        while time.time() < deadline:\n            if TIME_MANAGER.is_expired():\n                return False\n            \n            try:\n                models = client.models.list()\n                if models:\n                    print(f\"[CLIENT] Server ready after restart\")\n                    _CLIENT_READY = True\n                    return True\n            except:\n                pass\n            \n            time.sleep(2)\n    \n    print(\"[CLIENT] Server failed even after restart\")\n    return False\n\n\ndef fallback_solver(problem_text: str) -> int:\n    \"\"\"\n    Dumb fallback when LLM unavailable.\n    Extract numbers from problem, return something non-zero.\n    \"\"\"\n    # Extract all numbers from problem\n    numbers = [int(x) for x in re.findall(r'\\d+', problem_text) if len(x) <= 5]\n    \n    if not numbers:\n        return 42  # Non-zero default\n    \n    # Try some heuristics\n    # If asking for mod N, answer should be < N\n    mod_match = re.search(r'mod(?:ulo)?\\s*(\\d+)', problem_text.lower())\n    if mod_match:\n        modulus = int(mod_match.group(1))\n        return sum(numbers) % modulus\n    \n    # Otherwise return sum mod 100000\n    return sum(numbers) % 100000\n\nprint(\"[BANSHEEV5] Client + Server Restart: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# PROMPT ENGINEERING\n# 32 System Prompts from Zombie (23/50)\n# =========================\n\nCOGNITIVE_MACROS = \"\"\"\nCOGNITIVE TOOLKIT:\n- Try small cases to conjecture, then prove.\n- Search for invariants / monovariants.\n- Work backwards from desired form.\n- Check extremes / boundary cases.\n- Exploit symmetry / relabeling.\n- Pigeonhole principle.\n- Parity / modular arithmetic.\n- Bounding (upper/lower) and squeeze.\n- Complementary counting.\n- Construct bijection or involution.\n- Translate to algebra/graph/geometry.\n- Sanity-check units, integrality, constraints.\nOUTPUT: Finish with exactly one integer in \\\\boxed{}, 0 <= answer <= 99999.\n\"\"\"\n\n# All 32 battle-tested prompts from zombie_23.ipynb (scored 23/50)\nSYSTEM_PROMPTS = [\n    # 1. Elite mathematician with code execution\n    \"CRITICAL: You have Python code execution. Write ```python blocks for verification. \"\n    \"You are an elite mathematics researcher. Return only final integer in \\\\boxed{}, 0 <= answer <= 99999.\",\n    \n    # 2. IMO competitor rigor\n    \"You are an IMO competitor. Rigorously define variables, explore multiple strategies, \"\n    \"perform full case analysis, justify nontrivial steps. Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 3. Adversarial self-refutation\n    \"Solve with full rigor. After candidate solution, actively attempt refutation by \"\n    \"searching for counterexamples, stress-testing edge cases. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 4. Invariant-first under time pressure\n    \"Under IMO time pressure: identify key invariant/symmetry/extremal principle early, \"\n    \"avoid brute force unless justified. Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n    \n    # 5. Multiple solution approaches\n    \"Attempt at least two fundamentally different solution approaches. Proceed with more rigorous, \"\n    \"use other as verification. Return only verified final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 6. First principles restart on inconsistency\n    \"If step relies on unproven assumption or inconsistency, restart from first principles. \"\n    \"Return only final verified integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 7. Tool-integrated reasoning with early stopping\n    \"Tool-integrated reasoning, apply early-stopping when confident. Return verified final answer \"\n    \"in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 8. Adversarial academic review\n    \"Conduct adversarial academic review of proposed solution, then provide constructive critique. \"\n    \"Return only verified final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 9. Small answer skepticism\n    \"WARNING: Small answers (0, 1, 2, 3) are often wrong on competition problems. \"\n    \"If you get a small answer, re-verify with extra rigor. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 10. Constraint propagation\n    \"Apply constraint propagation: what does the problem FORCE to be true? What CANNOT happen? \"\n    \"Build the answer from forced conclusions. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 11. Backwards reasoning\n    \"Work backwards: What form must the answer have? What properties? Use this to constrain search. \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 12. Generating function / algebraic identity\n    \"Consider generating functions, algebraic identities, or polynomial methods. \"\n    \"Competition math often has elegant closed forms. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 13. Combinatorial bijection\n    \"Seek a bijection or double-counting argument. Competition problems often have elegant \"\n    \"combinatorial structures. Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 14. Modular arithmetic focus\n    \"Focus on modular arithmetic patterns. Check divisibility, remainders, Chinese Remainder Theorem. \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 15. Geometry to algebra translation\n    \"If geometry: translate to coordinates or trigonometry. If algebra: consider geometric interpretation. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 16. Extremal principle\n    \"Apply extremal principle: consider maximum/minimum elements, argue about their properties. \"\n    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 17. Graph theory modeling\n    \"Model the problem as a graph if applicable. Vertices, edges, degrees, paths, cycles. \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 18. Recurrence relation\n    \"Look for recurrence relations. Define f(n), find f(n) in terms of earlier values. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 19. Pigeonhole principle\n    \"Apply pigeonhole principle: if too many pigeons, some hole has multiple. What are the pigeons? Holes? \"\n    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 20. Greedy algorithm validation\n    \"Consider greedy approach. Prove it works or find counterexample. \"\n    \"Return only verified final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 21. Induction strategy\n    \"Prove by induction if pattern emerges. State base case, inductive step clearly. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 22. Probabilistic method intuition\n    \"Use probabilistic intuition: if random approach gives expected value X, constructive solution exists. \"\n    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 23. Number theory deep dive\n    \"For number theory: check prime factorization, Euler's theorem, quadratic residues. \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 24. Functional equation approach\n    \"For functional equations: try f(0), f(1), injectivity, surjectivity, substitutions. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 25. Inequality techniques\n    \"For inequalities: AM-GM, Cauchy-Schwarz, Jensen, rearrangement. When does equality hold? \"\n    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 26. Sequence analysis\n    \"Analyze sequences: arithmetic, geometric, periodic, eventually periodic, bounded? \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 27. Polynomial roots and coefficients\n    \"For polynomials: Vieta's formulas, root behavior, coefficient patterns. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 28. Game theory / strategy\n    \"If game theory: who has winning strategy? What invariant does winner maintain? \"\n    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 29. Coloring arguments\n    \"Consider coloring arguments: 2-color, checkerboard, mod-k coloring. What's forced? \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 30. Diophantine equation techniques\n    \"For Diophantine equations: factorization, descent, modular constraints. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 31. Confidence scoring\n    \"Rate your confidence 0-100 after solving. If below 85, try alternative approach. \"\n    \"Return only verified final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 32. Triangulation algorithm\n    \"Use triangulation: first determine answer's order of magnitude, then narrow range, then pinpoint. \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n]\n\n# Follow-up prompts for reflexion\nFOLLOWUP_NO_ANSWER = \"You did not provide a boxed answer. Please place your final integer answer in \\\\boxed{}.\"\nFOLLOWUP_SMALL_ANSWER = \"You answered with a small number. Small answers (0-10) are often wrong on IMO problems. Are you absolutely certain? Re-verify.\"\nFOLLOWUP_VERIFY = \"Please verify your answer one more time. Check arithmetic, edge cases, and logical steps.\"\nFOLLOWUP_GUESS = \"Time is running out. Make your best educated guess and put it in \\\\boxed{}.\"\n\n\ndef sanity_check_answer(question_text: str, ans: int) -> bool:\n    \"\"\"Check answer against problem constraints.\"\"\"\n    if ans < 0 or ans > 99999:\n        return False\n    t = question_text.lower()\n    \n    # Parity\n    if re.search(r'\\banswer\\s+is\\s+even\\b', t) and ans % 2 != 0:\n        return False\n    if re.search(r'\\banswer\\s+is\\s+odd\\b', t) and ans % 2 != 1:\n        return False\n    \n    # Divisibility\n    div_match = re.search(r'\\b(?:divisible by|multiple of)\\s+(\\d{1,5})\\b', t)\n    if div_match:\n        k = int(div_match.group(1))\n        if k != 0 and ans % k != 0:\n            return False\n    \n    return True\n\nprint(f\"[BANSHEEV4] Prompts: {len(SYSTEM_PROMPTS)} system prompts loaded\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# GENERATION HELPERS\n",
    "# =========================\n",
    "\n",
    "def annealed_temperature(step: int, total: int, t_start: float = 1.4, t_end: float = 0.2) -> float:\n",
    "    if total <= 1:\n",
    "        return t_end\n",
    "    return t_start * ((t_end / t_start) ** (step / (total - 1)))\n",
    "\n",
    "def annealed_max_tokens(step: int, total: int, start: int = 2048, end: int = 512) -> int:\n",
    "    if total <= 1:\n",
    "        return end\n",
    "    return int(start + (step / (total - 1)) * (end - start))\n",
    "\n",
    "def annealed_top_p(step: int, total: int, start: float = 0.95, end: float = 0.75) -> float:\n",
    "    if total <= 1:\n",
    "        return end\n",
    "    return start + (step / (total - 1)) * (end - start)\n",
    "\n",
    "def repetition_rate(text: str, window: int = 120) -> float:\n",
    "    toks = re.findall(r'\\w+|\\S', text.lower())\n",
    "    if len(toks) < window:\n",
    "        return 0.0\n",
    "    tail = toks[-window:]\n",
    "    return 1.0 - (len(set(tail)) / max(1, len(tail)))\n",
    "\n",
    "def tail_similarity(text: str, window: int = 900) -> float:\n",
    "    \"\"\"Check if text is repeating itself.\"\"\"\n",
    "    if len(text) < 2 * window:\n",
    "        return 0.0\n",
    "    a = text[-2*window:-window]\n",
    "    b = text[-window:]\n",
    "    # Simple char overlap\n",
    "    a_set = set(a.lower())\n",
    "    b_set = set(b.lower())\n",
    "    if not a_set or not b_set:\n",
    "        return 0.0\n",
    "    return len(a_set & b_set) / len(a_set | b_set)\n",
    "\n",
    "print(\"[BANSHEEV4] Generation Helpers: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# MAIN SOLVER CORE\n# =========================\n\nimport threading\nSTATE_LOCK = threading.Lock()\n\n# Global state\ncompleted_question_ids = set()\nquestion_id_to_counter = defaultdict(Counter)\nquestion_id_to_samples = defaultdict(list)\nquestion_id_to_traces = defaultdict(list)\nquestion_id_to_cic_history = defaultdict(list)\n\n\ndef is_valid_answer(ans) -> bool:\n    \"\"\"Check if answer is valid.\"\"\"\n    try:\n        return ans is not None and 0 <= int(ans) <= 99999\n    except:\n        return False\n\n\ndef vote_answer(question_id: str, force_answer: bool = False) -> Optional[int]:\n    \"\"\"Log-weighted voting.\"\"\"\n    counter = question_id_to_counter[question_id]\n    if not counter:\n        return None\n    \n    modified_counter = Counter()\n    for value, count in counter.items():\n        modified_counter[value] += math.log(1.25 + abs(value)) * count\n    \n    score_list = sorted(\n        (score, counter[value], value) for value, score in modified_counter.items()\n    )\n    \n    if force_answer and score_list:\n        if RUNTIME.VERBOSE_LOGGING:\n            print(f\"[VOTE] {sum(counter.values())} attempts\")\n            for score, count, value in score_list[::-1][:3]:\n                print(f\"  {value}: count={count}\")\n        return score_list[-1][-1]\n    \n    return None\n\n\ndef generate_solution(\n    question_text: str,\n    question_id: str,\n    solution_index: int,\n    system_prompt: str,\n    budget: float,\n    total_generations: int = 8,\n) -> Optional[int]:\n    \"\"\"\n    Generate solution with:\n    - NON-STREAMING (safer)\n    - Budget-tied timeout\n    - Uses extract_any_answer from Cell 5\n    \"\"\"\n    if question_id in completed_question_ids:\n        return None\n    if TIME_MANAGER.is_expired():\n        return None\n\n    gen_start = time.time()\n    os.makedirs(f\"solutions/{question_id}\", exist_ok=True)\n\n    # Use annealed parameters from Cell 12\n    temperature = annealed_temperature(solution_index, total_generations)\n    max_tokens = annealed_max_tokens(solution_index, total_generations)\n    \n    # Budget-tied timeout\n    remaining_budget = max(10, budget - (time.time() - gen_start))\n    request_timeout = min(90, remaining_budget - 5)\n\n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": question_text},\n    ]\n\n    text_response_to_save = \"\"\n    max_iterations = 2\n\n    for iteration in range(max_iterations):\n        if question_id in completed_question_ids:\n            break\n        if TIME_MANAGER.is_expired():\n            break\n        if not TIME_MANAGER.should_continue(gen_start, budget):\n            break\n\n        try:\n            # NON-STREAMING\n            resp = client.chat.completions.create(\n                model=\"vllm-model\",\n                messages=messages,\n                temperature=temperature,\n                max_tokens=max_tokens,\n                extra_body=dict(min_p=0.02, stop_token_ids=stop_token_ids),\n                timeout=request_timeout,\n            )\n            \n            text_response = resp.choices[0].message.content or \"\"\n            messages.append({\"role\": \"assistant\", \"content\": text_response})\n            text_response_to_save += text_response\n\n        except Exception as e:\n            if RUNTIME.VERBOSE_LOGGING:\n                print(f\"[GEN] Error: {e}\")\n            break\n\n        # Use extract_any_answer from Cell 5\n        ans = extract_any_answer(text_response_to_save)\n        \n        if is_valid_answer(ans):\n            if ans <= 10 and iteration == 0:\n                user_follow_up = \"Are you sure? Double-check your answer.\"\n                messages.append({\"role\": \"user\", \"content\": user_follow_up})\n                text_response_to_save += \"\\n===\\n\" + user_follow_up + \"\\n===\\n\"\n            else:\n                break\n        else:\n            if iteration == 0:\n                user_follow_up = \"Place your final answer in \\\\boxed{}.\"\n                messages.append({\"role\": \"user\", \"content\": user_follow_up})\n                text_response_to_save += \"\\n===\\n\" + user_follow_up + \"\\n===\\n\"\n\n    # Final extraction\n    ans = extract_any_answer(text_response_to_save)\n    \n    # Save trace (thread-safe)\n    if text_response_to_save:\n        with STATE_LOCK:\n            question_id_to_traces[question_id].append(text_response_to_save)\n        \n        try:\n            suffix = f\"-{ans}\" if is_valid_answer(ans) else \"\"\n            with open(f\"solutions/{question_id}/{solution_index:04d}{suffix}.txt\", \"w\") as f:\n                f.write(text_response_to_save)\n        except:\n            pass\n\n    if is_valid_answer(ans):\n        with STATE_LOCK:\n            question_id_to_counter[question_id][ans] += 1\n            question_id_to_samples[question_id].append(ans)\n        vote_answer(question_id)\n        return ans\n\n    return None\n\n\nprint(\"[BANSHEEV5] Main solver core: NON-STREAMING, uses Cell 5 & 12 functions\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# A/B SYMBOLIC AUTO-SOLVER\n# =========================\n# Deterministic solvers for easy A/B patterns\n# Runs BEFORE LLM pipeline - instant points with zero variance\n# =========================\n\n# Utility: safe eval of pure arithmetic expressions\n_ALLOWED_ARITH = set(\"0123456789+-*/()% ^\")\n\ndef _safe_arith_eval(expr: str) -> Optional[int]:\n    \"\"\"Evaluate simple integer arithmetic safely.\"\"\"\n    if not expr:\n        return None\n    expr = expr.strip()\n\n    # normalize ^ to **\n    expr = expr.replace(\"^\", \"**\")\n    # quick filter - no letters allowed\n    if any(ch.isalpha() for ch in expr):\n        return None\n    if any(ch not in _ALLOWED_ARITH and ch != \"*\" for ch in expr):\n        return None\n    try:\n        val = eval(expr, {\"__builtins__\": {}}, {})\n    except Exception:\n        return None\n    try:\n        if isinstance(val, bool):\n            return None\n        if isinstance(val, int):\n            return int(val)\n        if isinstance(val, float) and abs(val - round(val)) < 1e-9:\n            return int(round(val))\n    except Exception:\n        return None\n    return None\n\n\n# =========================\n# PATTERN SOLVERS\n# =========================\n\ndef solve_direct_arithmetic(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n    \"\"\"\n    Catch classic A problems:\n    - \"Compute 2+2\"\n    - \"Evaluate ( ... )\"\n    - \"Find the value of <expr>\"\n    \"\"\"\n    t = text.strip()\n    # Look for math expression after keywords\n    m = re.search(r\"(?:compute|evaluate|find the value of)\\s*[:\\-]?\\s*([0-9\\(\\)\\+\\-\\*\\/\\%\\^\\s]+)\", t, re.I)\n    if not m:\n        # Sometimes the whole prompt IS the expression\n        m2 = re.search(r\"^\\s*([0-9\\(\\)\\+\\-\\*\\/\\%\\^\\s]+)\\s*[\\.\\?]?\\s*$\", t)\n        if not m2:\n            return None\n        expr = m2.group(1)\n    else:\n        expr = m.group(1)\n\n    expr = expr.strip()\n    if len(expr) > 80:\n        return None\n\n    ans = _safe_arith_eval(expr)\n    if ans is None:\n        return None\n\n    if 0 <= ans <= 99999:\n        return ans, {\"method\": \"direct_arithmetic\", \"expr\": expr}\n    return None\n\n\ndef solve_mod_remainder(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n    \"\"\"\n    Solve easy remainder problems:\n    - \"Find the remainder when <expr> is divided by <m>\"\n    - \"Compute <expr> mod <m>\"\n    - \"a^b mod m\" (modular exponentiation)\n    \"\"\"\n    t = text.lower()\n\n    # Find modulus\n    mm = re.search(r\"\\bmod(?:ulo)?\\s*(\\d{1,7})\\b\", t)\n    if not mm:\n        mm = re.search(r\"remainder\\s+when.*divided\\s+by\\s+(\\d{1,7})\", t)\n    if not mm:\n        return None\n    mod = int(mm.group(1))\n    if mod <= 0 or mod > 10**7:\n        return None\n\n    # Try exponent form a^b first\n    expm = re.search(r\"(\\d{1,9})\\s*\\^\\s*(\\d{1,9})\", t)\n    if expm:\n        a = int(expm.group(1))\n        b = int(expm.group(2))\n        ans = pow(a, b, mod)\n        if 0 <= ans <= 99999:\n            return ans, {\"method\": \"pow_mod\", \"a\": a, \"b\": b, \"mod\": mod}\n        return None\n\n    # Try plain arithmetic expression\n    expr = None\n    mexpr = re.search(r\"(?:compute|find|evaluate)\\s+(.+?)\\s+\\bmod\\b\\s*\\d{1,7}\", text, re.I)\n    if mexpr:\n        expr = mexpr.group(1).strip()\n    if expr is None:\n        mexpr2 = re.search(r\"([0-9\\(\\)\\+\\-\\*\\/\\%\\^\\s]{3,80})\\s+\\bmod\\b\\s*\\d{1,7}\", text, re.I)\n        if mexpr2:\n            expr = mexpr2.group(1).strip()\n\n    if not expr:\n        return None\n\n    val = _safe_arith_eval(expr)\n    if val is None:\n        return None\n    ans = val % mod\n    if 0 <= ans <= 99999:\n        return ans, {\"method\": \"arith_mod\", \"expr\": expr, \"mod\": mod}\n    return None\n\n\ndef solve_gcd_lcm(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n    \"\"\"\n    Solve direct GCD/LCM:\n    - \"gcd(123, 456)\"\n    - \"lcm of 12 and 30\"\n    \"\"\"\n    t = text.lower()\n    \n    # GCD\n    mg = re.search(r\"\\bgcd\\s*\\(\\s*(\\d{1,9})\\s*,\\s*(\\d{1,9})\\s*\\)\", t)\n    if mg:\n        a = int(mg.group(1))\n        b = int(mg.group(2))\n        ans = math.gcd(a, b)\n        if 0 <= ans <= 99999:\n            return ans, {\"method\": \"gcd\", \"a\": a, \"b\": b}\n        return None\n\n    mg2 = re.search(r\"\\bgcd\\b.*?\\b(\\d{1,9})\\b.*?\\b(\\d{1,9})\\b\", t)\n    if \"gcd\" in t and mg2:\n        a = int(mg2.group(1))\n        b = int(mg2.group(2))\n        ans = math.gcd(a, b)\n        if 0 <= ans <= 99999:\n            return ans, {\"method\": \"gcd\", \"a\": a, \"b\": b}\n        return None\n\n    # LCM\n    if \"lcm\" in t:\n        ml = re.search(r\"\\b(\\d{1,9})\\b.*?\\b(\\d{1,9})\\b\", t)\n        if ml:\n            a = int(ml.group(1))\n            b = int(ml.group(2))\n            ans = abs(a // math.gcd(a, b) * b)\n            if 0 <= ans <= 99999:\n                return ans, {\"method\": \"lcm\", \"a\": a, \"b\": b}\n    return None\n\n\ndef solve_small_diophantine_count(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n    \"\"\"\n    Count integer solutions in a tiny box:\n    - \"How many pairs (x,y) with 0<=x,y<=N satisfy x+y=k\"\n    - \"How many integer solutions satisfy x*y=k with bounds\"\n    \"\"\"\n    t = text.lower()\n\n    # x+y=k with bounds\n    m = re.search(r\"\\bx\\s*\\+\\s*y\\s*=\\s*(\\d{1,6})\", t)\n    if m:\n        k = int(m.group(1))\n        b = re.search(r\"0\\s*<=\\s*x\\s*,?\\s*y\\s*<=\\s*(\\d{1,5})\", t)\n        if b:\n            N = int(b.group(1))\n            cnt = 0\n            for x in range(0, N + 1):\n                y = k - x\n                if 0 <= y <= N:\n                    cnt += 1\n            if 0 <= cnt <= 99999:\n                return cnt, {\"method\": \"count_xy_sum\", \"k\": k, \"N\": N}\n\n    # x*y = k with bounds\n    m2 = re.search(r\"\\bx\\s*\\*\\s*y\\s*=\\s*(\\d{1,6})\", t)\n    if m2:\n        k = int(m2.group(1))\n        b = re.search(r\"0\\s*<=\\s*x\\s*,?\\s*y\\s*<=\\s*(\\d{1,5})\", t)\n        if b:\n            N = int(b.group(1))\n            cnt = 0\n            for x in range(0, N + 1):\n                if x == 0:\n                    if k == 0:\n                        cnt += (N + 1)\n                    continue\n                if k % x == 0:\n                    y = k // x\n                    if 0 <= y <= N:\n                        cnt += 1\n            if 0 <= cnt <= 99999:\n                return cnt, {\"method\": \"count_xy_prod\", \"k\": k, \"N\": N}\n\n    return None\n\n\ndef solve_sum_formula(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n    \"\"\"\n    Sum of first n integers/squares/cubes:\n    - \"sum of first n integers\"\n    - \"1+2+3+...+n\"\n    \"\"\"\n    t = text.lower()\n    \n    # Sum of first n integers\n    m = re.search(r\"sum\\s+of\\s+(?:the\\s+)?first\\s+(\\d{1,6})\\s+(?:positive\\s+)?integers\", t)\n    if m:\n        n = int(m.group(1))\n        ans = n * (n + 1) // 2\n        if 0 <= ans <= 99999:\n            return ans, {\"method\": \"sum_n\", \"n\": n}\n    \n    # 1+2+...+n pattern\n    m2 = re.search(r\"1\\s*\\+\\s*2\\s*\\+\\s*(?:3\\s*\\+\\s*)?(?:\\.\\.\\.|\u2026)\\s*\\+?\\s*(\\d{1,6})\", t)\n    if m2:\n        n = int(m2.group(1))\n        ans = n * (n + 1) // 2\n        if 0 <= ans <= 99999:\n            return ans, {\"method\": \"sum_n\", \"n\": n}\n    \n    # Sum of squares\n    m3 = re.search(r\"sum\\s+of\\s+(?:the\\s+)?(?:first\\s+)?(\\d{1,4})\\s+(?:perfect\\s+)?squares\", t)\n    if m3:\n        n = int(m3.group(1))\n        ans = n * (n + 1) * (2 * n + 1) // 6\n        if 0 <= ans <= 99999:\n            return ans, {\"method\": \"sum_squares\", \"n\": n}\n    \n    return None\n\n\ndef solve_factorial_binomial(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n    \"\"\"\n    Small factorial/binomial:\n    - \"n!\"\n    - \"C(n,k)\" or \"n choose k\"\n    \"\"\"\n    t = text.lower()\n    \n    # Factorial\n    m = re.search(r\"(\\d{1,2})\\s*!\", t)\n    if m:\n        n = int(m.group(1))\n        if n <= 12:  # 12! = 479001600, fits in 99999 check\n            ans = math.factorial(n)\n            if 0 <= ans <= 99999:\n                return ans, {\"method\": \"factorial\", \"n\": n}\n    \n    # Binomial C(n,k)\n    m2 = re.search(r\"c\\s*\\(\\s*(\\d{1,3})\\s*,\\s*(\\d{1,3})\\s*\\)\", t)\n    if m2:\n        n = int(m2.group(1))\n        k = int(m2.group(2))\n        if n <= 30 and k <= n:\n            ans = math.comb(n, k)\n            if 0 <= ans <= 99999:\n                return ans, {\"method\": \"binomial\", \"n\": n, \"k\": k}\n    \n    # \"n choose k\"\n    m3 = re.search(r\"(\\d{1,3})\\s+choose\\s+(\\d{1,3})\", t)\n    if m3:\n        n = int(m3.group(1))\n        k = int(m3.group(2))\n        if n <= 30 and k <= n:\n            ans = math.comb(n, k)\n            if 0 <= ans <= 99999:\n                return ans, {\"method\": \"binomial\", \"n\": n, \"k\": k}\n    \n    return None\n\n\n# =========================\n# DISPATCHER\n# =========================\n\nAUTO_SOLVERS = [\n    solve_direct_arithmetic,\n    solve_mod_remainder,\n    solve_gcd_lcm,\n    solve_small_diophantine_count,\n    solve_sum_formula,\n    solve_factorial_binomial,\n]\n\n\ndef try_autosolve_AB(question_text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n    \"\"\"Returns (answer, meta) if solved deterministically, else None.\"\"\"\n    for f in AUTO_SOLVERS:\n        try:\n            out = f(question_text)\n            if out is not None:\n                ans, meta = out\n                if isinstance(ans, int) and 0 <= ans <= 99999:\n                    return ans, meta\n        except Exception:\n            continue\n    return None\n\n\nprint(\"[BANSHEEV5] A/B Auto-Solver: OK\")\nprint(f\"[BANSHEEV5] AUTO_SOLVERS: {len(AUTO_SOLVERS)} pattern solvers loaded\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# SOLVE - FULL COMPETITION ARCHITECTURE\n# =========================\n\ndef should_skip_fast(\n    *,\n    elapsed: float,\n    budget: float,\n    samples: List[int],\n    verifs: Dict[int, VerificationResult],\n    cic_history: List,\n    regen_attempts: int,\n) -> bool:\n    \"\"\"\n    Conservative skip: only when continuation is clearly low EV.\n    \"\"\"\n    if elapsed < 0.3 * budget:\n        return False\n\n    # Check if any answer passed verification\n    any_verified = any(vr.score >= 1 and \"brute_reject\" not in vr.failed_checks \n                       for vr in verifs.values())\n    if any_verified:\n        return False\n\n    # Need enough attempts before giving up\n    if len(samples) < 4:\n        return False\n\n    # Many hard rejections is a bad sign\n    hard_rejects = sum(1 for vr in verifs.values() if \"brute_reject\" in vr.failed_checks)\n    if hard_rejects < 2:\n        return False\n\n    # Budget pressure\n    if elapsed < 0.5 * budget:\n        return False\n\n    return True\n\n\ndef solve(question_text: str, question_id: str) -> int:\n    \"\"\"\n    Main solve function - FULL COMPETITION ARCHITECTURE.\n    \"\"\"\n    \n    # === PHASE 0: SYMBOLIC AUTO-SOLVE ===\n    auto = try_autosolve_AB(question_text)\n    if auto is not None:\n        ans, meta = auto\n        print(f\"[AUTO] Solved: {ans} via {meta.get('method')}\")\n        completed_question_ids.add(question_id)\n        return ans\n    \n    # Server check\n    server_ready = ensure_server()\n    if not server_ready:\n        print(f\"[SOLVE] Server unavailable - fallback\")\n        return fallback_solver(question_text)\n    \n    if TIME_MANAGER.is_expired():\n        print(f\"[SOLVE] TIME EXPIRED - fallback\")\n        return fallback_solver(question_text)\n    \n    # Reset state\n    question_id_to_counter[question_id] = Counter()\n    question_id_to_samples[question_id] = []\n    question_id_to_traces[question_id] = []\n    question_id_to_cic_history[question_id] = []\n    question_id_to_verification[question_id] = {}\n    completed_question_ids.discard(question_id)\n    \n    budget = TIME_MANAGER.start_problem()\n    solve_start = time.time()\n    \n    # IMPROVED: More generous unverified cap (35% instead of 25%)\n    MAX_UNVERIFIED_SECONDS = 0.35 * budget\n    unverified_start = time.time()\n    \n    print(f\"\\n[SOLVE] {question_id}\")\n    print(f\"[TIME] {TIME_MANAGER.status()}\")\n    print(f\"[BUDGET] {budget:.0f}s ({budget/60:.1f}m)\")\n    \n    if budget <= 10:\n        print(\"[SOLVE] Budget too low - fallback\")\n        TIME_MANAGER.end_problem(0, budget)\n        return fallback_solver(question_text)\n    \n    # Dynamic generation count\n    if budget < 60:\n        num_generations = 4\n    elif budget < 180:\n        num_generations = 8\n    else:\n        num_generations = 12\n    \n    prompt_indices = get_routed_prompts(question_text, num_generations)\n    print(f\"[SOLVE] {num_generations} generations\")\n    \n    regen_attempts = 0\n    \n    for i in range(num_generations):\n        if not TIME_MANAGER.should_continue(solve_start, budget):\n            print(f\"[SOLVE] Budget exhausted at gen {i}\")\n            break\n        \n        if question_id in completed_question_ids:\n            print(f\"[SOLVE] Crystallized at gen {i}\")\n            break\n        \n        elapsed = time.time() - solve_start\n        \n        # IMPROVED: Unverified cap with better conditions\n        if time.time() - unverified_start > MAX_UNVERIFIED_SECONDS:\n            samples = question_id_to_samples[question_id]\n            verifs = question_id_to_verification[question_id]\n            \n            # Only abort if: enough attempts AND no good signals AND no cluster forming\n            has_verified = any(vr.score >= 1 and \"brute_reject\" not in vr.failed_checks \n                              for vr in verifs.values())\n            has_cluster = len(samples) >= 2 and Counter(samples).most_common(1)[0][1] >= 2\n            \n            if not has_verified and not has_cluster and len(samples) >= 4:\n                print(\"[TIME] No verified answers or clusters - aborting\")\n                break\n            else:\n                unverified_start = time.time()  # Reset timer\n        \n        # Skip-fast heuristic\n        if should_skip_fast(\n            elapsed=elapsed,\n            budget=budget,\n            samples=question_id_to_samples[question_id],\n            verifs=question_id_to_verification[question_id],\n            cic_history=question_id_to_cic_history[question_id],\n            regen_attempts=regen_attempts,\n        ):\n            print(\"[SKIP] Fast-skip triggered\")\n            TIME_MANAGER.time_banked += 0.2 * (budget - elapsed)\n            break\n        \n        prompt_idx = prompt_indices[i] if i < len(prompt_indices) else i % len(SYSTEM_PROMPTS)\n        sys_prompt = SYSTEM_PROMPTS[prompt_idx]\n        \n        try:\n            answer = generate_solution(\n                question_text, question_id, i, sys_prompt, budget, num_generations\n            )\n            \n            if answer is not None:\n                # === VERIFICATION WITH BEST-OF STORAGE ===\n                vr = verify_answer(question_text, answer)\n                \n                # Keep best verification for each answer\n                prev = question_id_to_verification[question_id].get(answer)\n                if prev is None or vr.score > prev.score:\n                    question_id_to_verification[question_id][answer] = vr\n                \n                decision = regeneration_policy(\n                    question_id, question_text, answer, vr, i\n                )\n                \n                print(f\"[VERIFY] ans={answer}, score={vr.score}, decision={decision}\")\n                \n                if decision == \"reject\":\n                    print(f\"[VERIFY] HARD REJECT: {vr.failed_checks}\")\n                    regen_attempts += 1\n                    continue\n                \n                if decision == \"regenerate\":\n                    regen_attempts += 1\n                \n                # Safe crystallization\n                if RUNTIME.ENABLE_CRYSTALLIZATION and len(question_id_to_samples[question_id]) >= 4:\n                    if detect_safe_crystallization(\n                        question_id_to_samples[question_id],\n                        question_id_to_verification[question_id],\n                        question_id_to_cic_history[question_id],\n                    ):\n                        print(f\"[CRYSTAL] Safe crystallization at {len(question_id_to_samples[question_id])} samples\")\n                        completed_question_ids.add(question_id)\n                        break\n        \n        except Exception as e:\n            print(f\"[SOLVE] Gen {i} error: {e}\")\n            regen_attempts += 1\n            continue\n    \n    # === ANSWER SELECTION ===\n    samples = question_id_to_samples[question_id]\n    traces = question_id_to_traces[question_id]\n    \n    print(f\"[SOLVE] Collected {len(samples)} samples\")\n    \n    if not samples:\n        print(\"[SOLVE] No samples - fallback\")\n        final_answer = fallback_solver(question_text)\n    else:\n        try:\n            final_answer, confidence, metadata = select_answer_with_verification(\n                candidates=samples,\n                problem_text=question_text,\n                fallback=fallback_solver(question_text),\n            )\n            \n            print(f\"[SELECT] answer={final_answer}, conf={confidence:.2f}, reason={metadata.get('reason')}\")\n        \n        except Exception as e:\n            print(f\"[SOLVE] Selection error: {e}\")\n            voted = vote_answer(question_id, force_answer=True)\n            final_answer = voted if voted is not None else (samples[0] if samples else fallback_solver(question_text))\n    \n    # Validate\n    try:\n        final_answer = int(final_answer)\n    except:\n        final_answer = fallback_solver(question_text)\n    \n    final_answer = max(0, min(99999, final_answer))\n    \n    actual_time = time.time() - solve_start\n    TIME_MANAGER.end_problem(actual_time, budget)\n    \n    print(f\"[SOLVE] Final: {final_answer}\")\n    print(f\"[SOLVE] Time: {actual_time:.1f}s\")\n    \n    completed_question_ids.add(question_id)\n    return final_answer\n\n\nprint(\"[BANSHEEV5] solve(): VERIFICATION-GATED, BEST-OF STORAGE\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# PREDICT - NO UNCONDITIONAL ZEROS\n# =========================\nimport kaggle_evaluation.aimo_3_inference_server\nimport pandas as pd\nimport polars as pl\n\n# Load reference for debugging\nid_to_answer = {}\ntry:\n    ref_path = \"/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv\"\n    if os.path.exists(ref_path):\n        df = pd.read_csv(ref_path)\n        id_to_answer = dict(zip(df[\"id\"], df[\"answer\"]))\n        df.drop(\"answer\", axis=1).to_csv(\"reference.csv\", index=False)\nexcept:\n    pass\n\n_problems_processed = 0\n_correct_count = 0\n_total_count = 0\n\n\ndef predict(id_: pl.Series, problem: pl.Series) -> pl.DataFrame:\n    \"\"\"Kaggle API prediction. NEVER returns 0 unconditionally.\"\"\"\n    global _problems_processed, _correct_count, _total_count\n    \n    try:\n        question_id = str(id_.item(0))\n    except:\n        question_id = \"unknown\"\n    \n    try:\n        question_text = str(problem.item(0))\n    except:\n        question_text = \"\"\n    \n    _problems_processed += 1\n    print(f\"\\n{'='*60}\")\n    print(f\"[PREDICT] Problem #{_problems_processed}: {question_id}\")\n    print(f\"[TIME] {TIME_MANAGER.status()}\")\n    \n    # Even if time expired, use fallback (not 0)\n    if TIME_MANAGER.is_expired():\n        print(f\"[PREDICT] TIME EXPIRED - using fallback\")\n        prediction = fallback_solver(question_text) if question_text else 42\n        return pl.DataFrame({\"id\": [question_id], \"answer\": [prediction]})\n    \n    # Empty problem - use fallback\n    if not question_text.strip():\n        print(f\"[PREDICT] Empty problem - using fallback\")\n        return pl.DataFrame({\"id\": [question_id], \"answer\": [42]})\n    \n    # SOLVE\n    try:\n        prediction = solve(question_text, question_id=question_id)\n    except Exception as e:\n        print(f\"[PREDICT] Solve error: {e} - using fallback\")\n        prediction = fallback_solver(question_text)\n    \n    # Validate\n    try:\n        prediction = int(prediction)\n    except:\n        prediction = fallback_solver(question_text)\n    \n    prediction = max(0, min(99999, prediction))\n    \n    # Score tracking\n    if id_to_answer:\n        try:\n            true_answer = int(id_to_answer.get(question_id, -1))\n            _total_count += 1\n            if prediction == true_answer and true_answer != -1:\n                _correct_count += 1\n                print(f\"[SCORE] CORRECT: {_correct_count}/{_total_count}\")\n            elif true_answer != -1:\n                print(f\"[SCORE] WRONG: pred={prediction}, true={true_answer}\")\n        except:\n            pass\n    \n    print(f\"[PREDICT] Answer: {prediction}\")\n    return pl.DataFrame({\"id\": [question_id], \"answer\": [prediction]})\n\nprint(\"[BANSHEEV5] predict(): NO UNCONDITIONAL ZEROS\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# RUN SERVER - COMPETITION ONLY\n# =========================\nprint(\"\\n\" + \"=\" * 60)\nprint(\"BANSHEEV5: COMPETITION MODE\")\nprint(f\"SERVER_WAIT: {RUNTIME.SERVER_WAIT_TIMEOUT}s\")\nprint(f\"MOCK_ANSWERS: {RUNTIME.DRY_RUN_MOCK_ANSWERS}\")\nprint(f\"CLUSTERING: {RUNTIME.ENABLE_VALUE_CLUSTERING}\")\nprint(f\"CRYSTALLIZATION: {RUNTIME.ENABLE_CRYSTALLIZATION}\")\nprint(\"=\" * 60)\n\ninference_server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n\n# ALWAYS serve() - this is competition only\nif os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n    print(\"[SERVER] Competition rerun - serve()\")\n    inference_server.serve()\nelse:\n    # Validation run - use gateway with reference.csv\n    print(\"[SERVER] Validation - run_local_gateway()\")\n    inference_server.run_local_gateway((\"reference.csv\",))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CLEANUP\n",
    "# =========================\n",
    "import atexit\n",
    "\n",
    "def cleanup():\n",
    "    global vllm_process\n",
    "    if vllm_process and vllm_process.poll() is None:\n",
    "        print(\"[CLEANUP] Stopping vLLM...\")\n",
    "        vllm_process.terminate()\n",
    "        try:\n",
    "            vllm_process.wait(timeout=10)\n",
    "        except:\n",
    "            vllm_process.kill()\n",
    "        print(\"[CLEANUP] Done\")\n",
    "\n",
    "atexit.register(cleanup)\n",
    "print(\"[BANSHEEV4] Cleanup registered\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# =========================\n# BANSHEEV5 READY\n# =========================\nprint(\"[BANSHEEV5] All cells loaded. Competition mode only.\")\nprint(\"[BANSHEEV5] NO DRY-RUN. NO MOCKS. REAL LLM ONLY.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}