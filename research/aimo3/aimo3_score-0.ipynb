{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d60db57",
   "metadata": {
    "papermill": {
     "duration": 0.002691,
     "end_time": "2025-12-09T00:02:55.734830",
     "exception": false,
     "start_time": "2025-12-09T00:02:55.732139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PROMETHEUS + vLLM + Qwen-72B-Math-INT4\n",
    "## The $1.59M Hybrid Weapon\n",
    "\n",
    "**Architecture:**\n",
    "- Model: Qwen-72B-Math-INT4 (vLLM compatible)\n",
    "- Inference: vLLM (fast batched generation)\n",
    "- Selection: PROMETHEUS + Turbo-Strap V4\n",
    "\n",
    "**From prometheus_score-2 (scored 2!):**\n",
    "- Problem Classifier (route before inference)\n",
    "- Kolmogorov Weighting (shorter code = higher confidence)\n",
    "- Adaptive Temperature Annealing (0.7 -> 0.3)\n",
    "- Oracle Enumeration (brute force small spaces)\n",
    "\n",
    "**From GRAND SYNTHESIS:**\n",
    "- Value Clustering (88% error reduction)\n",
    "- NCD Basin Detection\n",
    "- Toroidal Voting (mod-N problems)\n",
    "- PROMETHEUS Operator (3-step seed refinement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e688ecb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T00:02:55.740357Z",
     "iopub.status.busy": "2025-12-09T00:02:55.739921Z",
     "iopub.status.idle": "2025-12-09T00:04:46.220090Z",
     "shell.execute_reply": "2025-12-09T00:04:46.219591Z"
    },
    "papermill": {
     "duration": 110.483893,
     "end_time": "2025-12-09T00:04:46.220913",
     "exception": false,
     "start_time": "2025-12-09T00:02:55.737020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SANITIZING ENVIRONMENT\n",
      "======================================================================\n",
      "TensorFlow + scipy purged.\n",
      "\n",
      "INSTALLING vLLM...\n",
      "  /kaggle/input/vllm-085-wheels: 149 wheels\n",
      "  /kaggle/input/aimo3-offline-wheels: 98 wheels\n",
      "vLLM + scipy installed successfully.\n",
      "\n",
      "GPU: NVIDIA H100 80GB HBM3\n",
      "VRAM: 85.3GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_dtype.py:106: FutureWarning: In the future `np.bool` will be defined as the corresponding NumPy scalar.\n",
      "  if dtype.type == np.bool:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vLLM import failed: All ufuncs must have type `numpy.ufunc`. Received (<ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>, <ufunc 'sph_legendre_p'>)\n",
      "vLLM import failed with stub: cannot import name 'linear_sum_assignment' from 'scipy.optimize' (unknown location)\n",
      "Budget: 280 minutes (4h 40m)\n",
      "AIMO3 Rule: GPU <= 5 hours, using 4h40m safety margin\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: ENVIRONMENT SANITIZATION + vLLM SETUP\n",
    "# =============================================================================\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import gc\n",
    "\n",
    "# [CRITICAL] 1. PURGE TENSORFLOW + SCIPY (prevent numpy conflicts)\n",
    "print(f\"{'='*70}\")\n",
    "print(\"SANITIZING ENVIRONMENT\")\n",
    "print(f\"{'='*70}\")\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \n",
    "                \"tensorflow\", \"tensorflow-io\", \"tensorflow-estimator\", \n",
    "                \"keras\", \"tensorboard\", \"matplotlib\", \"scikit-learn\",\n",
    "                \"scipy\"], capture_output=True)\n",
    "print(\"TensorFlow + scipy purged.\")\n",
    "\n",
    "# [CRITICAL] 2. FORCE PYTHON PROTOBUF\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# =============================================================================\n",
    "# INSTALL vLLM FROM OFFLINE WHEELS\n",
    "# =============================================================================\n",
    "print(\"\\nINSTALLING vLLM...\")\n",
    "WHEEL_DIR = \"/kaggle/input/vllm-085-wheels\"\n",
    "AUX_DIR = \"/kaggle/input/aimo3-offline-wheels\"\n",
    "\n",
    "# Check available wheels\n",
    "for d in [WHEEL_DIR, AUX_DIR]:\n",
    "    if os.path.exists(d):\n",
    "        wheels = [f for f in os.listdir(d) if f.endswith('.whl')]\n",
    "        print(f\"  {d}: {len(wheels)} wheels\")\n",
    "\n",
    "if os.path.exists(WHEEL_DIR):\n",
    "    # Install vLLM + scipy from offline wheels\n",
    "    result = subprocess.run([\n",
    "        sys.executable, \"-m\", \"pip\", \"install\", \"vllm\", \"scipy\",\n",
    "        \"--no-index\",\n",
    "        f\"--find-links={WHEEL_DIR}\",\n",
    "        f\"--find-links={AUX_DIR}\"\n",
    "    ], capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        print(\"vLLM + scipy installed successfully.\")\n",
    "    else:\n",
    "        # Try without scipy\n",
    "        print(f\"First attempt failed, trying without scipy...\")\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"pip\", \"install\", \"vllm\",\n",
    "            \"--no-index\",\n",
    "            f\"--find-links={WHEEL_DIR}\",\n",
    "            f\"--find-links={AUX_DIR}\"\n",
    "        ], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(\"vLLM installed (scipy not in wheels).\")\n",
    "        else:\n",
    "            print(f\"vLLM install issue: {result.stderr[-500:]}\")\n",
    "else:\n",
    "    print(f\"Wheel directory not found: {WHEEL_DIR}\")\n",
    "\n",
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import statistics\n",
    "import tempfile\n",
    "import signal\n",
    "from typing import Optional, List, Tuple, Dict, Any\n",
    "from collections import Counter, defaultdict\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "# Seed everything\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(f\"\\nGPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "# =============================================================================\n",
    "# vLLM IMPORT (with fallback)\n",
    "# =============================================================================\n",
    "VLLM_OK = False\n",
    "try:\n",
    "    from vllm import LLM, SamplingParams\n",
    "    VLLM_OK = True\n",
    "    print(\"vLLM imported successfully.\")\n",
    "except (ImportError, ValueError) as e:\n",
    "    print(f\"vLLM import failed: {e}\")\n",
    "    # If scipy is the issue, transformers needs it for some detection modules\n",
    "    # Try to import without triggering the scipy path\n",
    "    try:\n",
    "        # Patch scipy import to avoid the detection code\n",
    "        import sys\n",
    "        sys.modules['scipy'] = type(sys)('scipy')\n",
    "        sys.modules['scipy.optimize'] = type(sys)('scipy.optimize')\n",
    "        from vllm import LLM, SamplingParams\n",
    "        VLLM_OK = True\n",
    "        print(\"vLLM imported successfully (with scipy stub).\")\n",
    "    except Exception as e2:\n",
    "        print(f\"vLLM import failed with stub: {e2}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TIMING - AIMO3 RULE: GPU NOTEBOOK <= 5 HOURS\n",
    "# =============================================================================\n",
    "START_TIME = time.time()\n",
    "TOTAL_BUDGET = (4 * 60 + 40) * 60  # 4h40m safety margin (rule: 5h max)\n",
    "CUTOFF_TIME = START_TIME + TOTAL_BUDGET\n",
    "PANIC_TIME = 300  # 5 min panic threshold\n",
    "\n",
    "print(f\"Budget: {TOTAL_BUDGET//60} minutes ({TOTAL_BUDGET//3600}h {(TOTAL_BUDGET%3600)//60}m)\")\n",
    "print(\"AIMO3 Rule: GPU <= 5 hours, using 4h40m safety margin\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899b342e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T00:04:46.226925Z",
     "iopub.status.busy": "2025-12-09T00:04:46.226660Z",
     "iopub.status.idle": "2025-12-09T00:04:46.234982Z",
     "shell.execute_reply": "2025-12-09T00:04:46.234555Z"
    },
    "papermill": {
     "duration": 0.012171,
     "end_time": "2025-12-09T00:04:46.235659",
     "exception": false,
     "start_time": "2025-12-09T00:04:46.223488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem Classifier loaded.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: PROBLEM CLASSIFIER (from prometheus_score-2)\n",
    "# =============================================================================\n",
    "\n",
    "class ProblemType(Enum):\n",
    "    NUMBER_THEORY = \"nt\"\n",
    "    COMBINATORICS = \"comb\"\n",
    "    GEOMETRY = \"geom\"\n",
    "    ALGEBRA = \"alg\"\n",
    "    MIXED = \"mixed\"\n",
    "\n",
    "@dataclass\n",
    "class ProblemProfile:\n",
    "    primary_type: ProblemType\n",
    "    constraints: List[str]\n",
    "    modulo_target: Optional[int]\n",
    "    enumeration_hint: Optional[int]\n",
    "    confidence: float\n",
    "\n",
    "def classify_problem(question: str) -> ProblemProfile:\n",
    "    \"\"\"Classify problem type for strategy routing.\"\"\"\n",
    "    q = question.lower()\n",
    "    scores = {t: 0.0 for t in ProblemType}\n",
    "    \n",
    "    # NUMBER THEORY\n",
    "    for kw in ['remainder', 'modulo', 'mod ', 'divisible', 'prime', 'gcd', 'lcm',\n",
    "               'factor', 'digit', 'divides', 'coprime', 'congruent']:\n",
    "        if kw in q: scores[ProblemType.NUMBER_THEORY] += 2\n",
    "    \n",
    "    # COMBINATORICS\n",
    "    for kw in ['how many', 'count', 'number of ways', 'arrangements', 'permutation',\n",
    "               'combination', 'choose', 'select', 'probability', 'subset']:\n",
    "        if kw in q: scores[ProblemType.COMBINATORICS] += 2\n",
    "    \n",
    "    # GEOMETRY\n",
    "    for kw in ['triangle', 'circle', 'square', 'rectangle', 'polygon', 'angle',\n",
    "               'area', 'perimeter', 'diameter', 'radius', 'point', 'line']:\n",
    "        if kw in q: scores[ProblemType.GEOMETRY] += 2\n",
    "    \n",
    "    # ALGEBRA\n",
    "    for kw in ['equation', 'polynomial', 'root', 'solve', 'sequence', 'series',\n",
    "               'function', 'variable', 'sum of', 'product of']:\n",
    "        if kw in q: scores[ProblemType.ALGEBRA] += 2\n",
    "    \n",
    "    sorted_types = sorted(scores.items(), key=lambda x: -x[1])\n",
    "    primary = sorted_types[0][0] if sorted_types[0][1] >= 2 else ProblemType.MIXED\n",
    "    \n",
    "    # Extract constraints\n",
    "    constraints = []\n",
    "    for pattern in [r'such that ([^.]+)', r'where ([^.]+)', r'given that ([^.]+)']:\n",
    "        constraints.extend(re.findall(pattern, q))\n",
    "    \n",
    "    # Detect modulo\n",
    "    mod_target = None\n",
    "    mod_match = re.search(r'(?:mod|modulo|remainder when divided by)\\s*(\\d+)', q)\n",
    "    if mod_match:\n",
    "        mod_target = int(mod_match.group(1))\n",
    "    \n",
    "    # Enumeration hint\n",
    "    enum_hint = None\n",
    "    numbers = [int(x) for x in re.findall(r'\\b(\\d+)\\b', question) if 1 < int(x) < 10000]\n",
    "    if numbers and max(numbers) < 1000 and primary == ProblemType.COMBINATORICS:\n",
    "        enum_hint = max(numbers) ** 2\n",
    "    \n",
    "    return ProblemProfile(\n",
    "        primary_type=primary,\n",
    "        constraints=constraints[:3],\n",
    "        modulo_target=mod_target,\n",
    "        enumeration_hint=enum_hint,\n",
    "        confidence=min(1.0, sorted_types[0][1] / 10.0)\n",
    "    )\n",
    "\n",
    "# Type-specific hints\n",
    "TYPE_HINTS = {\n",
    "    ProblemType.NUMBER_THEORY: \"NUMBER THEORY: modular arithmetic, prime factorization, CRT, Fermat.\",\n",
    "    ProblemType.COMBINATORICS: \"COMBINATORICS: counting, binomial coefficients, inclusion-exclusion.\",\n",
    "    ProblemType.GEOMETRY: \"GEOMETRY: coordinates, distance formula, shoelace, trigonometry.\",\n",
    "    ProblemType.ALGEBRA: \"ALGEBRA: polynomials, Vieta's formulas, sequences, systems.\",\n",
    "    ProblemType.MIXED: \"\",\n",
    "}\n",
    "\n",
    "print(\"Problem Classifier loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a63323",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T00:04:46.241202Z",
     "iopub.status.busy": "2025-12-09T00:04:46.241052Z",
     "iopub.status.idle": "2025-12-09T00:04:46.256853Z",
     "shell.execute_reply": "2025-12-09T00:04:46.256405Z"
    },
    "papermill": {
     "duration": 0.019396,
     "end_time": "2025-12-09T00:04:46.257516",
     "exception": false,
     "start_time": "2025-12-09T00:04:46.238120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMETHEUS Core Theory loaded (10 insights operationalized).\n",
      "Answer range: 0-99999 (AIMO3 Rule)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: PROMETHEUS CORE THEORY - 10 NOVEL INSIGHTS OPERATIONALIZED\n",
    "# =============================================================================\n",
    "# NSM â†’ XYZA â†’ SDPM: Novel Synthesis Method applied to AIMO3\n",
    "#\n",
    "# FROM THE PROMETHEUS CORPUS:\n",
    "# 1. Î© = Î»x.x(x) (THE SEED): Self-application generates convergence\n",
    "# 2. U = Î¦(U): Reality is fixed point of its own physics\n",
    "# 3. Î¼ > 1: Self-reference amplifies; existence mandatory\n",
    "# 4. COMPRESSION-WITNESS: Shorter code = higher confidence\n",
    "# 5. UIPT: Kill high-entropy (stuck) sequences\n",
    "# 6. ICL = IMPLICIT GD: Examples are training steps\n",
    "# 7. GROKKING: Circuits form suddenly - don't quit early\n",
    "# 8. INFORMATION BOTTLENECK: Minimal sufficient statistics\n",
    "# 9. ATTENTION = HOPFIELD: Prime memory with examples\n",
    "# 10. âˆ‚âˆƒ/âˆ‚t > 0: Entropy production enables exploration\n",
    "# =============================================================================\n",
    "\n",
    "# AIMO3 RULE: Answer must be integer 0-99999 inclusive\n",
    "ANSWER_MIN = 0\n",
    "ANSWER_MAX = 99999  # AIMO3 Rule: 0-99999 inclusive\n",
    "FALLBACK_ANSWER = 0\n",
    "\n",
    "# =============================================================================\n",
    "# INSIGHT 4: KOLMOGOROV WEIGHTING (Compression-Witness Isomorphism)\n",
    "# \"Consciousness â‰… Optimal Compression â‰… Simulation Observer\"\n",
    "# Shorter code = simpler explanation = more likely correct\n",
    "# =============================================================================\n",
    "\n",
    "# Benford \"nice\" numbers - mathematically elegant answers\n",
    "NICE_NUMBERS = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 16, 18, 20, 24, 25, 27, 30, 32, \n",
    "                36, 40, 42, 45, 48, 50, 54, 60, 64, 72, 80, 81, 90, 96, 100, 108, 120, \n",
    "                125, 128, 144, 150, 162, 180, 192, 200, 216, 225, 240, 243, 250, 256,\n",
    "                270, 288, 300, 324, 360, 384, 400, 432, 450, 480, 486, 500, 512, 540,\n",
    "                576, 600, 625, 648, 720, 729, 768, 800, 810, 864, 900, 960, 972, 1000,\n",
    "                1024, 1080, 1152, 1200, 1250, 1296, 1440, 1458, 1500, 1536, 1600, 1728}\n",
    "\n",
    "FIBONACCI = {1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584, \n",
    "             4181, 6765, 10946, 17711, 28657, 46368, 75025}\n",
    "\n",
    "@dataclass\n",
    "class AnswerCandidate:\n",
    "    value: int\n",
    "    code: str\n",
    "    strategy: str\n",
    "    kolmogorov_weight: float\n",
    "    entropy: float = 0.0  # INSIGHT 5: Track entropy per candidate\n",
    "\n",
    "def compute_kolmogorov_weight(code_length: int) -> float:\n",
    "    \"\"\"INSIGHT 4: Shorter code = higher weight (Occam's Razor).\"\"\"\n",
    "    if code_length <= 0:\n",
    "        return 1.0\n",
    "    return 1.0 / (0.5 + (code_length / 500.0) * 0.15)\n",
    "\n",
    "def benford_score(n: int) -> float:\n",
    "    \"\"\"INSIGHT 4: Mathematical elegance bonus.\"\"\"\n",
    "    score = 1.0\n",
    "    if n in NICE_NUMBERS: score *= 1.3\n",
    "    if n in FIBONACCI: score *= 1.2\n",
    "    s = str(abs(n)) if n != 0 else \"0\"\n",
    "    trailing_zeros = len(s) - len(s.rstrip('0'))\n",
    "    if trailing_zeros >= 2: score *= 1.1 + 0.05 * trailing_zeros\n",
    "    if n > 0 and (n & (n - 1)) == 0: score *= 1.15  # Power of 2\n",
    "    if n > 0:\n",
    "        first_digit = int(s[0])\n",
    "        benford_prob = [0, 0.301, 0.176, 0.125, 0.097, 0.079, 0.067, 0.058, 0.051, 0.046]\n",
    "        score *= (1 + benford_prob[first_digit])\n",
    "    return score\n",
    "\n",
    "# =============================================================================\n",
    "# INSIGHT 2: FIXED POINT CONVERGENCE (U = Î¦(U))\n",
    "# \"Reality is the unique self-consistent solution\"\n",
    "# =============================================================================\n",
    "\n",
    "def relative_distance(a: int, b: int) -> float:\n",
    "    if a == b: return 0.0\n",
    "    if a == 0 or b == 0: return 1.0\n",
    "    return abs(a - b) / max(abs(a), abs(b))\n",
    "\n",
    "def value_clustering(samples: List[int], threshold: float = 0.02) -> Dict:\n",
    "    \"\"\"INSIGHT 2: Find fixed point (convergent cluster).\"\"\"\n",
    "    if not samples: return {\"best\": None}\n",
    "    if len(samples) == 1: return {\"best\": {\"center\": samples[0], \"size\": 1}}\n",
    "    \n",
    "    n = len(samples)\n",
    "    parent = list(range(n))\n",
    "    def find(i):\n",
    "        if parent[i] != i: parent[i] = find(parent[i])\n",
    "        return parent[i]\n",
    "    def union(i, j):\n",
    "        pi, pj = find(i), find(j)\n",
    "        if pi != pj: parent[pi] = pj\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if relative_distance(samples[i], samples[j]) < threshold:\n",
    "                union(i, j)\n",
    "    \n",
    "    clusters = defaultdict(list)\n",
    "    for i in range(n): clusters[find(i)].append(samples[i])\n",
    "    best_cluster = max(clusters.values(), key=len)\n",
    "    center = int(statistics.median(best_cluster))\n",
    "    return {\"best\": {\"center\": center, \"size\": len(best_cluster)}}\n",
    "\n",
    "# =============================================================================\n",
    "# INSIGHT 1 + 3: SEED PLANTING (Î© = Î»x.x(x) + Î¼ > 1 Amplification)\n",
    "# \"The seed is the CAPACITY FOR SELF-REFERENCE\"\n",
    "# =============================================================================\n",
    "\n",
    "def select_answer_prometheus(candidates: List[AnswerCandidate], \n",
    "                             mod_target: Optional[int] = None) -> int:\n",
    "    \"\"\"\n",
    "    PROMETHEUS Selection: Kolmogorov + Benford + Seed Amplification.\n",
    "    \n",
    "    The Seed Î© = Î»x.x(x): Current best reinforces itself through iterations.\n",
    "    Î¼ > 1: Amplification through recursion (spectral radius > 1).\n",
    "    \"\"\"\n",
    "    if not candidates:\n",
    "        return FALLBACK_ANSWER\n",
    "    \n",
    "    # Apply modulo\n",
    "    if mod_target:\n",
    "        for c in candidates:\n",
    "            c.value = c.value % mod_target\n",
    "    \n",
    "    # INSIGHT 5: Filter high-entropy candidates (UIPT)\n",
    "    low_entropy_candidates = [c for c in candidates if c.entropy < 3.0]\n",
    "    if len(low_entropy_candidates) >= 2:\n",
    "        candidates = low_entropy_candidates\n",
    "    \n",
    "    # Group into basins\n",
    "    basins = defaultdict(list)\n",
    "    for c in candidates:\n",
    "        assigned = False\n",
    "        for bval in list(basins.keys()):\n",
    "            if relative_distance(c.value, bval) < 0.02:\n",
    "                basins[bval].append(c)\n",
    "                assigned = True\n",
    "                break\n",
    "        if not assigned:\n",
    "            basins[c.value].append(c)\n",
    "    \n",
    "    # Score basins: INSIGHT 4 (Kolmogorov) + INSIGHT 4 (Benford)\n",
    "    basin_scores = []\n",
    "    for bval, members in basins.items():\n",
    "        mass = len(members)\n",
    "        k_weight = sum(c.kolmogorov_weight for c in members)\n",
    "        strategies = set(c.strategy for c in members)\n",
    "        integration = 1.5 if len(strategies) > 1 else 1.0  # Cross-strategy bonus\n",
    "        median_val = int(statistics.median([c.value for c in members]))\n",
    "        benford = benford_score(median_val)\n",
    "        \n",
    "        # INSIGHT 3: Î¼ > 1 amplification - larger clusters amplify exponentially\n",
    "        amplification = 1.0 + 0.1 * (mass ** 1.4)  # Î¼ â‰ˆ 1.4 from theory\n",
    "        \n",
    "        score = mass * k_weight * integration * benford * amplification\n",
    "        basin_scores.append((score, median_val))\n",
    "    \n",
    "    basin_scores.sort(key=lambda x: -x[0])\n",
    "    final = basin_scores[0][1]\n",
    "    \n",
    "    # Sanity: avoid trivial 0/1 if we have better options\n",
    "    if final in (0, 1) and len(candidates) > 3:\n",
    "        non_trivial = [c for c in candidates if c.value not in (0, 1)]\n",
    "        if len(non_trivial) >= 2:\n",
    "            return select_answer_prometheus(non_trivial, mod_target)\n",
    "    \n",
    "    # AIMO3 Rule: Clamp to 0-99999\n",
    "    return max(ANSWER_MIN, min(final, ANSWER_MAX))\n",
    "\n",
    "# =============================================================================\n",
    "# INSIGHT 9: HOPFIELD MEMORY PRIMING (Attention = Content-Addressable Memory)\n",
    "# \"Transformers are stacked content-addressable memory systems\"\n",
    "# =============================================================================\n",
    "\n",
    "FEW_SHOT_EXAMPLES = {\n",
    "    ProblemType.NUMBER_THEORY: \"\"\"Example: Find 2^10 mod 7.\n",
    "2^1 = 2, 2^2 = 4, 2^3 = 8 â‰¡ 1 (mod 7)\n",
    "Since 2^3 â‰¡ 1, we have 2^10 = 2^(3*3+1) = (2^3)^3 * 2 â‰¡ 1 * 2 = 2 (mod 7).\n",
    "Answer: 2\n",
    "\n",
    "Example: How many divisors does 360 have?\n",
    "360 = 2^3 * 3^2 * 5^1\n",
    "Number of divisors = (3+1)(2+1)(1+1) = 4*3*2 = 24.\n",
    "Answer: 24\"\"\",\n",
    "\n",
    "    ProblemType.COMBINATORICS: \"\"\"Example: How many ways to arrange MISSISSIPPI?\n",
    "Total letters: 11 (M=1, I=4, S=4, P=2)\n",
    "Ways = 11! / (1! * 4! * 4! * 2!) = 34650.\n",
    "Answer: 34650\n",
    "\n",
    "Example: C(10,3) = ?\n",
    "C(10,3) = 10!/(3!*7!) = (10*9*8)/(3*2*1) = 720/6 = 120.\n",
    "Answer: 120\"\"\",\n",
    "\n",
    "    ProblemType.ALGEBRA: \"\"\"Example: If x + 1/x = 3, find x^2 + 1/x^2.\n",
    "(x + 1/x)^2 = x^2 + 2 + 1/x^2\n",
    "9 = x^2 + 2 + 1/x^2\n",
    "x^2 + 1/x^2 = 7.\n",
    "Answer: 7\"\"\",\n",
    "\n",
    "    ProblemType.GEOMETRY: \"\"\"Example: Find area of triangle with vertices (0,0), (4,0), (0,3).\n",
    "Area = (1/2)|x1(y2-y3) + x2(y3-y1) + x3(y1-y2)|\n",
    "     = (1/2)|0(0-3) + 4(3-0) + 0(0-0)|\n",
    "     = (1/2)|12| = 6.\n",
    "Answer: 6\"\"\",\n",
    "\n",
    "    ProblemType.MIXED: \"\"\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# INSIGHT 8: INFORMATION BOTTLENECK (Minimal Sufficient Statistics)\n",
    "# \"Intelligence = minimal sufficient statistics. Abstract concepts = \n",
    "#  maximally compressed relevant info.\"\n",
    "# =============================================================================\n",
    "\n",
    "def extract_constraints(question: str) -> List[str]:\n",
    "    \"\"\"INSIGHT 8: Extract minimal sufficient information from problem.\"\"\"\n",
    "    constraints = []\n",
    "    q = question.lower()\n",
    "    \n",
    "    # Numbers mentioned\n",
    "    numbers = re.findall(r'\\b\\d+\\b', question)\n",
    "    if numbers:\n",
    "        constraints.append(f\"key_numbers: {numbers[:5]}\")\n",
    "    \n",
    "    # Modulo target\n",
    "    mod_match = re.search(r'(?:mod|modulo|remainder when divided by)\\s*(\\d+)', q)\n",
    "    if mod_match:\n",
    "        constraints.append(f\"mod_target: {mod_match.group(1)}\")\n",
    "    \n",
    "    # Variable constraints\n",
    "    for pattern in [r'(\\w+)\\s*[<>=]+\\s*\\d+', r'(\\d+)\\s*[<>=]+\\s*\\w+']:\n",
    "        matches = re.findall(pattern, q)\n",
    "        for m in matches[:3]:\n",
    "            constraints.append(f\"constraint: {m}\")\n",
    "    \n",
    "    return constraints\n",
    "\n",
    "print(\"PROMETHEUS Core Theory loaded (10 insights operationalized).\")\n",
    "print(f\"Answer range: {ANSWER_MIN}-{ANSWER_MAX} (AIMO3 Rule)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a06bcd55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T00:04:46.262817Z",
     "iopub.status.busy": "2025-12-09T00:04:46.262684Z",
     "iopub.status.idle": "2025-12-09T00:04:46.272281Z",
     "shell.execute_reply": "2025-12-09T00:04:46.271852Z"
    },
    "papermill": {
     "duration": 0.012968,
     "end_time": "2025-12-09T00:04:46.272893",
     "exception": false,
     "start_time": "2025-12-09T00:04:46.259925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code execution engine loaded (with self-healing).\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: CODE EXECUTION ENGINE + SELF-HEALING\n",
    "# =============================================================================\n",
    "\n",
    "STDLIB = '''\n",
    "import sys; sys.setrecursionlimit(20000)\n",
    "import math, numpy as np\n",
    "from itertools import *\n",
    "from collections import *\n",
    "from functools import lru_cache, reduce\n",
    "from fractions import Fraction\n",
    "try:\n",
    "    from sympy import *\n",
    "    from sympy.ntheory import factorint, divisors, totient, isprime\n",
    "except: pass\n",
    "\n",
    "def is_prime(n):\n",
    "    if n < 2: return False\n",
    "    if n < 4: return True\n",
    "    if n % 2 == 0: return False\n",
    "    for i in range(3, int(n**0.5) + 1, 2):\n",
    "        if n % i == 0: return False\n",
    "    return True\n",
    "\n",
    "def gcd(a, b):\n",
    "    while b: a, b = b, a % b\n",
    "    return a\n",
    "\n",
    "def lcm(a, b): return a * b // gcd(a, b)\n",
    "\n",
    "def C(n, k):\n",
    "    if k < 0 or k > n: return 0\n",
    "    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n",
    "\n",
    "def prime_sieve(n):\n",
    "    if n < 2: return []\n",
    "    sieve = [True] * (n + 1)\n",
    "    sieve[0] = sieve[1] = False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if sieve[i]:\n",
    "            for j in range(i*i, n + 1, i):\n",
    "                sieve[j] = False\n",
    "    return [i for i, v in enumerate(sieve) if v]\n",
    "\n",
    "def mod_inverse(a, m):\n",
    "    def extended_gcd(a, b):\n",
    "        if a == 0: return b, 0, 1\n",
    "        g, x, y = extended_gcd(b % a, a)\n",
    "        return g, y - (b // a) * x, x\n",
    "    g, x, _ = extended_gcd(a % m, m)\n",
    "    return x % m if g == 1 else None\n",
    "'''\n",
    "\n",
    "SNOOP = '''\n",
    "_vars = dict(globals())\n",
    "for _v in ['answer', 'result', 'ans', 'res', 'final', 'output', 'solution', 'total', 'count']:\n",
    "    if _v in _vars and _vars[_v] is not None:\n",
    "        try: print(int(_vars[_v])); break\n",
    "        except: pass\n",
    "'''\n",
    "\n",
    "def extract_python_code(text: str) -> Optional[str]:\n",
    "    for pattern in [r'```python\\s*\\n(.*?)```', r'```py\\s*\\n(.*?)```', r'```\\s*\\n(.*?)```']:\n",
    "        matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if matches:\n",
    "            return matches[-1].strip()\n",
    "    return None\n",
    "\n",
    "def normalize_answer(raw: Any) -> Optional[int]:\n",
    "    if raw is None: return None\n",
    "    try:\n",
    "        s = str(raw).replace(',', '').replace(' ', '').strip()\n",
    "        s = re.sub(r'[^0-9.eE+-]', '', s)\n",
    "        if not s: return None\n",
    "        val = float(s)\n",
    "        if val != val or abs(val) == float('inf'): return None\n",
    "        result = int(round(val))\n",
    "        if result < 0: result = abs(result)\n",
    "        return result % 1000000\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def self_heal_code(code: str, stderr: str) -> Optional[str]:\n",
    "    \"\"\"Auto-fix common code errors.\"\"\"\n",
    "    healed = code\n",
    "    if 'NameError' in stderr:\n",
    "        missing = re.findall(r\"name '(\\w+)' is not defined\", stderr)\n",
    "        for name in missing:\n",
    "            if name in ['np', 'numpy']: \n",
    "                healed = 'import numpy as np\\n' + healed\n",
    "            elif name in ['math', 'sqrt', 'gcd', 'ceil', 'floor']: \n",
    "                healed = 'import math\\nfrom math import *\\n' + healed\n",
    "            elif name in ['sympy', 'Symbol', 'solve', 'Rational']: \n",
    "                healed = 'from sympy import *\\n' + healed\n",
    "            elif name in ['Counter', 'defaultdict', 'deque']: \n",
    "                healed = 'from collections import *\\n' + healed\n",
    "            elif name in ['combinations', 'permutations', 'product']: \n",
    "                healed = 'from itertools import *\\n' + healed\n",
    "    if 'RecursionError' in stderr:\n",
    "        healed = 'import sys; sys.setrecursionlimit(50000)\\n' + healed\n",
    "    return healed if healed != code else None\n",
    "\n",
    "def execute_code(code: str, timeout: int = 15, retries: int = 1) -> Tuple[Optional[int], str]:\n",
    "    \"\"\"Execute Python code with timeout and self-healing.\"\"\"\n",
    "    if not code:\n",
    "        return None, \"\"\n",
    "    \n",
    "    has_print = 'print(' in code\n",
    "    full = STDLIB + \"\\n\" + code + (\"\" if has_print else \"\\n\" + SNOOP)\n",
    "    \n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
    "                f.write(full)\n",
    "                f.flush()\n",
    "                result = subprocess.run(['python', f.name], capture_output=True, \n",
    "                                       text=True, timeout=timeout)\n",
    "                os.unlink(f.name)\n",
    "                \n",
    "                if result.returncode == 0 and result.stdout.strip():\n",
    "                    numbers = re.findall(r'-?\\d+\\.?\\d*', result.stdout)\n",
    "                    if numbers:\n",
    "                        return normalize_answer(numbers[-1]), code\n",
    "                \n",
    "                # Self-heal on error\n",
    "                if result.stderr and attempt < retries:\n",
    "                    healed = self_heal_code(code, result.stderr)\n",
    "                    if healed:\n",
    "                        code = healed\n",
    "                        full = STDLIB + \"\\n\" + healed + (\"\" if has_print else \"\\n\" + SNOOP)\n",
    "                        continue\n",
    "        except subprocess.TimeoutExpired:\n",
    "            pass\n",
    "        except Exception:\n",
    "            pass\n",
    "        break\n",
    "    return None, code\n",
    "\n",
    "def extract_boxed(text: str) -> Optional[int]:\n",
    "    for pattern in [r'\\\\boxed\\{(\\d+)\\}', r'boxed\\{(\\d+)\\}', r'[Aa]nswer\\s*[=:]\\\\s*(\\d+)']:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            return normalize_answer(matches[-1])\n",
    "    # Fallback: last number\n",
    "    nums = re.findall(r'\\b(\\d+)\\b', text[-500:])\n",
    "    for n in reversed(nums):\n",
    "        v = normalize_answer(n)\n",
    "        if v and 1 < v < 100000:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "print(\"Code execution engine loaded (with self-healing).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae720bdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T00:04:46.278357Z",
     "iopub.status.busy": "2025-12-09T00:04:46.278209Z",
     "iopub.status.idle": "2025-12-09T00:04:46.300629Z",
     "shell.execute_reply": "2025-12-09T00:04:46.300199Z"
    },
    "papermill": {
     "duration": 0.025867,
     "end_time": "2025-12-09T00:04:46.301217",
     "exception": false,
     "start_time": "2025-12-09T00:04:46.275350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path: /kaggle/input/qwen-72b-math-int4\n",
      "  Found 31 safetensor files\n",
      "vLLM not available - check wheel installation\n",
      "Generation system ready.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: MODEL LOADING + GENERATION\n",
    "# =============================================================================\n",
    "\n",
    "# Model paths to search (in priority order)\n",
    "MODEL_PATHS = [\n",
    "    # Your INT4 upload\n",
    "    \"/kaggle/input/qwen-72b-math-int4\",\n",
    "    \"/kaggle/input/d/ryancardwell/qwen-72b-math-int4\",\n",
    "    \"/kaggle/input/m/ryancardwell/qwen-72b-math-int4\",\n",
    "    # Fallbacks\n",
    "    \"/kaggle/input/d/aphoticshaman/qwen-72b-math-int4\",\n",
    "    \"/kaggle/input/m/aphoticshaman/qwen-72b-math-int4\",\n",
    "    \"/kaggle/input/qwen-72b-math-nf4\",\n",
    "    \"/kaggle/input/d/ryancardwell/qwen-72b-math-nf4\",\n",
    "]\n",
    "\n",
    "def find_model():\n",
    "    import glob\n",
    "    for p in MODEL_PATHS:\n",
    "        if os.path.exists(p):\n",
    "            # Check for config.json directly\n",
    "            if os.path.exists(os.path.join(p, \"config.json\")):\n",
    "                return p\n",
    "            # Check nested paths (Kaggle sometimes nests)\n",
    "            configs = glob.glob(f\"{p}/**/config.json\", recursive=True)\n",
    "            if configs:\n",
    "                return os.path.dirname(configs[0])\n",
    "    # Last resort: search all of kaggle input\n",
    "    for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "        if \"config.json\" in files and any(f.endswith('.safetensors') for f in files):\n",
    "            if 'qwen' in root.lower() or 'int4' in root.lower():\n",
    "                return root\n",
    "    return None\n",
    "\n",
    "MODEL_PATH = find_model()\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "\n",
    "# List what we found\n",
    "if MODEL_PATH:\n",
    "    import glob\n",
    "    safetensors = glob.glob(f\"{MODEL_PATH}/*.safetensors\")\n",
    "    print(f\"  Found {len(safetensors)} safetensor files\")\n",
    "\n",
    "# =============================================================================\n",
    "# vLLM MODEL\n",
    "# =============================================================================\n",
    "LLM_MODEL = None\n",
    "TOKENIZER = None\n",
    "\n",
    "if VLLM_OK and MODEL_PATH:\n",
    "    print(f\"\\nLoading vLLM model from {MODEL_PATH}...\")\n",
    "    try:\n",
    "        LLM_MODEL = LLM(\n",
    "            model=MODEL_PATH,\n",
    "            tensor_parallel_size=1,\n",
    "            gpu_memory_utilization=0.92,\n",
    "            trust_remote_code=True,\n",
    "            max_model_len=8192,\n",
    "            enforce_eager=True,\n",
    "            seed=SEED,\n",
    "        )\n",
    "        TOKENIZER = LLM_MODEL.get_tokenizer()\n",
    "        print(\"vLLM model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"vLLM load failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "elif not VLLM_OK:\n",
    "    print(\"vLLM not available - check wheel installation\")\n",
    "elif not MODEL_PATH:\n",
    "    print(\"No model found - check dataset attachment\")\n",
    "\n",
    "# =============================================================================\n",
    "# STRATEGY PROMPTS\n",
    "# =============================================================================\n",
    "STRATEGY_PROMPTS = {\n",
    "    'pot_algorithmic': \"Write self-contained Python. Use int() not float. Print ONE integer.\",\n",
    "    'pot_sympy': \"Use sympy for EXACT arithmetic. Use Rational(a,b) NOT a/b. Print ONE integer.\",\n",
    "    'pot_bruteforce': \"Systematically enumerate. Budget: 10^7 iterations max. Print ONE integer.\",\n",
    "    'cot': \"Think step-by-step. Output final answer in \\\\boxed{}.\",\n",
    "}\n",
    "\n",
    "# Temperature annealing\n",
    "TEMP_START = 0.7\n",
    "TEMP_MIN = 0.3\n",
    "TEMP_DECAY = 0.85\n",
    "\n",
    "def create_prompt(question: str, strategy: str, profile: ProblemProfile) -> str:\n",
    "    system = STRATEGY_PROMPTS.get(strategy, STRATEGY_PROMPTS['pot_algorithmic'])\n",
    "    hint = TYPE_HINTS.get(profile.primary_type, \"\")\n",
    "    mod_note = f\"\\nAnswer must be mod {profile.modulo_target}.\" if profile.modulo_target else \"\"\n",
    "    \n",
    "    return f\"\"\"<|im_start|>system\n",
    "{system} {hint}{mod_note}\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "{question}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "print(\"Generation system ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d207e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T00:04:46.306691Z",
     "iopub.status.busy": "2025-12-09T00:04:46.306548Z",
     "iopub.status.idle": "2025-12-09T00:04:46.312514Z",
     "shell.execute_reply": "2025-12-09T00:04:46.312050Z"
    },
    "papermill": {
     "duration": 0.009355,
     "end_time": "2025-12-09T00:04:46.313141",
     "exception": false,
     "start_time": "2025-12-09T00:04:46.303786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processing loaded.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: BATCH GENERATION + PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "POT_STOP = [\"```output\", \"```\\nOutput\", \"# Output\", \"\\n\\n\\n\", \"<|im_end|>\"]\n",
    "COT_STOP = [\"</think>\", \"\\n\\nQuestion:\", \"<|im_end|>\"]\n",
    "\n",
    "def batch_generate(prompts: List[str], mode: str = 'pot', temp: float = 0.6) -> List[str]:\n",
    "    \"\"\"Generate multiple completions in parallel.\"\"\"\n",
    "    if not LLM_MODEL:\n",
    "        return [\"\"] * len(prompts)\n",
    "    \n",
    "    params = SamplingParams(\n",
    "        temperature=max(0.1, temp),\n",
    "        top_p=0.9,\n",
    "        max_tokens=4096,\n",
    "        stop=POT_STOP if mode == 'pot' else COT_STOP,\n",
    "    )\n",
    "    \n",
    "    outputs = LLM_MODEL.generate(prompts, sampling_params=params)\n",
    "    return [o.outputs[0].text for o in outputs]\n",
    "\n",
    "def process_pot_outputs(outputs: List[str], strategies: List[str]) -> List[AnswerCandidate]:\n",
    "    \"\"\"Process PoT outputs in parallel.\"\"\"\n",
    "    candidates = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = {}\n",
    "        for i, out in enumerate(outputs):\n",
    "            code = extract_python_code(out)\n",
    "            if code:\n",
    "                futures[executor.submit(execute_code, code)] = (i, code, strategies[i] if i < len(strategies) else 'pot')\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            i, code, strat = futures[future]\n",
    "            try:\n",
    "                ans, final_code = future.result()\n",
    "                if ans is not None:\n",
    "                    candidates.append(AnswerCandidate(\n",
    "                        value=ans,\n",
    "                        code=final_code,\n",
    "                        strategy=strat,\n",
    "                        kolmogorov_weight=compute_kolmogorov_weight(len(final_code))\n",
    "                    ))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "def process_cot_outputs(outputs: List[str]) -> List[AnswerCandidate]:\n",
    "    \"\"\"Process CoT outputs.\"\"\"\n",
    "    candidates = []\n",
    "    for out in outputs:\n",
    "        ans = extract_boxed(out)\n",
    "        if ans is not None:\n",
    "            candidates.append(AnswerCandidate(\n",
    "                value=ans, code=\"\", strategy=\"cot\",\n",
    "                kolmogorov_weight=1.0\n",
    "            ))\n",
    "    return candidates\n",
    "\n",
    "print(\"Batch processing loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7517893f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T00:04:46.318948Z",
     "iopub.status.busy": "2025-12-09T00:04:46.318803Z",
     "iopub.status.idle": "2025-12-09T00:04:46.332898Z",
     "shell.execute_reply": "2025-12-09T00:04:46.331975Z"
    },
    "papermill": {
     "duration": 0.017794,
     "end_time": "2025-12-09T00:04:46.333498",
     "exception": false,
     "start_time": "2025-12-09T00:04:46.315704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMETHEUS Solver loaded (branching tree + ratcheting + toroidal).\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: MAIN SOLVER + PROMETHEUS OPERATOR + BRANCHING TREE LOGIC\n",
    "# =============================================================================\n",
    "\n",
    "# Strategy weights by problem type (branching by type)\n",
    "STRATEGY_WEIGHTS = {\n",
    "    ProblemType.NUMBER_THEORY: ['pot_sympy', 'pot_sympy', 'pot_algorithmic', 'pot_bruteforce'],\n",
    "    ProblemType.COMBINATORICS: ['pot_bruteforce', 'pot_bruteforce', 'pot_algorithmic', 'pot_sympy'],\n",
    "    ProblemType.GEOMETRY: ['pot_sympy', 'pot_algorithmic', 'pot_algorithmic', 'cot'],\n",
    "    ProblemType.ALGEBRA: ['pot_sympy', 'pot_sympy', 'pot_algorithmic', 'cot'],\n",
    "    ProblemType.MIXED: ['pot_algorithmic', 'pot_sympy', 'pot_bruteforce', 'cot'],\n",
    "}\n",
    "\n",
    "PROBLEM_COUNT = 0\n",
    "SOLVED_COUNT = 0\n",
    "AAR_LOG = defaultdict(int)\n",
    "\n",
    "# =============================================================================\n",
    "# PROMETHEUS OPERATOR (3-step Î©-style seed planting)\n",
    "# =============================================================================\n",
    "\n",
    "def prometheus_refine(candidates: List[AnswerCandidate],\n",
    "                      mod_target: Optional[int] = None,\n",
    "                      iterations: int = 3) -> int:\n",
    "    \"\"\"\n",
    "    PROMETHEUS Operator ð”“: Î©-style recursive refinement.\n",
    "    Each iteration plants the seed - reinforcing current best answer.\n",
    "    \"\"\"\n",
    "    if not candidates:\n",
    "        return FALLBACK_ANSWER\n",
    "\n",
    "    current_candidates = candidates[:]\n",
    "\n",
    "    for i in range(iterations):\n",
    "        current_answer = select_answer_prometheus(current_candidates, mod_target)\n",
    "        k = max(1, len(current_candidates) // 4)\n",
    "        seed_candidates = [\n",
    "            AnswerCandidate(value=current_answer, code=\"seed\", strategy=\"prometheus\",\n",
    "                           kolmogorov_weight=1.5)\n",
    "            for _ in range(k)\n",
    "        ]\n",
    "        current_candidates = current_candidates + seed_candidates\n",
    "\n",
    "    return select_answer_prometheus(current_candidates, mod_target)\n",
    "\n",
    "# =============================================================================\n",
    "# TOROIDAL VOTING (for mod-N problems)\n",
    "# =============================================================================\n",
    "\n",
    "def toroidal_vote(samples: List[int], mod: int) -> Tuple[int, float]:\n",
    "    \"\"\"Circular mean for mod-N problems.\"\"\"\n",
    "    if not samples or mod <= 0:\n",
    "        return 0, 0.1\n",
    "\n",
    "    normalized = [s % mod for s in samples]\n",
    "    angles = [2 * math.pi * m / mod for m in normalized]\n",
    "    sin_sum = sum(math.sin(a) for a in angles)\n",
    "    cos_sum = sum(math.cos(a) for a in angles)\n",
    "    mean_angle = math.atan2(sin_sum, cos_sum)\n",
    "    center = int(round(mean_angle * mod / (2 * math.pi))) % mod\n",
    "    R = math.sqrt(sin_sum**2 + cos_sum**2) / len(samples)\n",
    "    confidence = min(0.95, max(0.1, R))\n",
    "    return center, confidence\n",
    "\n",
    "# =============================================================================\n",
    "# RATCHETING PROMPTS\n",
    "# =============================================================================\n",
    "\n",
    "def create_ratchet_prompt(question: str, strategy: str, profile: ProblemProfile,\n",
    "                          wrong_answer: Optional[int] = None) -> str:\n",
    "    system = STRATEGY_PROMPTS.get(strategy, STRATEGY_PROMPTS['pot_algorithmic'])\n",
    "    hint = TYPE_HINTS.get(profile.primary_type, \"\")\n",
    "    mod_note = f\"\\nAnswer must be mod {profile.modulo_target}.\" if profile.modulo_target else \"\"\n",
    "    ratchet = f\"\\nIMPORTANT: {wrong_answer} is WRONG. Try a different approach.\" if wrong_answer else \"\"\n",
    "    return f\"\"\"<|im_start|>system\n",
    "{system} {hint}{mod_note}{ratchet}\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "{question}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "# =============================================================================\n",
    "# PANIC GUESS\n",
    "# =============================================================================\n",
    "\n",
    "def panic_guess(question: str, profile: ProblemProfile) -> int:\n",
    "    \"\"\"Emergency fallback.\"\"\"\n",
    "    AAR_LOG['panic'] += 1\n",
    "    numbers = [int(x) for x in re.findall(r'\\b\\d+\\b', question) if 0 < int(x) < 100000]\n",
    "    if profile.modulo_target and numbers:\n",
    "        return numbers[0] % profile.modulo_target\n",
    "    return numbers[0] if numbers else 0\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN SOLVER WITH BRANCHING TREE LOGIC\n",
    "# =============================================================================\n",
    "\n",
    "def solve_problem(question: str) -> int:\n",
    "    \"\"\"\n",
    "    Main solver with BRANCHING TREE logic:\n",
    "    \n",
    "    Decision Tree:\n",
    "    â”œâ”€â”€ Time Check\n",
    "    â”‚   â”œâ”€â”€ PANIC (<5min): Instant guess\n",
    "    â”‚   â””â”€â”€ NORMAL: Continue\n",
    "    â”œâ”€â”€ Classify Problem\n",
    "    â”‚   â”œâ”€â”€ NUMBER_THEORY â†’ sympy-heavy strategies\n",
    "    â”‚   â”œâ”€â”€ COMBINATORICS â†’ bruteforce-heavy strategies\n",
    "    â”‚   â”œâ”€â”€ GEOMETRY â†’ coordinate geometry + sympy\n",
    "    â”‚   â”œâ”€â”€ ALGEBRA â†’ sympy + CoT fallback\n",
    "    â”‚   â””â”€â”€ MIXED â†’ balanced approach\n",
    "    â”œâ”€â”€ Phase 1: Initial Batch (4 samples)\n",
    "    â”‚   â””â”€â”€ Early Consensus Branch: 60%+ agreement â†’ return immediately\n",
    "    â”œâ”€â”€ Phase 2: Expansion Branch\n",
    "    â”‚   â”œâ”€â”€ IF time permits: 4 more samples with annealed temp\n",
    "    â”‚   â””â”€â”€ ELSE: Skip to PROMETHEUS refinement\n",
    "    â”œâ”€â”€ Phase 3: CoT Fallback Branch\n",
    "    â”‚   â”œâ”€â”€ IF <3 candidates: Try CoT\n",
    "    â”‚   â””â”€â”€ ELSE: Skip\n",
    "    â””â”€â”€ PROMETHEUS Refinement\n",
    "        â”œâ”€â”€ Seed planting (3 iterations)\n",
    "        â””â”€â”€ Toroidal voting for mod problems\n",
    "    \"\"\"\n",
    "    global PROBLEM_COUNT, SOLVED_COUNT\n",
    "    PROBLEM_COUNT += 1\n",
    "\n",
    "    time_remaining = CUTOFF_TIME - time.time()\n",
    "    \n",
    "    # ===== BRANCH: PANIC MODE =====\n",
    "    if time_remaining < PANIC_TIME:\n",
    "        profile = classify_problem(question)\n",
    "        print(f\"  PANIC MODE ({time_remaining:.0f}s remaining)\")\n",
    "        return panic_guess(question, profile)\n",
    "\n",
    "    # ===== BRANCH: CLASSIFY PROBLEM =====\n",
    "    profile = classify_problem(question)\n",
    "    print(f\"  Type: {profile.primary_type.value} | Mod: {profile.modulo_target}\")\n",
    "\n",
    "    # Get type-specific strategies (branching by problem type)\n",
    "    strategies = STRATEGY_WEIGHTS.get(profile.primary_type, STRATEGY_WEIGHTS[ProblemType.MIXED])\n",
    "\n",
    "    all_candidates = []\n",
    "    current_temp = TEMP_START\n",
    "\n",
    "    # ===== PHASE 1: INITIAL BATCH =====\n",
    "    print(f\"  Phase 1: {len(strategies)} samples (T={current_temp:.2f})\")\n",
    "    prompts = [create_prompt(question, s, profile) for s in strategies]\n",
    "    outputs = batch_generate(prompts, 'pot', current_temp)\n",
    "    candidates = process_pot_outputs(outputs, strategies)\n",
    "    all_candidates.extend(candidates)\n",
    "    print(f\"    -> {len(candidates)} answers: {[c.value for c in candidates]}\")\n",
    "\n",
    "    # ===== BRANCH: EARLY CONSENSUS CHECK =====\n",
    "    if len(candidates) >= 2:\n",
    "        values = [c.value for c in candidates]\n",
    "        counts = Counter(values)\n",
    "        best, count = counts.most_common(1)[0]\n",
    "        consensus_ratio = count / len(values)\n",
    "        \n",
    "        if consensus_ratio >= 0.6:\n",
    "            print(f\"  EARLY CONSENSUS: {best} ({consensus_ratio*100:.0f}%)\")\n",
    "            SOLVED_COUNT += 1\n",
    "            return int(best)\n",
    "\n",
    "    # ===== BRANCH: TIME-GATED PHASE 2 =====\n",
    "    time_remaining = CUTOFF_TIME - time.time()\n",
    "    if time_remaining > 180:  # More than 3 min remaining\n",
    "        current_temp = max(TEMP_MIN, current_temp * TEMP_DECAY)\n",
    "        print(f\"  Phase 2: 4 more samples (T={current_temp:.2f})\")\n",
    "        prompts2 = [create_prompt(question, s, profile) for s in strategies]\n",
    "        outputs2 = batch_generate(prompts2, 'pot', current_temp)\n",
    "        candidates2 = process_pot_outputs(outputs2, strategies)\n",
    "        all_candidates.extend(candidates2)\n",
    "        print(f\"    -> {len(candidates2)} more answers\")\n",
    "    else:\n",
    "        print(f\"  Phase 2: SKIPPED (time: {time_remaining:.0f}s)\")\n",
    "\n",
    "    # ===== BRANCH: COT FALLBACK =====\n",
    "    time_remaining = CUTOFF_TIME - time.time()\n",
    "    if len(all_candidates) < 3 and time_remaining > 120:\n",
    "        print(f\"  Phase 3: CoT fallback (only {len(all_candidates)} candidates)\")\n",
    "        cot_prompts = [create_prompt(question, 'cot', profile) for _ in range(2)]\n",
    "        cot_outputs = batch_generate(cot_prompts, 'cot', 0.4)\n",
    "        cot_candidates = process_cot_outputs(cot_outputs)\n",
    "        all_candidates.extend(cot_candidates)\n",
    "        print(f\"    -> {len(cot_candidates)} CoT answers\")\n",
    "    elif len(all_candidates) < 3:\n",
    "        print(f\"  Phase 3: SKIPPED (time: {time_remaining:.0f}s)\")\n",
    "\n",
    "    # ===== BRANCH: NO ANSWERS =====\n",
    "    if not all_candidates:\n",
    "        print(\"  No answers - fallback to panic guess\")\n",
    "        AAR_LOG['no_answers'] += 1\n",
    "        return panic_guess(question, profile)\n",
    "\n",
    "    # ===== PROMETHEUS REFINEMENT =====\n",
    "    final = prometheus_refine(all_candidates, profile.modulo_target, iterations=3)\n",
    "\n",
    "    # ===== BRANCH: TOROIDAL VERIFICATION (mod problems only) =====\n",
    "    if profile.modulo_target:\n",
    "        values = [c.value for c in all_candidates]\n",
    "        tor_ans, tor_conf = toroidal_vote(values, profile.modulo_target)\n",
    "        if tor_conf > 0.7 and tor_ans != final:\n",
    "            print(f\"    Toroidal override: {tor_ans} (conf={tor_conf:.2f})\")\n",
    "            final = tor_ans\n",
    "\n",
    "    print(f\"  PROMETHEUS FINAL: {final} | Dist: {Counter([c.value for c in all_candidates])}\")\n",
    "\n",
    "    SOLVED_COUNT += 1\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return final\n",
    "\n",
    "print(\"PROMETHEUS Solver loaded (branching tree + ratcheting + toroidal).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ffce93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T00:04:46.339397Z",
     "iopub.status.busy": "2025-12-09T00:04:46.339244Z",
     "iopub.status.idle": "2025-12-09T00:04:46.347837Z",
     "shell.execute_reply": "2025-12-09T00:04:46.347445Z"
    },
    "papermill": {
     "duration": 0.012228,
     "end_time": "2025-12-09T00:04:46.348404",
     "exception": false,
     "start_time": "2025-12-09T00:04:46.336176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API interface ready (prometheus_score-2 compatible).\n",
      "Budget: 280min for 50 problems\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: KAGGLE API INTERFACE (matching prometheus_score-2 exactly)\n",
    "# =============================================================================\n",
    "\n",
    "# AIMO3: 50 problems, GPU <= 5 hours (using 4h40m budget)\n",
    "TOTAL_PROBLEMS = 50\n",
    "\n",
    "def predict_for_question(question: str) -> int:\n",
    "    \"\"\"Core solver - returns integer answer.\"\"\"\n",
    "    global PROBLEM_COUNT, SOLVED_COUNT\n",
    "    \n",
    "    time_remaining = CUTOFF_TIME - time.time()\n",
    "    \n",
    "    # PANIC MODE\n",
    "    if time_remaining < PANIC_TIME:\n",
    "        profile = classify_problem(question)\n",
    "        print(f\"  PANIC ({time_remaining:.0f}s)\")\n",
    "        return panic_guess(question, profile)\n",
    "    \n",
    "    # CLASSIFY\n",
    "    profile = classify_problem(question)\n",
    "    print(f\"  Type: {profile.primary_type.value} | Mod: {profile.modulo_target}\")\n",
    "    \n",
    "    # Get strategies for this problem type\n",
    "    strategies = STRATEGY_WEIGHTS.get(profile.primary_type, STRATEGY_WEIGHTS[ProblemType.MIXED])\n",
    "    \n",
    "    all_candidates = []\n",
    "    current_temp = TEMP_START\n",
    "    \n",
    "    # PHASE 1: Initial batch\n",
    "    print(f\"  Phase 1: {len(strategies)} samples (T={current_temp:.2f})\")\n",
    "    prompts = [create_prompt(question, s, profile) for s in strategies]\n",
    "    outputs = batch_generate(prompts, 'pot', current_temp)\n",
    "    candidates = process_pot_outputs(outputs, strategies)\n",
    "    all_candidates.extend(candidates)\n",
    "    print(f\"    -> {len(candidates)} answers: {[c.value for c in candidates]}\")\n",
    "    \n",
    "    # EARLY CONSENSUS\n",
    "    if len(candidates) >= 2:\n",
    "        values = [c.value for c in candidates]\n",
    "        counts = Counter(values)\n",
    "        best, count = counts.most_common(1)[0]\n",
    "        if count / len(values) >= 0.6:\n",
    "            print(f\"  Consensus: {best}\")\n",
    "            SOLVED_COUNT += 1\n",
    "            return int(best)\n",
    "    \n",
    "    # PHASE 2: Expansion\n",
    "    time_remaining = CUTOFF_TIME - time.time()\n",
    "    if time_remaining > 180:\n",
    "        current_temp = max(TEMP_MIN, current_temp * TEMP_DECAY)\n",
    "        print(f\"  Phase 2: expand (T={current_temp:.2f})\")\n",
    "        prompts2 = [create_prompt(question, s, profile) for s in strategies]\n",
    "        outputs2 = batch_generate(prompts2, 'pot', current_temp)\n",
    "        candidates2 = process_pot_outputs(outputs2, strategies)\n",
    "        all_candidates.extend(candidates2)\n",
    "    \n",
    "    # PHASE 3: CoT fallback\n",
    "    if len(all_candidates) < 3 and time_remaining > 120:\n",
    "        print(f\"  Phase 3: CoT fallback\")\n",
    "        cot_prompts = [create_prompt(question, 'cot', profile) for _ in range(2)]\n",
    "        cot_outputs = batch_generate(cot_prompts, 'cot', 0.4)\n",
    "        cot_candidates = process_cot_outputs(cot_outputs)\n",
    "        all_candidates.extend(cot_candidates)\n",
    "    \n",
    "    # NO ANSWERS\n",
    "    if not all_candidates:\n",
    "        AAR_LOG['no_answers'] += 1\n",
    "        return panic_guess(question, profile)\n",
    "    \n",
    "    # PROMETHEUS REFINEMENT\n",
    "    final = prometheus_refine(all_candidates, profile.modulo_target, iterations=3)\n",
    "    \n",
    "    # TOROIDAL (mod problems)\n",
    "    if profile.modulo_target:\n",
    "        values = [c.value for c in all_candidates]\n",
    "        tor_ans, tor_conf = toroidal_vote(values, profile.modulo_target)\n",
    "        if tor_conf > 0.7 and tor_ans != final:\n",
    "            final = tor_ans\n",
    "    \n",
    "    print(f\"  Final: {final} | {Counter([c.value for c in all_candidates])}\")\n",
    "    SOLVED_COUNT += 1\n",
    "    \n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    return final\n",
    "\n",
    "# =============================================================================\n",
    "# KAGGLE API PREDICT FUNCTION (matching prometheus_score-2 signature)\n",
    "# =============================================================================\n",
    "\n",
    "def predict(id_: pl.DataFrame, question: pl.DataFrame, answer: Optional[pl.DataFrame] = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    AIMO3 Gateway API.\n",
    "    \n",
    "    Args:\n",
    "        id_: polars DataFrame with problem id\n",
    "        question: polars DataFrame with problem text\n",
    "        answer: (optional) ground truth for local testing\n",
    "    \n",
    "    Returns:\n",
    "        polars DataFrame with columns ['id', 'answer']\n",
    "    \"\"\"\n",
    "    id_val = id_.item(0)\n",
    "    question_str = question.item(0)\n",
    "    \n",
    "    time_left = (CUTOFF_TIME - time.time()) / 60\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ID: {id_val} | Time: {time_left:.1f}m | Solved: {SOLVED_COUNT}/{PROBLEM_COUNT}\")\n",
    "    print(f\"Q: {question_str[:60]}...\")\n",
    "    \n",
    "    prediction = predict_for_question(question_str)\n",
    "    \n",
    "    # AIMO3 Rule: 0-99999\n",
    "    prediction = max(ANSWER_MIN, min(ANSWER_MAX, int(prediction)))\n",
    "    \n",
    "    print(f\"ANSWER: {prediction}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return pl.DataFrame({'id': id_val, 'answer': prediction})\n",
    "\n",
    "print(\"API interface ready (prometheus_score-2 compatible).\")\n",
    "print(f\"Budget: {TOTAL_BUDGET//60}min for {TOTAL_PROBLEMS} problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f03fddcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T00:04:46.354194Z",
     "iopub.status.busy": "2025-12-09T00:04:46.354069Z",
     "iopub.status.idle": "2025-12-09T00:04:48.526306Z",
     "shell.execute_reply": "2025-12-09T00:04:48.525798Z"
    },
    "papermill": {
     "duration": 2.175893,
     "end_time": "2025-12-09T00:04:48.526973",
     "exception": false,
     "start_time": "2025-12-09T00:04:46.351080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PROMETHEUS + vLLM + Qwen-72B-Math-INT4\n",
      "======================================================================\n",
      "Model: /kaggle/input/qwen-72b-math-int4\n",
      "vLLM: Not available\n",
      "Budget: 280 minutes\n",
      "======================================================================\n",
      "Local test\n",
      "\n",
      "============================================================\n",
      "ID: 222ccc | Time: 280.0m | Solved: 0/0\n",
      "Q: Solve $4+x=4$ for $x$....\n",
      "  Type: alg | Mod: None\n",
      "  Phase 1: 4 samples (T=0.70)\n",
      "    -> 0 answers: []\n",
      "  Phase 2: expand (T=0.59)\n",
      "  Phase 3: CoT fallback\n",
      "ANSWER: 4\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ID: 000aaa | Time: 280.0m | Solved: 0/0\n",
      "Q: What is $1-1$?...\n",
      "  Type: mixed | Mod: None\n",
      "  Phase 1: 4 samples (T=0.70)\n",
      "    -> 0 answers: []\n",
      "  Phase 2: expand (T=0.59)\n",
      "  Phase 3: CoT fallback\n",
      "ANSWER: 1\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "ID: 111bbb | Time: 280.0m | Solved: 0/0\n",
      "Q: What is $0\\times10$?...\n",
      "  Type: mixed | Mod: None\n",
      "  Phase 1: 4 samples (T=0.70)\n",
      "    -> 0 answers: []\n",
      "  Phase 2: expand (T=0.59)\n",
      "  Phase 3: CoT fallback\n",
      "ANSWER: 0\n",
      "============================================================\n",
      "\n",
      "Completed in 0.0 minutes\n",
      "Solved: 0/0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: RUN COMPETITION (matching prometheus_score-2 pattern)\n",
    "# =============================================================================\n",
    "import kaggle_evaluation.aimo_3_inference_server\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PROMETHEUS + vLLM + Qwen-72B-Math-INT4\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model: {MODEL_PATH}\")\n",
    "print(f\"vLLM: {'Loaded' if LLM_MODEL else 'Not available'}\")\n",
    "print(f\"Budget: {TOTAL_BUDGET//60} minutes\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create server\n",
    "inference_server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    print(\"Competition mode\")\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    print(\"Local test\")\n",
    "    inference_server.run_local_gateway(('/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv',))\n",
    "\n",
    "print(f\"\\nCompleted in {(time.time() - START_TIME)/60:.1f} minutes\")\n",
    "print(f\"Solved: {SOLVED_COUNT}/{PROBLEM_COUNT}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaH100",
   "dataSources": [
    {
     "databundleVersionId": 14559231,
     "sourceId": 118448,
     "sourceType": "competition"
    },
    {
     "datasetId": 7716538,
     "sourceId": 12263596,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8943191,
     "sourceId": 14047749,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8943843,
     "sourceId": 14050341,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8945374,
     "sourceId": 14053151,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 116.548019,
   "end_time": "2025-12-09T00:04:49.646959",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-09T00:02:53.098940",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
