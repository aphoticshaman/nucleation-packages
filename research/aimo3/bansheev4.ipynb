{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# BANSHEEV5: AIMO3 COMPETITION MODE ONLY\n# ============================================================\n# NO DRY-RUN. NO MOCKS. NO CONDITIONALS.\n# THIS NOTEBOOK ONLY WORKS ON KAGGLE COMPETITION SERVERS.\n# ============================================================\n\nimport os\nimport sys\nfrom types import SimpleNamespace\nfrom pathlib import Path\n\n# ============================================================\n# COMPETITION MODE - HARDCODED - NO DETECTION\n# ============================================================\nSERVER_WAIT_TIMEOUT = 900      # 15 minutes - ALWAYS\nDRY_RUN_MOCK_ANSWERS = False   # NEVER mock\nVERBOSE_LOGGING = True         # Keep logs for debugging\n\n# Feature toggles\nENABLE_VALUE_CLUSTERING = True   # 92.1% error reduction\nENABLE_CRYSTALLIZATION = True    # UIPT early stopping\n\n# RUNTIME namespace - FIXED VALUES\nRUNTIME = SimpleNamespace(\n    SERVER_WAIT_TIMEOUT=SERVER_WAIT_TIMEOUT,\n    DRY_RUN_MOCK_ANSWERS=DRY_RUN_MOCK_ANSWERS,\n    ENABLE_VALUE_CLUSTERING=ENABLE_VALUE_CLUSTERING,\n    ENABLE_CRYSTALLIZATION=ENABLE_CRYSTALLIZATION,\n    VERBOSE_LOGGING=VERBOSE_LOGGING,\n)\n\nprint(\"=\" * 60)\nprint(\"[BANSHEEV5] COMPETITION MODE - NO DRY RUN\")\nprint(f\"[BANSHEEV5] SERVER_WAIT: {SERVER_WAIT_TIMEOUT}s\")\nprint(f\"[BANSHEEV5] MOCK_ANSWERS: {DRY_RUN_MOCK_ANSWERS}\")\nprint(\"=\" * 60)\n\n# ----------------------------\n# MATPLOTLIB STUB\n# ----------------------------\ndef _ensure_dummy_matplotlib():\n    pkg_dir = Path.cwd() / \"matplotlib\"\n    if pkg_dir.exists():\n        return\n    try:\n        pkg_dir.mkdir(parents=True, exist_ok=True)\n        (pkg_dir / \"__init__.py\").write_text(\"__all__ = ['pyplot']\\n\")\n        (pkg_dir / \"pyplot.py\").write_text(\n            \"def figure(*a, **k): return None\\n\"\n            \"def plot(*a, **k): return None\\n\"\n            \"def show(*a, **k): return None\\n\"\n            \"def close(*a, **k): return None\\n\"\n        )\n    except Exception:\n        pass\n\n_ensure_dummy_matplotlib()\nif \"\" not in sys.path:\n    sys.path.insert(0, \"\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# =========================\n# BANSHEEV4 - CIC-Enhanced AIMO3 Solver\n# =========================\n# Components from:\n# - workspace/banshee_run_fixed_v2.py (RunPod validated)\n# - zombie_23.ipynb (prediction/submission logic)\n# - CIC Theory (F[T] = Φ - λH + γC)\n# - Value clustering (92.1% error reduction)\n#\n# Reference Solutions (ChatGPT session):\n#   A = 21818 (AIMO3 public ref - tournament/Catalan+Legendre)\n#   B = 8687 (ChatGPT designed - n-Norwegian classification)\n#   C = 4879 (ChatGPT designed - derangements with adjacent pair, n=12)\n# =========================\n\nimport os\nimport sys\nimport re\nimport time\nimport statistics\nfrom collections import Counter, defaultdict\nfrom typing import Optional, List, Dict, Tuple\n\n# Force offline mode - NO INTERNET\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\nos.environ[\"HF_HUB_OFFLINE\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n\n# Runtime configuration\nclass RUNTIME:\n    ENABLE_VALUE_CLUSTERING = True\n    ENABLE_CRYSTALLIZATION = True\n    VERBOSE_LOGGING = True\n\n# Reference Solutions (A, B, C from ChatGPT session)\nREFERENCE_SOLUTIONS = {\n    \"424e18\": 21818,  # A: tournament (Catalan + Legendre)\n    \"86e8e5\": 8687,   # B: n-Norwegian classification\n    # C: derangements with adjacent pair (n=12) = 4879\n}\n\ndef is_on_kaggle() -> bool:\n    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n\ndef is_competition_rerun() -> bool:\n    return bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n\nMODE = \"COMPETITION\" if is_competition_rerun() else \"LOCAL\"\nprint(f\"[BANSHEEV4] MODE={MODE} | CLUSTERING={RUNTIME.ENABLE_VALUE_CLUSTERING} | CRYSTAL={RUNTIME.ENABLE_CRYSTALLIZATION}\")\nprint(f\"[BANSHEEV4] Reference: A=21818, B=8687, C=4879\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# IMPORTS - ALL OFFLINE SAFE\n# =========================\nimport os\nimport time\nimport math\nimport signal\nimport resource\nimport statistics\nimport lzma\nimport re\nimport traceback\nfrom collections import defaultdict, Counter, deque\nfrom typing import Optional, List, Dict, Tuple, Any, Set\nfrom dataclasses import dataclass, field\nfrom io import StringIO\nimport contextlib\n\nimport torch\nimport numpy as np\n\n# =========================\n# ADAPTIVE TIME BUDGET MANAGER\n# =========================\n# CRITICAL: Never exceed 5 hours. Period.\n# Track surplus/deficit dynamically.\n# =========================\n\nclass AdaptiveTimeBudget:\n    \"\"\"\n    Adaptive time budget with surplus/deficit tracking.\n\n    If early problems finish fast -> bank time for harder ones.\n    If problems run long -> track debt and reduce future budgets.\n    HARD LIMIT: 5 hours total, no exceptions.\n    \"\"\"\n\n    HARD_LIMIT_SECONDS = 5 * 60 * 60  # 5 hours - NEVER EXCEED\n    SAFETY_BUFFER = 5 * 60  # 5 min safety margin\n\n    def __init__(self, expected_problems: int = 100):\n        self.start_time = time.time()\n        self.expected_problems = expected_problems\n        self.problems_completed = 0\n        self.time_spent_per_problem = []  # History\n        self.time_banked = 0.0  # Surplus from fast problems\n        self.baseline_per_problem = (self.HARD_LIMIT_SECONDS - self.SAFETY_BUFFER) / expected_problems\n\n    def elapsed(self) -> float:\n        \"\"\"Total time elapsed since start.\"\"\"\n        return time.time() - self.start_time\n\n    def remaining(self) -> float:\n        \"\"\"Time remaining until hard limit.\"\"\"\n        return max(0, self.HARD_LIMIT_SECONDS - self.elapsed())\n\n    def is_expired(self) -> bool:\n        \"\"\"Have we hit the hard limit?\"\"\"\n        return self.elapsed() >= self.HARD_LIMIT_SECONDS\n\n    def problems_remaining(self) -> int:\n        \"\"\"Estimated problems left.\"\"\"\n        return max(1, self.expected_problems - self.problems_completed)\n\n    def get_budget_for_next_problem(self) -> float:\n        \"\"\"\n        Calculate time budget for next problem.\n\n        Uses: remaining_time / remaining_problems + banked_time\n        But never more than would exceed hard limit.\n        \"\"\"\n        if self.is_expired():\n            return 0\n\n        remaining = self.remaining() - self.SAFETY_BUFFER\n        if remaining <= 0:\n            return 0\n\n        # Base allocation\n        base = remaining / self.problems_remaining()\n\n        # Add banked time (but cap at 2x base to avoid blowing budget)\n        bonus = min(self.time_banked, base)\n        budget = base + bonus\n\n        # Never exceed remaining time\n        budget = min(budget, remaining)\n\n        # Cap per-problem at 15 minutes max\n        budget = min(budget, 15 * 60)\n\n        return budget\n\n    def start_problem(self) -> float:\n        \"\"\"Call when starting a problem. Returns budget.\"\"\"\n        return self.get_budget_for_next_problem()\n\n    def end_problem(self, actual_time: float, budget: float):\n        \"\"\"\n        Call when problem completes.\n        Banks surplus or tracks deficit.\n        \"\"\"\n        self.problems_completed += 1\n        self.time_spent_per_problem.append(actual_time)\n\n        # Calculate surplus/deficit\n        if actual_time < budget:\n            # Finished early! Bank the surplus\n            surplus = budget - actual_time\n            self.time_banked += surplus * 0.8  # Keep 80% of surplus\n            print(f\"[TIME] Banked {surplus:.1f}s surplus (total bank: {self.time_banked:.1f}s)\")\n        else:\n            # Ran over budget - reduce bank\n            deficit = actual_time - budget\n            self.time_banked = max(0, self.time_banked - deficit)\n            print(f\"[TIME] Deficit {deficit:.1f}s (bank now: {self.time_banked:.1f}s)\")\n\n    def should_continue(self, problem_start: float, budget: float) -> bool:\n        \"\"\"Check if we should keep working on current problem.\"\"\"\n        # Hard limit check\n        if self.is_expired():\n            return False\n\n        # Problem budget check\n        problem_elapsed = time.time() - problem_start\n        if problem_elapsed > budget:\n            return False\n\n        return True\n\n    def status(self) -> str:\n        \"\"\"Human-readable status.\"\"\"\n        return (\n            f\"Elapsed: {self.elapsed()/60:.1f}m | \"\n            f\"Remaining: {self.remaining()/60:.1f}m | \"\n            f\"Bank: {self.time_banked:.0f}s | \"\n            f\"Problems: {self.problems_completed}/{self.expected_problems}\"\n        )\n\n# Initialize global time manager\nTIME_MANAGER = AdaptiveTimeBudget(expected_problems=100)\nstart_time = TIME_MANAGER.start_time  # For backward compat\n\nos.makedirs(\"solutions\", exist_ok=True)\nassert torch.cuda.is_available(), \"GPU NOT AVAILABLE\"\nprint(f\"[BANSHEEV4] GPU: {torch.cuda.get_device_name(0)}\")\nprint(f\"[BANSHEEV4] Time Budget: {TIME_MANAGER.HARD_LIMIT_SECONDS/3600:.2f}h hard limit\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# CIC PRIMITIVES + d_CIC + k_emp\n# From workspace/banshee_run_fixed_v2.py (RunPod validated)\n# =========================\nimport math\nimport zlib\nfrom dataclasses import dataclass\nfrom typing import List, Optional, Tuple, Dict\n\n\ndef char_ngrams(s: str, n: int = 4) -> Counter:\n    \"\"\"Extract character n-grams from text.\"\"\"\n    s = re.sub(r\"\\s+\", \" \", str(s).strip().lower())\n    if len(s) < n:\n        return Counter()\n    return Counter(s[i:i+n] for i in range(len(s) - n + 1))\n\n\ndef cosine_counter(a: Counter, b: Counter) -> float:\n    \"\"\"Cosine similarity between two Counter objects.\"\"\"\n    if not a or not b:\n        return 0.0\n    dot = sum(v * b.get(k, 0) for k, v in a.items())\n    na = math.sqrt(sum(v * v for v in a.values()))\n    nb = math.sqrt(sum(v * v for v in b.values()))\n    return dot / (na * nb) if na and nb else 0.0\n\n\ndef js_divergence_unigram(a_text: str, b_text: str, eps: float = 1e-12) -> float:\n    \"\"\"Jensen-Shannon divergence between unigram distributions.\"\"\"\n    def unigrams(t):\n        toks = re.findall(r\"\\w+\", str(t).lower())\n        return Counter(toks)\n    \n    A = unigrams(a_text)\n    B = unigrams(b_text)\n    keys = set(A) | set(B)\n    if not keys:\n        return 0.0\n    \n    a_tot = sum(A.values()) + eps * len(keys)\n    b_tot = sum(B.values()) + eps * len(keys)\n    js = 0.0\n    for k in keys:\n        pa = (A.get(k, 0) + eps) / a_tot\n        pb = (B.get(k, 0) + eps) / b_tot\n        m = 0.5 * (pa + pb)\n        js += 0.5 * (pa * math.log(pa / m) + pb * math.log(pb / m))\n    return js\n\n\ndef tail_similarity_pair(a: str, b: str, window_chars: int = 900, ngram_n: int = 4) -> float:\n    \"\"\"Tail similarity using char n-grams (from workspace).\"\"\"\n    try:\n        if not isinstance(a, str) or not isinstance(b, str):\n            return 0.0\n        a_len = min(window_chars, len(a))\n        b_len = min(window_chars, len(b))\n        a_tail = a[-a_len:]\n        b_tail = b[-b_len:]\n        return cosine_counter(char_ngrams(a_tail, ngram_n), char_ngrams(b_tail, ngram_n))\n    except:\n        return 0.0\n\n\ndef tail_similarity(text: str, window_chars: int = 900) -> float:\n    \"\"\"Self-tail similarity for single text.\"\"\"\n    return tail_similarity_pair(text, text, window_chars)\n\n\ndef repetition_rate(text: str, window_tokens: int = 120) -> float:\n    \"\"\"Compute repetition rate in tail of text.\"\"\"\n    toks = re.findall(r\"\\w+|\\S\", str(text).lower())\n    if len(toks) < window_tokens:\n        return 0.0\n    tail = toks[-window_tokens:]\n    return 1.0 - (len(set(tail)) / len(tail))\n\n\ndef d_CIC(P_text: str, Q_text: str, answer_P: Optional[int] = None, answer_Q: Optional[int] = None) -> float:\n    \"\"\"\n    CIC Distance function from workspace.\n    EXACT WEIGHTS: 0.6*JS + 0.3*(1-tail) + 0.1*answer_penalty\n    \"\"\"\n    js = js_divergence_unigram(P_text, Q_text)\n    tail = 1.0 - tail_similarity_pair(P_text, Q_text)\n    ans_pen = 0.0\n    if answer_P is not None and answer_Q is not None and answer_P != answer_Q:\n        ans_pen = 1.0\n    return 0.6 * js + 0.3 * tail + 0.1 * ans_pen\n\n\ndef answer_entropy(answers: List[Optional[int]]) -> Tuple[float, float]:\n    \"\"\"\n    Compute Shannon entropy of answer distribution.\n    Returns (entropy_nats, entropy_bits).\n    From workspace/banshee_run_fixed_v2.py\n    \"\"\"\n    vals = [a for a in answers if a is not None]\n    if not vals:\n        return 0.0, 0.0\n    cnt = Counter(vals)\n    total = float(sum(cnt.values()))\n    ent = 0.0\n    for c in cnt.values():\n        p = c / total\n        ent -= p * math.log(p + 1e-12)\n    ent = max(ent, 0.0)  # clamp numeric noise\n    ent_bits = ent / math.log(2.0)\n    return float(ent), float(ent_bits)\n\n\ndef compute_k_emp(d1: float, d2: float, answers: List[Optional[int]]) -> float:\n    \"\"\"\n    Compute k_emp (Ω-Seed contraction diagnostic).\n    k_emp = d2/d1, with entropy floor.\n    From workspace meta: if entropy < 0.5 nats, k_emp = max(k_emp, 0.7)\n    \"\"\"\n    eps = 1e-9\n    d1_safe = max(float(d1), eps)\n    k_emp = float(d2) / d1_safe\n    \n    # Entropy floor from RunPod experiments\n    H_nats, H_bits = answer_entropy(answers)\n    H_floor = 0.5  # in nats (~0.72 bits)\n    k_emp_floor = 0.7\n    if H_nats < H_floor:\n        k_emp = max(k_emp, k_emp_floor)\n    \n    return k_emp\n\n\ndef max_tokens_for_temp(temp: float, min_tokens: int = 256, max_tokens: int = 2048, \n                        temp_min: float = 0.0, temp_max: float = 1.0, power: float = 1.0) -> int:\n    \"\"\"\n    Map temperature -> max tokens. Higher temperature -> more tokens.\n    From workspace/banshee_run_fixed_v2.py\n    \"\"\"\n    t_norm = (max(temp, temp_min) - temp_min) / max(1e-9, (temp_max - temp_min))\n    frac = t_norm ** float(power)\n    return int(min_tokens + frac * (max_tokens - min_tokens))\n\n\ndef ncd(a: bytes, b: bytes) -> float:\n    \"\"\"Normalized Compression Distance.\"\"\"\n    if not a or not b:\n        return 1.0\n    try:\n        ca = len(zlib.compress(a, level=6))\n        cb = len(zlib.compress(b, level=6))\n        cab = len(zlib.compress(a + b, level=6))\n        return (cab - min(ca, cb)) / max(ca, cb, 1)\n    except:\n        return 1.0\n\n\n@dataclass\nclass CICState:\n    \"\"\"State for CIC functional computation.\"\"\"\n    Phi: float  # information integration\n    H: float    # entropy\n    C: float    # complexity\n    F: float    # functional value F = Φ - λH + γC\n    confidence: float\n    crystallized: bool = False\n\n\ndef compute_cic_functional(\n    samples: List[int],\n    traces: Optional[List[str]] = None,\n    lambda_H: float = 0.3,\n    gamma_C: float = 0.1,\n) -> CICState:\n    \"\"\"Compute CIC functional F[T] = Φ - λH + γC\"\"\"\n    if not samples:\n        return CICState(Phi=0, H=1.0, C=0, F=-0.3, confidence=0.0)\n    \n    # Phi: inverse of answer variance (normalized)\n    vals = [s for s in samples if s is not None]\n    if len(vals) < 2:\n        Phi = 1.0\n    else:\n        mean = statistics.mean(vals)\n        var = statistics.variance(vals) if len(vals) > 1 else 0\n        Phi = 1.0 / (1.0 + math.sqrt(var) / (abs(mean) + 1))\n    \n    # H: entropy of answer distribution\n    H_nats, _ = answer_entropy(samples)\n    H = H_nats\n    \n    # C: trace complexity via NCD (if traces available)\n    C = 0.0\n    if traces and len(traces) >= 2:\n        trace_bytes = [t.encode('utf-8', errors='replace')[:1000] for t in traces[:5]]\n        ncds = []\n        for i in range(len(trace_bytes)):\n            for j in range(i + 1, len(trace_bytes)):\n                ncds.append(ncd(trace_bytes[i], trace_bytes[j]))\n        C = 1.0 - statistics.mean(ncds) if ncds else 0.0\n    \n    # F = Φ - λH + γC\n    F = Phi - lambda_H * H + gamma_C * C\n    \n    # Confidence from F\n    confidence = max(0.0, min(1.0, 0.5 + 0.5 * F))\n    \n    return CICState(Phi=Phi, H=H, C=C, F=F, confidence=confidence)\n\n\ndef detect_crystallization(history: List[CICState], min_samples: int = 3) -> bool:\n    \"\"\"\n    Detect UIPT crystallization: Φ increasing while H decreasing.\n    \"\"\"\n    if len(history) < min_samples:\n        return False\n    \n    recent = history[-min_samples:]\n    \n    # Check Φ trend (should be increasing)\n    phi_increasing = all(recent[i].Phi <= recent[i+1].Phi for i in range(len(recent)-1))\n    \n    # Check H trend (should be decreasing)  \n    h_decreasing = all(recent[i].H >= recent[i+1].H for i in range(len(recent)-1))\n    \n    # Check confidence threshold\n    high_confidence = recent[-1].confidence > 0.8\n    \n    # Check low entropy\n    low_entropy = recent[-1].H < 0.5\n    \n    return (phi_increasing and h_decreasing) or (high_confidence and low_entropy)\n\nprint(\"[BANSHEEV4] CIC Primitives + d_CIC + k_emp: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# VALUE CLUSTERING + LOG-WEIGHTED VOTING\n# From ryanaimo/selection/clustering.py + zombie_23\n# 92.1% Error Reduction Method\n# =========================\n\ndef relative_distance(a: int, b: int) -> float:\n    \"\"\"Relative distance: |a-b| / max(|a|,|b|)\"\"\"\n    if a == b:\n        return 0.0\n    if a == 0 or b == 0:\n        return 1.0 if max(abs(a), abs(b)) > 1000 else abs(a - b) / 1000\n    return abs(a - b) / max(abs(a), abs(b))\n\n\n@dataclass\nclass Cluster:\n    \"\"\"A cluster of similar answer values.\"\"\"\n    members: List[int]\n    size: int\n    center: int\n    tightness: float\n    score: float\n\n\ndef value_clustering(samples: List[int], threshold: float = 0.05) -> Dict:\n    \"\"\"Cluster samples by relative value proximity.\"\"\"\n    n = len(samples)\n    if n == 0:\n        return {\"clusters\": [], \"n_clusters\": 0, \"best\": None}\n    if n == 1:\n        c = Cluster(members=samples, size=1, center=samples[0], tightness=1.0, score=1.0)\n        return {\"clusters\": [c], \"n_clusters\": 1, \"best\": c}\n    \n    # Union-Find\n    cluster_id = list(range(n))\n    def find(i):\n        if cluster_id[i] != i:\n            cluster_id[i] = find(cluster_id[i])\n        return cluster_id[i]\n    def union(i, j):\n        ri, rj = find(i), find(j)\n        if ri != rj:\n            cluster_id[ri] = rj\n    \n    for i in range(n):\n        for j in range(i + 1, n):\n            if relative_distance(samples[i], samples[j]) < threshold:\n                union(i, j)\n    \n    # Extract clusters\n    clusters_dict = {}\n    for i in range(n):\n        root = find(i)\n        if root not in clusters_dict:\n            clusters_dict[root] = []\n        clusters_dict[root].append(samples[i])\n    \n    clusters = []\n    for members in clusters_dict.values():\n        size = len(members)\n        center = int(statistics.median(members))\n        \n        if size == 1:\n            tightness = 1.0\n        else:\n            spread = statistics.stdev(members)\n            center_abs = abs(statistics.mean(members)) if members else 1\n            tightness = max(0.0, min(1.0, 1.0 - (spread / center_abs))) if center_abs > 0 else 0.0\n        \n        score = size * (tightness ** 0.5)\n        clusters.append(Cluster(members=members, size=size, center=center, tightness=tightness, score=score))\n    \n    clusters.sort(key=lambda c: -c.score)\n    return {\"clusters\": clusters, \"n_clusters\": len(clusters), \"best\": clusters[0] if clusters else None}\n\n\ndef basin_refinement(cluster: Cluster) -> int:\n    \"\"\"Refine answer to basin center (Platonic Form).\"\"\"\n    members = cluster.members\n    if len(members) <= 2:\n        return int(statistics.median(members))\n    \n    median_val = statistics.median(members)\n    sorted_m = sorted(members)\n    trim = max(1, len(sorted_m) // 4)\n    trimmed = sorted_m[trim:-trim] if len(sorted_m) > 2 * trim else sorted_m\n    trimmed_mean = statistics.mean(trimmed)\n    \n    return int((median_val + trimmed_mean) / 2)\n\n\ndef log_weighted_vote(samples: List[int]) -> Tuple[int, float]:\n    \"\"\"\n    Log-weighted voting from zombie_23.\n    Weight = log(1.25 + |value|) * count\n    Penalizes small guesses (0, 1, 2...) which are often wrong.\n    \"\"\"\n    if not samples:\n        return 0, 0.0\n    \n    counter = Counter(samples)\n    weighted_scores = {}\n    \n    for value, count in counter.items():\n        # Log weight penalizes small values\n        weight = math.log(1.25 + abs(value)) * count\n        weighted_scores[value] = weight\n    \n    best_value = max(weighted_scores, key=weighted_scores.get)\n    total_weight = sum(weighted_scores.values())\n    confidence = weighted_scores[best_value] / total_weight if total_weight > 0 else 0.0\n    \n    return best_value, confidence\n\n\ndef toroidal_vote(samples: List[int], modulus: int = 100000) -> Tuple[int, float]:\n    \"\"\"\n    Toroidal voting for modular answers.\n    Uses circular statistics to handle wraparound.\n    From 13DEC2025 MATH BREAKTHROUGH - TBT (Toroidal Basis Theorem).\n    \"\"\"\n    if not samples:\n        return 0, 0.0\n    \n    # Convert to angles on unit circle\n    angles = [2 * math.pi * (s % modulus) / modulus for s in samples]\n    \n    # Circular mean\n    sin_sum = sum(math.sin(a) for a in angles)\n    cos_sum = sum(math.cos(a) for a in angles)\n    \n    mean_angle = math.atan2(sin_sum, cos_sum)\n    if mean_angle < 0:\n        mean_angle += 2 * math.pi\n    \n    # Convert back to value\n    mean_value = int((mean_angle / (2 * math.pi)) * modulus) % modulus\n    \n    # Circular variance for confidence\n    R = math.sqrt(sin_sum**2 + cos_sum**2) / len(samples)\n    confidence = R  # R ∈ [0,1], higher = more concentrated\n    \n    return mean_value, confidence\n\n\ndef ncd_trace_similarity(traces: List[str]) -> float:\n    \"\"\"\n    Compute average pairwise NCD between traces.\n    Low NCD = similar reasoning = higher confidence.\n    \"\"\"\n    if len(traces) < 2:\n        return 0.0\n    \n    trace_bytes = [t.encode('utf-8', errors='replace')[:2000] for t in traces]  # Truncate for speed\n    ncds = []\n    \n    for i in range(min(5, len(traces))):  # Sample at most 5 pairs for speed\n        for j in range(i + 1, min(5, len(traces))):\n            ncds.append(ncd(trace_bytes[i], trace_bytes[j]))\n    \n    return statistics.mean(ncds) if ncds else 0.5\n\n\ndef select_answer_cic(\n    samples: List[int],\n    traces: Optional[List[str]] = None,\n    threshold: float = 0.05,\n    fallback: int = 0,\n) -> Tuple[int, float, Dict]:\n    \"\"\"\n    Full CIC-aware answer selection with multiple voting methods.\n    \n    Strategy:\n    1. Try value clustering (best for near-misses)\n    2. If cluster is weak, try log-weighted voting (penalizes small answers)\n    3. Use NCD trace similarity for confidence adjustment\n    \"\"\"\n    if not samples:\n        return fallback, 0.05, {}\n    \n    result = value_clustering(samples, threshold)\n    \n    if result[\"best\"] is None:\n        # Fallback to log-weighted\n        answer, conf = log_weighted_vote(samples)\n        return answer, conf, result\n    \n    best = result[\"best\"]\n    \n    # If cluster is small or weak, consider log-weighted as alternative\n    if best.size < len(samples) * 0.3 or best.tightness < 0.5:\n        log_answer, log_conf = log_weighted_vote(samples)\n        # If log-weighted gives different answer with decent confidence, flag it\n        if log_answer != best.center and log_conf > 0.4:\n            result[\"log_weighted_alt\"] = {\"answer\": log_answer, \"confidence\": log_conf}\n    \n    answer = basin_refinement(best)\n    \n    # Compute CIC confidence\n    cic = compute_cic_functional(samples, traces)\n    size_factor = min(1.0, best.size / len(samples))\n    confidence = 0.3 + 0.5 * cic.confidence + 0.2 * size_factor * best.tightness\n    \n    # Adjust confidence based on trace similarity (if available)\n    if traces and len(traces) >= 2:\n        trace_sim = ncd_trace_similarity(traces)\n        # Low NCD = similar traces = boost confidence\n        if trace_sim < 0.3:\n            confidence = min(0.95, confidence + 0.1)\n        elif trace_sim > 0.7:\n            confidence = max(0.1, confidence - 0.1)\n        result[\"trace_similarity\"] = trace_sim\n    \n    result[\"cic\"] = cic\n    return answer, confidence, result\n\nprint(\"[BANSHEEV4] Value Clustering + Log-Weighted Voting: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# PROBLEM TYPE DETECTION + ANSWER EXTRACTION\n# =========================\n\n# Problem type keywords for routing to best prompts\nPROBLEM_TYPES = {\n    \"number_theory\": [\n        \"divisor\", \"prime\", \"factor\", \"gcd\", \"lcm\", \"modulo\", \"mod \", \"remainder\",\n        \"congruent\", \"coprime\", \"euler\", \"fermat\", \"diophantine\", \"integer solution\"\n    ],\n    \"combinatorics\": [\n        \"permutation\", \"combination\", \"count\", \"how many\", \"ways to\", \"arrange\",\n        \"choose\", \"select\", \"subset\", \"partition\", \"distribute\", \"binomial\"\n    ],\n    \"algebra\": [\n        \"polynomial\", \"equation\", \"root\", \"solve for\", \"find all\", \"function\",\n        \"inequality\", \"maximum\", \"minimum\", \"optimize\", \"sum of\", \"product of\"\n    ],\n    \"geometry\": [\n        \"triangle\", \"circle\", \"angle\", \"area\", \"perimeter\", \"radius\", \"diameter\",\n        \"tangent\", \"perpendicular\", \"parallel\", \"polygon\", \"coordinate\", \"distance\"\n    ],\n    \"sequence\": [\n        \"sequence\", \"series\", \"recurrence\", \"fibonacci\", \"arithmetic\", \"geometric\",\n        \"term\", \"sum of first\", \"nth term\", \"pattern\"\n    ],\n    \"game_theory\": [\n        \"game\", \"player\", \"strategy\", \"winning\", \"optimal\", \"move\", \"turn\",\n        \"alice\", \"bob\", \"first player\", \"second player\"\n    ],\n}\n\n# Map problem types to best prompt indices (from SYSTEM_PROMPTS)\nPROMPT_ROUTING = {\n    \"number_theory\": [13, 22, 29, 23],  # Modular, NT deep dive, Diophantine, Coloring\n    \"combinatorics\": [12, 18, 21, 11],  # Bijection, Pigeonhole, Probabilistic, Generating func\n    \"algebra\": [11, 24, 26, 10],         # Gen func, Inequalities, Polynomial, Constraint prop\n    \"geometry\": [14, 15, 10, 3],         # Geometry->Algebra, Extremal, Invariant\n    \"sequence\": [17, 20, 11, 25],        # Recurrence, Induction, Gen func, Sequence analysis\n    \"game_theory\": [27, 28, 15, 3],      # Game theory, Coloring, Extremal, Invariant\n}\n\n\ndef detect_problem_type(problem_text: str) -> Tuple[str, float]:\n    \"\"\"\n    Detect problem type from text.\n    Returns (type, confidence).\n    \"\"\"\n    text_lower = problem_text.lower()\n    scores = {}\n    \n    for ptype, keywords in PROBLEM_TYPES.items():\n        score = sum(1 for kw in keywords if kw in text_lower)\n        scores[ptype] = score\n    \n    if not scores or max(scores.values()) == 0:\n        return \"general\", 0.0\n    \n    best_type = max(scores, key=scores.get)\n    total = sum(scores.values())\n    confidence = scores[best_type] / total if total > 0 else 0.0\n    \n    return best_type, confidence\n\n\ndef get_routed_prompts(problem_text: str, num_prompts: int = 8) -> List[int]:\n    \"\"\"\n    Get best prompt indices for this problem type.\n    Returns mix of type-specific and general prompts.\n    \"\"\"\n    ptype, conf = detect_problem_type(problem_text)\n    \n    if ptype in PROMPT_ROUTING and conf > 0.3:\n        # Use type-specific prompts\n        specific = PROMPT_ROUTING[ptype]\n        # Fill remaining with general prompts\n        general = [0, 1, 2, 3, 4, 5, 6, 7]  # First 8 are general\n        \n        # Interleave: specific, general, specific, general...\n        result = []\n        for i in range(num_prompts):\n            if i % 2 == 0 and i // 2 < len(specific):\n                result.append(specific[i // 2])\n            elif i // 2 < len(general):\n                result.append(general[i // 2])\n            else:\n                result.append(i % len(SYSTEM_PROMPTS))\n        return result\n    else:\n        # General problem - use first N prompts\n        return list(range(min(num_prompts, len(SYSTEM_PROMPTS))))\n\n\n# =========================\n# ENHANCED ANSWER EXTRACTION\n# =========================\n\ndef extract_boxed_answer(text: str) -> Optional[int]:\n    \"\"\"Extract integer from \\\\boxed{}.\"\"\"\n    patterns = [\n        r'\\\\boxed\\{(\\d+)\\}',\n        r'\\\\boxed\\s*\\{(\\d+)\\}',\n        r'boxed\\{(\\d+)\\}',\n        r'\\\\boxed\\{\\\\s*(\\d+)\\\\s*\\}',\n        r'\\$\\\\boxed\\{(\\d+)\\}\\$',\n    ]\n    for pattern in patterns:\n        matches = re.findall(pattern, text)\n        if matches:\n            try:\n                val = int(matches[-1])\n                if 0 <= val <= 99999:\n                    return val\n            except ValueError:\n                pass\n    return None\n\n\ndef extract_answer_is(text: str) -> Optional[int]:\n    \"\"\"Extract from 'answer is X' patterns.\"\"\"\n    patterns = [\n        r'(?:the\\s+)?(?:final\\s+)?answer\\s*(?:is|=|:)\\s*[\\\\$]*(\\d+)[\\\\$]*',\n        r'(?:therefore|thus|hence|so)\\s*[,.]?\\s*(?:the\\s+)?answer\\s*(?:is|=|:)?\\s*[\\\\$]*(\\d+)',\n        r'=\\s*[\\\\$]*(\\d+)[\\\\$]*\\s*$',\n        r'answer\\s*:\\s*[\\\\$]*(\\d+)',\n    ]\n    for pattern in patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n        if matches:\n            try:\n                val = int(matches[-1])\n                if 0 <= val <= 99999:\n                    return val\n            except ValueError:\n                pass\n    return None\n\n\ndef extract_remainder_answer(text: str) -> Optional[int]:\n    \"\"\"Extract from 'remainder is X' for modular problems.\"\"\"\n    patterns = [\n        r'remainder\\s*(?:is|=|:)\\s*[\\\\$]*(\\d+)',\n        r'≡\\s*(\\d+)\\s*\\(?mod',\n        r'mod\\s*\\d+\\s*[)=]\\s*(\\d+)',\n    ]\n    for pattern in patterns:\n        matches = re.findall(pattern, text, re.IGNORECASE)\n        if matches:\n            try:\n                val = int(matches[-1])\n                if 0 <= val <= 99999:\n                    return val\n            except ValueError:\n                pass\n    return None\n\n\ndef extract_any_answer(text: str) -> Optional[int]:\n    \"\"\"Extract answer from any format, with priority order.\"\"\"\n    # Priority 1: Boxed (most explicit)\n    boxed = extract_boxed_answer(text)\n    if boxed is not None:\n        return boxed\n    \n    # Priority 2: \"answer is X\"\n    answer_is = extract_answer_is(text)\n    if answer_is is not None:\n        return answer_is\n    \n    # Priority 3: Remainder (for modular problems)\n    remainder = extract_remainder_answer(text)\n    if remainder is not None:\n        return remainder\n    \n    # Priority 4: Last number in final 500 chars\n    tail = text[-500:]\n    numbers = re.findall(r'\\b(\\d{1,5})\\b', tail)\n    if numbers:\n        try:\n            val = int(numbers[-1])\n            if 0 <= val <= 99999:\n                return val\n        except ValueError:\n            pass\n    \n    return None\n\n\ndef validate_proof_output(text: str) -> Tuple[bool, List[str]]:\n    \"\"\"Validate generated proof output.\"\"\"\n    issues = []\n    \n    # Check bracket balance (simplified)\n    open_count = text.count('(') + text.count('[') + text.count('{')\n    close_count = text.count(')') + text.count(']') + text.count('}')\n    if abs(open_count - close_count) > 5:\n        issues.append(\"unbalanced_brackets\")\n    \n    # Check for repetition loops (>3 identical phrases)\n    words = text.lower().split()\n    if len(words) > 50:\n        for window in [10, 20]:\n            if len(words) >= 2 * window:\n                tail1 = ' '.join(words[-window:])\n                tail2 = ' '.join(words[-2*window:-window])\n                if tail1 == tail2:\n                    issues.append(f\"repetition_loop_{window}\")\n                    break\n    \n    # Check for suspicious patterns\n    if text.count('...') > 10:\n        issues.append(\"excessive_ellipsis\")\n    \n    return len(issues) == 0, issues\n\nprint(\"[BANSHEEV4] Problem Type Detection + Answer Extraction: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# SECURE CODE EXECUTION\n# =========================\nimport multiprocessing as mp\n\ndef execute_python_code(code: str, timeout: int = 10, memory_limit_mb: int = 512) -> Tuple[bool, str]:\n    \"\"\"Secure Python execution with hard limits. NEVER hangs.\"\"\"\n    def run_code(code: str, result_queue: mp.Queue):\n        try:\n            resource.setrlimit(resource.RLIMIT_AS, (memory_limit_mb * 1024 * 1024, memory_limit_mb * 1024 * 1024))\n        except:\n            pass\n\n        import sys\n        from io import StringIO\n\n        old_stdout, old_stderr = sys.stdout, sys.stderr\n        sys.stdout = captured_out = StringIO()\n        sys.stderr = captured_err = StringIO()\n\n        try:\n            safe_globals = {\n                '__builtins__': {\n                    'print': print, 'range': range, 'len': len, 'sum': sum,\n                    'min': min, 'max': max, 'abs': abs, 'int': int, 'float': float,\n                    'str': str, 'list': list, 'dict': dict, 'set': set, 'tuple': tuple,\n                    'sorted': sorted, 'enumerate': enumerate, 'zip': zip,\n                    'pow': pow, 'round': round, 'divmod': divmod,\n                    'True': True, 'False': False, 'None': None,\n                    'bool': bool, 'type': type, 'isinstance': isinstance,\n                },\n            }\n\n            import math as safe_math\n            import itertools as safe_itertools\n            import fractions as safe_fractions\n            import decimal as safe_decimal\n            import collections as safe_collections\n\n            safe_globals['math'] = safe_math\n            safe_globals['itertools'] = safe_itertools\n            safe_globals['fractions'] = safe_fractions\n            safe_globals['decimal'] = safe_decimal\n            safe_globals['collections'] = safe_collections\n\n            exec(code, safe_globals)\n            output = captured_out.getvalue() + captured_err.getvalue()\n            result_queue.put((True, output.strip() or \"OK\"))\n\n        except MemoryError:\n            result_queue.put((False, f\"MemoryError: Exceeded {memory_limit_mb}MB\"))\n        except Exception as e:\n            result_queue.put((False, f\"{type(e).__name__}: {str(e)[:100]}\"))\n        finally:\n            sys.stdout, sys.stderr = old_stdout, old_stderr\n\n    result_queue = mp.Queue()\n    proc = mp.Process(target=run_code, args=(code, result_queue))\n    proc.start()\n    proc.join(timeout)\n\n    if proc.is_alive():\n        proc.terminate()\n        proc.join(2)\n        if proc.is_alive():\n            proc.kill()\n            proc.join(1)\n        return (False, f\"Timeout after {timeout}s\")\n\n    # CRITICAL: Queue.get() with timeout to prevent hang\n    try:\n        return result_queue.get(timeout=1)\n    except:\n        return (False, \"No result (queue timeout)\")\n\n\ndef extract_python_blocks(text: str) -> List[str]:\n    \"\"\"Extract ```python blocks.\"\"\"\n    blocks = re.findall(r\"```python\\s*(.*?)```\", text, re.DOTALL | re.IGNORECASE)\n    if not blocks:\n        blocks = re.findall(r\"```\\s*(.*?)```\", text, re.DOTALL)\n    return [b.strip() for b in blocks if b.strip()]\n\nprint(\"[BANSHEEV4] Code Execution: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# TIME MANAGEMENT HELPERS\n# (Uses AdaptiveTimeBudget from cell-2)\n# =========================\n\ndef get_time_budget_per_problem() -> float:\n    \"\"\"Get current budget from TIME_MANAGER.\"\"\"\n    return TIME_MANAGER.get_budget_for_next_problem()\n\n\ndef should_continue_generation(question_id: str, start_t: float, completed_ids: set, budget: float) -> bool:\n    \"\"\"Check if we should keep generating.\"\"\"\n    # Already completed this question\n    if question_id in completed_ids:\n        return False\n\n    # Use TIME_MANAGER for consistent checking\n    if not TIME_MANAGER.should_continue(start_t, budget):\n        return False\n\n    return True\n\nprint(\"[BANSHEEV4] Time Management Helpers: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# VLLM SERVER - COMPETITION ONLY\n# =========================\nimport subprocess\n\nvllm_process = None\n\n# Force offline mode\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\nos.environ[\"HF_HUB_OFFLINE\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\nos.environ[\"VLLM_ATTENTION_BACKEND\"] = \"TRITON_ATTN\"\nos.environ[\"TRITON_PTXAS_PATH\"] = \"/usr/local/cuda/bin/ptxas\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nos.environ[\"TIKTOKEN_ENCODINGS_BASE\"] = \"/kaggle/usr/lib/pip_install_aimo3_1/tiktoken_encodings\"\n\ncommand = [\n    \"python\", \"-m\", \"vllm.entrypoints.openai.api_server\",\n    \"--model\", \"/kaggle/input/gpt-oss-120b/transformers/default/1\",\n    \"--served-model-name\", \"vllm-model\",\n    \"--tensor-parallel-size\", \"1\",\n    \"--max-num-seqs\", \"16\",\n    \"--gpu-memory-utilization\", \"0.96\",\n    \"--host\", \"0.0.0.0\",\n    \"--port\", \"8000\",\n    \"--dtype\", \"auto\",\n    \"--max-model-len\", \"65536\",\n]\n\nwith open(\"/kaggle/working/vllm.log\", \"w\") as logfile:\n    vllm_process = subprocess.Popen(\n        command, stdout=logfile, stderr=subprocess.STDOUT, start_new_session=True\n    )\n\nprint(f\"[BANSHEEV5] vLLM server starting (PID: {vllm_process.pid})...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# OPENAI CLIENT - COMPETITION ONLY\n# =========================\nfrom openai import OpenAI\n\nos.environ[\"OPENAI_API_BASE\"] = \"http://127.0.0.1:8000/v1\"\nos.environ[\"OPENAI_API_KEY\"] = \"sk-local\"\n\nclient = OpenAI(\n    base_url=os.environ[\"OPENAI_API_BASE\"],\n    api_key=os.environ[\"OPENAI_API_KEY\"],\n    timeout=120.0,\n    max_retries=0,\n)\n\nstop_token_ids = [\n    token_id for token_id in range(200_000, 201_088)\n    if token_id not in [200005, 200006, 200007, 200008]\n]\n\n_CLIENT_READY = False\n\n\ndef await_client(max_wait: int = 900) -> bool:\n    \"\"\"Wait for vLLM server. ALWAYS waits up to 15 minutes.\"\"\"\n    global _CLIENT_READY\n\n    if _CLIENT_READY:\n        return True\n\n    print(f\"[CLIENT] Waiting for server (max {max_wait}s)...\")\n    deadline = time.time() + max_wait\n\n    while time.time() < deadline:\n        if TIME_MANAGER.is_expired():\n            print(\"[CLIENT] Time expired while waiting\")\n            return False\n\n        try:\n            models = client.models.list()\n            if models:\n                print(f\"[CLIENT] Server ready: {[m.id for m in models]}\")\n                _CLIENT_READY = True\n                return True\n        except Exception as e:\n            if RUNTIME.VERBOSE_LOGGING:\n                print(f\"[CLIENT] Waiting... ({type(e).__name__})\")\n\n        time.sleep(2)\n\n    print(f\"[CLIENT] ERROR: Server not ready after {max_wait}s\")\n    return False\n\nprint(\"[BANSHEEV5] OpenAI Client: OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# PROMPT ENGINEERING\n# 32 System Prompts from Zombie (23/50)\n# =========================\n\nCOGNITIVE_MACROS = \"\"\"\nCOGNITIVE TOOLKIT:\n- Try small cases to conjecture, then prove.\n- Search for invariants / monovariants.\n- Work backwards from desired form.\n- Check extremes / boundary cases.\n- Exploit symmetry / relabeling.\n- Pigeonhole principle.\n- Parity / modular arithmetic.\n- Bounding (upper/lower) and squeeze.\n- Complementary counting.\n- Construct bijection or involution.\n- Translate to algebra/graph/geometry.\n- Sanity-check units, integrality, constraints.\nOUTPUT: Finish with exactly one integer in \\\\boxed{}, 0 <= answer <= 99999.\n\"\"\"\n\n# All 32 battle-tested prompts from zombie_23.ipynb (scored 23/50)\nSYSTEM_PROMPTS = [\n    # 1. Elite mathematician with code execution\n    \"CRITICAL: You have Python code execution. Write ```python blocks for verification. \"\n    \"You are an elite mathematics researcher. Return only final integer in \\\\boxed{}, 0 <= answer <= 99999.\",\n    \n    # 2. IMO competitor rigor\n    \"You are an IMO competitor. Rigorously define variables, explore multiple strategies, \"\n    \"perform full case analysis, justify nontrivial steps. Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 3. Adversarial self-refutation\n    \"Solve with full rigor. After candidate solution, actively attempt refutation by \"\n    \"searching for counterexamples, stress-testing edge cases. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 4. Invariant-first under time pressure\n    \"Under IMO time pressure: identify key invariant/symmetry/extremal principle early, \"\n    \"avoid brute force unless justified. Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n    \n    # 5. Multiple solution approaches\n    \"Attempt at least two fundamentally different solution approaches. Proceed with more rigorous, \"\n    \"use other as verification. Return only verified final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 6. First principles restart on inconsistency\n    \"If step relies on unproven assumption or inconsistency, restart from first principles. \"\n    \"Return only final verified integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 7. Tool-integrated reasoning with early stopping\n    \"Tool-integrated reasoning, apply early-stopping when confident. Return verified final answer \"\n    \"in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 8. Adversarial academic review\n    \"Conduct adversarial academic review of proposed solution, then provide constructive critique. \"\n    \"Return only verified final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 9. Small answer skepticism\n    \"WARNING: Small answers (0, 1, 2, 3) are often wrong on competition problems. \"\n    \"If you get a small answer, re-verify with extra rigor. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 10. Constraint propagation\n    \"Apply constraint propagation: what does the problem FORCE to be true? What CANNOT happen? \"\n    \"Build the answer from forced conclusions. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 11. Backwards reasoning\n    \"Work backwards: What form must the answer have? What properties? Use this to constrain search. \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 12. Generating function / algebraic identity\n    \"Consider generating functions, algebraic identities, or polynomial methods. \"\n    \"Competition math often has elegant closed forms. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 13. Combinatorial bijection\n    \"Seek a bijection or double-counting argument. Competition problems often have elegant \"\n    \"combinatorial structures. Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 14. Modular arithmetic focus\n    \"Focus on modular arithmetic patterns. Check divisibility, remainders, Chinese Remainder Theorem. \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 15. Geometry to algebra translation\n    \"If geometry: translate to coordinates or trigonometry. If algebra: consider geometric interpretation. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 16. Extremal principle\n    \"Apply extremal principle: consider maximum/minimum elements, argue about their properties. \"\n    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 17. Graph theory modeling\n    \"Model the problem as a graph if applicable. Vertices, edges, degrees, paths, cycles. \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 18. Recurrence relation\n    \"Look for recurrence relations. Define f(n), find f(n) in terms of earlier values. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 19. Pigeonhole principle\n    \"Apply pigeonhole principle: if too many pigeons, some hole has multiple. What are the pigeons? Holes? \"\n    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 20. Greedy algorithm validation\n    \"Consider greedy approach. Prove it works or find counterexample. \"\n    \"Return only verified final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 21. Induction strategy\n    \"Prove by induction if pattern emerges. State base case, inductive step clearly. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 22. Probabilistic method intuition\n    \"Use probabilistic intuition: if random approach gives expected value X, constructive solution exists. \"\n    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 23. Number theory deep dive\n    \"For number theory: check prime factorization, Euler's theorem, quadratic residues. \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 24. Functional equation approach\n    \"For functional equations: try f(0), f(1), injectivity, surjectivity, substitutions. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 25. Inequality techniques\n    \"For inequalities: AM-GM, Cauchy-Schwarz, Jensen, rearrangement. When does equality hold? \"\n    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 26. Sequence analysis\n    \"Analyze sequences: arithmetic, geometric, periodic, eventually periodic, bounded? \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 27. Polynomial roots and coefficients\n    \"For polynomials: Vieta's formulas, root behavior, coefficient patterns. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 28. Game theory / strategy\n    \"If game theory: who has winning strategy? What invariant does winner maintain? \"\n    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 29. Coloring arguments\n    \"Consider coloring arguments: 2-color, checkerboard, mod-k coloring. What's forced? \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 30. Diophantine equation techniques\n    \"For Diophantine equations: factorization, descent, modular constraints. \"\n    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 31. Confidence scoring\n    \"Rate your confidence 0-100 after solving. If below 85, try alternative approach. \"\n    \"Return only verified final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n\n    # 32. Triangulation algorithm\n    \"Use triangulation: first determine answer's order of magnitude, then narrow range, then pinpoint. \"\n    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n]\n\n# Follow-up prompts for reflexion\nFOLLOWUP_NO_ANSWER = \"You did not provide a boxed answer. Please place your final integer answer in \\\\boxed{}.\"\nFOLLOWUP_SMALL_ANSWER = \"You answered with a small number. Small answers (0-10) are often wrong on IMO problems. Are you absolutely certain? Re-verify.\"\nFOLLOWUP_VERIFY = \"Please verify your answer one more time. Check arithmetic, edge cases, and logical steps.\"\nFOLLOWUP_GUESS = \"Time is running out. Make your best educated guess and put it in \\\\boxed{}.\"\n\n\ndef sanity_check_answer(question_text: str, ans: int) -> bool:\n    \"\"\"Check answer against problem constraints.\"\"\"\n    if ans < 0 or ans > 99999:\n        return False\n    t = question_text.lower()\n    \n    # Parity\n    if re.search(r'\\banswer\\s+is\\s+even\\b', t) and ans % 2 != 0:\n        return False\n    if re.search(r'\\banswer\\s+is\\s+odd\\b', t) and ans % 2 != 1:\n        return False\n    \n    # Divisibility\n    div_match = re.search(r'\\b(?:divisible by|multiple of)\\s+(\\d{1,5})\\b', t)\n    if div_match:\n        k = int(div_match.group(1))\n        if k != 0 and ans % k != 0:\n            return False\n    \n    return True\n\nprint(f\"[BANSHEEV4] Prompts: {len(SYSTEM_PROMPTS)} system prompts loaded\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# GENERATION HELPERS\n",
    "# =========================\n",
    "\n",
    "def annealed_temperature(step: int, total: int, t_start: float = 1.4, t_end: float = 0.2) -> float:\n",
    "    if total <= 1:\n",
    "        return t_end\n",
    "    return t_start * ((t_end / t_start) ** (step / (total - 1)))\n",
    "\n",
    "def annealed_max_tokens(step: int, total: int, start: int = 2048, end: int = 512) -> int:\n",
    "    if total <= 1:\n",
    "        return end\n",
    "    return int(start + (step / (total - 1)) * (end - start))\n",
    "\n",
    "def annealed_top_p(step: int, total: int, start: float = 0.95, end: float = 0.75) -> float:\n",
    "    if total <= 1:\n",
    "        return end\n",
    "    return start + (step / (total - 1)) * (end - start)\n",
    "\n",
    "def repetition_rate(text: str, window: int = 120) -> float:\n",
    "    toks = re.findall(r'\\w+|\\S', text.lower())\n",
    "    if len(toks) < window:\n",
    "        return 0.0\n",
    "    tail = toks[-window:]\n",
    "    return 1.0 - (len(set(tail)) / max(1, len(tail)))\n",
    "\n",
    "def tail_similarity(text: str, window: int = 900) -> float:\n",
    "    \"\"\"Check if text is repeating itself.\"\"\"\n",
    "    if len(text) < 2 * window:\n",
    "        return 0.0\n",
    "    a = text[-2*window:-window]\n",
    "    b = text[-window:]\n",
    "    # Simple char overlap\n",
    "    a_set = set(a.lower())\n",
    "    b_set = set(b.lower())\n",
    "    if not a_set or not b_set:\n",
    "        return 0.0\n",
    "    return len(a_set & b_set) / len(a_set | b_set)\n",
    "\n",
    "print(\"[BANSHEEV4] Generation Helpers: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# MAIN SOLVER\n# Annealed temp (workspace) + zombie prediction/submission logic\n# =========================\n\n# Global state\ncompleted_question_ids = set()\nquestion_id_to_counter = defaultdict(Counter)\nquestion_id_to_samples = defaultdict(list)\nquestion_id_to_traces = defaultdict(list)\nquestion_id_to_cic_history = defaultdict(list)\n\n\ndef extract_boxed_text(text: str) -> str:\n    \"\"\"Extract text inside \\\\boxed{} (zombie_23).\"\"\"\n    pattern = r\"oxed{(.*?)}\"\n    matches = re.findall(pattern, text)\n    if not matches:\n        return \"\"\n    for match in matches[::-1]:\n        if match != \"\":\n            return match\n    return \"\"\n\n\ndef is_valid_answer_string(text: str) -> bool:\n    \"\"\"Check if valid answer (zombie_23).\"\"\"\n    try:\n        if int(text) == float(text):\n            if 0 <= int(text) <= 99999:\n                return True\n    except:\n        pass\n    return False\n\n\n# === ANNEALED TEMPERATURE (from workspace) ===\ndef annealed_temperature(step: int, total_steps: int, t_start: float = 0.95, t_end: float = 0.20) -> float:\n    \"\"\"Temperature annealing: high->low (from workspace/banshee_run_fixed_v2.py).\"\"\"\n    if total_steps <= 1:\n        return t_end\n    frac = step / float(total_steps - 1)\n    return t_start + frac * (t_end - t_start)\n\n\ndef annealed_max_tokens(step: int, total_steps: int, min_tokens: int = 256, max_tokens: int = 2048) -> int:\n    \"\"\"Token allocation tied to temperature (workspace).\"\"\"\n    if total_steps <= 1:\n        return max_tokens\n    temp = annealed_temperature(step, total_steps)\n    return max_tokens_for_temp(temp, min_tokens=min_tokens, max_tokens=max_tokens)\n\n\ndef vote_answer(question_id: str, force_answer: bool = False) -> Optional[int]:\n    \"\"\"Log-weighted voting (zombie_23).\"\"\"\n    counter = question_id_to_counter[question_id]\n    if force_answer and not counter:\n        print(f\"[VOTE] No answers, fallback 0\")\n        completed_question_ids.add(question_id)\n        return 0\n    \n    modified_counter = Counter()\n    for value, count in counter.items():\n        modified_counter[value] += math.log(1.25 + abs(value)) * count\n    \n    total_score = sum(modified_counter.values())\n    score_list = sorted(\n        (score, counter[value], value) for value, score in modified_counter.items()\n    )\n    \n    if force_answer:\n        print(f\"[VOTE] total={total_score:.1f} over {sum(counter.values())} attempts\")\n        for score, count, value in score_list[::-1][:5]:\n            print(f\"  {value:10}   score={score:.1f}  count={count}\")\n        return score_list[-1][-1] if score_list else 0\n    \n    # Early stopping (zombie_23)\n    if score_list and score_list[-1][0] > max(3, total_score / (2 + math.log(1 + total_score))):\n        if len(score_list) == 1:\n            completed_question_ids.add(question_id)\n        elif score_list[-1][0] - score_list[-2][0] > 1:\n            completed_question_ids.add(question_id)\n    \n    return None\n\n\ndef generate_solution(\n    question_text: str,\n    question_id: str,\n    solution_index: int,\n    system_prompt: str,\n    budget: float,\n    total_generations: int = 8,\n) -> Optional[int]:\n    \"\"\"\n    Generate solution with:\n    - ANNEALED temperature (0.95 -> 0.20) from workspace\n    - ANNEALED max_tokens from workspace\n    - Follow-up prompts from zombie_23\n    \"\"\"\n    if question_id in completed_question_ids:\n        return None\n    if TIME_MANAGER.is_expired():\n        return None\n\n    gen_start = time.time()\n    os.makedirs(f\"solutions/{question_id}\", exist_ok=True)\n\n    # Annealed parameters\n    temperature = annealed_temperature(solution_index, total_generations)\n    max_tokens = annealed_max_tokens(solution_index, total_generations)\n\n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": question_text},\n    ]\n\n    text_response_to_save = \"\"\n    generation_idx = 0\n    max_iterations = 2\n\n    for iteration in range(max_iterations):\n        if question_id in completed_question_ids:\n            break\n        if TIME_MANAGER.is_expired():\n            break\n        if not TIME_MANAGER.should_continue(gen_start, budget):\n            break\n\n        text_response = \"\"\n        breaking = False\n        stream = None\n\n        try:\n            stream = client.chat.completions.create(\n                model=\"vllm-model\",\n                messages=messages,\n                temperature=temperature,  # ANNEALED\n                max_tokens=max_tokens,    # ANNEALED\n                stream=True,\n                extra_body=dict(min_p=0.02, stop_token_ids=stop_token_ids),\n                timeout=120,\n            )\n\n            for chunk in stream:\n                generation_idx += 1\n                delta = chunk.choices[0].delta\n                chunk_text = (\n                    delta.reasoning_content if hasattr(delta, 'reasoning_content') and delta.reasoning_content\n                    else delta.content or \"\"\n                )\n                if chunk_text:\n                    text_response += chunk_text\n                \n                if question_id in completed_question_ids:\n                    breaking = True\n                if TIME_MANAGER.is_expired():\n                    breaking = True\n                if generation_idx > 60000:\n                    breaking = True\n                if breaking:\n                    break\n                \n                if \"}\" in chunk_text and is_valid_answer_string(extract_boxed_text(text_response)):\n                    break\n                if iteration == 0 and generation_idx > 50000:\n                    break\n\n            messages.append({\"role\": \"assistant\", \"content\": text_response})\n            text_response_to_save += text_response\n\n        except Exception as e:\n            if RUNTIME.VERBOSE_LOGGING:\n                print(f\"[GEN] Error: {e}\")\n            break\n        finally:\n            if stream is not None:\n                try:\n                    stream.close()\n                except:\n                    pass\n\n        if breaking:\n            break\n\n        # Follow-ups (zombie_23)\n        boxed_text = extract_boxed_text(text_response)\n        \n        if not is_valid_answer_string(boxed_text) and iteration == 0 and generation_idx > 50000:\n            user_follow_up = \"Make an educated guess and put in \\\\boxed{}.\"\n            messages.append({\"role\": \"user\", \"content\": user_follow_up})\n            text_response_to_save += \"\\n===\\n\" + user_follow_up + \"\\n===\\n\"\n        elif not is_valid_answer_string(boxed_text):\n            user_follow_up = \"Place your final answer in \\\\boxed{}.\"\n            messages.append({\"role\": \"user\", \"content\": user_follow_up})\n            text_response_to_save += \"\\n===\\n\" + user_follow_up + \"\\n===\\n\"\n        elif int(boxed_text) <= 10:\n            user_follow_up = \"Are you sure? Small answers are often wrong.\"\n            messages.append({\"role\": \"user\", \"content\": user_follow_up})\n            text_response_to_save += \"\\n===\\n\" + user_follow_up + \"\\n===\\n\"\n        else:\n            break\n\n    boxed_text = extract_boxed_text(text_response_to_save)\n    \n    if text_response_to_save:\n        question_id_to_traces[question_id].append(text_response_to_save)\n        try:\n            suffix = f\"-{boxed_text}\" if is_valid_answer_string(boxed_text) else \"\"\n            with open(f\"solutions/{question_id}/{solution_index:04d}-{generation_idx}{suffix}.txt\", \"w\") as f:\n                f.write(text_response_to_save)\n        except:\n            pass\n\n    if is_valid_answer_string(boxed_text):\n        ans = int(boxed_text)\n        question_id_to_counter[question_id][ans] += 1\n        question_id_to_samples[question_id].append(ans)\n        vote_answer(question_id)\n        return ans\n\n    return None\n\nprint(\"[BANSHEEV4] generate_solution (annealed temp + zombie submission): OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# SOLVE - COMPETITION ONLY (NO MOCKS)\n# =========================\nfrom concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError as FuturesTimeoutError\n\n\ndef solve(question_text: str, question_id: str) -> int:\n    \"\"\"\n    Main solve function. NO MOCKS. Real LLM only.\n    \"\"\"\n    # Wait for server - NO FALLBACK\n    if not await_client(max_wait=900):\n        print(f\"[SOLVE] Server not ready - returning 0\")\n        return 0\n\n    if TIME_MANAGER.is_expired():\n        print(f\"[SOLVE] TIME EXPIRED\")\n        return 0\n\n    # Reset state\n    question_id_to_counter[question_id] = Counter()\n    question_id_to_samples[question_id] = []\n    question_id_to_traces[question_id] = []\n    question_id_to_cic_history[question_id] = []\n    completed_question_ids.discard(question_id)\n\n    budget = TIME_MANAGER.start_problem()\n    solve_start = time.time()\n\n    print(f\"\\n[SOLVE] {question_id}\")\n    print(f\"[TIME] {TIME_MANAGER.status()}\")\n    print(f\"[BUDGET] {budget:.0f}s ({budget/60:.1f}m)\")\n\n    if budget <= 0:\n        TIME_MANAGER.end_problem(0, 0)\n        return 0\n\n    # Dynamic generation count\n    if budget < 60:\n        num_generations = 4\n    elif budget < 180:\n        num_generations = 8\n    else:\n        num_generations = 12\n\n    prompt_indices = get_routed_prompts(question_text, num_generations)\n    print(f\"[SOLVE] {num_generations} generations\")\n\n    # Parallel generation\n    executor = None\n    try:\n        executor = ThreadPoolExecutor(max_workers=min(4, num_generations))\n        futures = []\n        \n        for i in range(num_generations):\n            prompt_idx = prompt_indices[i] if i < len(prompt_indices) else i % len(SYSTEM_PROMPTS)\n            sys_prompt = SYSTEM_PROMPTS[prompt_idx]\n            future = executor.submit(\n                generate_solution, \n                question_text, question_id, i, sys_prompt, budget, num_generations\n            )\n            futures.append(future)\n\n        for future in as_completed(futures, timeout=budget + 30):\n            if not TIME_MANAGER.should_continue(solve_start, budget):\n                print(f\"[SOLVE] Budget exhausted\")\n                break\n\n            try:\n                answer = future.result(timeout=5)\n                if answer is not None:\n                    if RUNTIME.ENABLE_CRYSTALLIZATION and len(question_id_to_samples[question_id]) >= 3:\n                        cic = compute_cic_functional(\n                            question_id_to_samples[question_id],\n                            question_id_to_traces[question_id]\n                        )\n                        question_id_to_cic_history[question_id].append(cic)\n                        \n                        if detect_crystallization(question_id_to_cic_history[question_id]):\n                            print(f\"[CRYSTAL] Crystallized at {len(question_id_to_samples[question_id])} samples\")\n                            completed_question_ids.add(question_id)\n                            break\n\n            except FuturesTimeoutError:\n                pass\n            except Exception as e:\n                if RUNTIME.VERBOSE_LOGGING:\n                    print(f\"[SOLVE] Future error: {e}\")\n\n    except Exception as e:\n        print(f\"[SOLVE] Executor error: {e}\")\n    finally:\n        if executor:\n            executor.shutdown(wait=False, cancel_futures=True)\n\n    # Answer selection\n    samples = question_id_to_samples[question_id]\n    traces = question_id_to_traces[question_id]\n    \n    print(f\"[SOLVE] Collected {len(samples)} samples\")\n\n    if not samples:\n        final_answer = vote_answer(question_id, force_answer=True)\n        if final_answer is None:\n            final_answer = 0\n    elif RUNTIME.ENABLE_VALUE_CLUSTERING and len(samples) >= 2:\n        try:\n            final_answer, confidence, metadata = select_answer_cic(samples, traces, threshold=0.05, fallback=0)\n            \n            cic_state = metadata.get(\"cic\")\n            if cic_state:\n                print(f\"[CIC] F={cic_state.F:.3f}, conf={confidence:.2f}\")\n            print(f\"[CLUSTER] {metadata.get('n_clusters', 0)} clusters\")\n            \n            log_answer = vote_answer(question_id, force_answer=True)\n            if log_answer != final_answer:\n                print(f\"[COMPARE] Cluster={final_answer}, LogVote={log_answer}\")\n            \n        except Exception as e:\n            print(f\"[SOLVE] Clustering error: {e}\")\n            final_answer = vote_answer(question_id, force_answer=True) or 0\n    else:\n        final_answer = vote_answer(question_id, force_answer=True) or samples[0]\n\n    try:\n        final_answer = int(final_answer)\n    except (TypeError, ValueError):\n        final_answer = 0\n    \n    final_answer = max(0, min(99999, final_answer))\n    \n    actual_time = time.time() - solve_start\n    TIME_MANAGER.end_problem(actual_time, budget)\n    \n    print(f\"[SOLVE] Final: {final_answer}\")\n    print(f\"[SOLVE] Time: {actual_time:.1f}s\")\n\n    completed_question_ids.add(question_id)\n    return final_answer\n\nprint(\"[BANSHEEV5] solve(): OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# PREDICT - COMPETITION ONLY\n# =========================\nimport kaggle_evaluation.aimo_3_inference_server\nimport pandas as pd\nimport polars as pl\n\n# Load reference for local debugging only\nid_to_answer = {}\ntry:\n    ref_path = \"/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv\"\n    if os.path.exists(ref_path):\n        df = pd.read_csv(ref_path)\n        id_to_answer = dict(zip(df[\"id\"], df[\"answer\"]))\n        df.drop(\"answer\", axis=1).to_csv(\"reference.csv\", index=False)\nexcept:\n    pass\n\n_problems_processed = 0\n_correct_count = 0\n_total_count = 0\n\n\ndef predict(id_: pl.Series, problem: pl.Series) -> pl.DataFrame:\n    \"\"\"Kaggle API prediction. NO MOCKS.\"\"\"\n    global _problems_processed, _correct_count, _total_count\n\n    try:\n        question_id = str(id_.item(0))\n    except:\n        question_id = \"unknown\"\n\n    try:\n        question_text = str(problem.item(0))\n    except:\n        question_text = \"\"\n\n    _problems_processed += 1\n    print(f\"\\n{'='*60}\")\n    print(f\"[PREDICT] Problem #{_problems_processed}: {question_id}\")\n    print(f\"[TIME] {TIME_MANAGER.status()}\")\n\n    if TIME_MANAGER.is_expired():\n        print(f\"[PREDICT] TIME EXPIRED\")\n        return pl.DataFrame({\"id\": [question_id], \"answer\": [0]})\n\n    if not question_text.strip():\n        print(f\"[PREDICT] Empty problem\")\n        return pl.DataFrame({\"id\": [question_id], \"answer\": [0]})\n\n    # SOLVE - NO FALLBACK\n    prediction = 0\n    try:\n        prediction = solve(question_text, question_id=question_id)\n    except Exception as e:\n        print(f\"[PREDICT] Solve error: {e}\")\n        prediction = 0\n\n    try:\n        prediction = int(prediction)\n    except:\n        prediction = 0\n    \n    prediction = max(0, min(99999, prediction))\n\n    # Score tracking\n    if id_to_answer:\n        try:\n            true_answer = int(id_to_answer.get(question_id, -1))\n            _total_count += 1\n            if prediction == true_answer and true_answer != -1:\n                _correct_count += 1\n                print(f\"[SCORE] CORRECT: {_correct_count}/{_total_count}\")\n            elif true_answer != -1:\n                print(f\"[SCORE] WRONG: pred={prediction}, true={true_answer}\")\n        except:\n            pass\n\n    print(f\"[PREDICT] Answer: {prediction}\")\n    return pl.DataFrame({\"id\": [question_id], \"answer\": [prediction]})\n\nprint(\"[BANSHEEV5] predict(): OK\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =========================\n# RUN SERVER - COMPETITION ONLY\n# =========================\nprint(\"\\n\" + \"=\" * 60)\nprint(\"BANSHEEV5: COMPETITION MODE\")\nprint(f\"SERVER_WAIT: {RUNTIME.SERVER_WAIT_TIMEOUT}s\")\nprint(f\"MOCK_ANSWERS: {RUNTIME.DRY_RUN_MOCK_ANSWERS}\")\nprint(f\"CLUSTERING: {RUNTIME.ENABLE_VALUE_CLUSTERING}\")\nprint(f\"CRYSTALLIZATION: {RUNTIME.ENABLE_CRYSTALLIZATION}\")\nprint(\"=\" * 60)\n\ninference_server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n\n# ALWAYS serve() - this is competition only\nif os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n    print(\"[SERVER] Competition rerun - serve()\")\n    inference_server.serve()\nelse:\n    # Validation run - use gateway with reference.csv\n    print(\"[SERVER] Validation - run_local_gateway()\")\n    inference_server.run_local_gateway((\"reference.csv\",))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CLEANUP\n",
    "# =========================\n",
    "import atexit\n",
    "\n",
    "def cleanup():\n",
    "    global vllm_process\n",
    "    if vllm_process and vllm_process.poll() is None:\n",
    "        print(\"[CLEANUP] Stopping vLLM...\")\n",
    "        vllm_process.terminate()\n",
    "        try:\n",
    "            vllm_process.wait(timeout=10)\n",
    "        except:\n",
    "            vllm_process.kill()\n",
    "        print(\"[CLEANUP] Done\")\n",
    "\n",
    "atexit.register(cleanup)\n",
    "print(\"[BANSHEEV4] Cleanup registered\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# =========================\n# BANSHEEV5 READY\n# =========================\nprint(\"[BANSHEEV5] All cells loaded. Competition mode only.\")\nprint(\"[BANSHEEV5] NO DRY-RUN. NO MOCKS. REAL LLM ONLY.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}