{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# PROMETHEUS v2.0 + vLLM + Qwen-72B-Math-INT4\n",
    "## The Synthesized Weapon: 20+ Novel Insights Operationalized\n",
    "\n",
    "**Architecture:**\n",
    "- Model: Qwen-72B-Math-INT4 (vLLM compatible)\n",
    "- Inference: vLLM (fast batched generation)\n",
    "- Selection: PROMETHEUS v2 + T.E.S.S.E.R.A.C.T. + NCD Topology\n",
    "\n",
    "**NEW in v2.0 (from PROMETHEUS SYNTHESIS ENCYCLOPEDIA):**\n",
    "1. **NCD Trace Topology Consensus** - Cluster traces by semantic similarity\n",
    "2. **Domain-Specific Basin Centers** - Canonical patterns per math domain\n",
    "3. **Causal Emergence Scoring (Ψ)** - Macro explains micro\n",
    "4. **Error Mode Detection** - Systematic error clustering\n",
    "5. **Confidence Calibration via NCD** - Better uncertainty estimation\n",
    "6. **ToM-Informed Prompting** - Perspective-taking in prompts\n",
    "7. **CIC Functional Scoring** - F[T] = Φ(T) - λH(T|X) + γC(T)\n",
    "8. **Kolmogorov-Weighted Voting** - Compression = confidence\n",
    "\n",
    "**From Riedl & Weidmann (2025):**\n",
    "- Theory of Mind predicts AI collaboration (ρs=0.17)\n",
    "- Solo ability has ZERO correlation with AI output quality (β=-0.00)\n",
    "- Human collaboration compresses model capability gaps by 5x\n",
    "\n",
    "**Competition Requirements:**\n",
    "- AIMO3: 50 problems, GPU ≤5h\n",
    "- Answer: Integer 0-999 (submit mod 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: ENVIRONMENT SETUP\n",
    "# =============================================================================\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import zlib  # For NCD computation\n",
    "\n",
    "# Environment flags\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "import torch\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import statistics\n",
    "import tempfile\n",
    "import subprocess\n",
    "import signal\n",
    "from typing import Optional, List, Tuple, Dict, Any\n",
    "from collections import Counter, defaultdict\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from scipy.cluster.hierarchy import fcluster, linkage\n",
    "\n",
    "from vllm import LLM, SamplingParams\n",
    "VLLM_OK = True\n",
    "\n",
    "# Seed\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PROMETHEUS v2.0 + vLLM + Qwen-72B-Math-INT4\")\n",
    "print(\"Synthesized with 20+ Novel Insights\")\n",
    "print(\"=\"*70)\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "# =============================================================================\n",
    "# TIMING\n",
    "# =============================================================================\n",
    "START_TIME = time.time()\n",
    "TOTAL_BUDGET = (4 * 60 + 40) * 60  # 4h40m\n",
    "CUTOFF_TIME = START_TIME + TOTAL_BUDGET\n",
    "PANIC_TIME = 300\n",
    "\n",
    "print(f\"Budget: {TOTAL_BUDGET//60} minutes\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: NCD (NORMALIZED COMPRESSION DISTANCE) - CORE PRIMITIVE\n",
    "# =============================================================================\n",
    "# From Li et al. (2004) \"The Similarity Metric\"\n",
    "# NCD approximates normalized information distance using compression\n",
    "#\n",
    "# NCD(x,y) = (K(xy) - min(K(x), K(y))) / max(K(x), K(y))\n",
    "#\n",
    "# Properties:\n",
    "# - 0 = identical (compress perfectly together)\n",
    "# - 1 = maximally different (no shared structure)\n",
    "# - ~0.5 = some shared structure\n",
    "# =============================================================================\n",
    "\n",
    "def ncd(x: str, y: str) -> float:\n",
    "    \"\"\"Normalized Compression Distance using zlib.\"\"\"\n",
    "    if not x or not y:\n",
    "        return 1.0\n",
    "    cx = len(zlib.compress(x.encode(), level=9))\n",
    "    cy = len(zlib.compress(y.encode(), level=9))\n",
    "    cxy = len(zlib.compress((x + y).encode(), level=9))\n",
    "    return (cxy - min(cx, cy)) / max(cx, cy)\n",
    "\n",
    "\n",
    "def kolmogorov_proxy(text: str) -> float:\n",
    "    \"\"\"Approximate Kolmogorov complexity via compression ratio.\"\"\"\n",
    "    if not text:\n",
    "        return 1.0\n",
    "    original = len(text.encode())\n",
    "    compressed = len(zlib.compress(text.encode(), level=9))\n",
    "    return compressed / original\n",
    "\n",
    "\n",
    "def compute_ncd_matrix(traces: List[str]) -> np.ndarray:\n",
    "    \"\"\"Compute pairwise NCD distance matrix.\"\"\"\n",
    "    n = len(traces)\n",
    "    dist = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            d = ncd(traces[i], traces[j])\n",
    "            dist[i, j] = d\n",
    "            dist[j, i] = d\n",
    "    return dist\n",
    "\n",
    "\n",
    "print(\"NCD primitives loaded.\")\n",
    "print(f\"  Test: ncd('hello world', 'hello world') = {ncd('hello world', 'hello world'):.3f}\")\n",
    "print(f\"  Test: ncd('hello world', 'goodbye moon') = {ncd('hello world', 'goodbye moon'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: PROBLEM CLASSIFIER + DOMAIN BASIN CENTERS\n",
    "# =============================================================================\n",
    "# INSIGHT B2: Domain-specific canonical reasoning patterns\n",
    "# =============================================================================\n",
    "\n",
    "class ProblemType(Enum):\n",
    "    NUMBER_THEORY = \"nt\"\n",
    "    COMBINATORICS = \"comb\"\n",
    "    GEOMETRY = \"geom\"\n",
    "    ALGEBRA = \"alg\"\n",
    "    MIXED = \"mixed\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ProblemProfile:\n",
    "    primary_type: ProblemType\n",
    "    constraints: List[str]\n",
    "    modulo_target: Optional[int]\n",
    "    enumeration_hint: Optional[int]\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DOMAIN BASIN CENTERS - Canonical reasoning patterns per domain\n",
    "# Traces closer to these patterns get higher confidence\n",
    "# =============================================================================\n",
    "BASIN_CENTERS = {\n",
    "    ProblemType.NUMBER_THEORY: [\n",
    "        \"\"\"Consider the prime factorization. Let n = p1^a1 * p2^a2 * ... * pk^ak.\n",
    "For divisibility, we need the exponent condition to be satisfied.\n",
    "Working modulo p, we apply Fermat's Little Theorem: a^(p-1) ≡ 1 (mod p).\n",
    "Therefore the answer is the value satisfying the modular constraint.\"\"\",\n",
    "        \"\"\"First, identify the gcd structure. By Bezout's identity, gcd(a,b) = ax + by.\n",
    "Using the Euclidean algorithm, we reduce step by step.\n",
    "The Chinese Remainder Theorem gives us the unique solution modulo lcm.\n",
    "Computing: answer = result.\"\"\",\n",
    "    ],\n",
    "    ProblemType.COMBINATORICS: [\n",
    "        \"\"\"We use a bijection argument. Define the mapping f: A -> B where f(x) = ...\n",
    "This mapping is well-defined because each element maps to exactly one element.\n",
    "Injectivity: if f(x) = f(y), then x = y by construction.\n",
    "Surjectivity: for any b in B, we can construct a = f^{-1}(b).\n",
    "Therefore |A| = |B| = answer.\"\"\",\n",
    "        \"\"\"Apply inclusion-exclusion. Let A_i be the set satisfying property i.\n",
    "|A_1 ∪ A_2 ∪ ... ∪ A_n| = Σ|A_i| - Σ|A_i ∩ A_j| + Σ|A_i ∩ A_j ∩ A_k| - ...\n",
    "Computing each term and summing gives the final count.\"\"\",\n",
    "    ],\n",
    "    ProblemType.ALGEBRA: [\n",
    "        \"\"\"Let's substitute to simplify. Set u = x + y, v = xy (Vieta's).\n",
    "The symmetric function becomes a polynomial in u and v.\n",
    "By AM-GM inequality, we have u^2 >= 4v with equality when x = y.\n",
    "Optimizing gives the extremal value.\"\"\",\n",
    "        \"\"\"Consider the polynomial P(x) with roots r_1, r_2, ..., r_n.\n",
    "By Vieta's formulas: sum of roots = -a_{n-1}/a_n, product = (-1)^n * a_0/a_n.\n",
    "The desired expression equals a combination of elementary symmetric polynomials.\"\"\",\n",
    "    ],\n",
    "    ProblemType.GEOMETRY: [\n",
    "        \"\"\"Set up coordinates. Place the origin at the center/vertex.\n",
    "Point A = (x_A, y_A), Point B = (x_B, y_B), etc.\n",
    "The distance formula gives |AB| = sqrt((x_A-x_B)^2 + (y_A-y_B)^2).\n",
    "Using the constraint equations, we solve for the unknown coordinates.\"\"\",\n",
    "        \"\"\"Apply the Law of Cosines: c^2 = a^2 + b^2 - 2ab*cos(C).\n",
    "For the area, use Heron's formula: A = sqrt(s(s-a)(s-b)(s-c)) where s = (a+b+c)/2.\n",
    "Alternatively, Area = (1/2)*base*height = (1/2)*ab*sin(C).\"\"\",\n",
    "    ],\n",
    "    ProblemType.MIXED: [],\n",
    "}\n",
    "\n",
    "\n",
    "def classify_problem(question: str) -> ProblemProfile:\n",
    "    \"\"\"Classify problem type for strategy routing.\"\"\"\n",
    "    q = question.lower()\n",
    "    scores = {t: 0.0 for t in ProblemType}\n",
    "    \n",
    "    # NUMBER THEORY keywords\n",
    "    for kw in ['remainder', 'modulo', 'mod ', 'divisible', 'prime', 'gcd', 'lcm',\n",
    "               'factor', 'digit', 'divides', 'coprime', 'congruent', 'fermat']:\n",
    "        if kw in q: scores[ProblemType.NUMBER_THEORY] += 2\n",
    "    \n",
    "    # COMBINATORICS keywords\n",
    "    for kw in ['how many', 'count', 'number of ways', 'arrangements', 'permutation',\n",
    "               'combination', 'choose', 'select', 'probability', 'subset', 'bijection']:\n",
    "        if kw in q: scores[ProblemType.COMBINATORICS] += 2\n",
    "    \n",
    "    # GEOMETRY keywords\n",
    "    for kw in ['triangle', 'circle', 'square', 'rectangle', 'polygon', 'angle',\n",
    "               'area', 'perimeter', 'diameter', 'radius', 'point', 'line', 'perpendicular']:\n",
    "        if kw in q: scores[ProblemType.GEOMETRY] += 2\n",
    "    \n",
    "    # ALGEBRA keywords\n",
    "    for kw in ['equation', 'polynomial', 'root', 'solve', 'sequence', 'series',\n",
    "               'function', 'variable', 'sum of', 'product of', 'inequality']:\n",
    "        if kw in q: scores[ProblemType.ALGEBRA] += 2\n",
    "    \n",
    "    sorted_types = sorted(scores.items(), key=lambda x: -x[1])\n",
    "    primary = sorted_types[0][0] if sorted_types[0][1] >= 2 else ProblemType.MIXED\n",
    "    \n",
    "    # Extract constraints\n",
    "    constraints = []\n",
    "    for pattern in [r'such that ([^.]+)', r'where ([^.]+)', r'given that ([^.]+)']:\n",
    "        constraints.extend(re.findall(pattern, q))\n",
    "    \n",
    "    # Detect modulo target\n",
    "    mod_target = None\n",
    "    mod_match = re.search(r'(?:mod|modulo|remainder when divided by)\\s*(\\d+)', q)\n",
    "    if mod_match:\n",
    "        mod_target = int(mod_match.group(1))\n",
    "    \n",
    "    # Enumeration hint\n",
    "    enum_hint = None\n",
    "    numbers = [int(x) for x in re.findall(r'\\b(\\d+)\\b', question) if 1 < int(x) < 10000]\n",
    "    if numbers and max(numbers) < 1000 and primary == ProblemType.COMBINATORICS:\n",
    "        enum_hint = max(numbers) ** 2\n",
    "    \n",
    "    return ProblemProfile(\n",
    "        primary_type=primary,\n",
    "        constraints=constraints[:3],\n",
    "        modulo_target=mod_target,\n",
    "        enumeration_hint=enum_hint,\n",
    "        confidence=min(1.0, sorted_types[0][1] / 10.0)\n",
    "    )\n",
    "\n",
    "\n",
    "def distance_to_basin(trace: str, domain: ProblemType) -> float:\n",
    "    \"\"\"INSIGHT B2: Distance to domain's canonical patterns.\"\"\"\n",
    "    centers = BASIN_CENTERS.get(domain, [])\n",
    "    if not centers:\n",
    "        return 0.5  # Neutral for unknown domain\n",
    "    distances = [ncd(trace, center) for center in centers]\n",
    "    return min(distances)  # Closest basin center\n",
    "\n",
    "\n",
    "print(\"Problem Classifier + Basin Centers loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: ERROR MODE DETECTION (INSIGHT B4)\n",
    "# =============================================================================\n",
    "# Models make systematic errors. Detect and discount them.\n",
    "# =============================================================================\n",
    "\n",
    "class ErrorMode(Enum):\n",
    "    ARITHMETIC = \"arithmetic\"          # Calculation errors\n",
    "    SIGN_ERROR = \"sign_error\"          # +/- confusion\n",
    "    OFF_BY_ONE = \"off_by_one\"          # Boundary condition errors\n",
    "    MODULAR_WRAP = \"modular_wrap\"      # Forgetting to take mod\n",
    "    INDEX_SHIFT = \"index_shift\"        # 0-indexed vs 1-indexed\n",
    "    OVERCOUNTING = \"overcounting\"      # Counting items multiple times\n",
    "    UNDERCOUNTING = \"undercounting\"    # Missing cases\n",
    "\n",
    "\n",
    "ERROR_PATTERNS = [\n",
    "    (ErrorMode.ARITHMETIC, r'\\d+\\s*[\\+\\-\\*/]\\s*\\d+\\s*=\\s*\\d+'),\n",
    "    (ErrorMode.SIGN_ERROR, r'(-?\\d+)\\s*-\\s*(-?\\d+)'),\n",
    "    (ErrorMode.OFF_BY_ONE, r'from\\s+\\d+\\s+to\\s+\\d+|≤|<|≥|>'),\n",
    "    (ErrorMode.MODULAR_WRAP, r'mod\\s+\\d+|\\(\\s*mod\\s+\\d+\\s*\\)'),\n",
    "]\n",
    "\n",
    "\n",
    "def detect_error_modes(trace: str, answer: int) -> List[ErrorMode]:\n",
    "    \"\"\"Detect likely error modes in a reasoning trace.\"\"\"\n",
    "    detected = []\n",
    "    trace_lower = trace.lower()\n",
    "    \n",
    "    for mode, pattern in ERROR_PATTERNS:\n",
    "        if re.search(pattern, trace_lower, re.IGNORECASE):\n",
    "            detected.append(mode)\n",
    "    \n",
    "    return detected\n",
    "\n",
    "\n",
    "def error_penalty(errors: List[ErrorMode]) -> float:\n",
    "    \"\"\"Compute penalty multiplier based on detected errors.\"\"\"\n",
    "    return 0.9 ** len(errors)  # 10% penalty per error mode\n",
    "\n",
    "\n",
    "print(\"Error Mode Detection loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: CAUSAL EMERGENCE SCORING (INSIGHT B7)\n",
    "# =============================================================================\n",
    "# Ψ measures how much macro-level structure explains micro-level details\n",
    "# High Ψ: \"By symmetry, pairs cancel\" (macro explains many micro)\n",
    "# Low Ψ: \"12+5=17, 17+3=20, ...\" (micro without macro)\n",
    "# =============================================================================\n",
    "\n",
    "MACRO_PATTERNS = [\n",
    "    r'by (symmetry|induction|contradiction|construction)',\n",
    "    r'(therefore|thus|hence|so)\\s+all',\n",
    "    r'in general',\n",
    "    r'for (all|any|every)',\n",
    "    r'without loss of generality',\n",
    "    r'the key (insight|observation|idea)',\n",
    "    r'this (implies|means|shows) that',\n",
    "]\n",
    "\n",
    "MICRO_PATTERNS = [\n",
    "    r'\\d+\\s*[\\+\\-\\*/]\\s*\\d+\\s*=\\s*\\d+',  # Arithmetic\n",
    "    r'x\\s*=\\s*\\d+',  # Variable assignment\n",
    "    r'case\\s+\\d+:',  # Case enumeration\n",
    "    r'step\\s+\\d+',  # Step enumeration\n",
    "]\n",
    "\n",
    "\n",
    "def compute_causal_emergence(trace: str) -> float:\n",
    "    \"\"\"\n",
    "    INSIGHT B7: Estimate causal emergence (Ψ) from trace.\n",
    "    \n",
    "    High Ψ = good abstraction (macro explains micro)\n",
    "    Low Ψ = mechanical computation (micro without macro)\n",
    "    \"\"\"\n",
    "    trace_lower = trace.lower()\n",
    "    \n",
    "    # Count macro-level statements\n",
    "    macro_count = sum(\n",
    "        len(re.findall(pattern, trace_lower))\n",
    "        for pattern in MACRO_PATTERNS\n",
    "    )\n",
    "    \n",
    "    # Count micro-level statements\n",
    "    micro_count = sum(\n",
    "        len(re.findall(pattern, trace))\n",
    "        for pattern in MICRO_PATTERNS\n",
    "    )\n",
    "    \n",
    "    if micro_count == 0:\n",
    "        return 0.5  # No micro details to explain\n",
    "    \n",
    "    # Ideal ratio: ~1 macro per 3 micros\n",
    "    ratio = macro_count / micro_count if micro_count > 0 else 0\n",
    "    ideal_ratio = 1/3\n",
    "    \n",
    "    # Score peaks at ideal, drops for too much/little macro\n",
    "    psi = 1 - min(1, abs(ratio - ideal_ratio) / ideal_ratio)\n",
    "    return max(0, min(1, psi))\n",
    "\n",
    "\n",
    "print(\"Causal Emergence Scoring (Ψ) loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: T.E.S.S.E.R.A.C.T. - TOPOLOGICAL TRACE CONSENSUS (INSIGHT B1)\n",
    "# =============================================================================\n",
    "# Topological Ensemble Selection via Semantic-Emergent Reasoning\n",
    "# And Compression Topology\n",
    "#\n",
    "# Instead of naive majority voting, cluster traces by NCD similarity\n",
    "# and weight consensus by basin stability.\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class AnswerCandidate:\n",
    "    value: int\n",
    "    trace: str\n",
    "    strategy: str\n",
    "    kolmogorov_weight: float = 1.0\n",
    "    basin_distance: float = 0.5\n",
    "    causal_emergence: float = 0.5\n",
    "    error_modes: List[ErrorMode] = field(default_factory=list)\n",
    "\n",
    "\n",
    "def cluster_traces_ncd(\n",
    "    candidates: List[AnswerCandidate],\n",
    "    threshold: float = 0.5\n",
    ") -> Dict[int, List[AnswerCandidate]]:\n",
    "    \"\"\"INSIGHT B1: Cluster traces using NCD-based hierarchical clustering.\"\"\"\n",
    "    if len(candidates) <= 1:\n",
    "        return {0: candidates} if candidates else {}\n",
    "    \n",
    "    traces = [c.trace for c in candidates]\n",
    "    \n",
    "    # Compute NCD distance matrix\n",
    "    dist_matrix = compute_ncd_matrix(traces)\n",
    "    \n",
    "    # Convert to condensed form for scipy\n",
    "    n = len(traces)\n",
    "    condensed = dist_matrix[np.triu_indices(n, k=1)]\n",
    "    \n",
    "    # Hierarchical clustering\n",
    "    if len(condensed) > 0:\n",
    "        Z = linkage(condensed, method='average')\n",
    "        clusters = fcluster(Z, threshold, criterion='distance')\n",
    "    else:\n",
    "        clusters = [1] * len(candidates)\n",
    "    \n",
    "    # Group by cluster\n",
    "    result = defaultdict(list)\n",
    "    for idx, (cluster_id, cand) in enumerate(zip(clusters, candidates)):\n",
    "        result[cluster_id].append(cand)\n",
    "    \n",
    "    return dict(result)\n",
    "\n",
    "\n",
    "def compute_basin_stability(cluster: List[AnswerCandidate]) -> float:\n",
    "    \"\"\"Compute stability of a reasoning basin.\"\"\"\n",
    "    if len(cluster) <= 1:\n",
    "        return 0.5\n",
    "    \n",
    "    traces = [c.trace for c in cluster]\n",
    "    answers = [c.value for c in cluster]\n",
    "    \n",
    "    # Internal cohesion: average pairwise similarity\n",
    "    total_sim = 0\n",
    "    count = 0\n",
    "    for i, t1 in enumerate(traces):\n",
    "        for t2 in traces[i+1:]:\n",
    "            total_sim += 1 - ncd(t1, t2)\n",
    "            count += 1\n",
    "    cohesion = total_sim / count if count > 0 else 0\n",
    "    \n",
    "    # Answer consistency\n",
    "    unique_answers = len(set(answers))\n",
    "    consistency = 1.0 / unique_answers\n",
    "    \n",
    "    return 0.6 * cohesion + 0.4 * consistency\n",
    "\n",
    "\n",
    "def tesseract_select(\n",
    "    candidates: List[AnswerCandidate],\n",
    "    mod_target: Optional[int] = None,\n",
    "    domain: ProblemType = ProblemType.MIXED\n",
    ") -> Tuple[int, float, Dict]:\n",
    "    \"\"\"\n",
    "    T.E.S.S.E.R.A.C.T. Selection Algorithm.\n",
    "    \n",
    "    Combines:\n",
    "    - NCD trace topology clustering (B1)\n",
    "    - Basin center distance (B2)\n",
    "    - Kolmogorov weighting (B3)\n",
    "    - Error mode penalty (B4)\n",
    "    - Causal emergence scoring (B7)\n",
    "    \"\"\"\n",
    "    if not candidates:\n",
    "        return 0, 0.0, {}\n",
    "    \n",
    "    # Apply modulo if specified\n",
    "    if mod_target:\n",
    "        for c in candidates:\n",
    "            c.value = c.value % mod_target\n",
    "    \n",
    "    # Enrich candidates with scores\n",
    "    for c in candidates:\n",
    "        c.kolmogorov_weight = 1.0 / (0.5 + kolmogorov_proxy(c.trace) * 0.15)\n",
    "        c.basin_distance = distance_to_basin(c.trace, domain)\n",
    "        c.causal_emergence = compute_causal_emergence(c.trace)\n",
    "        c.error_modes = detect_error_modes(c.trace, c.value)\n",
    "    \n",
    "    # Cluster by NCD topology\n",
    "    clusters = cluster_traces_ncd(candidates, threshold=0.5)\n",
    "    \n",
    "    # Score each cluster\n",
    "    cluster_scores = []\n",
    "    debug_info = {'clusters': []}\n",
    "    \n",
    "    for cluster_id, members in clusters.items():\n",
    "        stability = compute_basin_stability(members)\n",
    "        \n",
    "        # Aggregate scores\n",
    "        total_k = sum(c.kolmogorov_weight for c in members)\n",
    "        total_psi = sum(c.causal_emergence for c in members)\n",
    "        avg_basin = 1 - np.mean([c.basin_distance for c in members])  # Closer = higher\n",
    "        error_penalty_total = np.prod([error_penalty(c.error_modes) for c in members])\n",
    "        \n",
    "        # Majority answer in cluster\n",
    "        answers = [c.value for c in members]\n",
    "        majority = Counter(answers).most_common(1)[0][0]\n",
    "        \n",
    "        # Combined score (CIC-inspired)\n",
    "        # F[T] = Φ(T) - λH(T|X) + γC(T)\n",
    "        # ≈ stability * kolmogorov * emergence * basin_bonus * error_penalty\n",
    "        score = (\n",
    "            len(members) *       # Mass\n",
    "            stability *          # Basin stability (Φ proxy)\n",
    "            total_k *            # Kolmogorov (compression)\n",
    "            (1 + total_psi) *    # Causal emergence (C)\n",
    "            (1 + avg_basin) *    # Basin center bonus\n",
    "            error_penalty_total  # Error mode penalty\n",
    "        )\n",
    "        \n",
    "        cluster_scores.append((score, majority, cluster_id))\n",
    "        debug_info['clusters'].append({\n",
    "            'id': cluster_id,\n",
    "            'size': len(members),\n",
    "            'stability': stability,\n",
    "            'majority': majority,\n",
    "            'score': score,\n",
    "        })\n",
    "    \n",
    "    # Select highest-scoring cluster's majority answer\n",
    "    cluster_scores.sort(key=lambda x: -x[0])\n",
    "    selected = cluster_scores[0][1]\n",
    "    \n",
    "    # Confidence: ratio of top cluster to total\n",
    "    total_score = sum(s[0] for s in cluster_scores)\n",
    "    confidence = cluster_scores[0][0] / total_score if total_score > 0 else 0\n",
    "    \n",
    "    debug_info['selected'] = selected\n",
    "    debug_info['confidence'] = confidence\n",
    "    \n",
    "    return selected, confidence, debug_info\n",
    "\n",
    "\n",
    "print(\"T.E.S.S.E.R.A.C.T. Selection loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: CLASSIC PROMETHEUS COMPONENTS (from v1)\n",
    "# =============================================================================\n",
    "\n",
    "# AIMO3 RULE\n",
    "ANSWER_MIN = 0\n",
    "ANSWER_MAX = 999  # Submit mod 1000\n",
    "FALLBACK_ANSWER = 0\n",
    "\n",
    "# Benford \"nice\" numbers\n",
    "NICE_NUMBERS = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 15, 16, 18, 20, 24, 25, 27, 30, 32, \n",
    "                36, 40, 42, 45, 48, 50, 54, 60, 64, 72, 80, 81, 90, 96, 100, 108, 120, \n",
    "                125, 128, 144, 150, 162, 180, 192, 200, 216, 225, 240, 243, 250, 256,\n",
    "                270, 288, 300, 324, 360, 384, 400, 432, 450, 480, 486, 500, 512, 540,\n",
    "                576, 600, 625, 648, 720, 729, 768, 800, 810, 864, 900, 960, 972}\n",
    "\n",
    "FIBONACCI = {1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987}\n",
    "\n",
    "\n",
    "def benford_score(n: int) -> float:\n",
    "    \"\"\"Mathematical elegance bonus.\"\"\"\n",
    "    score = 1.0\n",
    "    if n in NICE_NUMBERS: score *= 1.3\n",
    "    if n in FIBONACCI: score *= 1.2\n",
    "    s = str(abs(n)) if n != 0 else \"0\"\n",
    "    trailing_zeros = len(s) - len(s.rstrip('0'))\n",
    "    if trailing_zeros >= 2: score *= 1.1 + 0.05 * trailing_zeros\n",
    "    if n > 0 and (n & (n - 1)) == 0: score *= 1.15  # Power of 2\n",
    "    return score\n",
    "\n",
    "\n",
    "def toroidal_vote(samples: List[int], mod: int) -> Tuple[int, float]:\n",
    "    \"\"\"Circular mean for mod-N problems.\"\"\"\n",
    "    if not samples or mod <= 0:\n",
    "        return 0, 0.1\n",
    "    \n",
    "    normalized = [s % mod for s in samples]\n",
    "    angles = [2 * math.pi * m / mod for m in normalized]\n",
    "    sin_sum = sum(math.sin(a) for a in angles)\n",
    "    cos_sum = sum(math.cos(a) for a in angles)\n",
    "    mean_angle = math.atan2(sin_sum, cos_sum)\n",
    "    center = int(round(mean_angle * mod / (2 * math.pi))) % mod\n",
    "    R = math.sqrt(sin_sum**2 + cos_sum**2) / len(samples)\n",
    "    confidence = min(0.95, max(0.1, R))\n",
    "    return center, confidence\n",
    "\n",
    "\n",
    "print(\"Classic PROMETHEUS components loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: CODE EXECUTION ENGINE + SELF-HEALING\n",
    "# =============================================================================\n",
    "\n",
    "STDLIB = '''\n",
    "import sys; sys.setrecursionlimit(20000)\n",
    "import math, numpy as np\n",
    "from itertools import *\n",
    "from collections import *\n",
    "from functools import lru_cache, reduce\n",
    "from fractions import Fraction\n",
    "try:\n",
    "    from sympy import *\n",
    "    from sympy.ntheory import factorint, divisors, totient, isprime\n",
    "except: pass\n",
    "\n",
    "def is_prime(n):\n",
    "    if n < 2: return False\n",
    "    if n < 4: return True\n",
    "    if n % 2 == 0: return False\n",
    "    for i in range(3, int(n**0.5) + 1, 2):\n",
    "        if n % i == 0: return False\n",
    "    return True\n",
    "\n",
    "def gcd(a, b):\n",
    "    while b: a, b = b, a % b\n",
    "    return a\n",
    "\n",
    "def lcm(a, b): return a * b // gcd(a, b)\n",
    "\n",
    "def C(n, k):\n",
    "    if k < 0 or k > n: return 0\n",
    "    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n",
    "\n",
    "def mod_inverse(a, m):\n",
    "    def extended_gcd(a, b):\n",
    "        if a == 0: return b, 0, 1\n",
    "        g, x, y = extended_gcd(b % a, a)\n",
    "        return g, y - (b // a) * x, x\n",
    "    g, x, _ = extended_gcd(a % m, m)\n",
    "    return x % m if g == 1 else None\n",
    "'''\n",
    "\n",
    "SNOOP = '''\n",
    "_vars = dict(globals())\n",
    "for _v in ['answer', 'result', 'ans', 'res', 'final', 'output', 'solution', 'total', 'count']:\n",
    "    if _v in _vars and _vars[_v] is not None:\n",
    "        try: print(int(_vars[_v])); break\n",
    "        except: pass\n",
    "'''\n",
    "\n",
    "\n",
    "def extract_python_code(text: str) -> Optional[str]:\n",
    "    for pattern in [r'```python\\s*\\n(.*?)```', r'```py\\s*\\n(.*?)```', r'```\\s*\\n(.*?)```']:\n",
    "        matches = re.findall(pattern, text, re.DOTALL | re.IGNORECASE)\n",
    "        if matches:\n",
    "            return matches[-1].strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_answer(raw: Any) -> Optional[int]:\n",
    "    if raw is None: return None\n",
    "    try:\n",
    "        s = str(raw).replace(',', '').replace(' ', '').strip()\n",
    "        s = re.sub(r'[^0-9.eE+-]', '', s)\n",
    "        if not s: return None\n",
    "        val = float(s)\n",
    "        if val != val or abs(val) == float('inf'): return None\n",
    "        result = int(round(val))\n",
    "        if result < 0: result = abs(result)\n",
    "        return result % 1000000\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def self_heal_code(code: str, stderr: str) -> Optional[str]:\n",
    "    healed = code\n",
    "    if 'NameError' in stderr:\n",
    "        missing = re.findall(r\"name '(\\w+)' is not defined\", stderr)\n",
    "        for name in missing:\n",
    "            if name in ['np', 'numpy']: \n",
    "                healed = 'import numpy as np\\n' + healed\n",
    "            elif name in ['math', 'sqrt', 'gcd', 'ceil', 'floor']: \n",
    "                healed = 'import math\\nfrom math import *\\n' + healed\n",
    "            elif name in ['sympy', 'Symbol', 'solve', 'Rational']: \n",
    "                healed = 'from sympy import *\\n' + healed\n",
    "            elif name in ['Counter', 'defaultdict', 'deque']: \n",
    "                healed = 'from collections import *\\n' + healed\n",
    "            elif name in ['combinations', 'permutations', 'product']: \n",
    "                healed = 'from itertools import *\\n' + healed\n",
    "    if 'RecursionError' in stderr:\n",
    "        healed = 'import sys; sys.setrecursionlimit(50000)\\n' + healed\n",
    "    return healed if healed != code else None\n",
    "\n",
    "\n",
    "def execute_code(code: str, timeout: int = 15, retries: int = 1) -> Tuple[Optional[int], str]:\n",
    "    if not code:\n",
    "        return None, \"\"\n",
    "    \n",
    "    has_print = 'print(' in code\n",
    "    full = STDLIB + \"\\n\" + code + (\"\" if has_print else \"\\n\" + SNOOP)\n",
    "    \n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
    "                f.write(full)\n",
    "                f.flush()\n",
    "                result = subprocess.run(['python', f.name], capture_output=True, \n",
    "                                       text=True, timeout=timeout)\n",
    "                os.unlink(f.name)\n",
    "                \n",
    "                if result.returncode == 0 and result.stdout.strip():\n",
    "                    numbers = re.findall(r'-?\\d+\\.?\\d*', result.stdout)\n",
    "                    if numbers:\n",
    "                        return normalize_answer(numbers[-1]), code\n",
    "                \n",
    "                if result.stderr and attempt < retries:\n",
    "                    healed = self_heal_code(code, result.stderr)\n",
    "                    if healed:\n",
    "                        code = healed\n",
    "                        full = STDLIB + \"\\n\" + healed + (\"\" if has_print else \"\\n\" + SNOOP)\n",
    "                        continue\n",
    "        except subprocess.TimeoutExpired:\n",
    "            pass\n",
    "        except Exception:\n",
    "            pass\n",
    "        break\n",
    "    return None, code\n",
    "\n",
    "\n",
    "def extract_boxed(text: str) -> Optional[int]:\n",
    "    for pattern in [r'\\\\boxed\\{(\\d+)\\}', r'boxed\\{(\\d+)\\}', r'[Aa]nswer\\s*[=:]\\\\s*(\\d+)']:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            return normalize_answer(matches[-1])\n",
    "    nums = re.findall(r'\\b(\\d+)\\b', text[-500:])\n",
    "    for n in reversed(nums):\n",
    "        v = normalize_answer(n)\n",
    "        if v and 1 < v < 100000:\n",
    "            return v\n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"Code execution engine loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: MODEL LOADING + ToM-INFORMED PROMPTS\n",
    "# =============================================================================\n",
    "\n",
    "MODEL_PATHS = [\n",
    "    \"/kaggle/input/qwen-72b-math-int4\",\n",
    "    \"/kaggle/input/d/ryancardwell/qwen-72b-math-int4\",\n",
    "    \"/kaggle/input/qwen-72b-math-nf4\",\n",
    "]\n",
    "\n",
    "def find_model():\n",
    "    import glob\n",
    "    for p in MODEL_PATHS:\n",
    "        if os.path.exists(p):\n",
    "            if os.path.exists(os.path.join(p, \"config.json\")):\n",
    "                return p\n",
    "            configs = glob.glob(f\"{p}/**/config.json\", recursive=True)\n",
    "            if configs:\n",
    "                return os.path.dirname(configs[0])\n",
    "    return None\n",
    "\n",
    "MODEL_PATH = find_model()\n",
    "print(f\"Model path: {MODEL_PATH}\")\n",
    "\n",
    "# =============================================================================\n",
    "# vLLM MODEL\n",
    "# =============================================================================\n",
    "LLM_MODEL = None\n",
    "\n",
    "if VLLM_OK and MODEL_PATH:\n",
    "    print(f\"\\nLoading vLLM model...\")\n",
    "    try:\n",
    "        LLM_MODEL = LLM(\n",
    "            model=MODEL_PATH,\n",
    "            tensor_parallel_size=1,\n",
    "            gpu_memory_utilization=0.92,\n",
    "            trust_remote_code=True,\n",
    "            max_model_len=8192,\n",
    "            enforce_eager=True,\n",
    "            seed=SEED,\n",
    "        )\n",
    "        print(\"vLLM model loaded!\")\n",
    "    except Exception as e:\n",
    "        print(f\"vLLM load failed: {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# ToM-INFORMED STRATEGY PROMPTS (INSIGHT from Riedl & Weidmann)\n",
    "# =============================================================================\n",
    "# Key insight: Frame the model's ROLE clearly, not what it shouldn't do\n",
    "# =============================================================================\n",
    "\n",
    "STRATEGY_PROMPTS = {\n",
    "    'pot_algorithmic': \"\"\"You are a mathematical computation engine.\n",
    "Your role: Convert the problem into executable Python code that computes the answer.\n",
    "Rules:\n",
    "- Use int() not float() for final answer\n",
    "- Print exactly ONE integer at the end\n",
    "- Use efficient algorithms (avoid O(n!) when possible)\n",
    "- The printed integer IS your answer\"\"\",\n",
    "\n",
    "    'pot_sympy': \"\"\"You are a symbolic mathematics engine using SymPy.\n",
    "Your role: Solve the problem using exact symbolic computation.\n",
    "Rules:\n",
    "- Use Rational(a,b) NOT a/b for fractions\n",
    "- Use sympy.Integer for large numbers\n",
    "- Print exactly ONE integer at the end\n",
    "- Verify your symbolic solution numerically if possible\"\"\",\n",
    "\n",
    "    'pot_bruteforce': \"\"\"You are an enumeration engine for exhaustive search.\n",
    "Your role: Systematically enumerate all cases to find the answer.\n",
    "Rules:\n",
    "- Budget: Maximum 10^7 iterations\n",
    "- Use generators/itertools for memory efficiency\n",
    "- Early termination when pattern is clear\n",
    "- Print exactly ONE integer at the end\"\"\",\n",
    "\n",
    "    'cot': \"\"\"You are a step-by-step mathematical reasoner.\n",
    "Your role: Work through the problem systematically, showing each step.\n",
    "Rules:\n",
    "- Show your reasoning clearly\n",
    "- Check your work at each step\n",
    "- Put your final answer in \\\\boxed{}\n",
    "- The boxed value must be a single integer\"\"\",\n",
    "}\n",
    "\n",
    "TYPE_HINTS = {\n",
    "    ProblemType.NUMBER_THEORY: \"DOMAIN: Number theory. Consider: modular arithmetic, prime factorization, CRT, Fermat/Euler.\",\n",
    "    ProblemType.COMBINATORICS: \"DOMAIN: Combinatorics. Consider: bijections, inclusion-exclusion, generating functions, recursion.\",\n",
    "    ProblemType.GEOMETRY: \"DOMAIN: Geometry. Consider: coordinates, distance formula, shoelace, trigonometry, similar triangles.\",\n",
    "    ProblemType.ALGEBRA: \"DOMAIN: Algebra. Consider: polynomials, Vieta's formulas, AM-GM, substitution, symmetry.\",\n",
    "    ProblemType.MIXED: \"\",\n",
    "}\n",
    "\n",
    "# Temperature annealing\n",
    "TEMP_START = 0.7\n",
    "TEMP_MIN = 0.3\n",
    "TEMP_DECAY = 0.85\n",
    "\n",
    "\n",
    "def create_prompt(question: str, strategy: str, profile: ProblemProfile) -> str:\n",
    "    system = STRATEGY_PROMPTS.get(strategy, STRATEGY_PROMPTS['pot_algorithmic'])\n",
    "    hint = TYPE_HINTS.get(profile.primary_type, \"\")\n",
    "    mod_note = f\"\\nIMPORTANT: Final answer must be computed mod {profile.modulo_target}.\" if profile.modulo_target else \"\"\n",
    "    \n",
    "    return f\"\"\"<|im_start|>system\n",
    "{system}\n",
    "{hint}{mod_note}\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "{question}\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"ToM-informed prompts loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: BATCH GENERATION + PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "POT_STOP = [\"```output\", \"```\\nOutput\", \"# Output\", \"\\n\\n\\n\", \"<|im_end|>\"]\n",
    "COT_STOP = [\"</think>\", \"\\n\\nQuestion:\", \"<|im_end|}\"]\n",
    "\n",
    "\n",
    "def batch_generate(prompts: List[str], mode: str = 'pot', temp: float = 0.6) -> List[str]:\n",
    "    if not LLM_MODEL:\n",
    "        return [\"\"] * len(prompts)\n",
    "    \n",
    "    params = SamplingParams(\n",
    "        temperature=max(0.1, temp),\n",
    "        top_p=0.9,\n",
    "        max_tokens=4096,\n",
    "        stop=POT_STOP if mode == 'pot' else COT_STOP,\n",
    "    )\n",
    "    \n",
    "    outputs = LLM_MODEL.generate(prompts, sampling_params=params)\n",
    "    return [o.outputs[0].text for o in outputs]\n",
    "\n",
    "\n",
    "def process_pot_outputs(outputs: List[str], strategies: List[str]) -> List[AnswerCandidate]:\n",
    "    candidates = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "        futures = {}\n",
    "        for i, out in enumerate(outputs):\n",
    "            code = extract_python_code(out)\n",
    "            if code:\n",
    "                futures[executor.submit(execute_code, code)] = (i, code, out, strategies[i] if i < len(strategies) else 'pot')\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            i, code, full_output, strat = futures[future]\n",
    "            try:\n",
    "                ans, final_code = future.result()\n",
    "                if ans is not None:\n",
    "                    candidates.append(AnswerCandidate(\n",
    "                        value=ans,\n",
    "                        trace=full_output,  # Full output as trace for NCD\n",
    "                        strategy=strat,\n",
    "                    ))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return candidates\n",
    "\n",
    "\n",
    "def process_cot_outputs(outputs: List[str]) -> List[AnswerCandidate]:\n",
    "    candidates = []\n",
    "    for out in outputs:\n",
    "        ans = extract_boxed(out)\n",
    "        if ans is not None:\n",
    "            candidates.append(AnswerCandidate(\n",
    "                value=ans,\n",
    "                trace=out,\n",
    "                strategy=\"cot\",\n",
    "            ))\n",
    "    return candidates\n",
    "\n",
    "\n",
    "print(\"Batch processing loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: MAIN SOLVER - PROMETHEUS v2.0 with T.E.S.S.E.R.A.C.T.\n",
    "# =============================================================================\n",
    "\n",
    "STRATEGY_WEIGHTS = {\n",
    "    ProblemType.NUMBER_THEORY: ['pot_sympy', 'pot_sympy', 'pot_algorithmic', 'pot_bruteforce'],\n",
    "    ProblemType.COMBINATORICS: ['pot_bruteforce', 'pot_bruteforce', 'pot_algorithmic', 'pot_sympy'],\n",
    "    ProblemType.GEOMETRY: ['pot_sympy', 'pot_algorithmic', 'pot_algorithmic', 'cot'],\n",
    "    ProblemType.ALGEBRA: ['pot_sympy', 'pot_sympy', 'pot_algorithmic', 'cot'],\n",
    "    ProblemType.MIXED: ['pot_algorithmic', 'pot_sympy', 'pot_bruteforce', 'cot'],\n",
    "}\n",
    "\n",
    "PROBLEM_COUNT = 0\n",
    "SOLVED_COUNT = 0\n",
    "\n",
    "\n",
    "def panic_guess(question: str, profile: ProblemProfile) -> int:\n",
    "    \"\"\"Emergency fallback.\"\"\"\n",
    "    numbers = [int(x) for x in re.findall(r'\\b\\d+\\b', question) if 0 < int(x) < 100000]\n",
    "    if profile.modulo_target and numbers:\n",
    "        return numbers[0] % profile.modulo_target\n",
    "    return numbers[0] % 1000 if numbers else 0\n",
    "\n",
    "\n",
    "def solve_problem(question: str) -> int:\n",
    "    \"\"\"\n",
    "    PROMETHEUS v2.0 Solver with T.E.S.S.E.R.A.C.T. selection.\n",
    "    \n",
    "    Incorporates all 20+ insights from PROMETHEUS SYNTHESIS ENCYCLOPEDIA.\n",
    "    \"\"\"\n",
    "    global PROBLEM_COUNT, SOLVED_COUNT\n",
    "    PROBLEM_COUNT += 1\n",
    "    \n",
    "    time_remaining = CUTOFF_TIME - time.time()\n",
    "    \n",
    "    # PANIC MODE\n",
    "    if time_remaining < PANIC_TIME:\n",
    "        profile = classify_problem(question)\n",
    "        print(f\"  PANIC ({time_remaining:.0f}s)\")\n",
    "        return panic_guess(question, profile)\n",
    "    \n",
    "    # CLASSIFY\n",
    "    profile = classify_problem(question)\n",
    "    print(f\"  Type: {profile.primary_type.value} | Mod: {profile.modulo_target}\")\n",
    "    \n",
    "    strategies = STRATEGY_WEIGHTS.get(profile.primary_type, STRATEGY_WEIGHTS[ProblemType.MIXED])\n",
    "    all_candidates = []\n",
    "    current_temp = TEMP_START\n",
    "    \n",
    "    # PHASE 1: Initial batch\n",
    "    print(f\"  Phase 1: {len(strategies)} samples (T={current_temp:.2f})\")\n",
    "    prompts = [create_prompt(question, s, profile) for s in strategies]\n",
    "    outputs = batch_generate(prompts, 'pot', current_temp)\n",
    "    candidates = process_pot_outputs(outputs, strategies)\n",
    "    all_candidates.extend(candidates)\n",
    "    print(f\"    -> {len(candidates)} answers: {[c.value for c in candidates]}\")\n",
    "    \n",
    "    # EARLY CONSENSUS (60%+ agreement)\n",
    "    if len(candidates) >= 2:\n",
    "        values = [c.value for c in candidates]\n",
    "        counts = Counter(values)\n",
    "        best, count = counts.most_common(1)[0]\n",
    "        if count / len(values) >= 0.6:\n",
    "            print(f\"  EARLY CONSENSUS: {best}\")\n",
    "            SOLVED_COUNT += 1\n",
    "            return int(best) % 1000\n",
    "    \n",
    "    # PHASE 2: Expansion (if time permits)\n",
    "    time_remaining = CUTOFF_TIME - time.time()\n",
    "    if time_remaining > 180:\n",
    "        current_temp = max(TEMP_MIN, current_temp * TEMP_DECAY)\n",
    "        print(f\"  Phase 2: expand (T={current_temp:.2f})\")\n",
    "        prompts2 = [create_prompt(question, s, profile) for s in strategies]\n",
    "        outputs2 = batch_generate(prompts2, 'pot', current_temp)\n",
    "        candidates2 = process_pot_outputs(outputs2, strategies)\n",
    "        all_candidates.extend(candidates2)\n",
    "    \n",
    "    # PHASE 3: CoT fallback (if few candidates)\n",
    "    if len(all_candidates) < 3 and time_remaining > 120:\n",
    "        print(f\"  Phase 3: CoT fallback\")\n",
    "        cot_prompts = [create_prompt(question, 'cot', profile) for _ in range(2)]\n",
    "        cot_outputs = batch_generate(cot_prompts, 'cot', 0.4)\n",
    "        cot_candidates = process_cot_outputs(cot_outputs)\n",
    "        all_candidates.extend(cot_candidates)\n",
    "    \n",
    "    # NO ANSWERS\n",
    "    if not all_candidates:\n",
    "        return panic_guess(question, profile)\n",
    "    \n",
    "    # =================================================================\n",
    "    # T.E.S.S.E.R.A.C.T. SELECTION (the key innovation of v2.0)\n",
    "    # =================================================================\n",
    "    final, confidence, debug = tesseract_select(\n",
    "        all_candidates,\n",
    "        mod_target=profile.modulo_target,\n",
    "        domain=profile.primary_type\n",
    "    )\n",
    "    \n",
    "    # TOROIDAL verification for mod problems\n",
    "    if profile.modulo_target:\n",
    "        values = [c.value for c in all_candidates]\n",
    "        tor_ans, tor_conf = toroidal_vote(values, profile.modulo_target)\n",
    "        if tor_conf > 0.7 and tor_ans != final:\n",
    "            print(f\"    Toroidal override: {tor_ans} (conf={tor_conf:.2f})\")\n",
    "            final = tor_ans\n",
    "    \n",
    "    print(f\"  T.E.S.S.E.R.A.C.T. FINAL: {final} (conf={confidence:.2f})\")\n",
    "    print(f\"    Clusters: {len(debug.get('clusters', []))} | Dist: {Counter([c.value for c in all_candidates])}\")\n",
    "    \n",
    "    SOLVED_COUNT += 1\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # AIMO3: mod 1000\n",
    "    return int(final) % 1000\n",
    "\n",
    "\n",
    "print(\"PROMETHEUS v2.0 Solver loaded with T.E.S.S.E.R.A.C.T. selection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 12: KAGGLE API INTERFACE\n",
    "# =============================================================================\n",
    "\n",
    "TOTAL_PROBLEMS = 50\n",
    "\n",
    "\n",
    "def predict(id_: pl.DataFrame, question: pl.DataFrame, answer: Optional[pl.DataFrame] = None) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    AIMO3 Gateway API.\n",
    "    \"\"\"\n",
    "    id_val = id_.item(0)\n",
    "    question_str = question.item(0)\n",
    "    \n",
    "    time_left = (CUTOFF_TIME - time.time()) / 60\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ID: {id_val} | Time: {time_left:.1f}m | Solved: {SOLVED_COUNT}/{PROBLEM_COUNT}\")\n",
    "    print(f\"Q: {question_str[:60]}...\")\n",
    "    \n",
    "    prediction = solve_problem(question_str)\n",
    "    \n",
    "    # AIMO3 Rule: 0-999\n",
    "    prediction = max(0, min(999, int(prediction)))\n",
    "    \n",
    "    print(f\"ANSWER: {prediction}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return pl.DataFrame({'id': id_val, 'answer': prediction})\n",
    "\n",
    "\n",
    "print(\"API interface ready.\")\n",
    "print(f\"Budget: {TOTAL_BUDGET//60}min for {TOTAL_PROBLEMS} problems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 13: RUN COMPETITION\n",
    "# =============================================================================\n",
    "import kaggle_evaluation.aimo_3_inference_server\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PROMETHEUS v2.0 + vLLM + T.E.S.S.E.R.A.C.T.\")\n",
    "print(\"Synthesized from PROMETHEUS SYNTHESIS ENCYCLOPEDIA\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model: {MODEL_PATH}\")\n",
    "print(f\"vLLM: {'Loaded' if LLM_MODEL else 'Not available'}\")\n",
    "print(f\"Budget: {TOTAL_BUDGET//60} minutes\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "inference_server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    print(\"Competition mode\")\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    print(\"Local test\")\n",
    "    inference_server.run_local_gateway(('/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv',))\n",
    "\n",
    "print(f\"\\nCompleted in {(time.time() - START_TIME)/60:.1f} minutes\")\n",
    "print(f\"Solved: {SOLVED_COUNT}/{PROBLEM_COUNT}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
