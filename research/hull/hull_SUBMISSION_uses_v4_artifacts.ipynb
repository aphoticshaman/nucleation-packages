{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Hull Tactical - Submission v4\n",
    "\n",
    "**Uses artifacts_v4** with:\n",
    "- More aggressive position sizing (scale_factor 120, bounds [0.0, 2.0])\n",
    "- Lower risk aversion (35 vs 50)\n",
    "- PROMETHEUS features trained into models\n",
    "- Deeper trees, more iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths - try v4 artifacts first\n",
    "if os.path.exists('/kaggle/input/hull-tactical-market-prediction'):\n",
    "    DATA_DIR = Path('/kaggle/input/hull-tactical-market-prediction')\n",
    "    # Try multiple artifact locations\n",
    "    for artifact_name in ['hull-artifacts-v4', 'hull-artifacts', 'hull-submission-artifacts']:\n",
    "        test_path = Path(f'/kaggle/input/{artifact_name}')\n",
    "        if test_path.exists():\n",
    "            ARTIFACTS_DIR = test_path\n",
    "            break\n",
    "    else:\n",
    "        ARTIFACTS_DIR = Path('/kaggle/working')\n",
    "else:\n",
    "    DATA_DIR = Path('/home/user/aimo3/hull/hull-tactical-market-prediction')\n",
    "    ARTIFACTS_DIR = Path('/home/user/aimo3/hull/artifacts_v4')\n",
    "\n",
    "print(f\"Data: {DATA_DIR}\")\n",
    "print(f\"Artifacts: {ARTIFACTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global inference state\n",
    "class InferenceState:\n",
    "    scaler = None\n",
    "    feature_cols = None\n",
    "    lgb_models = None\n",
    "    xgb_models = None\n",
    "    config = None\n",
    "    recent_data = None\n",
    "    history = []\n",
    "    initialized = False\n",
    "\n",
    "\n",
    "def initialize():\n",
    "    if InferenceState.initialized:\n",
    "        return\n",
    "    \n",
    "    print(\"Loading V4 artifacts...\")\n",
    "    \n",
    "    with open(ARTIFACTS_DIR / 'scaler.pkl', 'rb') as f:\n",
    "        InferenceState.scaler = pickle.load(f)\n",
    "    \n",
    "    with open(ARTIFACTS_DIR / 'feature_cols.pkl', 'rb') as f:\n",
    "        InferenceState.feature_cols = pickle.load(f)\n",
    "    \n",
    "    with open(ARTIFACTS_DIR / 'lgb_models.pkl', 'rb') as f:\n",
    "        InferenceState.lgb_models = pickle.load(f)\n",
    "    \n",
    "    InferenceState.xgb_models = []\n",
    "    i = 0\n",
    "    while (ARTIFACTS_DIR / f'xgb_model_{i}.json').exists():\n",
    "        model = xgb.Booster()\n",
    "        model.load_model(str(ARTIFACTS_DIR / f'xgb_model_{i}.json'))\n",
    "        InferenceState.xgb_models.append(model)\n",
    "        i += 1\n",
    "    \n",
    "    with open(ARTIFACTS_DIR / 'config.pkl', 'rb') as f:\n",
    "        InferenceState.config = pickle.load(f)\n",
    "    \n",
    "    InferenceState.recent_data = pd.read_parquet(ARTIFACTS_DIR / 'recent_data.parquet')\n",
    "    \n",
    "    InferenceState.initialized = True\n",
    "    print(f\"Loaded {len(InferenceState.lgb_models)} LGB + {len(InferenceState.xgb_models)} XGB\")\n",
    "    print(f\"Config: {InferenceState.config}\")\n",
    "    print(f\"Features: {len(InferenceState.feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PROMETHEUS FEATURE ENGINEERING (same as training)\n",
    "# ============================================================================\n",
    "\n",
    "def add_prometheus_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add PROMETHEUS features - must match training.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # === BASIC ROLLING FEATURES ===\n",
    "    key_cols = ['V1', 'V2', 'V3', 'M1', 'M2', 'S1', 'S2', 'E1', 'P1', 'I1']\n",
    "    key_cols = [c for c in key_cols if c in df.columns]\n",
    "    \n",
    "    for col in key_cols:\n",
    "        for window in [5, 21, 63]:\n",
    "            if len(df) >= window:\n",
    "                df[f'{col}_ma{window}'] = df[col].rolling(window, min_periods=1).mean()\n",
    "                df[f'{col}_std{window}'] = df[col].rolling(window, min_periods=1).std().fillna(0)\n",
    "    \n",
    "    # === LAGGED RETURNS ===\n",
    "    if 'lagged_forward_returns' in df.columns:\n",
    "        df['lagged_ret'] = df['lagged_forward_returns']\n",
    "    elif 'forward_returns' in df.columns:\n",
    "        df['lagged_ret'] = df['forward_returns'].shift(1).fillna(0)\n",
    "    else:\n",
    "        df['lagged_ret'] = 0\n",
    "    \n",
    "    for w in [5, 10, 21, 63]:\n",
    "        if len(df) >= w:\n",
    "            df[f'ret_cumsum_{w}'] = df['lagged_ret'].rolling(w, min_periods=1).sum()\n",
    "            df[f'ret_vol_{w}'] = df['lagged_ret'].rolling(w, min_periods=1).std().fillna(0)\n",
    "            df[f'sharpe_{w}'] = df[f'ret_cumsum_{w}'] / (df[f'ret_vol_{w}'] * np.sqrt(w) + 1e-8)\n",
    "    \n",
    "    # === TIER 1: PHASE TRANSITION ===\n",
    "    if len(df) >= 63:\n",
    "        df['var_21'] = df['lagged_ret'].rolling(21, min_periods=5).var().fillna(0)\n",
    "        df['var_63'] = df['lagged_ret'].rolling(63, min_periods=10).var().fillna(0)\n",
    "        df['var_ratio'] = df['var_21'] / (df['var_63'] + 1e-8)\n",
    "        df['var_compression'] = (df['var_ratio'] < 0.5).astype(float)\n",
    "    else:\n",
    "        df['var_21'] = df['var_63'] = df['var_ratio'] = 0\n",
    "        df['var_compression'] = 0\n",
    "    \n",
    "    # Critical slowing down\n",
    "    if len(df) >= 63:\n",
    "        def calc_ac1(x):\n",
    "            if len(x) < 10:\n",
    "                return 0\n",
    "            try:\n",
    "                return np.corrcoef(x[:-1], x[1:])[0, 1]\n",
    "            except:\n",
    "                return 0\n",
    "        df['ac1'] = df['lagged_ret'].rolling(63, min_periods=10).apply(calc_ac1, raw=True).fillna(0)\n",
    "        df['ac1_ma21'] = df['ac1'].rolling(21, min_periods=1).mean()\n",
    "        df['ac1_rising'] = (df['ac1'] > df['ac1_ma21']).astype(float)\n",
    "    else:\n",
    "        df['ac1'] = df['ac1_ma21'] = df['ac1_rising'] = 0\n",
    "    \n",
    "    # === TIER 2: TEMPERATURE & COHERENCE ===\n",
    "    v_cols = [c for c in df.columns if c.startswith('V') and c[1:].isdigit()]\n",
    "    m_cols = [c for c in df.columns if c.startswith('M') and c[1:].isdigit()]\n",
    "    s_cols = [c for c in df.columns if c.startswith('S') and c[1:].isdigit()]\n",
    "    e_cols = [c for c in df.columns if c.startswith('E') and c[1:].isdigit()]\n",
    "    i_cols = [c for c in df.columns if c.startswith('I') and c[1:].isdigit()]\n",
    "    \n",
    "    if v_cols:\n",
    "        df['v_mean'] = df[v_cols].mean(axis=1)\n",
    "        df['v_std'] = df[v_cols].std(axis=1)\n",
    "        df['temperature'] = df['v_std'] / (df['v_mean'].abs() + 1e-8)\n",
    "    else:\n",
    "        df['v_mean'] = df['v_std'] = df['temperature'] = 0\n",
    "    \n",
    "    for prefix, cols in [('V', v_cols), ('M', m_cols), ('S', s_cols)]:\n",
    "        if len(cols) >= 2:\n",
    "            zscores = (df[cols] - df[cols].mean()) / (df[cols].std() + 1e-8)\n",
    "            df[f'{prefix}_order'] = 1 - zscores.var(axis=1).fillna(1)\n",
    "        else:\n",
    "            df[f'{prefix}_order'] = 0\n",
    "    \n",
    "    if v_cols:\n",
    "        df['vol_regime'] = df[v_cols].mean(axis=1)\n",
    "        df['vol_regime_ma21'] = df['vol_regime'].rolling(21, min_periods=1).mean()\n",
    "        df['vol_expanding'] = (df['vol_regime'] > df['vol_regime_ma21']).astype(float)\n",
    "    else:\n",
    "        df['vol_regime'] = df['vol_regime_ma21'] = df['vol_expanding'] = 0\n",
    "    \n",
    "    # === TIER 3: INTERACTIONS ===\n",
    "    if s_cols:\n",
    "        df['sent_mean'] = df[s_cols].mean(axis=1)\n",
    "        df['sent_vol_interact'] = df['sent_mean'] / (df['vol_regime'] + 1e-8)\n",
    "    else:\n",
    "        df['sent_mean'] = df['sent_vol_interact'] = 0\n",
    "    \n",
    "    if 'ret_cumsum_21' in df.columns:\n",
    "        df['cum_ret_std'] = df['ret_cumsum_21'].rolling(63, min_periods=1).std().fillna(0)\n",
    "        df['momentum_strong'] = (df['ret_cumsum_21'].abs() > df['cum_ret_std']).astype(float)\n",
    "    else:\n",
    "        df['cum_ret_std'] = df['momentum_strong'] = 0\n",
    "    \n",
    "    if e_cols:\n",
    "        df['econ_mean'] = df[e_cols].mean(axis=1)\n",
    "        df['econ_momentum'] = df['econ_mean'].diff(5).fillna(0)\n",
    "        df['econ_surprise'] = df['econ_momentum'] - df['econ_momentum'].rolling(63, min_periods=1).mean()\n",
    "    else:\n",
    "        df['econ_mean'] = df['econ_momentum'] = df['econ_surprise'] = 0\n",
    "    \n",
    "    if len(i_cols) >= 3 and 'I3' in df.columns and 'I1' in df.columns:\n",
    "        df['rate_slope'] = df['I3'] - df['I1']\n",
    "        df['rate_slope_pct'] = df['rate_slope'].rolling(63, min_periods=1).rank(pct=True).fillna(0.5)\n",
    "        df['rate_inverting'] = (df['rate_slope_pct'] < 0.1).astype(float)\n",
    "    else:\n",
    "        df['rate_slope'] = 0\n",
    "        df['rate_slope_pct'] = 0.5\n",
    "        df['rate_inverting'] = 0\n",
    "    \n",
    "    # === TIER 4: CROSS-DOMAIN ===\n",
    "    if v_cols and m_cols and s_cols and len(df) >= 21:\n",
    "        vm = df[v_cols].mean(axis=1)\n",
    "        mm = df[m_cols].mean(axis=1)\n",
    "        sm = df[s_cols].mean(axis=1)\n",
    "        \n",
    "        corr_vm = vm.rolling(21, min_periods=5).corr(mm).fillna(0)\n",
    "        corr_vs = vm.rolling(21, min_periods=5).corr(sm).fillna(0)\n",
    "        corr_ms = mm.rolling(21, min_periods=5).corr(sm).fillna(0)\n",
    "        \n",
    "        avg_corr = (abs(corr_vm) + abs(corr_vs) + abs(corr_ms)) / 3\n",
    "        df['cross_domain_corr'] = avg_corr\n",
    "        df['correlation_surge'] = (avg_corr > 0.7).astype(float)\n",
    "    else:\n",
    "        df['cross_domain_corr'] = 0\n",
    "        df['correlation_surge'] = 0\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame) -> float:\n",
    "    \"\"\"V4 prediction with trained PROMETHEUS features.\"\"\"\n",
    "    if not InferenceState.initialized:\n",
    "        initialize()\n",
    "    \n",
    "    test_pd = test.to_pandas()\n",
    "    \n",
    "    # Update history\n",
    "    InferenceState.history.append(test_pd)\n",
    "    if len(InferenceState.history) > 300:\n",
    "        InferenceState.history = InferenceState.history[-300:]\n",
    "    \n",
    "    # Combine with historical data\n",
    "    if len(InferenceState.history) < 63:\n",
    "        n_needed = 300 - len(InferenceState.history)\n",
    "        combined = pd.concat(\n",
    "            [InferenceState.recent_data.tail(n_needed)] + InferenceState.history,\n",
    "            ignore_index=True\n",
    "        )\n",
    "    else:\n",
    "        combined = pd.concat(InferenceState.history, ignore_index=True)\n",
    "    \n",
    "    # Add PROMETHEUS features\n",
    "    combined = add_prometheus_features(combined)\n",
    "    \n",
    "    # Ensure all feature columns exist\n",
    "    for col in InferenceState.feature_cols:\n",
    "        if col not in combined.columns:\n",
    "            combined[col] = 0\n",
    "    \n",
    "    # Get features and scale\n",
    "    X = combined[InferenceState.feature_cols].iloc[[-1]].fillna(0)\n",
    "    X_scaled = pd.DataFrame(\n",
    "        InferenceState.scaler.transform(X),\n",
    "        columns=InferenceState.feature_cols\n",
    "    )\n",
    "    \n",
    "    # Ensemble predictions\n",
    "    predictions = []\n",
    "    \n",
    "    for model in InferenceState.lgb_models:\n",
    "        pred = model.predict(X_scaled)[0]\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    dtest = xgb.DMatrix(X_scaled)\n",
    "    for model in InferenceState.xgb_models:\n",
    "        pred = model.predict(dtest)[0]\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    mean_pred = predictions.mean()\n",
    "    std_pred = predictions.std()\n",
    "    \n",
    "    # Position sizing with V4 config (more aggressive)\n",
    "    cfg = InferenceState.config\n",
    "    uncertainty = max(std_pred, 1e-5)\n",
    "    kelly = mean_pred / (cfg['risk_aversion'] * uncertainty**2 + 1e-8)\n",
    "    position = cfg['base_position'] + cfg['scale_factor'] * kelly\n",
    "    position = np.clip(position, cfg['min_position'], cfg['max_position'])\n",
    "    \n",
    "    return float(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference server setup\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    import kaggle_evaluation.default_inference_server\n",
    "    inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "    print(\"V4 inference server ready.\")\n",
    "else:\n",
    "    print(\"Skipping inference server setup (not in competition rerun)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # Local validation\n",
    "    print(\"Local validation mode...\")\n",
    "    initialize()\n",
    "    print(f\"\\nV4 Config:\")\n",
    "    for k, v in InferenceState.config.items():\n",
    "        print(f\"  {k}: {v}\")\n",
    "    print(f\"\\nFeatures: {len(InferenceState.feature_cols)}\")\n",
    "    print(\"\\nV4 validation passed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
