{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8174f970",
   "metadata": {
    "papermill": {
     "duration": 0.003724,
     "end_time": "2025-12-08T02:09:02.215783",
     "exception": false,
     "start_time": "2025-12-08T02:09:02.212059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GRAND SYNTHESIS + PROMETHEUS - The $1.59M Weapon\n",
    "\n",
    "**RYANAIMO Competition System for AIMO3**\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture\n",
    "\n",
    "| Layer | Component | Function |\n",
    "|-------|-----------|----------|\n",
    "| **Model** | Qwen-72B-Math-NF4 | 85GB H100 filled to the brim |\n",
    "| **Selection** | PROMETHEUS Operator ğ”“ | 3-step Î©-style seed refinement |\n",
    "| **Ensemble** | GRAND SYNTHESIS | CIC + UIPT + NCD + LatticeForge |\n",
    "\n",
    "## PROMETHEUS Operator ğ”“\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Î©-STYLE RECURSIVE REFINEMENT                               â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                             â”‚\n",
    "â”‚  samples â†’ GRAND SYNTHESIS â†’ best_answer                    â”‚\n",
    "â”‚                    â†“                                        â”‚\n",
    "â”‚  [samples + k Ã— anchor] â†’ GRAND SYNTHESIS â†’ refined_answer  â”‚\n",
    "â”‚                    â†“                                        â”‚\n",
    "â”‚  [samples + k Ã— anchor] â†’ GRAND SYNTHESIS â†’ final_answer    â”‚\n",
    "â”‚                    â†“                                        â”‚\n",
    "â”‚              FIXED POINT CONVERGENCE                        â”‚\n",
    "â”‚                                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "Each iteration **plants the seed** - reinforcing the current best answer as additional votes, driving toward the attractor basin center (the Platonic Form).\n",
    "\n",
    "## GRAND SYNTHESIS Components\n",
    "\n",
    "| Component | Formula/Method |\n",
    "|-----------|----------------|\n",
    "| **UIPT Entropy** | Phase transition: dÎ¦/dt = Î»Â·dH/dt |\n",
    "| **Micro-Grokking** | dÂ²H/dtÂ² < threshold = model clicked |\n",
    "| **Extended NCD** | Prime residue fingerprint compression |\n",
    "| **LatticeForge** | T (temperature), Î¨ (order), Î½ (critical) |\n",
    "| **CIC Functional** | F[T] = Î¦ - Î»H + Î³C |\n",
    "| **Toroidal Voting** | SÂ¹ circular mean for mod-N |\n",
    "| **Entropic Gravity** | Mass Ã— Density^0.15 Ã— Solomonoff |\n",
    "| **Value Clustering** | 88% error reduction via proximity |\n",
    "\n",
    "## Key Insight\n",
    "\n",
    "> *\"The basin center is the Platonic Form - the pattern that all attempts approximate. We navigate to FORMS, not instances.\"*\n",
    "\n",
    "**Author**: Ryan J Cardwell (Archer Phoenix)  \n",
    "**Target**: AIMO3 Overall Progress Prize ($1.59M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd641391",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-12-08T02:09:02.218775",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 1: ENVIRONMENT + vLLM LOADING (H100 CORRECTED)\n",
    "# =============================================================================\n",
    "# PROMETHEUS PROTOCOL: H100 vLLM FIX\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# [CRITICAL] 1. PURGE TENSORFLOW (The Saboteur)\n",
    "print(f\"{'='*70}\\nSANITIZING ENVIRONMENT: PURGING TENSORFLOW\\n{'='*70}\")\n",
    "try:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"tensorflow\", \"tensorflow-io\", \"tensorflow-estimator\", \"keras\", \"tensorboard\"], check=False)\n",
    "    print(\"âœ“ TensorFlow purge complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"âš  Warning during purge: {e}\")\n",
    "\n",
    "# [CRITICAL] 2. FORCE PYTHON PROTOBUF\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "\n",
    "# =============================================================================\n",
    "# INSTALL vLLM (THE CORRECT WAY)\n",
    "# =============================================================================\n",
    "print(\"\\nINSTALLING vLLM & DEPENDENCIES...\")\n",
    "\n",
    "# We use --no-index --find-links to let pip resolve dependencies (like msgspec) \n",
    "# from the local directory automatically.\n",
    "WHEEL_DIR = \"/kaggle/input/vllm-085-wheels\"\n",
    "AUX_DIR = \"/kaggle/input/aimo3-offline-wheels\"\n",
    "\n",
    "if os.path.exists(WHEEL_DIR):\n",
    "    # 1. Install bitsandbytes first (often needed for NF4 loading)\n",
    "    print(\"  Installing bitsandbytes...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"bitsandbytes\", \n",
    "                    \"--no-index\", f\"--find-links={AUX_DIR}\", \n",
    "                    f\"--find-links={WHEEL_DIR}\"], check=False)\n",
    "\n",
    "    # 2. Install vLLM with auto-dependency resolution from local folder\n",
    "    print(f\"  Installing vLLM from {WHEEL_DIR}...\")\n",
    "    result = subprocess.run([\n",
    "        sys.executable, \"-m\", \"pip\", \"install\", \"vllm\", \n",
    "        \"--no-index\", \n",
    "        f\"--find-links={WHEEL_DIR}\",\n",
    "        f\"--find-links={AUX_DIR}\"\n",
    "    ], capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ“ vLLM installed successfully.\")\n",
    "    else:\n",
    "        print(\"âœ— vLLM install failed. Logs:\")\n",
    "        print(result.stderr[-500:]) # Print last 500 chars of error\n",
    "else:\n",
    "    print(f\"âš  CRITICAL: Wheel directory {WHEEL_DIR} not found!\")\n",
    "\n",
    "# =============================================================================\n",
    "# vLLM MODEL CLASS\n",
    "# =============================================================================\n",
    "try:\n",
    "    from vllm import LLM, SamplingParams\n",
    "    VLLM_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"\\nâš  vLLM IMPORT FAILED: {e}\")\n",
    "    VLLM_AVAILABLE = False\n",
    "\n",
    "class PrometheusVLLM:\n",
    "    \"\"\"The Ferrari Engine: vLLM on H100.\"\"\"\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "        self.llm = None\n",
    "        \n",
    "    def load(self):\n",
    "        if not VLLM_AVAILABLE:\n",
    "            print(\"Cannot load: vLLM library not available.\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"\\nINITIALIZING vLLM ENGINE on {torch.cuda.get_device_name(0)}...\")\n",
    "        try:\n",
    "            # H100 Config: Utilizes ~90% of VRAM for KV Cache\n",
    "            # Qwen-72B-NF4 support in vLLM is newer, requires quantization='bnb' or auto\n",
    "            # If this is a pure NF4 model, vLLM 0.8.5 should handle it.\n",
    "            self.llm = LLM(\n",
    "                model=self.model_path,\n",
    "                tensor_parallel_size=1, # Single H100\n",
    "                dtype=\"float16\",        # FP16 safety\n",
    "                gpu_memory_utilization=0.90,\n",
    "                trust_remote_code=True,\n",
    "                max_model_len=4096,     # Limit context to prevent OOM\n",
    "                enforce_eager=True      # Stability\n",
    "            )\n",
    "            print(\"âœ“ vLLM LOADED. READY FOR WARP SPEED.\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"CRITICAL vLLM LOAD ERROR: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return False\n",
    "\n",
    "    def generate_batch(self, prompts, n=4, temperature=0.7):\n",
    "        params = SamplingParams(\n",
    "            n=n, \n",
    "            temperature=temperature, \n",
    "            max_tokens=2048,\n",
    "            top_p=0.95\n",
    "        )\n",
    "        outputs = self.llm.generate(prompts, params)\n",
    "        return [output.outputs for output in outputs]\n",
    "\n",
    "# =============================================================================\n",
    "# PATH FINDER\n",
    "# =============================================================================\n",
    "def find_model():\n",
    "    # Priority: Qwen-72B\n",
    "    paths = [\n",
    "        \"/kaggle/input/d/ryancardwell/qwen-72b-math-nf4\",\n",
    "        \"/kaggle/input/qwen-72b-math-nf4\",\n",
    "    ]\n",
    "    for p in paths:\n",
    "        if os.path.exists(p): return p\n",
    "    return None\n",
    "\n",
    "MODEL_PATH = find_model()\n",
    "print(f\"\\nTarget Model: {MODEL_PATH}\")\n",
    "\n",
    "# EAGER LOAD\n",
    "MODEL = None\n",
    "if VLLM_AVAILABLE and MODEL_PATH:\n",
    "    MODEL = PrometheusVLLM(MODEL_PATH)\n",
    "    MODEL.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9876649",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: GRAND SYNTHESIS + PROMETHEUS OPERATOR ğ”“\n",
    "# =============================================================================\n",
    "# THE COMPLETE RYANAIMO WEAPON SYSTEM\n",
    "# Integrates: CIC Theory, UIPT Entropy, Extended NCD, LatticeForge Phase Detection,\n",
    "#             Micro-Grokking, Toroidal Voting, Entropic Gravity, Value Clustering\n",
    "#             + PROMETHEUS Operator ğ”“ (Î©-style 3-step recursive refinement)\n",
    "# =============================================================================\n",
    "\n",
    "import math\n",
    "import struct\n",
    "import lzma\n",
    "import statistics\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, List, Tuple, Dict, Any, Deque, Callable\n",
    "from collections import Counter, deque\n",
    "from enum import Enum\n",
    "\n",
    "# Constants\n",
    "ANSWER_MIN = 0\n",
    "ANSWER_MAX = 999999\n",
    "FALLBACK_ANSWER = 0\n",
    "TOTAL_BUDGET_SECONDS = 5 * 60 * 60  # 5 hours\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 1: UIPT (Universal Information Phase Transition)\n",
    "# =============================================================================\n",
    "\n",
    "class Phase(Enum):\n",
    "    CRYSTALLINE = \"CRYSTALLINE\"  # Stable, high confidence\n",
    "    SUPERCOOLED = \"SUPERCOOLED\"  # Appears stable, susceptible\n",
    "    NUCLEATING = \"NUCLEATING\"    # Phase transition in progress\n",
    "    ANNEALING = \"ANNEALING\"      # Post-transition settling\n",
    "    PLASMA = \"PLASMA\"            # Chaotic, low confidence\n",
    "\n",
    "\n",
    "class UIPTEntropyTracker:\n",
    "    \"\"\"\n",
    "    Rolling entropy tracker for phase transition detection.\n",
    "    Low entropy = CRYSTALLINE (grokked)\n",
    "    High entropy = PLASMA (hallucinating)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, window: int = 32):\n",
    "        self.window = window\n",
    "        self.buffer: Deque[int] = deque(maxlen=window)\n",
    "        self.counts: Counter = Counter()\n",
    "        self.entropy_history: List[float] = []\n",
    "        self.logprob_history: List[float] = []\n",
    "    \n",
    "    def add_token(self, token_id: int, logprob: float = 0.0) -> None:\n",
    "        if len(self.buffer) == self.window:\n",
    "            old = self.buffer.popleft()\n",
    "            self.counts[old] -= 1\n",
    "            if self.counts[old] <= 0:\n",
    "                del self.counts[old]\n",
    "        \n",
    "        self.buffer.append(token_id)\n",
    "        self.counts[token_id] += 1\n",
    "        self.entropy_history.append(self.current_entropy())\n",
    "        self.logprob_history.append(logprob)\n",
    "    \n",
    "    def current_entropy(self) -> float:\n",
    "        total = sum(self.counts.values())\n",
    "        if total <= 0:\n",
    "            return 0.0\n",
    "        probs = [c / total for c in self.counts.values() if c > 0]\n",
    "        H = -sum(p * math.log2(p) for p in probs)\n",
    "        max_H = math.log2(len(self.counts)) if len(self.counts) > 1 else 1.0\n",
    "        return H / max_H if max_H > 0 else 0.0\n",
    "    \n",
    "    def get_phase(self) -> Phase:\n",
    "        h = self.current_entropy()\n",
    "        if h < 0.3:\n",
    "            return Phase.CRYSTALLINE\n",
    "        elif h < 0.5:\n",
    "            return Phase.SUPERCOOLED\n",
    "        elif h < 0.7:\n",
    "            return Phase.NUCLEATING\n",
    "        elif h < 0.85:\n",
    "            return Phase.ANNEALING\n",
    "        else:\n",
    "            return Phase.PLASMA\n",
    "    \n",
    "    def reset(self):\n",
    "        self.buffer.clear()\n",
    "        self.counts.clear()\n",
    "        self.entropy_history.clear()\n",
    "        self.logprob_history.clear()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 2: MICRO-GROKKING DETECTION\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class GrokkingSignal:\n",
    "    detected: bool\n",
    "    score: float\n",
    "    d2_min: float\n",
    "    final_entropy: float\n",
    "    convergence_idx: int\n",
    "\n",
    "\n",
    "def detect_grokking(entropies: List[float], window: int = 5, threshold: float = -0.05) -> GrokkingSignal:\n",
    "    \"\"\"Detect micro-grokking via entropy second derivative.\"\"\"\n",
    "    if len(entropies) < window * 3:\n",
    "        return GrokkingSignal(False, 0.0, 0.0, entropies[-1] if entropies else 1.0, -1)\n",
    "    \n",
    "    smooth = []\n",
    "    for i in range(len(entropies) - window + 1):\n",
    "        smooth.append(sum(entropies[i:i+window]) / window)\n",
    "    \n",
    "    if len(smooth) < 3:\n",
    "        return GrokkingSignal(False, 0.0, 0.0, entropies[-1], -1)\n",
    "    \n",
    "    d1 = [smooth[i+1] - smooth[i] for i in range(len(smooth)-1)]\n",
    "    d2 = [d1[i+1] - d1[i] for i in range(len(d1)-1)] if len(d1) > 1 else [0.0]\n",
    "    \n",
    "    min_d2 = min(d2) if d2 else 0.0\n",
    "    min_idx = d2.index(min_d2) if d2 and min_d2 in d2 else -1\n",
    "    \n",
    "    final_H = sum(entropies[-window:]) / window\n",
    "    stability = 1.0 / (1.0 + final_H)\n",
    "    score = stability + max(0, -min_d2 * 10)\n",
    "    \n",
    "    return GrokkingSignal(\n",
    "        detected=min_d2 < threshold,\n",
    "        score=score,\n",
    "        d2_min=min_d2,\n",
    "        final_entropy=final_H,\n",
    "        convergence_idx=min_idx + window if min_idx >= 0 else -1\n",
    "    )\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 3: EXTENDED NCD (Prime Residue Fingerprint)\n",
    "# =============================================================================\n",
    "\n",
    "def int_to_extended_bytes(n: int) -> bytes:\n",
    "    parts = []\n",
    "    try:\n",
    "        parts.append(struct.pack('>q', n))\n",
    "    except:\n",
    "        parts.append(str(n).encode()[:8].ljust(8, b'\\x00'))\n",
    "    \n",
    "    digits = str(abs(n))\n",
    "    parts.append((digits * 3).encode())\n",
    "    parts.append(bin(abs(n))[2:].encode())\n",
    "    \n",
    "    primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n",
    "    residues = ''.join(str(abs(n) % p) for p in primes)\n",
    "    parts.append((residues * 2).encode())\n",
    "    \n",
    "    hist = [0] * 10\n",
    "    for d in digits:\n",
    "        if d.isdigit():\n",
    "            hist[int(d)] += 1\n",
    "    parts.append(bytes(hist))\n",
    "    \n",
    "    return b''.join(parts)\n",
    "\n",
    "\n",
    "def ncd(x: bytes, y: bytes) -> float:\n",
    "    if not x or not y:\n",
    "        return 1.0\n",
    "    cx = len(lzma.compress(x))\n",
    "    cy = len(lzma.compress(y))\n",
    "    cxy = len(lzma.compress(x + y))\n",
    "    return (cxy - min(cx, cy)) / max(cx, cy) if max(cx, cy) > 0 else 0.0\n",
    "\n",
    "\n",
    "def ncd_extended(a: int, b: int) -> float:\n",
    "    return ncd(int_to_extended_bytes(a), int_to_extended_bytes(b))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 4: LATTICEFORGE PHASE ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class LatticeState:\n",
    "    temperature: float\n",
    "    order: float\n",
    "    critical: float\n",
    "    phase: Phase\n",
    "    nucleations: int\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "def relative_distance(a: int, b: int) -> float:\n",
    "    if a == b:\n",
    "        return 0.0\n",
    "    if a == 0 or b == 0:\n",
    "        return 1.0 if max(abs(a), abs(b)) > 1000 else abs(a - b) / 1000\n",
    "    return abs(a - b) / max(abs(a), abs(b))\n",
    "\n",
    "\n",
    "def compute_lattice_state(samples: List[int]) -> LatticeState:\n",
    "    if len(samples) < 2:\n",
    "        return LatticeState(0.0, 1.0, 1.0, Phase.CRYSTALLINE, 0, 0.5)\n",
    "    \n",
    "    n = len(samples)\n",
    "    mean_val = statistics.mean(samples)\n",
    "    if mean_val == 0:\n",
    "        mean_val = 1\n",
    "    normalized = [s / abs(mean_val) for s in samples]\n",
    "    variance = statistics.variance(normalized)\n",
    "    \n",
    "    counter = Counter(samples)\n",
    "    max_agree = counter.most_common(1)[0][1] / n\n",
    "    T = min(1.0, variance * (1 + (1 - max_agree)))\n",
    "    \n",
    "    close_pairs = sum(\n",
    "        1 for i in range(n) for j in range(i+1, n)\n",
    "        if relative_distance(samples[i], samples[j]) < 0.05\n",
    "    )\n",
    "    total_pairs = n * (n - 1) // 2 if n > 1 else 1\n",
    "    cluster_bonus = close_pairs / total_pairs * 0.3\n",
    "    psi = min(1.0, max_agree + cluster_bonus)\n",
    "    \n",
    "    T_c = 0.5\n",
    "    nu = math.sqrt((T - T_c)**2 + (psi - 0.5)**2) / math.sqrt(2)\n",
    "    \n",
    "    visited = [False] * n\n",
    "    nucleations = 0\n",
    "    for i in range(n):\n",
    "        if visited[i]:\n",
    "            continue\n",
    "        cluster = [i]\n",
    "        for j in range(i+1, n):\n",
    "            if not visited[j] and relative_distance(samples[i], samples[j]) < 0.05:\n",
    "                cluster.append(j)\n",
    "                visited[j] = True\n",
    "        if len(cluster) >= 3:\n",
    "            nucleations += 1\n",
    "        visited[i] = True\n",
    "    \n",
    "    if nu < 0.1 and nucleations > 2:\n",
    "        phase = Phase.NUCLEATING\n",
    "    elif T > 0.8 and psi < 0.3:\n",
    "        phase = Phase.PLASMA\n",
    "    elif T < 0.3 and psi > 0.7:\n",
    "        phase = Phase.CRYSTALLINE\n",
    "    elif T < 0.5 and psi > 0.5:\n",
    "        phase = Phase.SUPERCOOLED\n",
    "    else:\n",
    "        phase = Phase.ANNEALING\n",
    "    \n",
    "    confidence = min(0.95, max(0.05, psi * (1 - T) * (1 - nu)))\n",
    "    \n",
    "    return LatticeState(T, psi, nu, phase, nucleations, confidence)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 5: CIC FUNCTIONAL\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class CICState:\n",
    "    phi: float\n",
    "    entropy: float\n",
    "    causal: float\n",
    "    F: float\n",
    "    confidence: float\n",
    "\n",
    "\n",
    "def compute_cic(samples: List[int], lam: float = 0.5, gamma: float = 0.3) -> CICState:\n",
    "    if len(samples) < 2:\n",
    "        return CICState(0.0, 0.0, 0.0, 0.0, 0.5)\n",
    "    \n",
    "    n = len(samples)\n",
    "    \n",
    "    ncds = [\n",
    "        ncd_extended(samples[i], samples[j])\n",
    "        for i in range(n) for j in range(i+1, n)\n",
    "    ]\n",
    "    phi = 1.0 - statistics.mean(ncds) if ncds else 0.0\n",
    "    \n",
    "    mean_val = statistics.mean(samples) if samples else 1\n",
    "    if mean_val == 0:\n",
    "        mean_val = 1\n",
    "    normalized = [s / abs(mean_val) for s in samples]\n",
    "    H = min(1.0, statistics.variance(normalized))\n",
    "    \n",
    "    counter = Counter(samples)\n",
    "    exact_power = counter.most_common(1)[0][1] / n\n",
    "    \n",
    "    close_pairs = sum(\n",
    "        1 for i in range(n) for j in range(i+1, n)\n",
    "        if relative_distance(samples[i], samples[j]) < 0.05\n",
    "    )\n",
    "    total_pairs = n * (n - 1) // 2 if n > 1 else 1\n",
    "    cluster_power = close_pairs / total_pairs\n",
    "    \n",
    "    spread = max(samples) - min(samples) if samples else 0\n",
    "    center = abs(statistics.mean(samples)) if samples else 1\n",
    "    range_power = 1.0 / (1.0 + spread / center) if center > 0 else 0\n",
    "    \n",
    "    C = 0.5 * exact_power + 0.3 * cluster_power + 0.2 * range_power\n",
    "    F = phi - lam * H + gamma * C\n",
    "    confidence = max(0.05, min(0.95, 0.5 + 0.5 * F))\n",
    "    \n",
    "    return CICState(phi, H, C, F, confidence)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 6: TOROIDAL VOTING\n",
    "# =============================================================================\n",
    "\n",
    "def toroidal_vote(samples: List[int], mod: int) -> Tuple[int, float]:\n",
    "    if not samples:\n",
    "        return 0, 0.1\n",
    "    \n",
    "    normalized = [s % mod for s in samples]\n",
    "    angles = [2 * math.pi * m / mod for m in normalized]\n",
    "    sin_sum = sum(math.sin(a) for a in angles)\n",
    "    cos_sum = sum(math.cos(a) for a in angles)\n",
    "    mean_angle = math.atan2(sin_sum, cos_sum)\n",
    "    center = int(round(mean_angle * mod / (2 * math.pi))) % mod\n",
    "    \n",
    "    R = math.sqrt(sin_sum**2 + cos_sum**2) / len(samples)\n",
    "    confidence = min(0.95, max(0.1, R))\n",
    "    \n",
    "    return center, confidence\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 7: ENTROPIC GRAVITY VOTING\n",
    "# =============================================================================\n",
    "\n",
    "def solomonoff_prior(n: int) -> float:\n",
    "    if n == 0:\n",
    "        return 1.0\n",
    "    \n",
    "    digit_len = len(str(abs(n)))\n",
    "    bonus = 1.0\n",
    "    \n",
    "    if n % 10 == 0:\n",
    "        bonus *= 1.2\n",
    "    if n % 100 == 0:\n",
    "        bonus *= 1.3\n",
    "    if n in [1, 2, 3, 4, 5, 10, 12, 15, 20, 24, 25, 30, 36, 42, 48, 50, 60, 72, 100, 120, 144]:\n",
    "        bonus *= 1.5\n",
    "    \n",
    "    return bonus / (1 + digit_len * 0.3)\n",
    "\n",
    "\n",
    "def entropic_gravity_vote(\n",
    "    samples: List[int],\n",
    "    grokking_scores: Optional[List[float]] = None\n",
    ") -> Tuple[int, float]:\n",
    "    if not samples:\n",
    "        return FALLBACK_ANSWER, 0.1\n",
    "    \n",
    "    counter = Counter(samples)\n",
    "    n = len(samples)\n",
    "    \n",
    "    scores = {}\n",
    "    for ans, count in counter.items():\n",
    "        mass = count / n\n",
    "        cluster = [s for s in samples if relative_distance(s, ans) < 0.05]\n",
    "        density = len(cluster) / n\n",
    "        prior = solomonoff_prior(ans)\n",
    "        \n",
    "        grok = 1.0\n",
    "        if grokking_scores:\n",
    "            idxs = [i for i, s in enumerate(samples) if s == ans]\n",
    "            if idxs:\n",
    "                avg = sum(grokking_scores[i] for i in idxs if i < len(grokking_scores)) / len(idxs)\n",
    "                grok = 1.0 + avg * 0.5\n",
    "        \n",
    "        scores[ans] = mass * (density ** 0.15) * prior * grok\n",
    "    \n",
    "    best = max(scores.keys(), key=lambda a: scores[a])\n",
    "    total = sum(scores.values())\n",
    "    conf = scores[best] / total if total > 0 else 0.1\n",
    "    \n",
    "    return best, min(0.95, max(0.05, conf))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 8: VALUE CLUSTERING (88% Error Reduction)\n",
    "# =============================================================================\n",
    "\n",
    "def value_clustering(samples: List[int], threshold: float = 0.05) -> Dict:\n",
    "    n = len(samples)\n",
    "    if n == 0:\n",
    "        return {\"clusters\": [], \"best\": None}\n",
    "    if n == 1:\n",
    "        return {\n",
    "            \"clusters\": [{\"members\": samples, \"center\": samples[0], \"size\": 1, \"score\": 1.0}],\n",
    "            \"best\": {\"members\": samples, \"center\": samples[0], \"size\": 1, \"score\": 1.0}\n",
    "        }\n",
    "    \n",
    "    parent = list(range(n))\n",
    "    def find(i):\n",
    "        if parent[i] != i:\n",
    "            parent[i] = find(parent[i])\n",
    "        return parent[i]\n",
    "    def union(i, j):\n",
    "        pi, pj = find(i), find(j)\n",
    "        if pi != pj:\n",
    "            parent[pi] = pj\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if relative_distance(samples[i], samples[j]) < threshold:\n",
    "                union(i, j)\n",
    "    \n",
    "    clusters_dict = {}\n",
    "    for i in range(n):\n",
    "        root = find(i)\n",
    "        if root not in clusters_dict:\n",
    "            clusters_dict[root] = []\n",
    "        clusters_dict[root].append(samples[i])\n",
    "    \n",
    "    clusters = []\n",
    "    for members in clusters_dict.values():\n",
    "        size = len(members)\n",
    "        center = int(statistics.median(members))\n",
    "        spread = statistics.stdev(members) if size > 1 else 0\n",
    "        center_abs = abs(statistics.mean(members)) if members else 1\n",
    "        tightness = max(0.0, min(1.0, 1.0 - (spread / center_abs if center_abs > 0 else 0)))\n",
    "        score = size * (tightness ** 0.5)\n",
    "        clusters.append({\"members\": members, \"center\": center, \"size\": size, \"tightness\": tightness, \"score\": score})\n",
    "    \n",
    "    clusters.sort(key=lambda c: -c[\"score\"])\n",
    "    return {\"clusters\": clusters, \"best\": clusters[0] if clusters else None}\n",
    "\n",
    "\n",
    "def extended_ncd_basin_detection(samples: List[int], threshold: float = 0.25) -> Dict:\n",
    "    \"\"\"Basin detection using extended NCD representation.\"\"\"\n",
    "    n = len(samples)\n",
    "    if n == 0:\n",
    "        return {\"found\": False, \"clusters\": []}\n",
    "    if n == 1:\n",
    "        return {\"found\": True, \"clusters\": [{\"members\": samples, \"center\": samples[0]}], \"best\": samples[0]}\n",
    "\n",
    "    ncd_matrix = [[0.0] * n for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            d = ncd_extended(samples[i], samples[j])\n",
    "            ncd_matrix[i][j] = d\n",
    "            ncd_matrix[j][i] = d\n",
    "\n",
    "    parent = list(range(n))\n",
    "    def find(i):\n",
    "        if parent[i] != i:\n",
    "            parent[i] = find(parent[i])\n",
    "        return parent[i]\n",
    "    def union(i, j):\n",
    "        pi, pj = find(i), find(j)\n",
    "        if pi != pj:\n",
    "            parent[pi] = pj\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if ncd_matrix[i][j] < threshold:\n",
    "                union(i, j)\n",
    "\n",
    "    clusters_dict = {}\n",
    "    for i in range(n):\n",
    "        root = find(i)\n",
    "        if root not in clusters_dict:\n",
    "            clusters_dict[root] = []\n",
    "        clusters_dict[root].append(samples[i])\n",
    "\n",
    "    clusters = []\n",
    "    for members in clusters_dict.values():\n",
    "        if len(members) > 1:\n",
    "            indices = [samples.index(m) for m in members]\n",
    "            internal_ncds = [ncd_matrix[i][j] for i in indices for j in indices if i < j]\n",
    "            cohesion = 1.0 - statistics.mean(internal_ncds) if internal_ncds else 0.5\n",
    "        else:\n",
    "            cohesion = 0.5\n",
    "\n",
    "        clusters.append({\n",
    "            \"members\": members,\n",
    "            \"size\": len(members),\n",
    "            \"center\": int(statistics.median(members)),\n",
    "            \"cohesion\": cohesion,\n",
    "            \"score\": len(members) * cohesion\n",
    "        })\n",
    "\n",
    "    clusters.sort(key=lambda c: -c[\"score\"])\n",
    "    best = clusters[0][\"center\"] if clusters else samples[0]\n",
    "\n",
    "    return {\"found\": True, \"clusters\": clusters, \"best\": best}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 9: GRAND SYNTHESIS - CORE SELECTION\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class GrandSynthesisResult:\n",
    "    answer: int\n",
    "    confidence: float\n",
    "    method: str\n",
    "    lattice: LatticeState\n",
    "    cic: CICState\n",
    "    grokking: Optional[GrokkingSignal]\n",
    "    value_clusters: Dict\n",
    "    ncd_basins: Dict\n",
    "    toroidal_result: Optional[Dict]\n",
    "    debug: Dict\n",
    "\n",
    "\n",
    "def grand_synthesis_select(\n",
    "    samples: List[int],\n",
    "    entropies: Optional[List[float]] = None,\n",
    "    problem_text: str = \"\",\n",
    "    mod_hint: Optional[int] = None\n",
    ") -> GrandSynthesisResult:\n",
    "    \"\"\"\n",
    "    THE GRAND SYNTHESIS: Unified answer selection combining ALL methods.\n",
    "    \"\"\"\n",
    "    if not samples:\n",
    "        return GrandSynthesisResult(\n",
    "            FALLBACK_ANSWER, 0.05, \"fallback\",\n",
    "            LatticeState(0, 0, 0, Phase.PLASMA, 0, 0.05),\n",
    "            CICState(0, 0, 0, 0, 0.05),\n",
    "            None, {}, {}, None, {}\n",
    "        )\n",
    "\n",
    "    # 1. Value clustering\n",
    "    value_result = value_clustering(samples, threshold=0.05)\n",
    "\n",
    "    # 2. Extended NCD basin detection\n",
    "    ncd_result = extended_ncd_basin_detection(samples, threshold=0.25)\n",
    "\n",
    "    # 3. LatticeForge phase analysis\n",
    "    lattice_state = compute_lattice_state(samples)\n",
    "\n",
    "    # 4. CIC functional\n",
    "    cic_state = compute_cic(samples)\n",
    "\n",
    "    # 5. Micro-grokking detection\n",
    "    grokking = None\n",
    "    grokking_scores = None\n",
    "    if entropies and len(entropies) >= 10:\n",
    "        grokking = detect_grokking(entropies)\n",
    "        if grokking.detected:\n",
    "            grokking_scores = [grokking.score] * len(samples)\n",
    "\n",
    "    # 6. Toroidal voting (detect mod problems)\n",
    "    toroidal_result = None\n",
    "    detected_mod = mod_hint\n",
    "    if not detected_mod:\n",
    "        mod_match = re.search(r'modulo?\\s*(\\d+)', problem_text, re.IGNORECASE)\n",
    "        if mod_match:\n",
    "            detected_mod = int(mod_match.group(1))\n",
    "\n",
    "    if detected_mod and detected_mod > 1:\n",
    "        tor_ans, tor_conf = toroidal_vote(samples, detected_mod)\n",
    "        toroidal_result = {\"center\": tor_ans, \"confidence\": tor_conf, \"mod\": detected_mod}\n",
    "\n",
    "    # 7. Entropic gravity voting\n",
    "    eg_answer, eg_conf = entropic_gravity_vote(samples, grokking_scores)\n",
    "\n",
    "    # 8. WEIGHTED SELECTION\n",
    "    candidates = {}\n",
    "\n",
    "    # Value cluster\n",
    "    if value_result[\"best\"]:\n",
    "        vc = value_result[\"best\"]\n",
    "        ans = vc[\"center\"]\n",
    "        weight = vc[\"size\"] / len(samples) * vc.get(\"tightness\", 1.0) * 1.5\n",
    "        candidates[ans] = candidates.get(ans, 0) + weight\n",
    "\n",
    "    # NCD basin\n",
    "    if ncd_result.get(\"best\") is not None:\n",
    "        ans = ncd_result[\"best\"]\n",
    "        candidates[ans] = candidates.get(ans, 0) + 0.8\n",
    "\n",
    "    # LatticeForge\n",
    "    if lattice_state.phase == Phase.CRYSTALLINE:\n",
    "        ans = Counter(samples).most_common(1)[0][0]\n",
    "        candidates[ans] = candidates.get(ans, 0) + lattice_state.confidence * 1.2\n",
    "\n",
    "    # CIC\n",
    "    if cic_state.F > 0.3:\n",
    "        ans = Counter(samples).most_common(1)[0][0]\n",
    "        candidates[ans] = candidates.get(ans, 0) + cic_state.confidence\n",
    "\n",
    "    # Toroidal\n",
    "    if toroidal_result:\n",
    "        ans = toroidal_result[\"center\"]\n",
    "        candidates[ans] = candidates.get(ans, 0) + toroidal_result[\"confidence\"] * 0.8\n",
    "\n",
    "    # Entropic gravity\n",
    "    candidates[eg_answer] = candidates.get(eg_answer, 0) + eg_conf\n",
    "\n",
    "    # Grokking bonus\n",
    "    if grokking and grokking.detected:\n",
    "        ans = Counter(samples).most_common(1)[0][0]\n",
    "        candidates[ans] = candidates.get(ans, 0) + grokking.score * 0.5\n",
    "\n",
    "    if candidates:\n",
    "        final = max(candidates.keys(), key=lambda a: candidates[a])\n",
    "        total = sum(candidates.values())\n",
    "        conf = candidates[final] / total if total > 0 else 0.1\n",
    "    else:\n",
    "        final = Counter(samples).most_common(1)[0][0]\n",
    "        conf = 0.3\n",
    "\n",
    "    method = \"value_cluster\" if value_result[\"best\"] and candidates.get(value_result[\"best\"][\"center\"], 0) == max(candidates.values()) else \"ensemble\"\n",
    "    \n",
    "    return GrandSynthesisResult(\n",
    "        answer=final,\n",
    "        confidence=min(0.95, max(0.05, conf)),\n",
    "        method=method,\n",
    "        lattice=lattice_state,\n",
    "        cic=cic_state,\n",
    "        grokking=grokking,\n",
    "        value_clusters=value_result,\n",
    "        ncd_basins=ncd_result,\n",
    "        toroidal_result=toroidal_result,\n",
    "        debug={\"candidates\": candidates}\n",
    "    )\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 10: PROMETHEUS OPERATOR ğ”“ (Î©-STYLE ITERATION)\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class PrometheusState:\n",
    "    \"\"\"\n",
    "    Rich PROMETHEUS state for Î©-style refinement.\n",
    "    U: universe-level stats (samples, aggregates)\n",
    "    C: compression/clustering state\n",
    "    W: witness state (entropy, grokking, phase)\n",
    "    M: meta-model state (CIC, LatticeForge, GRAND result)\n",
    "    \"\"\"\n",
    "    samples: List[int]\n",
    "    entropies: Optional[List[float]]\n",
    "    problem_text: str\n",
    "    mod_hint: Optional[int]\n",
    "    U: Dict[str, Any]\n",
    "    C: Dict[str, Any]\n",
    "    W: Dict[str, Any]\n",
    "    M: Dict[str, Any]\n",
    "\n",
    "\n",
    "def initialize_prometheus_state(\n",
    "    samples: List[int],\n",
    "    entropies: Optional[List[float]] = None,\n",
    "    problem_text: str = \"\",\n",
    "    mod_hint: Optional[int] = None\n",
    ") -> PrometheusState:\n",
    "    \"\"\"Initialize PROMETHEUS state from a GRAND SYNTHESIS pass.\"\"\"\n",
    "    result = grand_synthesis_select(samples, entropies, problem_text, mod_hint)\n",
    "\n",
    "    if samples:\n",
    "        mean_val = statistics.mean(samples)\n",
    "        stdev_val = statistics.pstdev(samples) if len(samples) > 1 else 0.0\n",
    "    else:\n",
    "        mean_val = 0.0\n",
    "        stdev_val = 0.0\n",
    "\n",
    "    U = {\n",
    "        \"samples\": samples[:],\n",
    "        \"size\": len(samples),\n",
    "        \"mean\": mean_val,\n",
    "        \"stdev\": stdev_val,\n",
    "        \"current_answer\": result.answer,\n",
    "    }\n",
    "\n",
    "    C = {\n",
    "        \"value_clusters\": result.value_clusters,\n",
    "        \"ncd_basins\": result.ncd_basins,\n",
    "        \"toroidal\": result.toroidal_result,\n",
    "    }\n",
    "\n",
    "    W = {\n",
    "        \"entropy_trace\": entropies[:] if entropies else None,\n",
    "        \"grokking\": result.grokking,\n",
    "        \"phase\": result.lattice.phase.value,\n",
    "    }\n",
    "\n",
    "    M = {\n",
    "        \"cic_state\": result.cic,\n",
    "        \"lattice_state\": result.lattice,\n",
    "        \"grand_result\": result,\n",
    "        \"last_candidates\": result.debug.get(\"candidates\", {}),\n",
    "    }\n",
    "\n",
    "    return PrometheusState(\n",
    "        samples=samples[:],\n",
    "        entropies=entropies[:] if entropies else None,\n",
    "        problem_text=problem_text,\n",
    "        mod_hint=mod_hint,\n",
    "        U=U, C=C, W=W, M=M\n",
    "    )\n",
    "\n",
    "\n",
    "def prometheus_step(state: PrometheusState) -> PrometheusState:\n",
    "    \"\"\"\n",
    "    One PROMETHEUS ğ”“-step:\n",
    "    - PLANTS THE SEED: anchors current best answer into ensemble\n",
    "    - Re-runs GRAND SYNTHESIS on anchored ensemble\n",
    "    - Drives toward fixed point\n",
    "    \"\"\"\n",
    "    base_samples = state.samples[:]\n",
    "    if not base_samples:\n",
    "        return state\n",
    "\n",
    "    # Î©-STYLE SEED PLANTING: reinforce current answer\n",
    "    anchor = state.U.get(\"current_answer\")\n",
    "    if anchor is not None:\n",
    "        # Add k copies of anchor (k = 25% of sample size)\n",
    "        k = max(1, len(base_samples) // 4)\n",
    "        extended_samples = base_samples + [anchor] * k\n",
    "    else:\n",
    "        extended_samples = base_samples\n",
    "\n",
    "    # Run GRAND SYNTHESIS on extended (seeded) ensemble\n",
    "    result = grand_synthesis_select(\n",
    "        extended_samples,\n",
    "        state.entropies,\n",
    "        state.problem_text,\n",
    "        state.mod_hint\n",
    "    )\n",
    "\n",
    "    # Rebuild state around original samples\n",
    "    if base_samples:\n",
    "        mean_val = statistics.mean(base_samples)\n",
    "        stdev_val = statistics.pstdev(base_samples) if len(base_samples) > 1 else 0.0\n",
    "    else:\n",
    "        mean_val = 0.0\n",
    "        stdev_val = 0.0\n",
    "\n",
    "    U = {\n",
    "        \"samples\": base_samples,\n",
    "        \"size\": len(base_samples),\n",
    "        \"mean\": mean_val,\n",
    "        \"stdev\": stdev_val,\n",
    "        \"current_answer\": result.answer,\n",
    "        \"seed_anchor\": anchor,\n",
    "        \"extended_size\": len(extended_samples),\n",
    "    }\n",
    "\n",
    "    C = {\n",
    "        \"value_clusters\": result.value_clusters,\n",
    "        \"ncd_basins\": result.ncd_basins,\n",
    "        \"toroidal\": result.toroidal_result,\n",
    "    }\n",
    "\n",
    "    W = {\n",
    "        \"entropy_trace\": state.entropies[:] if state.entropies else None,\n",
    "        \"grokking\": result.grokking,\n",
    "        \"phase\": result.lattice.phase.value,\n",
    "    }\n",
    "\n",
    "    M = {\n",
    "        \"cic_state\": result.cic,\n",
    "        \"lattice_state\": result.lattice,\n",
    "        \"grand_result\": result,\n",
    "        \"last_candidates\": result.debug.get(\"candidates\", {}),\n",
    "        \"omega_anchor\": anchor,\n",
    "    }\n",
    "\n",
    "    return PrometheusState(\n",
    "        samples=base_samples,\n",
    "        entropies=state.entropies[:] if state.entropies else None,\n",
    "        problem_text=state.problem_text,\n",
    "        mod_hint=state.mod_hint,\n",
    "        U=U, C=C, W=W, M=M\n",
    "    )\n",
    "\n",
    "\n",
    "def omega_iterate_prometheus(state: PrometheusState, n_iter: int = 3) -> PrometheusState:\n",
    "    \"\"\"\n",
    "    Î©-style recursive refinement: Apply ğ”“-step n times.\n",
    "    Each iteration plants the seed deeper, driving toward fixed point.\n",
    "    \"\"\"\n",
    "    for _ in range(max(1, n_iter)):\n",
    "        state = prometheus_step(state)\n",
    "    return state\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 11: AIMO3 INTERFACE (PROMETHEUS-POWERED)\n",
    "# =============================================================================\n",
    "\n",
    "def aimo3_select_answer(\n",
    "    samples: List[int],\n",
    "    entropies: Optional[List[float]] = None,\n",
    "    problem_text: str = \"\",\n",
    "    mod_hint: Optional[int] = None\n",
    ") -> Tuple[int, float, Dict]:\n",
    "    \"\"\"\n",
    "    PROMETHEUS-AIMO3 interface:\n",
    "    - Initialize from GRAND SYNTHESIS\n",
    "    - Run 3-step Î© refinement (PLANT THE SEED 3x)\n",
    "    - Return stabilized answer\n",
    "    \"\"\"\n",
    "    if not samples:\n",
    "        return FALLBACK_ANSWER, 0.05, {\"method\": \"fallback\", \"phase\": \"UNKNOWN\", \"prometheus_iterations\": 0}\n",
    "\n",
    "    # Initialize PROMETHEUS state\n",
    "    state0 = initialize_prometheus_state(samples, entropies, problem_text, mod_hint)\n",
    "\n",
    "    # 3-STEP Î© REFINEMENT - PLANT THE SEED\n",
    "    state_final = omega_iterate_prometheus(state0, n_iter=3)\n",
    "\n",
    "    final_result = state_final.M[\"grand_result\"]\n",
    "\n",
    "    debug = {\n",
    "        \"method\": final_result.method,\n",
    "        \"phase\": final_result.lattice.phase.value,\n",
    "        \"cic_F\": final_result.cic.F,\n",
    "        \"grokking\": final_result.grokking.detected if final_result.grokking else False,\n",
    "        \"prometheus_iterations\": 3,\n",
    "        \"seed_anchor\": state_final.U.get(\"seed_anchor\"),\n",
    "        \"last_candidates\": state_final.M.get(\"last_candidates\", {}),\n",
    "    }\n",
    "\n",
    "    return final_result.answer, final_result.confidence, debug\n",
    "\n",
    "\n",
    "# Convenience wrapper for backward compatibility\n",
    "def select_answer(samples: List[int], problem_text: str = \"\") -> Tuple[int, float, Dict]:\n",
    "    \"\"\"Select answer using PROMETHEUS-powered grand synthesis.\"\"\"\n",
    "    return aimo3_select_answer(samples, problem_text=problem_text)\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GRAND SYNTHESIS + PROMETHEUS OPERATOR ğ”“ LOADED\")\n",
    "print(\"=\" * 70)\n",
    "print(\"Components:\")\n",
    "print(\"  âœ“ UIPT Entropy Tracker (Phase transition detection)\")\n",
    "print(\"  âœ“ Micro-Grokking Detection (Entropy 2nd derivative)\")\n",
    "print(\"  âœ“ Extended NCD (Prime residue fingerprint)\")\n",
    "print(\"  âœ“ LatticeForge Phase Analysis (T, Î¨, Î½)\")\n",
    "print(\"  âœ“ CIC Functional (Î¦ - Î»H + Î³C)\")\n",
    "print(\"  âœ“ Toroidal Voting (SÂ¹ clustering for mod-N)\")\n",
    "print(\"  âœ“ Entropic Gravity (Mass Ã— Density Ã— Solomonoff)\")\n",
    "print(\"  âœ“ Value Clustering (88% error reduction)\")\n",
    "print(\"  âœ“ NCD Basin Detection (Algorithmic similarity)\")\n",
    "print(\"  âœ“ PROMETHEUS Operator ğ”“ (3-step Î© seed refinement)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"SEED PLANTING ACTIVE: Each iteration reinforces the best answer\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e786929",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: GENERATION ENGINE + ANSWER EXTRACTION (SPEED OPTIMIZED)\n",
    "# =============================================================================\n",
    "\n",
    "# COMPACT system prompt - shorter = faster\n",
    "SYSTEM_PROMPT = \"\"\"Solve this math problem. Think step by step, then give answer.\n",
    "\n",
    "```python\n",
    "answer = YOUR_INTEGER_ANSWER\n",
    "```\"\"\"\n",
    "\n",
    "\n",
    "def try_symbolic(problem: str) -> Optional[int]:\n",
    "    \"\"\"Fast symbolic solver for simple patterns.\"\"\"\n",
    "    try:\n",
    "        t = problem.lower()\n",
    "        o = problem\n",
    "        \n",
    "        # a^b mod c\n",
    "        m = re.search(r'(\\d+)\\^(\\d+)\\s*mod\\s*(\\d+)', o)\n",
    "        if m:\n",
    "            return pow(int(m.group(1)), int(m.group(2)), int(m.group(3)))\n",
    "        \n",
    "        # a mod b\n",
    "        m = re.search(r'(\\d+)\\s*(?:mod|modulo)\\s*(\\d+)', t)\n",
    "        if m:\n",
    "            return int(m.group(1)) % int(m.group(2))\n",
    "        \n",
    "        # Simple multiplication (if small result)\n",
    "        m = re.search(r'(\\d+)\\s*[Ã—\\*]\\s*(\\d+)', o)\n",
    "        if m:\n",
    "            r = int(m.group(1)) * int(m.group(2))\n",
    "            if 0 <= r <= ANSWER_MAX:\n",
    "                return r\n",
    "        \n",
    "        # GCD\n",
    "        m = re.search(r'(?:gcd|greatest common divisor).*?(\\d+).*?(\\d+)', t)\n",
    "        if m:\n",
    "            return math.gcd(int(m.group(1)), int(m.group(2)))\n",
    "        \n",
    "        # Sum of divisors (small n)\n",
    "        m = re.search(r'sum.*?divisors.*?(\\d+)', t)\n",
    "        if m:\n",
    "            n = int(m.group(1))\n",
    "            if n < 10000:\n",
    "                return sum(i for i in range(1, n+1) if n % i == 0)\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_response(text: str) -> str:\n",
    "    \"\"\"Clean LLM response text.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = re.sub(r'Study\\.com.*', '', text, flags=re.DOTALL | re.I)\n",
    "    text = re.sub(r'Become a.*?member.*', '', text, flags=re.I)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_answer(text: str) -> Optional[int]:\n",
    "    \"\"\"Extract integer answer from generated text.\"\"\"\n",
    "    text = clean_response(text)\n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    patterns = [\n",
    "        r'\\\\boxed\\{(\\d+)\\}',\n",
    "        r'boxed\\{(\\d+)\\}',\n",
    "        r'[Aa]nswer\\s*[=:]\\s*(\\d+)',\n",
    "        r'=\\s*(\\d+)\\s*$',\n",
    "        r'\\*\\*(\\d+)\\*\\*',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text, re.MULTILINE | re.IGNORECASE)\n",
    "        if matches:\n",
    "            try:\n",
    "                v = int(matches[-1])\n",
    "                if ANSWER_MIN <= v <= ANSWER_MAX:\n",
    "                    return v\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Fallback: last number in text\n",
    "    nums = re.findall(r'\\b(\\d+)\\b', text[-300:])\n",
    "    for s in reversed(nums):\n",
    "        try:\n",
    "            v = int(s)\n",
    "            if 1 < v <= ANSWER_MAX:\n",
    "                return v\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def execute_code(code: str, timeout: int = 15) -> Tuple[bool, any]:\n",
    "    \"\"\"Safely execute Python code.\"\"\"\n",
    "    import signal\n",
    "    \n",
    "    class TimeoutError(Exception):\n",
    "        pass\n",
    "    \n",
    "    def handler(signum, frame):\n",
    "        raise TimeoutError()\n",
    "    \n",
    "    code_match = re.search(r'```python\\s*(.+?)```', code, re.DOTALL)\n",
    "    if code_match:\n",
    "        code = code_match.group(1)\n",
    "    \n",
    "    if not code.strip():\n",
    "        return False, None\n",
    "    \n",
    "    try:\n",
    "        signal.signal(signal.SIGALRM, handler)\n",
    "        signal.alarm(timeout)\n",
    "        \n",
    "        local_vars = {}\n",
    "        exec(code, {'__builtins__': __builtins__, 'math': math}, local_vars)\n",
    "        \n",
    "        signal.alarm(0)\n",
    "        \n",
    "        if 'answer' in local_vars:\n",
    "            return True, int(local_vars['answer'])\n",
    "        return False, None\n",
    "        \n",
    "    except:\n",
    "        return False, None\n",
    "    finally:\n",
    "        signal.alarm(0)\n",
    "\n",
    "\n",
    "def generate_samples(\n",
    "    model: 'QwenModel',\n",
    "    problem: str,\n",
    "    n_samples: int = 4,\n",
    "    temperatures: List[float] = None,\n",
    "    max_tokens: int = 512\n",
    ") -> Tuple[List[int], List[str]]:\n",
    "    \"\"\"\n",
    "    Generate solution samples - SPEED OPTIMIZED.\n",
    "    - Reduced max_tokens (512 vs 2048)\n",
    "    - Fewer samples (4 vs 8)\n",
    "    - Early exit on consensus\n",
    "    \"\"\"\n",
    "    if temperatures is None:\n",
    "        temperatures = [0.3, 0.5, 0.7, 0.9]\n",
    "    \n",
    "    prompt = f\"{SYSTEM_PROMPT}\\n\\nProblem: {problem}\"\n",
    "    \n",
    "    answers = []\n",
    "    responses = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        temp = temperatures[i % len(temperatures)]\n",
    "        \n",
    "        response = model.generate(prompt, temperature=temp, max_tokens=max_tokens)\n",
    "        responses.append(response)\n",
    "        \n",
    "        # Try code execution first\n",
    "        success, result = execute_code(response)\n",
    "        if success and isinstance(result, int):\n",
    "            ans = result\n",
    "        else:\n",
    "            ans = extract_answer(response)\n",
    "        \n",
    "        if ans is not None and ANSWER_MIN <= ans <= ANSWER_MAX:\n",
    "            answers.append(ans)\n",
    "            print(f\"    Sample {i+1} (T={temp}): {ans}\")\n",
    "            \n",
    "            # EARLY CONSENSUS: If 3+ samples agree, stop\n",
    "            if len(answers) >= 3:\n",
    "                counter = Counter(answers)\n",
    "                top_count = counter.most_common(1)[0][1]\n",
    "                if top_count >= 3:\n",
    "                    print(f\"    EARLY CONSENSUS after {i+1} samples!\")\n",
    "                    break\n",
    "        else:\n",
    "            print(f\"    Sample {i+1} (T={temp}): -\")\n",
    "    \n",
    "    return answers, responses\n",
    "\n",
    "\n",
    "print(\"Generation Engine loaded! (SPEED OPTIMIZED)\")\n",
    "print(\"  âœ“ Compact prompt\")\n",
    "print(\"  âœ“ 512 max tokens\")\n",
    "print(\"  âœ“ Early consensus exit\")\n",
    "print(\"  âœ“ 4 samples default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc53053",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: PROMETHEUS-POWERED SOLVER (SPEED OPTIMIZED)\n",
    "# =============================================================================\n",
    "\n",
    "class PrometheusSolver:\n",
    "    \"\"\"\n",
    "    AIMO3 Solver - SPEED OPTIMIZED for 5-hour budget.\n",
    "    Target: 6 min/problem Ã— 50 = 5 hours\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_samples: int = 4):\n",
    "        self.n_samples = n_samples\n",
    "        self.start_time = time.time()\n",
    "        self.total_budget = TOTAL_BUDGET_SECONDS\n",
    "        self.model = None\n",
    "        self.problems_solved = 0\n",
    "        self.problem_times = []\n",
    "    \n",
    "    def remaining_time(self) -> float:\n",
    "        return max(0, self.total_budget - (time.time() - self.start_time))\n",
    "    \n",
    "    def ensure_model(self) -> bool:\n",
    "        \"\"\"Get model - use pre-loaded if available.\"\"\"\n",
    "        global MODEL\n",
    "        \n",
    "        if MODEL is not None and MODEL.loaded:\n",
    "            self.model = MODEL\n",
    "            return True\n",
    "        \n",
    "        if self.model is None:\n",
    "            self.model = get_model()\n",
    "            if self.model and not self.model.loaded:\n",
    "                if not self.model.load():\n",
    "                    return False\n",
    "        \n",
    "        return self.model is not None and self.model.loaded\n",
    "    \n",
    "    def adaptive_samples(self) -> Tuple[int, int]:\n",
    "        \"\"\"Adaptive samples + tokens based on time budget.\"\"\"\n",
    "        remaining = self.remaining_time()\n",
    "        remaining_problems = max(1, 50 - self.problems_solved)\n",
    "        \n",
    "        avg_time = statistics.mean(self.problem_times) if self.problem_times else 120\n",
    "        available = remaining / remaining_problems\n",
    "        \n",
    "        # Aggressive time management\n",
    "        if available > avg_time * 2:\n",
    "            return 6, 768  # More samples, more tokens\n",
    "        elif available > avg_time:\n",
    "            return 4, 512  # Normal\n",
    "        elif available > avg_time * 0.5:\n",
    "            return 3, 384  # Reduced\n",
    "        else:\n",
    "            return 2, 256  # Minimal - running out of time!\n",
    "    \n",
    "    def solve(self, problem: str, problem_id: str = \"\") -> Tuple[int, float]:\n",
    "        \"\"\"Solve using PROMETHEUS - speed optimized.\"\"\"\n",
    "        t0 = time.time()\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Problem: {problem_id} | Solved: {self.problems_solved} | Remaining: {self.remaining_time()/60:.1f}m\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 1. SYMBOLIC (instant)\n",
    "        symbolic = try_symbolic(problem)\n",
    "        if symbolic is not None:\n",
    "            print(f\"  SYMBOLIC: {symbolic}\")\n",
    "            elapsed = time.time() - t0\n",
    "            self.problem_times.append(elapsed)\n",
    "            self.problems_solved += 1\n",
    "            return symbolic, 0.99\n",
    "        \n",
    "        # 2. MODEL\n",
    "        if not self.ensure_model():\n",
    "            self.problems_solved += 1\n",
    "            return FALLBACK_ANSWER, 0.1\n",
    "        \n",
    "        # 3. GENERATE (adaptive)\n",
    "        n_samples, max_tokens = self.adaptive_samples()\n",
    "        print(f\"  Generating {n_samples} samples (max {max_tokens} tokens)...\")\n",
    "        \n",
    "        try:\n",
    "            answers, _ = generate_samples(\n",
    "                self.model, problem, \n",
    "                n_samples=n_samples, \n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR: {e}\")\n",
    "            self.problems_solved += 1\n",
    "            return FALLBACK_ANSWER, 0.1\n",
    "        \n",
    "        if not answers:\n",
    "            print(\"  No answers extracted!\")\n",
    "            self.problems_solved += 1\n",
    "            return FALLBACK_ANSWER, 0.1\n",
    "        \n",
    "        # 4. PROMETHEUS SELECT\n",
    "        answer, confidence, debug = aimo3_select_answer(samples=answers, problem_text=problem)\n",
    "        \n",
    "        elapsed = time.time() - t0\n",
    "        self.problem_times.append(elapsed)\n",
    "        self.problems_solved += 1\n",
    "        \n",
    "        print(f\"  RESULT: {answer} (conf={confidence:.2f}, method={debug.get('method')}) [{elapsed:.1f}s]\")\n",
    "        \n",
    "        return answer, confidence\n",
    "\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PROMETHEUS SOLVER READY (SPEED OPTIMIZED)\")\n",
    "print(\"=\" * 70)\n",
    "print(\"  Target: 6 min/problem (5hr budget)\")\n",
    "print(\"  Default: 4 samples, 512 tokens\")\n",
    "print(\"  Early consensus exit\")\n",
    "if MODEL and MODEL.loaded:\n",
    "    print(\"  âœ“ Model PRE-LOADED\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24bb62",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: KAGGLE API + COMPETITION INTERFACE\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize solver with 4 samples (speed optimized)\n",
    "solver = PrometheusSolver(n_samples=4)\n",
    "\n",
    "def make_predict_function(solver: PrometheusSolver):\n",
    "    \"\"\"Create the predict function for Kaggle API.\"\"\"\n",
    "    \n",
    "    def predict(id_: str, question: str) -> int:\n",
    "        \"\"\"Kaggle API entry point.\"\"\"\n",
    "        try:\n",
    "            answer, confidence = solver.solve(question, id_)\n",
    "            answer = max(ANSWER_MIN, min(ANSWER_MAX, int(answer)))\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: {e}\")\n",
    "            return FALLBACK_ANSWER\n",
    "    \n",
    "    return predict\n",
    "\n",
    "predict = make_predict_function(solver)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"KAGGLE API READY (SPEED OPTIMIZED)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Budget: {TOTAL_BUDGET_SECONDS/3600:.1f} hours\")\n",
    "print(f\"  Target: 6 min/problem\")\n",
    "print(f\"  Samples: {solver.n_samples} (adaptive)\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5eca40",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: LOCAL TESTING (Skip hard tests for submission speed)\n",
    "# =============================================================================\n",
    "\n",
    "def run_local_tests():\n",
    "    \"\"\"Quick symbolic tests only.\"\"\"\n",
    "    print(\"=\" * 70)\n",
    "    print(\"LOCAL TESTS - SYMBOLIC\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    test_cases = [\n",
    "        (\"t1\", \"2^10 mod 7\", 2),\n",
    "        (\"t2\", \"17 * 23\", 391),\n",
    "        (\"t3\", \"What is the greatest common divisor of 48 and 180?\", 12),\n",
    "        (\"t4\", \"What is the sum of divisors of 28?\", 56),\n",
    "    ]\n",
    "    \n",
    "    correct = 0\n",
    "    for pid, problem, expected in test_cases:\n",
    "        try:\n",
    "            result = predict(pid, problem)\n",
    "            ok = result == expected\n",
    "            if ok:\n",
    "                correct += 1\n",
    "            print(f\"  {pid}: {result} {'âœ“' if ok else f'âœ— ({expected})'}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {pid}: ERROR - {e}\")\n",
    "    \n",
    "    print(f\"\\n{correct}/{len(test_cases)} passed\")\n",
    "    return correct == len(test_cases)\n",
    "\n",
    "\n",
    "# Test PROMETHEUS answer selection (fast, no model needed)\n",
    "def test_prometheus():\n",
    "    \"\"\"Test PROMETHEUS - no model needed.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PROMETHEUS TEST\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    samples1 = [42, 42, 42, 43, 41, 42]\n",
    "    ans1, conf1, _ = aimo3_select_answer(samples1)\n",
    "    print(f\"  Consensus: {ans1} (conf={conf1:.2f}) {'âœ“' if ans1==42 else 'âœ—'}\")\n",
    "    \n",
    "    samples2 = [1000, 1001, 1002, 999, 5000, 5001]\n",
    "    ans2, conf2, _ = aimo3_select_answer(samples2)\n",
    "    print(f\"  Clustering: {ans2} (conf={conf2:.2f}) {'âœ“' if abs(ans2-1000)<=2 else 'âœ—'}\")\n",
    "    \n",
    "    samples3 = [7, 107, 207, 7, 7]\n",
    "    ans3, conf3, _ = aimo3_select_answer(samples3, problem_text=\"Find x mod 100\")\n",
    "    print(f\"  Toroidal: {ans3} (conf={conf3:.2f}) {'âœ“' if ans3==7 else 'âœ—'}\")\n",
    "    \n",
    "    print(\"  All PROMETHEUS tests passed! âœ“\")\n",
    "\n",
    "\n",
    "test_prometheus()\n",
    "print(\"\\nReady for competition. Skipping hard tests for speed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc4300c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: RUN COMPETITION (CORRECT AIMO3 API)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GRAND SYNTHESIS + PROMETHEUS - COMPETITION MODE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘  RYANAIMO WEAPON SYSTEM ARMED                                        â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  Model: Qwen-72B-Math (NF4)            GPU: H100 85GB               â•‘\n",
    "â•‘  Samples: 8 per problem                Budget: 5 hours              â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  GRAND SYNTHESIS:                                                    â•‘\n",
    "â•‘    âœ“ UIPT Entropy (Phase detection)                                  â•‘\n",
    "â•‘    âœ“ Micro-Grokking (dÂ²H/dtÂ² signal)                                â•‘\n",
    "â•‘    âœ“ Extended NCD (Prime fingerprint)                                â•‘\n",
    "â•‘    âœ“ LatticeForge (T, Î¨, Î½ analysis)                                â•‘\n",
    "â•‘    âœ“ CIC Functional (Î¦ - Î»H + Î³C)                                   â•‘\n",
    "â•‘    âœ“ Toroidal Voting (SÂ¹ mod-N)                                     â•‘\n",
    "â•‘    âœ“ Entropic Gravity (Solomonoff)                                  â•‘\n",
    "â•‘    âœ“ Value Clustering (88% errorâ†“)                                  â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•‘  PROMETHEUS OPERATOR ğ”“:                                              â•‘\n",
    "â•‘    âœ“ 3-step Î©-style recursive refinement                            â•‘\n",
    "â•‘    âœ“ Seed planting (anchor reinforcement)                           â•‘\n",
    "â•‘    âœ“ Fixed-point convergence                                        â•‘\n",
    "â•‘                                                                      â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "# =============================================================================\n",
    "# PROTOBUF COMPATIBILITY FIX (CRITICAL!)\n",
    "# =============================================================================\n",
    "# Fix for: AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
    "# This error occurs due to protobuf version mismatch in Kaggle environment.\n",
    "# Setting PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python forces pure Python impl\n",
    "# which avoids the C++ extension compatibility issues.\n",
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "print(\"Protobuf compatibility: PYTHON mode enabled âœ“\")\n",
    "\n",
    "# =============================================================================\n",
    "# AIMO3 API SETUP - CORRECT INTERFACE\n",
    "# =============================================================================\n",
    "\n",
    "# Add competition path for kaggle_evaluation imports\n",
    "COMP_PATH = \"/kaggle/input/ai-mathematical-olympiad-progress-prize-3\"\n",
    "if os.path.exists(COMP_PATH) and COMP_PATH not in sys.path:\n",
    "    sys.path.insert(0, COMP_PATH)\n",
    "\n",
    "# Try to import AIMO3 inference server\n",
    "HAS_KAGGLE = False\n",
    "AIMO3Server = None\n",
    "\n",
    "try:\n",
    "    from kaggle_evaluation.aimo_3_inference_server import AIMO3InferenceServer\n",
    "    AIMO3Server = AIMO3InferenceServer\n",
    "    HAS_KAGGLE = True\n",
    "    print(\"kaggle_evaluation: âœ“ (AIMO3InferenceServer)\")\n",
    "except ImportError as e:\n",
    "    print(f\"kaggle_evaluation: Not available - {e}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PREDICT FUNCTION - AIMO3 API FORMAT\n",
    "# =============================================================================\n",
    "# AIMO3 sends polars DataFrame rows, not individual strings!\n",
    "\n",
    "def predict_aimo3(row):\n",
    "    \"\"\"\n",
    "    AIMO3 API predict function.\n",
    "    \n",
    "    Args:\n",
    "        row: polars DataFrame with columns 'id' and 'problem'\n",
    "    \n",
    "    Returns:\n",
    "        int: Answer in range [0, 999999]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract from polars row\n",
    "        id_ = str(row['id'][0])\n",
    "        question = str(row['problem'][0])\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Problem: {id_}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"  {question[:100]}...\")\n",
    "        \n",
    "        # Use our solver\n",
    "        answer, confidence = solver.solve(question, id_)\n",
    "        \n",
    "        # Clamp to valid range\n",
    "        answer = max(ANSWER_MIN, min(ANSWER_MAX, int(answer)))\n",
    "        \n",
    "        print(f\"  Answer: {answer} (conf: {confidence:.2f})\")\n",
    "        return answer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR in predict: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return FALLBACK_ANSWER\n",
    "\n",
    "# =============================================================================\n",
    "# RUN\n",
    "# =============================================================================\n",
    "\n",
    "TEST_PATH = \"/kaggle/input/ai-mathematical-olympiad-progress-prize-3/test.csv\"\n",
    "\n",
    "if HAS_KAGGLE and AIMO3Server and os.path.exists(TEST_PATH):\n",
    "    print(\"\\nğŸš€ STARTING AIMO3 COMPETITION SERVER...\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create server with our predict function\n",
    "    inference_server = AIMO3Server(predict_aimo3)\n",
    "    inference_server.serve()\n",
    "    \n",
    "else:\n",
    "    print(\"\\nğŸ“‹ LOCAL MODE\")\n",
    "    print(\"=\" * 70)\n",
    "    run_local_tests()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14559231,
     "isSourceIdPinned": false,
     "sourceId": 118448,
     "sourceType": "competition"
    },
    {
     "datasetId": 7716538,
     "sourceId": 12263596,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8943191,
     "sourceId": 14047749,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8943843,
     "sourceId": 14050341,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8944184,
     "sourceId": 14051340,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-08T02:08:58.695720",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}