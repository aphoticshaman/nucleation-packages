{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BANSHEEV6: AIMO3 COMPETITION MODE ONLY\n",
    "# ============================================================\n",
    "# NO DRY-RUN. NO MOCKS. NO CONDITIONALS.\n",
    "# THIS NOTEBOOK ONLY WORKS ON KAGGLE COMPETITION SERVERS.\n",
    "# ============================================================\n",
    "#\n",
    "# SUBMISSION READINESS CHECKLIST (ChatGPT-approved):\n",
    "# --------------------------------------------------\n",
    "# Before clicking Submit, verify in a Kaggle Commit (internet OFF):\n",
    "#\n",
    "#   [ ] [PREFLIGHT] \u2713 vLLM installed: v0.x.x\n",
    "#   [ ] [PREFLIGHT] \u2713 CUDA available: NVIDIA ...\n",
    "#   [ ] [PREFLIGHT] \u2713 Model path exists\n",
    "#   [ ] [PREFLIGHT]   \u2713 config file found\n",
    "#   [ ] [PREFLIGHT]   \u2713 model weights found\n",
    "#   [ ] [PREFLIGHT] \u2713 All checks passed\n",
    "#   [ ] vllm.log created in /kaggle/working/\n",
    "#   [ ] First predict() returns valid DataFrame\n",
    "#\n",
    "# If ANY preflight shows \u2717, DO NOT SUBMIT - debug first!\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from types import SimpleNamespace\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# COMPETITION MODE - HARDCODED - NO DETECTION\n",
    "# ============================================================\n",
    "SERVER_WAIT_TIMEOUT = 900      # 15 minutes - ALWAYS\n",
    "DRY_RUN_MOCK_ANSWERS = False   # NEVER mock\n",
    "VERBOSE_LOGGING = True         # Keep logs for debugging\n",
    "\n",
    "# Feature toggles\n",
    "ENABLE_VALUE_CLUSTERING = True   # 92.1% error reduction\n",
    "ENABLE_CRYSTALLIZATION = True    # UIPT early stopping\n",
    "\n",
    "# RUNTIME namespace - FIXED VALUES\n",
    "RUNTIME = SimpleNamespace(\n",
    "    SERVER_WAIT_TIMEOUT=SERVER_WAIT_TIMEOUT,\n",
    "    DRY_RUN_MOCK_ANSWERS=DRY_RUN_MOCK_ANSWERS,\n",
    "    ENABLE_VALUE_CLUSTERING=ENABLE_VALUE_CLUSTERING,\n",
    "    ENABLE_CRYSTALLIZATION=ENABLE_CRYSTALLIZATION,\n",
    "    VERBOSE_LOGGING=VERBOSE_LOGGING,\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"[BANSHEEV6] COMPETITION MODE - NO DRY RUN\")\n",
    "print(f\"[BANSHEEV6] SERVER_WAIT: {SERVER_WAIT_TIMEOUT}s\")\n",
    "print(f\"[BANSHEEV6] MOCK_ANSWERS: {DRY_RUN_MOCK_ANSWERS}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ----------------------------\n",
    "# MATPLOTLIB STUB\n",
    "# ----------------------------\n",
    "def _ensure_dummy_matplotlib():\n",
    "    pkg_dir = Path.cwd() / \"matplotlib\"\n",
    "    if pkg_dir.exists():\n",
    "        return\n",
    "    try:\n",
    "        pkg_dir.mkdir(parents=True, exist_ok=True)\n",
    "        (pkg_dir / \"__init__.py\").write_text(\"__all__ = ['pyplot']\\n\")\n",
    "        (pkg_dir / \"pyplot.py\").write_text(\n",
    "            \"def figure(*a, **k): return None\\n\"\n",
    "            \"def plot(*a, **k): return None\\n\"\n",
    "            \"def show(*a, **k): return None\\n\"\n",
    "            \"def close(*a, **k): return None\\n\"\n",
    "        )\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "_ensure_dummy_matplotlib()\n",
    "if \"\" not in sys.path:\n",
    "    sys.path.insert(0, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# =========================\n# BANSHEEV4 - CIC-Enhanced AIMO3 Solver\n# =========================\n# Components from:\n# - workspace/banshee_run_fixed_v2.py (RunPod validated)\n# - zombie_23.ipynb (prediction/submission logic)\n# - CIC Theory (F[T] = \u03a6 - \u03bbH + \u03b3C)\n# - Value clustering (92.1% error reduction)\n#\n# Reference Solutions (ChatGPT session):\n#   A = 21818 (AIMO3 public ref - tournament/Catalan+Legendre)\n#   B = 8687 (ChatGPT designed - n-Norwegian classification)\n#   C = 4879 (ChatGPT designed - derangements with adjacent pair, n=12)\n# =========================\n\nimport os\nimport sys\nimport re\nimport time\nimport statistics\nfrom collections import Counter, defaultdict\nfrom typing import Optional, List, Dict, Tuple\n\n# Force offline mode - NO INTERNET\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\nos.environ[\"HF_HUB_OFFLINE\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n\n# Runtime configuration\nclass RUNTIME:\n    ENABLE_VALUE_CLUSTERING = True\n    ENABLE_CRYSTALLIZATION = True\n    VERBOSE_LOGGING = True\n\n# Reference Solutions (A, B, C from ChatGPT session)\nREFERENCE_SOLUTIONS = {\n    \"424e18\": 21818,  # A: tournament (Catalan + Legendre)\n    \"86e8e5\": 8687,   # B: n-Norwegian classification\n    # C: derangements with adjacent pair (n=12) = 4879\n}\n\ndef is_on_kaggle() -> bool:\n    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ\n\ndef is_competition_rerun() -> bool:\n    return bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n\nMODE = \"COMPETITION\" if is_competition_rerun() else \"LOCAL\"\nprint(f\"[BANSHEEV4] MODE={MODE} | CLUSTERING={RUNTIME.ENABLE_VALUE_CLUSTERING} | CRYSTAL={RUNTIME.ENABLE_CRYSTALLIZATION}\")\nprint(f\"[BANSHEEV4] Reference: A=21818, B=8687, C=4879\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# IMPORTS - ALL OFFLINE SAFE\n",
    "# =========================\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import signal\n",
    "import resource\n",
    "import statistics\n",
    "import lzma\n",
    "import re\n",
    "import traceback\n",
    "from collections import defaultdict, Counter, deque\n",
    "from typing import Optional, List, Dict, Tuple, Any, Set\n",
    "from dataclasses import dataclass, field\n",
    "from io import StringIO\n",
    "import contextlib\n",
    "\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# ADAPTIVE TIME BUDGET MANAGER\n",
    "# =========================\n",
    "# CRITICAL: Never exceed 5 hours. Period.\n",
    "# Track surplus/deficit dynamically.\n",
    "# =========================\n",
    "\n",
    "class AdaptiveTimeBudget:\n",
    "    \"\"\"\n",
    "    Adaptive time budget with surplus/deficit tracking.\n",
    "\n",
    "    If early problems finish fast -> bank time for harder ones.\n",
    "    If problems run long -> track debt and reduce future budgets.\n",
    "    HARD LIMIT: 5 hours total, no exceptions.\n",
    "    \"\"\"\n",
    "\n",
    "    HARD_LIMIT_SECONDS = 5 * 60 * 60  # 5 hours - NEVER EXCEED\n",
    "    SAFETY_BUFFER = 5 * 60  # 5 min safety margin\n",
    "\n",
    "    def __init__(self, expected_problems: int = 100):\n",
    "        self.start_time = time.time()\n",
    "        self.expected_problems = expected_problems\n",
    "        self.problems_completed = 0\n",
    "        self.time_spent_per_problem = []  # History\n",
    "        self.time_banked = 0.0  # Surplus from fast problems\n",
    "        self.baseline_per_problem = (self.HARD_LIMIT_SECONDS - self.SAFETY_BUFFER) / expected_problems\n",
    "\n",
    "    def elapsed(self) -> float:\n",
    "        \"\"\"Total time elapsed since start.\"\"\"\n",
    "        return time.time() - self.start_time\n",
    "\n",
    "    def remaining(self) -> float:\n",
    "        \"\"\"Time remaining until hard limit.\"\"\"\n",
    "        return max(0, self.HARD_LIMIT_SECONDS - self.elapsed())\n",
    "\n",
    "    def is_expired(self) -> bool:\n",
    "        \"\"\"Have we hit the hard limit?\"\"\"\n",
    "        return self.elapsed() >= self.HARD_LIMIT_SECONDS\n",
    "\n",
    "    def problems_remaining(self) -> int:\n",
    "        \"\"\"Estimated problems left.\"\"\"\n",
    "        return max(1, self.expected_problems - self.problems_completed)\n",
    "\n",
    "    def get_budget_for_next_problem(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculate time budget for next problem.\n",
    "\n",
    "        Uses: remaining_time / remaining_problems + banked_time\n",
    "        But never more than would exceed hard limit.\n",
    "        \"\"\"\n",
    "        if self.is_expired():\n",
    "            return 0\n",
    "\n",
    "        remaining = self.remaining() - self.SAFETY_BUFFER\n",
    "        if remaining <= 0:\n",
    "            return 0\n",
    "\n",
    "        # Base allocation\n",
    "        base = remaining / self.problems_remaining()\n",
    "\n",
    "        # Add banked time (but cap at 2x base to avoid blowing budget)\n",
    "        bonus = min(self.time_banked, base)\n",
    "        budget = base + bonus\n",
    "\n",
    "        # Never exceed remaining time\n",
    "        budget = min(budget, remaining)\n",
    "\n",
    "        # Cap per-problem at 15 minutes max\n",
    "        budget = min(budget, 15 * 60)\n",
    "\n",
    "        return budget\n",
    "\n",
    "    def start_problem(self) -> float:\n",
    "        \"\"\"Call when starting a problem. Returns budget.\"\"\"\n",
    "        return self.get_budget_for_next_problem()\n",
    "\n",
    "    def end_problem(self, actual_time: float, budget: float):\n",
    "        \"\"\"\n",
    "        Call when problem completes.\n",
    "        Banks surplus or tracks deficit.\n",
    "        \"\"\"\n",
    "        self.problems_completed += 1\n",
    "        self.time_spent_per_problem.append(actual_time)\n",
    "\n",
    "        # Calculate surplus/deficit\n",
    "        if actual_time < budget:\n",
    "            # Finished early! Bank the surplus\n",
    "            surplus = budget - actual_time\n",
    "            self.time_banked += surplus * 0.8  # Keep 80% of surplus\n",
    "            print(f\"[TIME] Banked {surplus:.1f}s surplus (total bank: {self.time_banked:.1f}s)\")\n",
    "        else:\n",
    "            # Ran over budget - reduce bank\n",
    "            deficit = actual_time - budget\n",
    "            self.time_banked = max(0, self.time_banked - deficit)\n",
    "            print(f\"[TIME] Deficit {deficit:.1f}s (bank now: {self.time_banked:.1f}s)\")\n",
    "\n",
    "    def should_continue(self, problem_start: float, budget: float) -> bool:\n",
    "        \"\"\"Check if we should keep working on current problem.\"\"\"\n",
    "        # Hard limit check\n",
    "        if self.is_expired():\n",
    "            return False\n",
    "\n",
    "        # Problem budget check\n",
    "        problem_elapsed = time.time() - problem_start\n",
    "        if problem_elapsed > budget:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def status(self) -> str:\n",
    "        \"\"\"Human-readable status.\"\"\"\n",
    "        return (\n",
    "            f\"Elapsed: {self.elapsed()/60:.1f}m | \"\n",
    "            f\"Remaining: {self.remaining()/60:.1f}m | \"\n",
    "            f\"Bank: {self.time_banked:.0f}s | \"\n",
    "            f\"Problems: {self.problems_completed}/{self.expected_problems}\"\n",
    "        )\n",
    "\n",
    "# Initialize global time manager\n",
    "TIME_MANAGER = AdaptiveTimeBudget(expected_problems=100)\n",
    "start_time = TIME_MANAGER.start_time  # For backward compat\n",
    "\n",
    "os.makedirs(\"solutions\", exist_ok=True)\n",
    "\n",
    "# Graceful GPU handling (don't crash if GPU unavailable)\n",
    "GPU_AVAILABLE = torch.cuda.is_available()\n",
    "if GPU_AVAILABLE:\n",
    "    print(f\"[BANSHEEV6] GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"[BANSHEEV6] WARNING: No GPU detected - running in degraded mode\")\n",
    "    # Reduce expectations in CPU mode\n",
    "    TIME_MANAGER.baseline_per_problem *= 0.5\n",
    "\n",
    "print(f\"[BANSHEEV6] Time Budget: {TIME_MANAGER.HARD_LIMIT_SECONDS/3600:.2f}h hard limit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CIC PRIMITIVES + d_CIC + k_emp\n",
    "# From workspace/banshee_run_fixed_v2.py (RunPod validated)\n",
    "# =========================\n",
    "import math\n",
    "import zlib\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "\n",
    "\n",
    "def char_ngrams(s: str, n: int = 4) -> Counter:\n",
    "    \"\"\"Extract character n-grams from text.\"\"\"\n",
    "    s = re.sub(r\"\\s+\", \" \", str(s).strip().lower())\n",
    "    if len(s) < n:\n",
    "        return Counter()\n",
    "    return Counter(s[i:i+n] for i in range(len(s) - n + 1))\n",
    "\n",
    "\n",
    "def cosine_counter(a: Counter, b: Counter) -> float:\n",
    "    \"\"\"Cosine similarity between two Counter objects.\"\"\"\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "    dot = sum(v * b.get(k, 0) for k, v in a.items())\n",
    "    na = math.sqrt(sum(v * v for v in a.values()))\n",
    "    nb = math.sqrt(sum(v * v for v in b.values()))\n",
    "    return dot / (na * nb) if na and nb else 0.0\n",
    "\n",
    "\n",
    "def js_divergence_unigram(a_text: str, b_text: str, eps: float = 1e-12) -> float:\n",
    "    \"\"\"Jensen-Shannon divergence between unigram distributions.\"\"\"\n",
    "    def unigrams(t):\n",
    "        toks = re.findall(r\"\\w+\", str(t).lower())\n",
    "        return Counter(toks)\n",
    "    \n",
    "    A = unigrams(a_text)\n",
    "    B = unigrams(b_text)\n",
    "    keys = set(A) | set(B)\n",
    "    if not keys:\n",
    "        return 0.0\n",
    "    \n",
    "    a_tot = sum(A.values()) + eps * len(keys)\n",
    "    b_tot = sum(B.values()) + eps * len(keys)\n",
    "    js = 0.0\n",
    "    for k in keys:\n",
    "        pa = (A.get(k, 0) + eps) / a_tot\n",
    "        pb = (B.get(k, 0) + eps) / b_tot\n",
    "        m = 0.5 * (pa + pb)\n",
    "        js += 0.5 * (pa * math.log(pa / m) + pb * math.log(pb / m))\n",
    "    return js\n",
    "\n",
    "\n",
    "def tail_similarity_pair(a: str, b: str, window_chars: int = 900, ngram_n: int = 4) -> float:\n",
    "    \"\"\"Tail similarity using char n-grams (from workspace).\"\"\"\n",
    "    try:\n",
    "        if not isinstance(a, str) or not isinstance(b, str):\n",
    "            return 0.0\n",
    "        a_len = min(window_chars, len(a))\n",
    "        b_len = min(window_chars, len(b))\n",
    "        a_tail = a[-a_len:]\n",
    "        b_tail = b[-b_len:]\n",
    "        return cosine_counter(char_ngrams(a_tail, ngram_n), char_ngrams(b_tail, ngram_n))\n",
    "    except:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def tail_similarity(text: str, window_chars: int = 900) -> float:\n",
    "    \"\"\"Self-tail similarity for single text.\"\"\"\n",
    "    return tail_similarity_pair(text, text, window_chars)\n",
    "\n",
    "\n",
    "def repetition_rate(text: str, window_tokens: int = 120) -> float:\n",
    "    \"\"\"Compute repetition rate in tail of text.\"\"\"\n",
    "    toks = re.findall(r\"\\w+|\\S\", str(text).lower())\n",
    "    if len(toks) < window_tokens:\n",
    "        return 0.0\n",
    "    tail = toks[-window_tokens:]\n",
    "    return 1.0 - (len(set(tail)) / len(tail))\n",
    "\n",
    "\n",
    "def d_CIC(P_text: str, Q_text: str, answer_P: Optional[int] = None, answer_Q: Optional[int] = None) -> float:\n",
    "    \"\"\"\n",
    "    CIC Distance function from workspace.\n",
    "    EXACT WEIGHTS: 0.6*JS + 0.3*(1-tail) + 0.1*answer_penalty\n",
    "    \"\"\"\n",
    "    js = js_divergence_unigram(P_text, Q_text)\n",
    "    tail = 1.0 - tail_similarity_pair(P_text, Q_text)\n",
    "    ans_pen = 0.0\n",
    "    if answer_P is not None and answer_Q is not None and answer_P != answer_Q:\n",
    "        ans_pen = 1.0\n",
    "    return 0.6 * js + 0.3 * tail + 0.1 * ans_pen\n",
    "\n",
    "\n",
    "def answer_entropy(answers: List[Optional[int]]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Compute Shannon entropy of answer distribution.\n",
    "    Returns (entropy_nats, entropy_bits).\n",
    "    From workspace/banshee_run_fixed_v2.py\n",
    "    \"\"\"\n",
    "    vals = [a for a in answers if a is not None]\n",
    "    if not vals:\n",
    "        return 0.0, 0.0\n",
    "    cnt = Counter(vals)\n",
    "    total = float(sum(cnt.values()))\n",
    "    ent = 0.0\n",
    "    for c in cnt.values():\n",
    "        p = c / total\n",
    "        ent -= p * math.log(p + 1e-12)\n",
    "    ent = max(ent, 0.0)  # clamp numeric noise\n",
    "    ent_bits = ent / math.log(2.0)\n",
    "    return float(ent), float(ent_bits)\n",
    "\n",
    "\n",
    "def compute_k_emp(d1: float, d2: float, answers: List[Optional[int]]) -> float:\n",
    "    \"\"\"\n",
    "    Compute k_emp (\u03a9-Seed contraction diagnostic).\n",
    "    k_emp = d2/d1, with entropy floor.\n",
    "    From workspace meta: if entropy < 0.5 nats, k_emp = max(k_emp, 0.7)\n",
    "    \"\"\"\n",
    "    eps = 1e-9\n",
    "    d1_safe = max(float(d1), eps)\n",
    "    k_emp = float(d2) / d1_safe\n",
    "    \n",
    "    # Entropy floor from RunPod experiments\n",
    "    H_nats, H_bits = answer_entropy(answers)\n",
    "    H_floor = 0.5  # in nats (~0.72 bits)\n",
    "    k_emp_floor = 0.7\n",
    "    if H_nats < H_floor:\n",
    "        k_emp = max(k_emp, k_emp_floor)\n",
    "    \n",
    "    return k_emp\n",
    "\n",
    "\n",
    "def max_tokens_for_temp(temp: float, min_tokens: int = 256, max_tokens: int = 2048, \n",
    "                        temp_min: float = 0.0, temp_max: float = 1.0, power: float = 1.0) -> int:\n",
    "    \"\"\"\n",
    "    Map temperature -> max tokens. Higher temperature -> more tokens.\n",
    "    From workspace/banshee_run_fixed_v2.py\n",
    "    \"\"\"\n",
    "    t_norm = (max(temp, temp_min) - temp_min) / max(1e-9, (temp_max - temp_min))\n",
    "    frac = t_norm ** float(power)\n",
    "    return int(min_tokens + frac * (max_tokens - min_tokens))\n",
    "\n",
    "\n",
    "def ncd(a: bytes, b: bytes) -> float:\n",
    "    \"\"\"Normalized Compression Distance.\"\"\"\n",
    "    if not a or not b:\n",
    "        return 1.0\n",
    "    try:\n",
    "        ca = len(zlib.compress(a, level=6))\n",
    "        cb = len(zlib.compress(b, level=6))\n",
    "        cab = len(zlib.compress(a + b, level=6))\n",
    "        return (cab - min(ca, cb)) / max(ca, cb, 1)\n",
    "    except:\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CICState:\n",
    "    \"\"\"State for CIC functional computation.\"\"\"\n",
    "    Phi: float  # information integration\n",
    "    H: float    # entropy\n",
    "    C: float    # complexity\n",
    "    F: float    # functional value F = \u03a6 - \u03bbH + \u03b3C\n",
    "    confidence: float\n",
    "    crystallized: bool = False\n",
    "\n",
    "\n",
    "def compute_cic_functional(\n",
    "    samples: List[int],\n",
    "    traces: Optional[List[str]] = None,\n",
    "    lambda_H: float = 0.3,\n",
    "    gamma_C: float = 0.1,\n",
    ") -> CICState:\n",
    "    \"\"\"Compute CIC functional F[T] = \u03a6 - \u03bbH + \u03b3C\"\"\"\n",
    "    if not samples:\n",
    "        return CICState(Phi=0, H=1.0, C=0, F=-0.3, confidence=0.0)\n",
    "    \n",
    "    # Phi: inverse of answer variance (normalized)\n",
    "    vals = [s for s in samples if s is not None]\n",
    "    if len(vals) < 2:\n",
    "        Phi = 1.0\n",
    "    else:\n",
    "        mean = statistics.mean(vals)\n",
    "        var = statistics.variance(vals) if len(vals) > 1 else 0\n",
    "        Phi = 1.0 / (1.0 + math.sqrt(var) / (abs(mean) + 1))\n",
    "    \n",
    "    # H: entropy of answer distribution\n",
    "    H_nats, _ = answer_entropy(samples)\n",
    "    H = H_nats\n",
    "    \n",
    "    # C: trace complexity via NCD (if traces available)\n",
    "    C = 0.0\n",
    "    if traces and len(traces) >= 2:\n",
    "        trace_bytes = [t.encode('utf-8', errors='replace')[:1000] for t in traces[:5]]\n",
    "        ncds = []\n",
    "        for i in range(len(trace_bytes)):\n",
    "            for j in range(i + 1, len(trace_bytes)):\n",
    "                ncds.append(ncd(trace_bytes[i], trace_bytes[j]))\n",
    "        C = 1.0 - statistics.mean(ncds) if ncds else 0.0\n",
    "    \n",
    "    # F = \u03a6 - \u03bbH + \u03b3C\n",
    "    F = Phi - lambda_H * H + gamma_C * C\n",
    "    \n",
    "    # Confidence from F\n",
    "    confidence = max(0.0, min(1.0, 0.5 + 0.5 * F))\n",
    "    \n",
    "    return CICState(Phi=Phi, H=H, C=C, F=F, confidence=confidence)\n",
    "\n",
    "\n",
    "def detect_crystallization(history: List[CICState], min_samples: int = 3) -> bool:\n",
    "    \"\"\"\n",
    "    Detect UIPT crystallization: \u03a6 increasing while H decreasing.\n",
    "    \"\"\"\n",
    "    if len(history) < min_samples:\n",
    "        return False\n",
    "    \n",
    "    recent = history[-min_samples:]\n",
    "    \n",
    "    # Check \u03a6 trend (should be increasing)\n",
    "    phi_increasing = all(recent[i].Phi <= recent[i+1].Phi for i in range(len(recent)-1))\n",
    "    \n",
    "    # Check H trend (should be decreasing)  \n",
    "    h_decreasing = all(recent[i].H >= recent[i+1].H for i in range(len(recent)-1))\n",
    "    \n",
    "    # Check confidence threshold\n",
    "    high_confidence = recent[-1].confidence > 0.8\n",
    "    \n",
    "    # Check low entropy\n",
    "    low_entropy = recent[-1].H < 0.5\n",
    "    \n",
    "    return (phi_increasing and h_decreasing) or (high_confidence and low_entropy)\n",
    "\n",
    "print(\"[BANSHEEV6] CIC Primitives + d_CIC + k_emp: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# VALUE CLUSTERING + LOG-WEIGHTED VOTING\n",
    "# From ryanaimo/selection/clustering.py + zombie_23\n",
    "# 92.1% Error Reduction Method\n",
    "# =========================\n",
    "\n",
    "def relative_distance(a: int, b: int) -> float:\n",
    "    \"\"\"Relative distance: |a-b| / max(|a|,|b|)\"\"\"\n",
    "    if a == b:\n",
    "        return 0.0\n",
    "    if a == 0 or b == 0:\n",
    "        return 1.0 if max(abs(a), abs(b)) > 1000 else abs(a - b) / 1000\n",
    "    return abs(a - b) / max(abs(a), abs(b))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Cluster:\n",
    "    \"\"\"A cluster of similar answer values.\"\"\"\n",
    "    members: List[int]\n",
    "    size: int\n",
    "    center: int\n",
    "    tightness: float\n",
    "    score: float\n",
    "\n",
    "\n",
    "def value_clustering(samples: List[int], threshold: float = 0.05) -> Dict:\n",
    "    \"\"\"Cluster samples by relative value proximity.\"\"\"\n",
    "    n = len(samples)\n",
    "    if n == 0:\n",
    "        return {\"clusters\": [], \"n_clusters\": 0, \"best\": None}\n",
    "    if n == 1:\n",
    "        c = Cluster(members=samples, size=1, center=samples[0], tightness=1.0, score=1.0)\n",
    "        return {\"clusters\": [c], \"n_clusters\": 1, \"best\": c}\n",
    "    \n",
    "    # Union-Find\n",
    "    cluster_id = list(range(n))\n",
    "    def find(i):\n",
    "        if cluster_id[i] != i:\n",
    "            cluster_id[i] = find(cluster_id[i])\n",
    "        return cluster_id[i]\n",
    "    def union(i, j):\n",
    "        ri, rj = find(i), find(j)\n",
    "        if ri != rj:\n",
    "            cluster_id[ri] = rj\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if relative_distance(samples[i], samples[j]) < threshold:\n",
    "                union(i, j)\n",
    "    \n",
    "    # Extract clusters\n",
    "    clusters_dict = {}\n",
    "    for i in range(n):\n",
    "        root = find(i)\n",
    "        if root not in clusters_dict:\n",
    "            clusters_dict[root] = []\n",
    "        clusters_dict[root].append(samples[i])\n",
    "    \n",
    "    clusters = []\n",
    "    for members in clusters_dict.values():\n",
    "        size = len(members)\n",
    "        center = int(statistics.median(members))\n",
    "        \n",
    "        if size == 1:\n",
    "            tightness = 1.0\n",
    "        else:\n",
    "            spread = statistics.stdev(members)\n",
    "            center_abs = abs(statistics.mean(members)) if members else 1\n",
    "            tightness = max(0.0, min(1.0, 1.0 - (spread / center_abs))) if center_abs > 0 else 0.0\n",
    "        \n",
    "        score = size * (tightness ** 0.5)\n",
    "        clusters.append(Cluster(members=members, size=size, center=center, tightness=tightness, score=score))\n",
    "    \n",
    "    clusters.sort(key=lambda c: -c.score)\n",
    "    return {\"clusters\": clusters, \"n_clusters\": len(clusters), \"best\": clusters[0] if clusters else None}\n",
    "\n",
    "\n",
    "def basin_refinement(cluster: Cluster) -> int:\n",
    "    \"\"\"Refine answer to basin center (Platonic Form).\"\"\"\n",
    "    members = cluster.members\n",
    "    if len(members) <= 2:\n",
    "        return int(statistics.median(members))\n",
    "    \n",
    "    median_val = statistics.median(members)\n",
    "    sorted_m = sorted(members)\n",
    "    trim = max(1, len(sorted_m) // 4)\n",
    "    trimmed = sorted_m[trim:-trim] if len(sorted_m) > 2 * trim else sorted_m\n",
    "    trimmed_mean = statistics.mean(trimmed)\n",
    "    \n",
    "    return int((median_val + trimmed_mean) / 2)\n",
    "\n",
    "\n",
    "def log_weighted_vote(samples: List[int]) -> Tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Log-weighted voting from zombie_23.\n",
    "    Weight = log(1.25 + |value|) * count\n",
    "    Penalizes small guesses (0, 1, 2...) which are often wrong.\n",
    "    \"\"\"\n",
    "    if not samples:\n",
    "        return 0, 0.0\n",
    "    \n",
    "    counter = Counter(samples)\n",
    "    weighted_scores = {}\n",
    "    \n",
    "    for value, count in counter.items():\n",
    "        # Log weight penalizes small values\n",
    "        weight = math.log(1.25 + abs(value)) * count\n",
    "        weighted_scores[value] = weight\n",
    "    \n",
    "    best_value = max(weighted_scores, key=weighted_scores.get)\n",
    "    total_weight = sum(weighted_scores.values())\n",
    "    confidence = weighted_scores[best_value] / total_weight if total_weight > 0 else 0.0\n",
    "    \n",
    "    return best_value, confidence\n",
    "\n",
    "\n",
    "def toroidal_vote(samples: List[int], modulus: int = 100000) -> Tuple[int, float]:\n",
    "    \"\"\"\n",
    "    Toroidal voting for modular answers.\n",
    "    Uses circular statistics to handle wraparound.\n",
    "    From 13DEC2025 MATH BREAKTHROUGH - TBT (Toroidal Basis Theorem).\n",
    "    \"\"\"\n",
    "    if not samples:\n",
    "        return 0, 0.0\n",
    "    \n",
    "    # Convert to angles on unit circle\n",
    "    angles = [2 * math.pi * (s % modulus) / modulus for s in samples]\n",
    "    \n",
    "    # Circular mean\n",
    "    sin_sum = sum(math.sin(a) for a in angles)\n",
    "    cos_sum = sum(math.cos(a) for a in angles)\n",
    "    \n",
    "    mean_angle = math.atan2(sin_sum, cos_sum)\n",
    "    if mean_angle < 0:\n",
    "        mean_angle += 2 * math.pi\n",
    "    \n",
    "    # Convert back to value\n",
    "    mean_value = int((mean_angle / (2 * math.pi)) * modulus) % modulus\n",
    "    \n",
    "    # Circular variance for confidence\n",
    "    R = math.sqrt(sin_sum**2 + cos_sum**2) / len(samples)\n",
    "    confidence = R  # R \u2208 [0,1], higher = more concentrated\n",
    "    \n",
    "    return mean_value, confidence\n",
    "\n",
    "\n",
    "def ncd_trace_similarity(traces: List[str]) -> float:\n",
    "    \"\"\"\n",
    "    Compute average pairwise NCD between traces.\n",
    "    Low NCD = similar reasoning = higher confidence.\n",
    "    \"\"\"\n",
    "    if len(traces) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    trace_bytes = [t.encode('utf-8', errors='replace')[:2000] for t in traces]  # Truncate for speed\n",
    "    ncds = []\n",
    "    \n",
    "    for i in range(min(5, len(traces))):  # Sample at most 5 pairs for speed\n",
    "        for j in range(i + 1, min(5, len(traces))):\n",
    "            ncds.append(ncd(trace_bytes[i], trace_bytes[j]))\n",
    "    \n",
    "    return statistics.mean(ncds) if ncds else 0.5\n",
    "\n",
    "\n",
    "def select_answer_cic(\n",
    "    samples: List[int],\n",
    "    traces: Optional[List[str]] = None,\n",
    "    threshold: float = 0.05,\n",
    "    fallback: int = 0,\n",
    ") -> Tuple[int, float, Dict]:\n",
    "    \"\"\"\n",
    "    Full CIC-aware answer selection with multiple voting methods.\n",
    "    \n",
    "    Strategy:\n",
    "    1. Try value clustering (best for near-misses)\n",
    "    2. If cluster is weak, try log-weighted voting (penalizes small answers)\n",
    "    3. Use NCD trace similarity for confidence adjustment\n",
    "    \"\"\"\n",
    "    if not samples:\n",
    "        return fallback, 0.05, {}\n",
    "    \n",
    "    result = value_clustering(samples, threshold)\n",
    "    \n",
    "    if result[\"best\"] is None:\n",
    "        # Fallback to log-weighted\n",
    "        answer, conf = log_weighted_vote(samples)\n",
    "        return answer, conf, result\n",
    "    \n",
    "    best = result[\"best\"]\n",
    "    \n",
    "    # If cluster is small or weak, consider log-weighted as alternative\n",
    "    if best.size < len(samples) * 0.3 or best.tightness < 0.5:\n",
    "        log_answer, log_conf = log_weighted_vote(samples)\n",
    "        # If log-weighted gives different answer with decent confidence, flag it\n",
    "        if log_answer != best.center and log_conf > 0.4:\n",
    "            result[\"log_weighted_alt\"] = {\"answer\": log_answer, \"confidence\": log_conf}\n",
    "    \n",
    "    answer = basin_refinement(best)\n",
    "    \n",
    "    # Compute CIC confidence\n",
    "    cic = compute_cic_functional(samples, traces)\n",
    "    size_factor = min(1.0, best.size / len(samples))\n",
    "    confidence = 0.3 + 0.5 * cic.confidence + 0.2 * size_factor * best.tightness\n",
    "    \n",
    "    # Adjust confidence based on trace similarity (if available)\n",
    "    if traces and len(traces) >= 2:\n",
    "        trace_sim = ncd_trace_similarity(traces)\n",
    "        # Low NCD = similar traces = boost confidence\n",
    "        if trace_sim < 0.3:\n",
    "            confidence = min(0.95, confidence + 0.1)\n",
    "        elif trace_sim > 0.7:\n",
    "            confidence = max(0.1, confidence - 0.1)\n",
    "        result[\"trace_similarity\"] = trace_sim\n",
    "    \n",
    "    result[\"cic\"] = cic\n",
    "    return answer, confidence, result\n",
    "\n",
    "print(\"[BANSHEEV6] Value Clustering + Log-Weighted Voting: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PROBLEM TYPE DETECTION + ANSWER EXTRACTION\n",
    "# =========================\n",
    "\n",
    "# Problem type keywords for routing to best prompts\n",
    "PROBLEM_TYPES = {\n",
    "    \"number_theory\": [\n",
    "        \"divisor\", \"prime\", \"factor\", \"gcd\", \"lcm\", \"modulo\", \"mod \", \"remainder\",\n",
    "        \"congruent\", \"coprime\", \"euler\", \"fermat\", \"diophantine\", \"integer solution\"\n",
    "    ],\n",
    "    \"combinatorics\": [\n",
    "        \"permutation\", \"combination\", \"count\", \"how many\", \"ways to\", \"arrange\",\n",
    "        \"choose\", \"select\", \"subset\", \"partition\", \"distribute\", \"binomial\"\n",
    "    ],\n",
    "    \"algebra\": [\n",
    "        \"polynomial\", \"equation\", \"root\", \"solve for\", \"find all\", \"function\",\n",
    "        \"inequality\", \"maximum\", \"minimum\", \"optimize\", \"sum of\", \"product of\"\n",
    "    ],\n",
    "    \"geometry\": [\n",
    "        \"triangle\", \"circle\", \"angle\", \"area\", \"perimeter\", \"radius\", \"diameter\",\n",
    "        \"tangent\", \"perpendicular\", \"parallel\", \"polygon\", \"coordinate\", \"distance\"\n",
    "    ],\n",
    "    \"sequence\": [\n",
    "        \"sequence\", \"series\", \"recurrence\", \"fibonacci\", \"arithmetic\", \"geometric\",\n",
    "        \"term\", \"sum of first\", \"nth term\", \"pattern\"\n",
    "    ],\n",
    "    \"game_theory\": [\n",
    "        \"game\", \"player\", \"strategy\", \"winning\", \"optimal\", \"move\", \"turn\",\n",
    "        \"alice\", \"bob\", \"first player\", \"second player\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Map problem types to best prompt indices (from SYSTEM_PROMPTS)\n",
    "PROMPT_ROUTING = {\n",
    "    \"number_theory\": [13, 22, 29, 23],  # Modular, NT deep dive, Diophantine, Coloring\n",
    "    \"combinatorics\": [12, 18, 21, 11],  # Bijection, Pigeonhole, Probabilistic, Generating func\n",
    "    \"algebra\": [11, 24, 26, 10],         # Gen func, Inequalities, Polynomial, Constraint prop\n",
    "    \"geometry\": [14, 15, 10, 3],         # Geometry->Algebra, Extremal, Invariant\n",
    "    \"sequence\": [17, 20, 11, 25],        # Recurrence, Induction, Gen func, Sequence analysis\n",
    "    \"game_theory\": [27, 28, 15, 3],      # Game theory, Coloring, Extremal, Invariant\n",
    "}\n",
    "\n",
    "\n",
    "def detect_problem_type(problem_text: str) -> Tuple[str, float]:\n",
    "    \"\"\"\n",
    "    Detect problem type from text.\n",
    "    Returns (type, confidence).\n",
    "    \"\"\"\n",
    "    text_lower = problem_text.lower()\n",
    "    scores = {}\n",
    "    \n",
    "    for ptype, keywords in PROBLEM_TYPES.items():\n",
    "        score = sum(1 for kw in keywords if kw in text_lower)\n",
    "        scores[ptype] = score\n",
    "    \n",
    "    if not scores or max(scores.values()) == 0:\n",
    "        return \"general\", 0.0\n",
    "    \n",
    "    best_type = max(scores, key=scores.get)\n",
    "    total = sum(scores.values())\n",
    "    confidence = scores[best_type] / total if total > 0 else 0.0\n",
    "    \n",
    "    return best_type, confidence\n",
    "\n",
    "\n",
    "def get_routed_prompts(problem_text: str, num_prompts: int = 8) -> List[int]:\n",
    "    \"\"\"\n",
    "    Get best prompt indices for this problem type.\n",
    "    Returns mix of type-specific and general prompts.\n",
    "    \"\"\"\n",
    "    ptype, conf = detect_problem_type(problem_text)\n",
    "    \n",
    "    if ptype in PROMPT_ROUTING and conf > 0.3:\n",
    "        # Use type-specific prompts\n",
    "        specific = PROMPT_ROUTING[ptype]\n",
    "        # Fill remaining with general prompts\n",
    "        general = [0, 1, 2, 3, 4, 5, 6, 7]  # First 8 are general\n",
    "        \n",
    "        # Interleave: specific, general, specific, general...\n",
    "        result = []\n",
    "        for i in range(num_prompts):\n",
    "            if i % 2 == 0 and i // 2 < len(specific):\n",
    "                result.append(specific[i // 2])\n",
    "            elif i // 2 < len(general):\n",
    "                result.append(general[i // 2])\n",
    "            else:\n",
    "                result.append(i % len(SYSTEM_PROMPTS))\n",
    "        return result\n",
    "    else:\n",
    "        # General problem - use first N prompts\n",
    "        return list(range(min(num_prompts, len(SYSTEM_PROMPTS))))\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ENHANCED ANSWER EXTRACTION\n",
    "# =========================\n",
    "\n",
    "def extract_boxed_answer(text: str) -> Optional[int]:\n",
    "    \"\"\"Extract integer from \\\\boxed{}.\"\"\"\n",
    "    patterns = [\n",
    "        r'\\\\boxed\\{(\\d+)\\}',\n",
    "        r'\\\\boxed\\s*\\{(\\d+)\\}',\n",
    "        r'boxed\\{(\\d+)\\}',\n",
    "        r'\\\\boxed\\{\\\\s*(\\d+)\\\\s*\\}',\n",
    "        r'\\$\\\\boxed\\{(\\d+)\\}\\$',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        if matches:\n",
    "            try:\n",
    "                val = int(matches[-1])\n",
    "                if 0 <= val <= 99999:\n",
    "                    return val\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_answer_is(text: str) -> Optional[int]:\n",
    "    \"\"\"Extract from 'answer is X' patterns.\"\"\"\n",
    "    patterns = [\n",
    "        r'(?:the\\s+)?(?:final\\s+)?answer\\s*(?:is|=|:)\\s*[\\\\$]*(\\d+)[\\\\$]*',\n",
    "        r'(?:therefore|thus|hence|so)\\s*[,.]?\\s*(?:the\\s+)?answer\\s*(?:is|=|:)?\\s*[\\\\$]*(\\d+)',\n",
    "        r'=\\s*[\\\\$]*(\\d+)[\\\\$]*\\s*$',\n",
    "        r'answer\\s*:\\s*[\\\\$]*(\\d+)',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
    "        if matches:\n",
    "            try:\n",
    "                val = int(matches[-1])\n",
    "                if 0 <= val <= 99999:\n",
    "                    return val\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_remainder_answer(text: str) -> Optional[int]:\n",
    "    \"\"\"Extract from 'remainder is X' for modular problems.\"\"\"\n",
    "    patterns = [\n",
    "        r'remainder\\s*(?:is|=|:)\\s*[\\\\$]*(\\d+)',\n",
    "        r'\u2261\\s*(\\d+)\\s*\\(?mod',\n",
    "        r'mod\\s*\\d+\\s*[)=]\\s*(\\d+)',\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        if matches:\n",
    "            try:\n",
    "                val = int(matches[-1])\n",
    "                if 0 <= val <= 99999:\n",
    "                    return val\n",
    "            except ValueError:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_any_answer(text: str) -> Optional[int]:\n",
    "    \"\"\"Extract answer from any format, with priority order.\"\"\"\n",
    "    # Priority 1: Boxed (most explicit)\n",
    "    boxed = extract_boxed_answer(text)\n",
    "    if boxed is not None:\n",
    "        return boxed\n",
    "    \n",
    "    # Priority 2: \"answer is X\"\n",
    "    answer_is = extract_answer_is(text)\n",
    "    if answer_is is not None:\n",
    "        return answer_is\n",
    "    \n",
    "    # Priority 3: Remainder (for modular problems)\n",
    "    remainder = extract_remainder_answer(text)\n",
    "    if remainder is not None:\n",
    "        return remainder\n",
    "    \n",
    "    # Priority 4: Last number in final 500 chars\n",
    "    tail = text[-500:]\n",
    "    numbers = re.findall(r'\\b(\\d{1,5})\\b', tail)\n",
    "    if numbers:\n",
    "        try:\n",
    "            val = int(numbers[-1])\n",
    "            if 0 <= val <= 99999:\n",
    "                return val\n",
    "        except ValueError:\n",
    "            pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def validate_proof_output(text: str) -> Tuple[bool, List[str]]:\n",
    "    \"\"\"Validate generated proof output.\"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    # Check bracket balance (simplified)\n",
    "    open_count = text.count('(') + text.count('[') + text.count('{')\n",
    "    close_count = text.count(')') + text.count(']') + text.count('}')\n",
    "    if abs(open_count - close_count) > 5:\n",
    "        issues.append(\"unbalanced_brackets\")\n",
    "    \n",
    "    # Check for repetition loops (>3 identical phrases)\n",
    "    words = text.lower().split()\n",
    "    if len(words) > 50:\n",
    "        for window in [10, 20]:\n",
    "            if len(words) >= 2 * window:\n",
    "                tail1 = ' '.join(words[-window:])\n",
    "                tail2 = ' '.join(words[-2*window:-window])\n",
    "                if tail1 == tail2:\n",
    "                    issues.append(f\"repetition_loop_{window}\")\n",
    "                    break\n",
    "    \n",
    "    # Check for suspicious patterns\n",
    "    if text.count('...') > 10:\n",
    "        issues.append(\"excessive_ellipsis\")\n",
    "    \n",
    "    return len(issues) == 0, issues\n",
    "\n",
    "print(\"[BANSHEEV6] Problem Type Detection + Answer Extraction: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# DIFFICULTY CLASSIFIER (Tier 2)\n",
    "# =========================\n",
    "# Cheap heuristic to route problems to appropriate strategies.\n",
    "# NO LLM calls - pure text analysis.\n",
    "# =========================\n",
    "\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "\n",
    "\n",
    "class Difficulty(Enum):\n",
    "    EASY = \"easy\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HARD = \"hard\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DifficultyAssessment:\n",
    "    \"\"\"Result of difficulty classification.\"\"\"\n",
    "    level: Difficulty\n",
    "    confidence: float  # 0-1\n",
    "    signals: Dict[str, float]  # Individual signal scores\n",
    "    recommended_samples: int\n",
    "    recommended_max_tokens: int\n",
    "\n",
    "\n",
    "# === SIGNAL DETECTORS ===\n",
    "\n",
    "def signal_text_length(text: str) -> float:\n",
    "    \"\"\"Longer problems tend to be harder. Returns 0-1.\"\"\"\n",
    "    length = len(text)\n",
    "    if length < 200:\n",
    "        return 0.0  # Very short = likely easy\n",
    "    elif length < 500:\n",
    "        return 0.3\n",
    "    elif length < 1000:\n",
    "        return 0.6\n",
    "    else:\n",
    "        return 1.0  # Long = likely hard\n",
    "\n",
    "\n",
    "def signal_symbol_density(text: str) -> float:\n",
    "    \"\"\"Mathematical symbol density. Returns 0-1.\"\"\"\n",
    "    # Count math symbols\n",
    "    math_symbols = len(re.findall(r'[+\\-*/^=<>\u2264\u2265\u2260\u2208\u2209\u2286\u2287\u2229\u222a\u2200\u2203\u2211\u220f\u222b\u221a\u03c0\u03b8\u03c6\u03b1\u03b2\u03b3\u03b4\u03b5]', text))\n",
    "    # Count LaTeX commands\n",
    "    latex_cmds = len(re.findall(r'\\\\[a-zA-Z]+', text))\n",
    "    # Count fractions, exponents\n",
    "    fractions = len(re.findall(r'\\\\frac|\\\\dfrac|/\\s*\\d+', text))\n",
    "    \n",
    "    total = math_symbols + latex_cmds * 2 + fractions * 3\n",
    "    length = max(len(text), 1)\n",
    "    density = total / length * 100\n",
    "    \n",
    "    if density < 1:\n",
    "        return 0.2\n",
    "    elif density < 3:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.9\n",
    "\n",
    "\n",
    "def signal_hard_keywords(text: str) -> float:\n",
    "    \"\"\"Keywords indicating hard problems. Returns 0-1.\"\"\"\n",
    "    t = text.lower()\n",
    "    \n",
    "    hard_keywords = [\n",
    "        \"prove\", \"show that\", \"for all\", \"for every\", \"for any\",\n",
    "        \"if and only if\", \"iff\", \"necessary and sufficient\",\n",
    "        \"infinitely many\", \"uncountable\", \"bijection\",\n",
    "        \"induction\", \"contradiction\", \"contrapositive\",\n",
    "        \"without loss of generality\", \"wlog\",\n",
    "        \"construct\", \"determine all\", \"find all\",\n",
    "        \"characterize\", \"classify\",\n",
    "    ]\n",
    "    \n",
    "    hard_count = sum(1 for kw in hard_keywords if kw in t)\n",
    "    \n",
    "    if hard_count == 0:\n",
    "        return 0.0\n",
    "    elif hard_count <= 2:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "\n",
    "def signal_easy_keywords(text: str) -> float:\n",
    "    \"\"\"Keywords indicating easier problems. Returns 0-1 (inverted).\"\"\"\n",
    "    t = text.lower()\n",
    "    \n",
    "    easy_keywords = [\n",
    "        \"compute\", \"calculate\", \"evaluate\", \"simplify\",\n",
    "        \"what is\", \"find the value\", \"find the sum\",\n",
    "        \"find the product\", \"find the remainder\",\n",
    "        \"how many\", \"count the number\",\n",
    "    ]\n",
    "    \n",
    "    easy_count = sum(1 for kw in easy_keywords if kw in t)\n",
    "    \n",
    "    if easy_count >= 2:\n",
    "        return 0.0  # Multiple easy keywords = likely easy\n",
    "    elif easy_count == 1:\n",
    "        return 0.3\n",
    "    else:\n",
    "        return 0.6  # No easy keywords = might be harder\n",
    "\n",
    "\n",
    "def signal_numeric_complexity(text: str) -> float:\n",
    "    \"\"\"Complexity from numbers in problem. Returns 0-1.\"\"\"\n",
    "    numbers = re.findall(r'\\b\\d+\\b', text)\n",
    "    \n",
    "    if not numbers:\n",
    "        return 0.5  # No numbers = could be abstract/hard\n",
    "    \n",
    "    # Check for large numbers\n",
    "    max_num = max(int(n) for n in numbers if len(n) <= 10)\n",
    "    num_count = len(numbers)\n",
    "    \n",
    "    # Many numbers or large numbers = harder computation\n",
    "    if max_num > 10000 or num_count > 10:\n",
    "        return 0.8\n",
    "    elif max_num > 100 or num_count > 5:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.2\n",
    "\n",
    "\n",
    "def signal_nested_structure(text: str) -> float:\n",
    "    \"\"\"Nested quantifiers, conditions indicate complexity. Returns 0-1.\"\"\"\n",
    "    t = text.lower()\n",
    "    \n",
    "    # Count nested structures\n",
    "    quantifiers = len(re.findall(r'\\b(for all|for every|for each|there exists|such that)\\b', t))\n",
    "    conditionals = len(re.findall(r'\\b(if|when|whenever|unless|provided)\\b', t))\n",
    "    parts = len(re.findall(r'\\b(part [a-z]|\\([a-z]\\)|[a-z]\\)|i+\\.|\\d+\\.)\\b', t))\n",
    "    \n",
    "    nesting = quantifiers + conditionals * 0.5 + parts * 0.3\n",
    "    \n",
    "    if nesting < 2:\n",
    "        return 0.2\n",
    "    elif nesting < 5:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.9\n",
    "\n",
    "\n",
    "def signal_competition_markers(text: str) -> float:\n",
    "    \"\"\"Markers of competition-level difficulty. Returns 0-1.\"\"\"\n",
    "    t = text.lower()\n",
    "    \n",
    "    comp_markers = [\n",
    "        \"imo\", \"usamo\", \"putnam\", \"olympiad\",\n",
    "        \"aime\", \"amc\", \"mathcounts\",\n",
    "        \"competition\", \"contest\",\n",
    "    ]\n",
    "    \n",
    "    # IMO/USAMO/Putnam = very hard\n",
    "    if any(m in t for m in [\"imo\", \"usamo\", \"putnam\"]):\n",
    "        return 1.0\n",
    "    elif any(m in t for m in comp_markers):\n",
    "        return 0.7\n",
    "    else:\n",
    "        return 0.3\n",
    "\n",
    "\n",
    "# === MAIN CLASSIFIER ===\n",
    "\n",
    "def classify_difficulty(problem_text: str) -> DifficultyAssessment:\n",
    "    \"\"\"\n",
    "    Classify problem difficulty using cheap text signals.\n",
    "    \n",
    "    Returns assessment with:\n",
    "    - level: EASY, MEDIUM, or HARD\n",
    "    - confidence: how sure we are\n",
    "    - signals: breakdown of individual scores\n",
    "    - recommended_samples: how many LLM samples to use\n",
    "    - recommended_max_tokens: token budget per sample\n",
    "    \"\"\"\n",
    "    signals = {\n",
    "        \"length\": signal_text_length(problem_text),\n",
    "        \"symbols\": signal_symbol_density(problem_text),\n",
    "        \"hard_kw\": signal_hard_keywords(problem_text),\n",
    "        \"easy_kw\": signal_easy_keywords(problem_text),\n",
    "        \"numeric\": signal_numeric_complexity(problem_text),\n",
    "        \"nested\": signal_nested_structure(problem_text),\n",
    "        \"competition\": signal_competition_markers(problem_text),\n",
    "    }\n",
    "    \n",
    "    # Weighted combination\n",
    "    weights = {\n",
    "        \"length\": 0.10,\n",
    "        \"symbols\": 0.15,\n",
    "        \"hard_kw\": 0.25,\n",
    "        \"easy_kw\": 0.20,\n",
    "        \"numeric\": 0.10,\n",
    "        \"nested\": 0.10,\n",
    "        \"competition\": 0.10,\n",
    "    }\n",
    "    \n",
    "    # Compute weighted score (0 = easy, 1 = hard)\n",
    "    score = sum(signals[k] * weights[k] for k in signals)\n",
    "    \n",
    "    # Determine level\n",
    "    if score < 0.35:\n",
    "        level = Difficulty.EASY\n",
    "        recommended_samples = 2\n",
    "        recommended_max_tokens = 1024\n",
    "    elif score < 0.65:\n",
    "        level = Difficulty.MEDIUM\n",
    "        recommended_samples = 4\n",
    "        recommended_max_tokens = 1536\n",
    "    else:\n",
    "        level = Difficulty.HARD\n",
    "        recommended_samples = 3  # Fewer but more careful\n",
    "        recommended_max_tokens = 2048\n",
    "    \n",
    "    # Confidence based on signal agreement\n",
    "    signal_values = list(signals.values())\n",
    "    variance = sum((s - score) ** 2 for s in signal_values) / len(signal_values)\n",
    "    confidence = max(0.3, 1.0 - variance)\n",
    "    \n",
    "    return DifficultyAssessment(\n",
    "        level=level,\n",
    "        confidence=confidence,\n",
    "        signals=signals,\n",
    "        recommended_samples=recommended_samples,\n",
    "        recommended_max_tokens=recommended_max_tokens,\n",
    "    )\n",
    "\n",
    "\n",
    "# === ROUTING STRATEGIES ===\n",
    "\n",
    "@dataclass  \n",
    "class SolveStrategy:\n",
    "    \"\"\"Strategy for solving based on difficulty.\"\"\"\n",
    "    max_samples: int\n",
    "    max_tokens_per_sample: int\n",
    "    temperature_start: float\n",
    "    temperature_end: float\n",
    "    early_exit_threshold: float  # Confidence needed for early exit\n",
    "    use_verification: bool\n",
    "    use_clustering: bool\n",
    "\n",
    "\n",
    "STRATEGIES = {\n",
    "    Difficulty.EASY: SolveStrategy(\n",
    "        max_samples=2,\n",
    "        max_tokens_per_sample=1024,  # EASY\n",
    "        temperature_start=0.7,\n",
    "        temperature_end=0.3,\n",
    "        early_exit_threshold=0.7,  # Exit quickly on easy problems\n",
    "        use_verification=True,\n",
    "        use_clustering=False,  # Not needed for easy\n",
    "    ),\n",
    "    Difficulty.MEDIUM: SolveStrategy(\n",
    "        max_samples=4,\n",
    "        max_tokens_per_sample=1600,  # MEDIUM: H100 headroom\n",
    "        temperature_start=1.0,\n",
    "        temperature_end=0.4,\n",
    "        early_exit_threshold=0.8,\n",
    "        use_verification=True,\n",
    "        use_clustering=True,\n",
    "    ),\n",
    "    Difficulty.HARD: SolveStrategy(\n",
    "        max_samples=3,\n",
    "        max_tokens_per_sample=2048,  # HARD\n",
    "        temperature_start=1.2,\n",
    "        temperature_end=0.5,\n",
    "        early_exit_threshold=0.9,  # Need high confidence to exit early\n",
    "        use_verification=True,\n",
    "        use_clustering=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def get_strategy(difficulty: DifficultyAssessment) -> SolveStrategy:\n",
    "    \"\"\"Get the solve strategy for a difficulty level.\"\"\"\n",
    "    return STRATEGIES[difficulty.level]\n",
    "\n",
    "\n",
    "print(\"[BANSHEEV6] DifficultyClassifier: EASY/MEDIUM/HARD routing enabled\")\n",
    "print(f\"[BANSHEEV6] Strategy samples: EASY={STRATEGIES[Difficulty.EASY].max_samples}, MEDIUM={STRATEGIES[Difficulty.MEDIUM].max_samples}, HARD={STRATEGIES[Difficulty.HARD].max_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# VERIFICATION LAYER (GUARDIAN-ALIGNED)\n",
    "# =========================\n",
    "# UNIFIED SPEC COMPLIANCE:\n",
    "#\n",
    "# INVARIANT 1: Only PARSEABILITY gates acceptance\n",
    "#   - extract_any_answer() succeeds \u2192 candidate is valid\n",
    "#   - Range 0-99999 is the ONLY hard constraint\n",
    "#\n",
    "# INVARIANT 2: REJECT is illegal in competition mode\n",
    "#   - HARD_CHECKS can flag, not reject\n",
    "#   - Flag = confidence penalty, not gate\n",
    "#\n",
    "# INVARIANT 3: Repairs require explicit justification\n",
    "#   - Only when problem statement implies transformation\n",
    "#   - Never silent, always logged\n",
    "#\n",
    "# INVARIANT 4: PROMETHEUS is sovereign\n",
    "#   - GUARDIAN validates format, not correctness\n",
    "#   - Selection logic (clustering, CIC) is upstream\n",
    "#\n",
    "# CLASSIFICATION:\n",
    "#   DECISION-SAFE: Can influence retry/accept decision\n",
    "#   ANNOTATION-ONLY: Metadata for logging, never gates\n",
    "# =========================\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class VerificationResult:\n",
    "    score: int\n",
    "    passed_checks: List[str]\n",
    "    failed_checks: List[str]\n",
    "    flags: List[str] = None  # ANNOTATION-ONLY metadata\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.flags is None:\n",
    "            self.flags = []\n",
    "\n",
    "\n",
    "# Global verification tracking (best-of storage)\n",
    "question_id_to_verification = defaultdict(dict)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DECISION-SAFE CHECKS\n",
    "# These can return False ONLY when problem text PROVES contradiction\n",
    "# =========================\n",
    "\n",
    "def check_modular_strict(text: str, ans: int) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    DECISION-SAFE: Reject if problem explicitly asks for remainder AND ans >= mod.\n",
    "    \n",
    "    Justification: If problem says \"find remainder when X divided by M\",\n",
    "    the answer MUST be < M. This is mathematical fact, not heuristic.\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "    \n",
    "    # Must explicitly ask for remainder as the answer\n",
    "    is_remainder_problem = bool(\n",
    "        re.search(r'(?:find|compute|what is).*remainder.*(?:divided by|mod)', t) or\n",
    "        re.search(r'(?:find|compute).*mod\\s*\\d+\\s*[.\\?]?\\s*$', t)\n",
    "    )\n",
    "    \n",
    "    if not is_remainder_problem:\n",
    "        return None\n",
    "    \n",
    "    mods = re.findall(r'(?:mod|modulo)\\s*(\\d+)', t)\n",
    "    if not mods:\n",
    "        mods = re.findall(r'divided by\\s*(\\d+)', t)\n",
    "    \n",
    "    if mods:\n",
    "        mod = int(mods[-1])\n",
    "        if mod > 0 and ans >= mod:\n",
    "            return False  # PROVEN: remainder must be < modulus\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def check_explicit_bounds(text: str, ans: int) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    DECISION-SAFE: Reject if explicit bounds in problem are violated.\n",
    "    \n",
    "    Justification: If problem states \"0 <= x <= 100\", answer outside\n",
    "    that range is mathematically impossible.\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "    \n",
    "    # \"answer is between A and B\"\n",
    "    m = re.search(r'(?:answer|result).*(?:between|from)\\s*(\\d+)\\s*(?:and|to)\\s*(\\d+)', t)\n",
    "    if m:\n",
    "        low, high = int(m.group(1)), int(m.group(2))\n",
    "        if not (low <= ans <= high):\n",
    "            return False  # PROVEN: outside stated range\n",
    "    \n",
    "    # \"at most N\"\n",
    "    m = re.search(r'(?:answer|result).*at most\\s*(\\d+)', t)\n",
    "    if m and ans > int(m.group(1)):\n",
    "        return False\n",
    "    \n",
    "    # \"at least N\"\n",
    "    m = re.search(r'(?:answer|result).*at least\\s*(\\d+)', t)\n",
    "    if m and ans < int(m.group(1)):\n",
    "        return False\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def check_divisibility(text: str, ans: int) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    DECISION-SAFE: Reject if explicit divisibility violated.\n",
    "    \n",
    "    Justification: \"answer is divisible by 7\" + ans % 7 != 0 = contradiction.\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "    \n",
    "    m = re.search(r'(?:answer|result).*(?:divisible by|multiple of)\\s*(\\d+)', t)\n",
    "    if m:\n",
    "        d = int(m.group(1))\n",
    "        if d > 0 and ans % d != 0:\n",
    "            return False  # PROVEN: violates divisibility\n",
    "    \n",
    "    if re.search(r'(?:answer|result).*(?:is|must be)\\s*even', t):\n",
    "        if ans % 2 != 0:\n",
    "            return False\n",
    "    \n",
    "    if re.search(r'(?:answer|result).*(?:is|must be)\\s*odd', t):\n",
    "        if ans % 2 != 1:\n",
    "            return False\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def check_congruence(text: str, ans: int) -> Optional[bool]:\n",
    "    \"\"\"\n",
    "    DECISION-SAFE: Reject if explicit congruence violated.\n",
    "    \n",
    "    Justification: \"x \u2261 3 (mod 7)\" + ans % 7 != 3 = contradiction.\n",
    "    \"\"\"\n",
    "    m = re.search(r'[\u2261=]\\s*(\\d+)\\s*\\(?mod\\s*(\\d+)', text.lower())\n",
    "    if m:\n",
    "        r, mod = int(m.group(1)), int(m.group(2))\n",
    "        if mod > 0 and ans % mod != r % mod:\n",
    "            return False  # PROVEN: violates congruence\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# All decision-safe checks\n",
    "DECISION_SAFE_CHECKS = [\n",
    "    check_modular_strict,\n",
    "    check_explicit_bounds,\n",
    "    check_divisibility,\n",
    "    check_congruence,\n",
    "]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# ANNOTATION-ONLY CHECKS\n",
    "# These NEVER return False - only provide metadata\n",
    "# =========================\n",
    "\n",
    "def annotate_counting(text: str, ans: int) -> Optional[str]:\n",
    "    \"\"\"ANNOTATION-ONLY: Flag if counting problem has ans=0.\"\"\"\n",
    "    if \"how many\" in text.lower() and ans == 0:\n",
    "        return \"counting_zero\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def annotate_small_answer(text: str, ans: int) -> Optional[str]:\n",
    "    \"\"\"ANNOTATION-ONLY: Flag small answers for logging.\"\"\"\n",
    "    if ans <= 2:\n",
    "        return f\"small_answer_{ans}\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def annotate_magic_number(text: str, ans: int) -> Optional[str]:\n",
    "    \"\"\"ANNOTATION-ONLY: Flag common magic numbers.\"\"\"\n",
    "    MAGIC = {42, 69, 100, 1000, 12345}\n",
    "    if ans in MAGIC:\n",
    "        return f\"magic_number_{ans}\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def annotate_round_number(text: str, ans: int) -> Optional[str]:\n",
    "    \"\"\"ANNOTATION-ONLY: Flag suspiciously round numbers.\"\"\"\n",
    "    if ans > 0 and ans % 1000 == 0:\n",
    "        return \"round_thousands\"\n",
    "    if ans > 0 and ans % 100 == 0:\n",
    "        return \"round_hundreds\"\n",
    "    return None\n",
    "\n",
    "\n",
    "ANNOTATION_CHECKS = [\n",
    "    annotate_counting,\n",
    "    annotate_small_answer,\n",
    "    annotate_magic_number,\n",
    "    annotate_round_number,\n",
    "]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN VERIFY FUNCTION\n",
    "# =========================\n",
    "\n",
    "def verify_answer(\n",
    "    question_text: str,\n",
    "    ans: int,\n",
    ") -> VerificationResult:\n",
    "    \"\"\"\n",
    "    GUARDIAN-compliant verification.\n",
    "    \n",
    "    INVARIANT: Never rejects based on heuristics.\n",
    "    Only proven contradictions from problem text can fail.\n",
    "    \"\"\"\n",
    "    passed = []\n",
    "    failed = []\n",
    "    flags = []\n",
    "\n",
    "    # HARD GATE: Range (competition format requirement)\n",
    "    if not (0 <= ans <= 99999):\n",
    "        return VerificationResult(\n",
    "            score=0,\n",
    "            passed_checks=[],\n",
    "            failed_checks=[\"range_violation\"],\n",
    "            flags=[\"HARD_GATE: answer outside 0-99999\"]\n",
    "        )\n",
    "    passed.append(\"range\")\n",
    "\n",
    "    # Run decision-safe checks\n",
    "    for check in DECISION_SAFE_CHECKS:\n",
    "        try:\n",
    "            result = check(question_text, ans)\n",
    "            if result is False:\n",
    "                failed.append(check.__name__)\n",
    "            elif result is True:\n",
    "                passed.append(check.__name__)\n",
    "            # None = not applicable, no action\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Run annotation-only checks (metadata, no gating)\n",
    "    for check in ANNOTATION_CHECKS:\n",
    "        try:\n",
    "            flag = check(question_text, ans)\n",
    "            if flag:\n",
    "                flags.append(flag)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Score = passed checks (annotations don't count)\n",
    "    score = len(passed)\n",
    "    \n",
    "    return VerificationResult(\n",
    "        score=score,\n",
    "        passed_checks=passed,\n",
    "        failed_checks=failed,\n",
    "        flags=flags\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# SELECTION (PROMETHEUS-SOVEREIGN)\n",
    "# =========================\n",
    "\n",
    "def select_answer_with_verification(\n",
    "    candidates: List[int],\n",
    "    problem_text: str,\n",
    "    fallback: int\n",
    ") -> Tuple[int, float, dict]:\n",
    "    \"\"\"\n",
    "    GUARDIAN validates, PROMETHEUS selects.\n",
    "    \n",
    "    Decision logic:\n",
    "    1. Verify all candidates\n",
    "    2. Remove only PROVEN contradictions\n",
    "    3. Return best by count (PROMETHEUS is sovereign)\n",
    "    \"\"\"\n",
    "    if not candidates:\n",
    "        return fallback, 0.05, {\"reason\": \"no_candidates\"}\n",
    "    \n",
    "    # Verify and filter\n",
    "    valid_candidates = []\n",
    "    all_results = {}\n",
    "    \n",
    "    for ans in set(candidates):\n",
    "        vr = verify_answer(problem_text, ans)\n",
    "        all_results[ans] = vr\n",
    "        \n",
    "        # Only exclude if DECISION-SAFE check PROVED contradiction\n",
    "        if not vr.failed_checks:\n",
    "            count = candidates.count(ans)\n",
    "            valid_candidates.append((ans, vr.score, count, vr.flags))\n",
    "    \n",
    "    if not valid_candidates:\n",
    "        # All had proven contradictions - use highest-count anyway with warning\n",
    "        counts = Counter(candidates)\n",
    "        best = counts.most_common(1)[0][0]\n",
    "        return best, 0.1, {\"reason\": \"all_failed_using_most_common\", \"warning\": \"GUARDIAN override\"}\n",
    "    \n",
    "    # Sort by count (PROMETHEUS sovereignty), then score as tiebreak\n",
    "    valid_candidates.sort(key=lambda x: (-x[2], -x[1]))\n",
    "    \n",
    "    best_ans, best_score, best_count, best_flags = valid_candidates[0]\n",
    "    confidence = min(0.95, 0.3 + 0.1 * best_score + 0.05 * best_count)\n",
    "    \n",
    "    return best_ans, confidence, {\n",
    "        \"reason\": \"verified\",\n",
    "        \"score\": best_score,\n",
    "        \"count\": best_count,\n",
    "        \"flags\": best_flags\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================\n",
    "# SAFE CRYSTALLIZATION\n",
    "# =========================\n",
    "\n",
    "def detect_safe_crystallization(\n",
    "    samples: List[int],\n",
    "    verifications: Dict[int, VerificationResult],\n",
    "    cic_history: List,\n",
    "    min_samples: int = 4,\n",
    ") -> bool:\n",
    "    \"\"\"Crystallization gated by verification, not heuristics.\"\"\"\n",
    "    if len(samples) < min_samples:\n",
    "        return False\n",
    "\n",
    "    counts = Counter(samples)\n",
    "    top_answer, top_count = counts.most_common(1)[0]\n",
    "\n",
    "    # Must have verification and no proven contradictions\n",
    "    vr = verifications.get(top_answer)\n",
    "    if not vr or vr.failed_checks:\n",
    "        return False\n",
    "\n",
    "    # Must have dominance\n",
    "    if top_count < 2:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# =========================\n",
    "# REGENERATION POLICY\n",
    "# =========================\n",
    "\n",
    "def regeneration_policy(\n",
    "    question_id: str,\n",
    "    question_text: str,\n",
    "    ans: int,\n",
    "    verification: VerificationResult,\n",
    "    attempt_idx: int,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    GUARDIAN-compliant regeneration.\n",
    "    \n",
    "    Returns: \"retry\" (proven contradiction) or \"accept\"\n",
    "    NOTE: \"reject\" is ILLEGAL in competition mode\n",
    "    \"\"\"\n",
    "    # Only retry on proven contradiction\n",
    "    if verification.failed_checks:\n",
    "        return \"retry\"\n",
    "    \n",
    "    return \"accept\"\n",
    "\n",
    "\n",
    "print(\"[BANSHEEV6] GUARDIAN-ALIGNED Verification Layer\")\n",
    "print(f\"[BANSHEEV6] DECISION_SAFE_CHECKS: {len(DECISION_SAFE_CHECKS)}\")\n",
    "print(f\"[BANSHEEV6] ANNOTATION_CHECKS: {len(ANNOTATION_CHECKS)}\")\n",
    "print(\"[BANSHEEV6] INVARIANT: REJECT is illegal, only RETRY on proven contradiction\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SECURE CODE EXECUTION\n",
    "# =========================\n",
    "import multiprocessing as mp\n",
    "\n",
    "def execute_python_code(code: str, timeout: int = 10, memory_limit_mb: int = 512) -> Tuple[bool, str]:\n",
    "    \"\"\"Secure Python execution with hard limits. NEVER hangs.\"\"\"\n",
    "    def run_code(code: str, result_queue: mp.Queue):\n",
    "        try:\n",
    "            resource.setrlimit(resource.RLIMIT_AS, (memory_limit_mb * 1024 * 1024, memory_limit_mb * 1024 * 1024))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        import sys\n",
    "        from io import StringIO\n",
    "\n",
    "        old_stdout, old_stderr = sys.stdout, sys.stderr\n",
    "        sys.stdout = captured_out = StringIO()\n",
    "        sys.stderr = captured_err = StringIO()\n",
    "\n",
    "        try:\n",
    "            safe_globals = {\n",
    "                '__builtins__': {\n",
    "                    'print': print, 'range': range, 'len': len, 'sum': sum,\n",
    "                    'min': min, 'max': max, 'abs': abs, 'int': int, 'float': float,\n",
    "                    'str': str, 'list': list, 'dict': dict, 'set': set, 'tuple': tuple,\n",
    "                    'sorted': sorted, 'enumerate': enumerate, 'zip': zip,\n",
    "                    'pow': pow, 'round': round, 'divmod': divmod,\n",
    "                    'True': True, 'False': False, 'None': None,\n",
    "                    'bool': bool, 'type': type, 'isinstance': isinstance,\n",
    "                },\n",
    "            }\n",
    "\n",
    "            import math as safe_math\n",
    "            import itertools as safe_itertools\n",
    "            import fractions as safe_fractions\n",
    "            import decimal as safe_decimal\n",
    "            import collections as safe_collections\n",
    "\n",
    "            safe_globals['math'] = safe_math\n",
    "            safe_globals['itertools'] = safe_itertools\n",
    "            safe_globals['fractions'] = safe_fractions\n",
    "            safe_globals['decimal'] = safe_decimal\n",
    "            safe_globals['collections'] = safe_collections\n",
    "\n",
    "            exec(code, safe_globals)\n",
    "            output = captured_out.getvalue() + captured_err.getvalue()\n",
    "            result_queue.put((True, output.strip() or \"OK\"))\n",
    "\n",
    "        except MemoryError:\n",
    "            result_queue.put((False, f\"MemoryError: Exceeded {memory_limit_mb}MB\"))\n",
    "        except Exception as e:\n",
    "            result_queue.put((False, f\"{type(e).__name__}: {str(e)[:100]}\"))\n",
    "        finally:\n",
    "            sys.stdout, sys.stderr = old_stdout, old_stderr\n",
    "\n",
    "    result_queue = mp.Queue()\n",
    "    proc = mp.Process(target=run_code, args=(code, result_queue))\n",
    "    proc.start()\n",
    "    proc.join(timeout)\n",
    "\n",
    "    if proc.is_alive():\n",
    "        proc.terminate()\n",
    "        proc.join(2)\n",
    "        if proc.is_alive():\n",
    "            proc.kill()\n",
    "            proc.join(1)\n",
    "        return (False, f\"Timeout after {timeout}s\")\n",
    "\n",
    "    # CRITICAL: Queue.get() with timeout to prevent hang\n",
    "    try:\n",
    "        return result_queue.get(timeout=1)\n",
    "    except:\n",
    "        return (False, \"No result (queue timeout)\")\n",
    "\n",
    "\n",
    "def extract_python_blocks(text: str) -> List[str]:\n",
    "    \"\"\"Extract ```python blocks.\"\"\"\n",
    "    blocks = re.findall(r\"```python\\s*(.*?)```\", text, re.DOTALL | re.IGNORECASE)\n",
    "    if not blocks:\n",
    "        blocks = re.findall(r\"```\\s*(.*?)```\", text, re.DOTALL)\n",
    "    return [b.strip() for b in blocks if b.strip()]\n",
    "\n",
    "print(\"[BANSHEEV6] Code Execution: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# TIME MANAGEMENT HELPERS\n",
    "# (Uses AdaptiveTimeBudget from cell-2)\n",
    "# =========================\n",
    "\n",
    "def get_time_budget_per_problem() -> float:\n",
    "    \"\"\"Get current budget from TIME_MANAGER.\"\"\"\n",
    "    return TIME_MANAGER.get_budget_for_next_problem()\n",
    "\n",
    "\n",
    "def should_continue_generation(question_id: str, start_t: float, completed_ids: set, budget: float) -> bool:\n",
    "    \"\"\"Check if we should keep generating.\"\"\"\n",
    "    # Already completed this question\n",
    "    if question_id in completed_ids:\n",
    "        return False\n",
    "\n",
    "    # Use TIME_MANAGER for consistent checking\n",
    "    if not TIME_MANAGER.should_continue(start_t, budget):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "print(\"[BANSHEEV6] Time Management Helpers: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VLLM SERVER - LAZY STARTUP WITH PREFLIGHT VALIDATION\n",
    "# =============================================================================\n",
    "# ChatGPT Review Compliance:\n",
    "#   1. Preflight checks run at import (lightweight, won't block serve())\n",
    "#   2. Model path validated before subprocess launch\n",
    "#   3. vLLM import validated before assuming it exists\n",
    "#   4. Clear logging for debugging failed submissions\n",
    "# =============================================================================\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "MODEL_PATH = \"/kaggle/input/gpt-oss-120b/transformers/default/1\"\n",
    "VLLM_HOST = \"0.0.0.0\"\n",
    "VLLM_PORT = 8000\n",
    "\n",
    "# === PREFLIGHT VALIDATION ===\n",
    "_PREFLIGHT_PASSED = False\n",
    "_VLLM_AVAILABLE = False\n",
    "\n",
    "def run_preflight():\n",
    "    \"\"\"\n",
    "    Lightweight preflight checks at import time.\n",
    "    MUST NOT block or do heavy work - just validate environment.\n",
    "    \"\"\"\n",
    "    global _PREFLIGHT_PASSED, _VLLM_AVAILABLE\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"[PREFLIGHT] Running environment validation...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    # Check 1: vLLM installed?\n",
    "    try:\n",
    "        import vllm\n",
    "        print(f\"[PREFLIGHT] \u2713 vLLM installed: v{vllm.__version__}\")\n",
    "        _VLLM_AVAILABLE = True\n",
    "    except ImportError as e:\n",
    "        print(f\"[PREFLIGHT] \u2717 vLLM NOT INSTALLED: {e}\")\n",
    "        errors.append(\"vllm_missing\")\n",
    "    \n",
    "    # Check 2: CUDA available?\n",
    "    try:\n",
    "        import torch\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            print(f\"[PREFLIGHT] \u2713 CUDA available: {gpu_name} ({gpu_mem:.1f}GB)\")\n",
    "        else:\n",
    "            print(\"[PREFLIGHT] \u2717 CUDA NOT AVAILABLE - vLLM will fail!\")\n",
    "            errors.append(\"no_cuda\")\n",
    "    except Exception as e:\n",
    "        print(f\"[PREFLIGHT] \u2717 CUDA check failed: {e}\")\n",
    "        errors.append(\"cuda_error\")\n",
    "    \n",
    "    # Check 3: Model path exists AND is valid?\n",
    "    if os.path.exists(MODEL_PATH) and os.path.isdir(MODEL_PATH):\n",
    "        try:\n",
    "            contents = os.listdir(MODEL_PATH)\n",
    "            print(f\"[PREFLIGHT] \u2713 Model path exists: {MODEL_PATH}\")\n",
    "            print(f\"[PREFLIGHT]   Files: {contents[:8]}{'...' if len(contents) > 8 else ''}\")\n",
    "            \n",
    "            # ChatGPT: \"check readability, not just existence\"\n",
    "            # config.json is REQUIRED for vLLM to load the model\n",
    "            if any(\"config\" in f.lower() for f in contents):\n",
    "                print(f\"[PREFLIGHT]   \u2713 config file found\")\n",
    "            else:\n",
    "                print(f\"[PREFLIGHT]   \u2717 NO config file - vLLM will fail!\")\n",
    "                errors.append(\"no_config\")\n",
    "            \n",
    "            # Check for model weights\n",
    "            has_weights = any(f.endswith(('.bin', '.safetensors', '.pt')) for f in contents)\n",
    "            if has_weights:\n",
    "                print(f\"[PREFLIGHT]   \u2713 model weights found\")\n",
    "            else:\n",
    "                print(f\"[PREFLIGHT]   \u2717 NO model weights - vLLM will fail!\")\n",
    "                errors.append(\"no_weights\")\n",
    "                \n",
    "        except PermissionError:\n",
    "            print(f\"[PREFLIGHT] \u2717 Cannot read model path (permission denied)\")\n",
    "            errors.append(\"model_unreadable\")\n",
    "        except Exception as e:\n",
    "            print(f\"[PREFLIGHT] \u2717 Cannot list model path: {e}\")\n",
    "            errors.append(\"model_unreadable\")\n",
    "    else:\n",
    "        print(f\"[PREFLIGHT] \u2717 Model path NOT FOUND: {MODEL_PATH}\")\n",
    "        # Debug: show what IS available\n",
    "        for check_path in [\"/kaggle/input\", \"/kaggle\"]:\n",
    "            if os.path.exists(check_path):\n",
    "                print(f\"[PREFLIGHT]   {check_path} contains: {os.listdir(check_path)[:10]}\")\n",
    "        errors.append(\"model_missing\")\n",
    "    \n",
    "    # Summary\n",
    "    if errors:\n",
    "        print(f\"[PREFLIGHT] \u26a0 WARNINGS: {errors}\")\n",
    "        print(\"[PREFLIGHT] Server may fail - fallback solver will be used\")\n",
    "        _PREFLIGHT_PASSED = False\n",
    "    else:\n",
    "        print(\"[PREFLIGHT] \u2713 All checks passed\")\n",
    "        _PREFLIGHT_PASSED = True\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    return _PREFLIGHT_PASSED\n",
    "\n",
    "# Run preflight NOW (at import, before serve())\n",
    "run_preflight()\n",
    "\n",
    "# === VLLM PROCESS MANAGEMENT ===\n",
    "vllm_process = None\n",
    "_VLLM_STARTED = False\n",
    "\n",
    "# Force offline mode\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"\n",
    "\n",
    "# vLLM backend config\n",
    "os.environ[\"VLLM_ATTENTION_BACKEND\"] = \"FLASH_ATTN\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "VLLM_COMMAND = [\n",
    "    \"python\", \"-m\", \"vllm.entrypoints.openai.api_server\",\n",
    "    \"--model\", MODEL_PATH,\n",
    "    \"--served-model-name\", \"vllm-model\",\n",
    "    \"--tensor-parallel-size\", \"1\",\n",
    "    \"--max-num-seqs\", \"16\",\n",
    "    \"--gpu-memory-utilization\", \"0.90\",\n",
    "    \"--host\", VLLM_HOST,\n",
    "    \"--port\", str(VLLM_PORT),\n",
    "    \"--dtype\", \"auto\",\n",
    "    \"--max-model-len\", \"65536\",\n",
    "    \"--trust-remote-code\",\n",
    "]\n",
    "\n",
    "\n",
    "def start_vllm_server():\n",
    "    \"\"\"\n",
    "    Start vLLM server lazily (called on first predict).\n",
    "    Returns immediately - server starts in background.\n",
    "    \"\"\"\n",
    "    global vllm_process, _VLLM_STARTED\n",
    "    \n",
    "    if _VLLM_STARTED:\n",
    "        return True\n",
    "    \n",
    "    _VLLM_STARTED = True\n",
    "    \n",
    "    # Don't even try if preflight failed critically\n",
    "    if not _VLLM_AVAILABLE:\n",
    "        print(\"[VLLM] Skipping - vLLM not available\")\n",
    "        return False\n",
    "    \n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"[VLLM] Skipping - model path missing: {MODEL_PATH}\")\n",
    "        return False\n",
    "    \n",
    "    print(\"[VLLM] Starting server (lazy startup)...\")\n",
    "    print(f\"[VLLM] Command: {' '.join(VLLM_COMMAND[:6])}...\")\n",
    "    \n",
    "    try:\n",
    "        log_path = \"/kaggle/working/vllm.log\"\n",
    "        with open(log_path, \"w\") as logfile:\n",
    "            vllm_process = subprocess.Popen(\n",
    "                VLLM_COMMAND,\n",
    "                stdout=logfile,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                start_new_session=True\n",
    "            )\n",
    "        print(f\"[VLLM] Server starting (PID: {vllm_process.pid}, log: {log_path})\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"[VLLM] Failed to start: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"[BANSHEEV6] Preflight complete. vLLM configured for lazy start.\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OPENAI CLIENT + SERVER HEALTH MANAGEMENT\n",
    "# =============================================================================\n",
    "# ChatGPT Review Compliance:\n",
    "#   - Probe calls are FAST (short timeouts, won't block relay)\n",
    "#   - 8-minute initial budget, then quick checks\n",
    "#   - Never fully gives up (server might come up late)\n",
    "#   - Strict per-call timeouts to avoid blocking\n",
    "# =============================================================================\n",
    "from openai import OpenAI\n",
    "import httpx\n",
    "\n",
    "# === CLIENT CONFIGURATION ===\n",
    "VLLM_BASE_URL = f\"http://127.0.0.1:{VLLM_PORT}/v1\"\n",
    "\n",
    "os.environ[\"OPENAI_API_BASE\"] = VLLM_BASE_URL\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-dummy\"\n",
    "\n",
    "# Client with STRICT timeouts (ChatGPT: \"keep probe calls very fast\")\n",
    "client = OpenAI(\n",
    "    base_url=VLLM_BASE_URL,\n",
    "    api_key=\"sk-dummy\",\n",
    "    timeout=httpx.Timeout(10.0, connect=5.0),  # 10s total, 5s connect\n",
    "    max_retries=0,  # Don't retry - we handle retries ourselves\n",
    ")\n",
    "\n",
    "# === SERVER STATE ===\n",
    "_CLIENT_READY = False\n",
    "_SERVER_RESTARTED = False\n",
    "_INITIAL_PROBE_DONE = False\n",
    "_SERVER_PROBE_START = None\n",
    "\n",
    "# === TIMING CONSTANTS (ChatGPT-aligned) ===\n",
    "INITIAL_PROBE_BUDGET = 480    # 8 minutes total initial effort\n",
    "RESTART_AT = 240              # Restart at 4-minute mark\n",
    "QUICK_PROBE_TIMEOUT = 3       # Quick check after initial period\n",
    "PROBE_INTERVAL = 3            # Check every 3s\n",
    "HEALTH_CHECK_TIMEOUT = 2      # Individual health check timeout\n",
    "\n",
    "\n",
    "def check_server_health() -> bool:\n",
    "    \"\"\"\n",
    "    Fast health check with strict timeout.\n",
    "    ChatGPT: \"keep probe calls very fast (short timeouts)\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Use requests directly for tighter timeout control\n",
    "        import requests\n",
    "        resp = requests.get(\n",
    "            f\"http://127.0.0.1:{VLLM_PORT}/health\",\n",
    "            timeout=HEALTH_CHECK_TIMEOUT\n",
    "        )\n",
    "        return resp.status_code == 200\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback: try models endpoint\n",
    "    try:\n",
    "        models = client.models.list()\n",
    "        return bool(models)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def restart_vllm_server():\n",
    "    \"\"\"Kill and restart vLLM server (called once at 4-min mark).\"\"\"\n",
    "    global vllm_process, _VLLM_STARTED\n",
    "    \n",
    "    print(\"[SERVER] Restarting vLLM...\")\n",
    "    \n",
    "    if vllm_process and vllm_process.poll() is None:\n",
    "        try:\n",
    "            vllm_process.terminate()\n",
    "            vllm_process.wait(timeout=10)\n",
    "        except:\n",
    "            try:\n",
    "                vllm_process.kill()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    _VLLM_STARTED = False\n",
    "    start_vllm_server()\n",
    "    \n",
    "    if vllm_process:\n",
    "        print(f\"[SERVER] Restarted (PID: {vllm_process.pid})\")\n",
    "\n",
    "\n",
    "def ensure_server() -> bool:\n",
    "    \"\"\"\n",
    "    Ensure vLLM server is ready. NEVER FULLY GIVES UP.\n",
    "    \n",
    "    Strategy (ChatGPT-aligned):\n",
    "      Phase 1 (0-8 min): Serious probing with restart at 4min\n",
    "      Phase 2 (8+ min): Quick 3s checks each problem\n",
    "    \n",
    "    Returns:\n",
    "        True  - Server ready, use LLM\n",
    "        False - Not ready yet, use fallback (but check again next problem)\n",
    "    \"\"\"\n",
    "    global _CLIENT_READY, _SERVER_RESTARTED, _INITIAL_PROBE_DONE, _SERVER_PROBE_START\n",
    "    \n",
    "    # Fast path: already confirmed working\n",
    "    if _CLIENT_READY:\n",
    "        return True\n",
    "    \n",
    "    # Start server if not started\n",
    "    if not start_vllm_server():\n",
    "        return False  # Can't even start (missing deps/model)\n",
    "    \n",
    "    # Initialize probe timer\n",
    "    if _SERVER_PROBE_START is None:\n",
    "        _SERVER_PROBE_START = time.time()\n",
    "    \n",
    "    total_elapsed = time.time() - _SERVER_PROBE_START\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PHASE 1: INITIAL 8-MINUTE PROBE\n",
    "    # =========================================================================\n",
    "    if not _INITIAL_PROBE_DONE:\n",
    "        remaining = INITIAL_PROBE_BUDGET - total_elapsed\n",
    "        \n",
    "        if remaining > 0:\n",
    "            probe_time = min(30, remaining)\n",
    "            print(f\"[CLIENT] Probing... {total_elapsed:.0f}s/{INITIAL_PROBE_BUDGET}s\")\n",
    "            deadline = time.time() + probe_time\n",
    "            \n",
    "            while time.time() < deadline:\n",
    "                if TIME_MANAGER.is_expired():\n",
    "                    print(\"[CLIENT] Competition time expired\")\n",
    "                    return False\n",
    "                \n",
    "                if check_server_health():\n",
    "                    startup_time = time.time() - _SERVER_PROBE_START\n",
    "                    print(f\"[CLIENT] \u2713 Server ready after {startup_time:.0f}s\")\n",
    "                    _CLIENT_READY = True\n",
    "                    return True\n",
    "                \n",
    "                time.sleep(PROBE_INTERVAL)\n",
    "            \n",
    "            # Restart at 4-minute mark\n",
    "            total_elapsed = time.time() - _SERVER_PROBE_START\n",
    "            if not _SERVER_RESTARTED and total_elapsed >= RESTART_AT:\n",
    "                _SERVER_RESTARTED = True\n",
    "                print(f\"[CLIENT] Not ready at {total_elapsed:.0f}s - restarting\")\n",
    "                restart_vllm_server()\n",
    "            \n",
    "            # Still have budget? Return, will probe again next call\n",
    "            if total_elapsed < INITIAL_PROBE_BUDGET:\n",
    "                return False\n",
    "        \n",
    "        print(\"[CLIENT] Initial 8-min probe done \u2192 quick check mode\")\n",
    "        _INITIAL_PROBE_DONE = True\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PHASE 2: QUICK CHECK (never give up)\n",
    "    # =========================================================================\n",
    "    deadline = time.time() + QUICK_PROBE_TIMEOUT\n",
    "    while time.time() < deadline:\n",
    "        if check_server_health():\n",
    "            print(\"[CLIENT] \u2713 Server came up late!\")\n",
    "            _CLIENT_READY = True\n",
    "            return True\n",
    "        time.sleep(1)\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def fallback_solver(problem_text: str) -> int:\n",
    "    \"\"\"\n",
    "    Smarter heuristic fallback when LLM unavailable.\n",
    "    ChatGPT: \"add a second-tier non-LLM heuristic\"\n",
    "    \"\"\"\n",
    "    t = problem_text.lower()\n",
    "    numbers = [int(x) for x in re.findall(r'\\d+', problem_text) if len(x) <= 5]\n",
    "    \n",
    "    if not numbers:\n",
    "        return 42\n",
    "    \n",
    "    # Pattern 1: Modular arithmetic \"mod N\"\n",
    "    mod_match = re.search(r'mod(?:ulo)?\\s*(\\d+)', t)\n",
    "    if mod_match:\n",
    "        m = int(mod_match.group(1))\n",
    "        if m > 0:\n",
    "            return sum(numbers) % m\n",
    "    \n",
    "    # Pattern 2: \"remainder when divided by N\"\n",
    "    rem_match = re.search(r'remainder.*(?:divided|by)\\s*(\\d+)', t)\n",
    "    if rem_match:\n",
    "        d = int(rem_match.group(1))\n",
    "        if d > 0:\n",
    "            return sum(numbers) % d\n",
    "    \n",
    "    # Pattern 3: Counting problems\n",
    "    if any(kw in t for kw in ['how many', 'count', 'number of ways', 'number of']):\n",
    "        return numbers[-1] % 10000 if numbers[-1] < 100000 else 1\n",
    "    \n",
    "    # Pattern 4: Extrema\n",
    "    if any(kw in t for kw in ['largest', 'maximum', 'greatest', 'max']):\n",
    "        return max(numbers) % 100000\n",
    "    if any(kw in t for kw in ['smallest', 'minimum', 'least', 'min']):\n",
    "        return min(numbers) % 100000\n",
    "    \n",
    "    # Pattern 5: Product\n",
    "    if 'product' in t:\n",
    "        p = 1\n",
    "        for n in numbers[:4]:\n",
    "            p = (p * n) % 100000\n",
    "        return p\n",
    "    \n",
    "    # Pattern 6: Sum\n",
    "    if 'sum' in t:\n",
    "        return sum(numbers) % 100000\n",
    "    \n",
    "    # Pattern 7: Last number (often answer-related)\n",
    "    return numbers[-1] % 100000\n",
    "\n",
    "\n",
    "print(f\"[BANSHEEV6] Client: strict {HEALTH_CHECK_TIMEOUT}s health checks, 8-min probe budget\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PROMPT ENGINEERING\n",
    "# 32 System Prompts from Zombie (23/50)\n",
    "# =========================\n",
    "\n",
    "COGNITIVE_MACROS = \"\"\"\n",
    "COGNITIVE TOOLKIT:\n",
    "- Try small cases to conjecture, then prove.\n",
    "- Search for invariants / monovariants.\n",
    "- Work backwards from desired form.\n",
    "- Check extremes / boundary cases.\n",
    "- Exploit symmetry / relabeling.\n",
    "- Pigeonhole principle.\n",
    "- Parity / modular arithmetic.\n",
    "- Bounding (upper/lower) and squeeze.\n",
    "- Complementary counting.\n",
    "- Construct bijection or involution.\n",
    "- Translate to algebra/graph/geometry.\n",
    "- Sanity-check units, integrality, constraints.\n",
    "OUTPUT: Finish with exactly one integer in \\\\boxed{}, 0 <= answer <= 99999.\n",
    "\"\"\"\n",
    "\n",
    "# All 32 battle-tested prompts from zombie_23.ipynb (scored 23/50)\n",
    "SYSTEM_PROMPTS = [\n",
    "    # 1. Elite mathematician with code execution\n",
    "    \"CRITICAL: You have Python code execution. Write ```python blocks for verification. \"\n",
    "    \"You are an elite mathematics researcher. Return only final integer in \\\\boxed{}, 0 <= answer <= 99999.\",\n",
    "    \n",
    "    # 2. IMO competitor rigor\n",
    "    \"You are an IMO competitor. Rigorously define variables, explore multiple strategies, \"\n",
    "    \"perform full case analysis, justify nontrivial steps. Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 3. Adversarial self-refutation\n",
    "    \"Solve with full rigor. After candidate solution, actively attempt refutation by \"\n",
    "    \"searching for counterexamples, stress-testing edge cases. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 4. Invariant-first under time pressure\n",
    "    \"Under IMO time pressure: identify key invariant/symmetry/extremal principle early, \"\n",
    "    \"avoid brute force unless justified. Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "    \n",
    "    # 5. Multiple solution approaches\n",
    "    \"Attempt at least two fundamentally different solution approaches. Proceed with more rigorous, \"\n",
    "    \"use other as verification. Return only verified final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 6. First principles restart on inconsistency\n",
    "    \"If step relies on unproven assumption or inconsistency, restart from first principles. \"\n",
    "    \"Return only final verified integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 7. Tool-integrated reasoning with early stopping\n",
    "    \"Tool-integrated reasoning, apply early-stopping when confident. Return verified final answer \"\n",
    "    \"in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 8. Adversarial academic review\n",
    "    \"Conduct adversarial academic review of proposed solution, then provide constructive critique. \"\n",
    "    \"Return only verified final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 9. Small answer skepticism\n",
    "    \"WARNING: Small answers (0, 1, 2, 3) are often wrong on competition problems. \"\n",
    "    \"If you get a small answer, re-verify with extra rigor. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 10. Constraint propagation\n",
    "    \"Apply constraint propagation: what does the problem FORCE to be true? What CANNOT happen? \"\n",
    "    \"Build the answer from forced conclusions. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 11. Backwards reasoning\n",
    "    \"Work backwards: What form must the answer have? What properties? Use this to constrain search. \"\n",
    "    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 12. Generating function / algebraic identity\n",
    "    \"Consider generating functions, algebraic identities, or polynomial methods. \"\n",
    "    \"Competition math often has elegant closed forms. Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 13. Combinatorial bijection\n",
    "    \"Seek a bijection or double-counting argument. Competition problems often have elegant \"\n",
    "    \"combinatorial structures. Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 14. Modular arithmetic focus\n",
    "    \"Focus on modular arithmetic patterns. Check divisibility, remainders, Chinese Remainder Theorem. \"\n",
    "    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 15. Geometry to algebra translation\n",
    "    \"If geometry: translate to coordinates or trigonometry. If algebra: consider geometric interpretation. \"\n",
    "    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 16. Extremal principle\n",
    "    \"Apply extremal principle: consider maximum/minimum elements, argue about their properties. \"\n",
    "    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 17. Graph theory modeling\n",
    "    \"Model the problem as a graph if applicable. Vertices, edges, degrees, paths, cycles. \"\n",
    "    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 18. Recurrence relation\n",
    "    \"Look for recurrence relations. Define f(n), find f(n) in terms of earlier values. \"\n",
    "    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 19. Pigeonhole principle\n",
    "    \"Apply pigeonhole principle: if too many pigeons, some hole has multiple. What are the pigeons? Holes? \"\n",
    "    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 20. Greedy algorithm validation\n",
    "    \"Consider greedy approach. Prove it works or find counterexample. \"\n",
    "    \"Return only verified final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 21. Induction strategy\n",
    "    \"Prove by induction if pattern emerges. State base case, inductive step clearly. \"\n",
    "    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 22. Probabilistic method intuition\n",
    "    \"Use probabilistic intuition: if random approach gives expected value X, constructive solution exists. \"\n",
    "    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 23. Number theory deep dive\n",
    "    \"For number theory: check prime factorization, Euler's theorem, quadratic residues. \"\n",
    "    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 24. Functional equation approach\n",
    "    \"For functional equations: try f(0), f(1), injectivity, surjectivity, substitutions. \"\n",
    "    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 25. Inequality techniques\n",
    "    \"For inequalities: AM-GM, Cauchy-Schwarz, Jensen, rearrangement. When does equality hold? \"\n",
    "    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 26. Sequence analysis\n",
    "    \"Analyze sequences: arithmetic, geometric, periodic, eventually periodic, bounded? \"\n",
    "    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 27. Polynomial roots and coefficients\n",
    "    \"For polynomials: Vieta's formulas, root behavior, coefficient patterns. \"\n",
    "    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 28. Game theory / strategy\n",
    "    \"If game theory: who has winning strategy? What invariant does winner maintain? \"\n",
    "    \"Return only final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 29. Coloring arguments\n",
    "    \"Consider coloring arguments: 2-color, checkerboard, mod-k coloring. What's forced? \"\n",
    "    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 30. Diophantine equation techniques\n",
    "    \"For Diophantine equations: factorization, descent, modular constraints. \"\n",
    "    \"Return in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 31. Confidence scoring\n",
    "    \"Rate your confidence 0-100 after solving. If below 85, try alternative approach. \"\n",
    "    \"Return only verified final answer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "\n",
    "    # 32. Triangulation algorithm\n",
    "    \"Use triangulation: first determine answer's order of magnitude, then narrow range, then pinpoint. \"\n",
    "    \"Return only final integer in \\\\boxed{}. 0 <= answer <= 99999.\",\n",
    "]\n",
    "\n",
    "# Follow-up prompts for reflexion\n",
    "FOLLOWUP_NO_ANSWER = \"You did not provide a boxed answer. Please place your final integer answer in \\\\boxed{}.\"\n",
    "FOLLOWUP_SMALL_ANSWER = \"You answered with a small number. Small answers (0-10) are often wrong on IMO problems. Are you absolutely certain? Re-verify.\"\n",
    "FOLLOWUP_VERIFY = \"Please verify your answer one more time. Check arithmetic, edge cases, and logical steps.\"\n",
    "FOLLOWUP_GUESS = \"Time is running out. Make your best educated guess and put it in \\\\boxed{}.\"\n",
    "\n",
    "\n",
    "def sanity_check_answer(question_text: str, ans: int) -> bool:\n",
    "    \"\"\"Check answer against problem constraints.\"\"\"\n",
    "    if ans < 0 or ans > 99999:\n",
    "        return False\n",
    "    t = question_text.lower()\n",
    "    \n",
    "    # Parity\n",
    "    if re.search(r'\\banswer\\s+is\\s+even\\b', t) and ans % 2 != 0:\n",
    "        return False\n",
    "    if re.search(r'\\banswer\\s+is\\s+odd\\b', t) and ans % 2 != 1:\n",
    "        return False\n",
    "    \n",
    "    # Divisibility\n",
    "    div_match = re.search(r'\\b(?:divisible by|multiple of)\\s+(\\d{1,5})\\b', t)\n",
    "    if div_match:\n",
    "        k = int(div_match.group(1))\n",
    "        if k != 0 and ans % k != 0:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(f\"[BANSHEEV6] Prompts: {len(SYSTEM_PROMPTS)} system prompts loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# GENERATION HELPERS\n",
    "# =========================\n",
    "\n",
    "def annealed_temperature(step: int, total: int, t_start: float = 1.4, t_end: float = 0.2) -> float:\n",
    "    if total <= 1:\n",
    "        return t_end\n",
    "    return t_start * ((t_end / t_start) ** (step / (total - 1)))\n",
    "\n",
    "def annealed_max_tokens(step: int, total: int, start: int = 2048, end: int = 640) -> int:\n",
    "    \"\"\"H100: slightly higher token floor for better reasoning.\"\"\"\n",
    "    if total <= 1:\n",
    "        return end\n",
    "    return int(start + (step / (total - 1)) * (end - start))\n",
    "\n",
    "def annealed_top_p(step: int, total: int, start: float = 0.95, end: float = 0.75) -> float:\n",
    "    if total <= 1:\n",
    "        return end\n",
    "    return start + (step / (total - 1)) * (end - start)\n",
    "\n",
    "def repetition_rate(text: str, window: int = 120) -> float:\n",
    "    toks = re.findall(r'\\w+|\\S', text.lower())\n",
    "    if len(toks) < window:\n",
    "        return 0.0\n",
    "    tail = toks[-window:]\n",
    "    return 1.0 - (len(set(tail)) / max(1, len(tail)))\n",
    "\n",
    "def tail_similarity(text: str, window: int = 900) -> float:\n",
    "    \"\"\"Check if text is repeating itself.\"\"\"\n",
    "    if len(text) < 2 * window:\n",
    "        return 0.0\n",
    "    a = text[-2*window:-window]\n",
    "    b = text[-window:]\n",
    "    # Simple char overlap\n",
    "    a_set = set(a.lower())\n",
    "    b_set = set(b.lower())\n",
    "    if not a_set or not b_set:\n",
    "        return 0.0\n",
    "    return len(a_set & b_set) / len(a_set | b_set)\n",
    "\n",
    "print(\"[BANSHEEV6] Generation Helpers: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# MAIN SOLVER CORE\n",
    "# =========================\n",
    "\n",
    "import threading\n",
    "STATE_LOCK = threading.Lock()\n",
    "\n",
    "# Global state\n",
    "completed_question_ids = set()\n",
    "question_id_to_counter = defaultdict(Counter)\n",
    "question_id_to_samples = defaultdict(list)\n",
    "question_id_to_traces = defaultdict(list)\n",
    "question_id_to_cic_history = defaultdict(list)\n",
    "\n",
    "\n",
    "def is_valid_answer(ans) -> bool:\n",
    "    \"\"\"Check if answer is valid.\"\"\"\n",
    "    try:\n",
    "        return ans is not None and 0 <= int(ans) <= 99999\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "def vote_answer(question_id: str, force_answer: bool = False) -> Optional[int]:\n",
    "    \"\"\"Log-weighted voting.\"\"\"\n",
    "    counter = question_id_to_counter[question_id]\n",
    "    if not counter:\n",
    "        return None\n",
    "    \n",
    "    modified_counter = Counter()\n",
    "    for value, count in counter.items():\n",
    "        modified_counter[value] += math.log(1.25 + abs(value)) * count\n",
    "    \n",
    "    score_list = sorted(\n",
    "        (score, counter[value], value) for value, score in modified_counter.items()\n",
    "    )\n",
    "    \n",
    "    if force_answer and score_list:\n",
    "        if RUNTIME.VERBOSE_LOGGING:\n",
    "            print(f\"[VOTE] {sum(counter.values())} attempts\")\n",
    "            for score, count, value in score_list[::-1][:3]:\n",
    "                print(f\"  {value}: count={count}\")\n",
    "        return score_list[-1][-1]\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_solution(\n",
    "    question_text: str,\n",
    "    question_id: str,\n",
    "    solution_index: int,\n",
    "    system_prompt: str,\n",
    "    budget: float,\n",
    "    total_generations: int = 8,\n",
    ") -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Generate solution with:\n",
    "    - NON-STREAMING (safer)\n",
    "    - Budget-tied timeout\n",
    "    - Uses extract_any_answer from Cell 5\n",
    "    \"\"\"\n",
    "    if question_id in completed_question_ids:\n",
    "        return None\n",
    "    if TIME_MANAGER.is_expired():\n",
    "        return None\n",
    "\n",
    "    gen_start = time.time()\n",
    "    os.makedirs(f\"solutions/{question_id}\", exist_ok=True)\n",
    "\n",
    "    # Use annealed parameters from Cell 12\n",
    "    temperature = annealed_temperature(solution_index, total_generations)\n",
    "    max_tokens = annealed_max_tokens(solution_index, total_generations)\n",
    "    \n",
    "    # Budget-tied timeout\n",
    "    remaining_budget = max(10, budget - (time.time() - gen_start))\n",
    "    request_timeout = min(90, remaining_budget - 5)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question_text},\n",
    "    ]\n",
    "\n",
    "    text_response_to_save = \"\"\n",
    "    max_iterations = 2\n",
    "\n",
    "    for iteration in range(max_iterations):\n",
    "        if question_id in completed_question_ids:\n",
    "            break\n",
    "        if TIME_MANAGER.is_expired():\n",
    "            break\n",
    "        if not TIME_MANAGER.should_continue(gen_start, budget):\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # NON-STREAMING\n",
    "            resp = client.chat.completions.create(\n",
    "                model=\"vllm-model\",\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                extra_body=dict(min_p=0.02, stop_token_ids=stop_token_ids),\n",
    "                timeout=request_timeout,\n",
    "            )\n",
    "            \n",
    "            text_response = resp.choices[0].message.content or \"\"\n",
    "            messages.append({\"role\": \"assistant\", \"content\": text_response})\n",
    "            text_response_to_save += text_response\n",
    "\n",
    "        except Exception as e:\n",
    "            if RUNTIME.VERBOSE_LOGGING:\n",
    "                print(f\"[GEN] Error: {e}\")\n",
    "            break\n",
    "\n",
    "        # Use extract_any_answer from Cell 5\n",
    "        ans = extract_any_answer(text_response_to_save)\n",
    "        \n",
    "        if is_valid_answer(ans):\n",
    "            if ans <= 10 and iteration == 0:\n",
    "                user_follow_up = \"Are you sure? Double-check your answer.\"\n",
    "                messages.append({\"role\": \"user\", \"content\": user_follow_up})\n",
    "                text_response_to_save += \"\\n===\\n\" + user_follow_up + \"\\n===\\n\"\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            if iteration == 0:\n",
    "                user_follow_up = \"Place your final answer in \\\\boxed{}.\"\n",
    "                messages.append({\"role\": \"user\", \"content\": user_follow_up})\n",
    "                text_response_to_save += \"\\n===\\n\" + user_follow_up + \"\\n===\\n\"\n",
    "\n",
    "    # Final extraction\n",
    "    ans = extract_any_answer(text_response_to_save)\n",
    "    \n",
    "    # Save trace (thread-safe)\n",
    "    if text_response_to_save:\n",
    "        with STATE_LOCK:\n",
    "            question_id_to_traces[question_id].append(text_response_to_save)\n",
    "        \n",
    "        try:\n",
    "            suffix = f\"-{ans}\" if is_valid_answer(ans) else \"\"\n",
    "            with open(f\"solutions/{question_id}/{solution_index:04d}{suffix}.txt\", \"w\") as f:\n",
    "                f.write(text_response_to_save)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if is_valid_answer(ans):\n",
    "        with STATE_LOCK:\n",
    "            question_id_to_counter[question_id][ans] += 1\n",
    "            question_id_to_samples[question_id].append(ans)\n",
    "        vote_answer(question_id)\n",
    "        return ans\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"[BANSHEEV6] Main solver core: NON-STREAMING, uses Cell 5 & 12 functions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# TWO-PHASE REASONING (Tier 3)\n",
    "# =========================\n",
    "# Phase A: Normal reasoning to get candidate answer\n",
    "# Phase B: Short arithmetic recomputation to catch slips\n",
    "#\n",
    "# Catches: last-line arithmetic errors, sign mistakes, modulo slips\n",
    "# Cost: ~256 extra tokens per verified sample\n",
    "# =========================\n",
    "\n",
    "PHASE_B_PROMPTS = [\n",
    "    \"\"\"The candidate answer is {answer}. \n",
    "\n",
    "Before accepting this, carefully recompute the final arithmetic step by step:\n",
    "1. What was the final expression/calculation?\n",
    "2. Compute each step explicitly\n",
    "3. Verify the result\n",
    "\n",
    "If the arithmetic confirms {answer}, output \\\\boxed{{{answer}}}.\n",
    "If you find an error, output the corrected answer in \\\\boxed{{}}.\"\"\",\n",
    "\n",
    "    \"\"\"A solution claims the answer is {answer}.\n",
    "\n",
    "Quick sanity check:\n",
    "- Does this value make sense given the problem constraints?\n",
    "- Verify the final calculation that produced {answer}\n",
    "- Check for any sign errors or off-by-one mistakes\n",
    "\n",
    "Final verified answer in \\\\boxed{{}}.\"\"\",\n",
    "\n",
    "    \"\"\"The proposed answer is {answer}.\n",
    "\n",
    "If this involves modular arithmetic:\n",
    "- Verify: result mod M = {answer}?\n",
    "- Check: is {answer} in the valid range [0, M-1]?\n",
    "\n",
    "Recompute the final step and confirm in \\\\boxed{{}}.\"\"\",\n",
    "]\n",
    "\n",
    "\n",
    "def should_run_phase_b(answer: int, difficulty: DifficultyAssessment, elapsed: float, budget: float) -> bool:\n",
    "    \"\"\"Decide whether to run Phase B verification.\"\"\"\n",
    "    if budget - elapsed < 15:\n",
    "        return False\n",
    "    if difficulty.level == Difficulty.EASY:\n",
    "        return False\n",
    "    if difficulty.level == Difficulty.HARD:\n",
    "        return True\n",
    "    # MEDIUM: run if answer has arithmetic-slip risk\n",
    "    return (answer % 10 == 0 or answer > 10000 or \n",
    "            abs(answer - round(answer, -2)) < 5 or answer in [0, 1, 2])\n",
    "\n",
    "\n",
    "def run_phase_b(question_text: str, candidate_answer: int, question_id: str, timeout: float = 20.0) -> Optional[int]:\n",
    "    \"\"\"Phase B: Arithmetic verification. Short prompt to recompute final arithmetic.\"\"\"\n",
    "    if TIME_MANAGER.is_expired():\n",
    "        return None\n",
    "    \n",
    "    t = question_text.lower()\n",
    "    prompt_template = PHASE_B_PROMPTS[2] if (\"mod\" in t or \"remainder\" in t) else PHASE_B_PROMPTS[0]\n",
    "    phase_b_prompt = prompt_template.format(answer=candidate_answer)\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are verifying a mathematical calculation. Be brief and precise.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Problem: {question_text[:1000]}\\n\\n{phase_b_prompt}\"},\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"vllm-model\",\n",
    "            messages=messages,\n",
    "            temperature=0.3,\n",
    "            max_tokens=256,\n",
    "            extra_body=dict(min_p=0.02, stop_token_ids=stop_token_ids),\n",
    "            timeout=timeout,\n",
    "        )\n",
    "        \n",
    "        response_text = resp.choices[0].message.content or \"\"\n",
    "        verified = extract_any_answer(response_text)\n",
    "        \n",
    "        if verified is not None and 0 <= verified <= 99999:\n",
    "            if verified != candidate_answer:\n",
    "                print(f\"[PHASE-B] Correction: {candidate_answer} -> {verified}\")\n",
    "            else:\n",
    "                print(f\"[PHASE-B] Confirmed: {verified}\")\n",
    "            return verified\n",
    "        else:\n",
    "            print(f\"[PHASE-B] No extraction, keeping {candidate_answer}\")\n",
    "            return candidate_answer\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[PHASE-B] Error: {e}, keeping {candidate_answer}\")\n",
    "        return candidate_answer\n",
    "\n",
    "\n",
    "print(\"[BANSHEEV6] Two-Phase Reasoning: Phase A (reason) + Phase B (verify arithmetic)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SELF-CONSISTENCY REFINEMENT (Tier 4)\n",
    "# =========================\n",
    "# When samples cluster but don't perfectly agree:\n",
    "# Re-prompt within the dominant basin to break ties.\n",
    "#\n",
    "# Key insight: Nudging toward the attractor increases accuracy\n",
    "# without adding full sampling cost.\n",
    "# =========================\n",
    "\n",
    "REFINEMENT_PROMPT = \"\"\"Several independent solution attempts for this problem suggest the answer is approximately {basin_center}.\n",
    "\n",
    "The candidate values were: {candidates}\n",
    "\n",
    "Please carefully recompute to determine the exact answer:\n",
    "1. Verify the approach that led to values around {basin_center}\n",
    "2. Check for any arithmetic errors in the final steps\n",
    "3. Confirm the precise integer answer\n",
    "\n",
    "Put your final verified answer in \\\\boxed{{}}.\"\"\"\n",
    "\n",
    "\n",
    "def should_refine_with_basin(\n",
    "    samples: List[int],\n",
    "    difficulty: DifficultyAssessment,\n",
    "    elapsed: float,\n",
    "    budget: float,\n",
    ") -> Tuple[bool, Optional[int], List[int]]:\n",
    "    \"\"\"\n",
    "    Decide whether to run basin refinement.\n",
    "    \n",
    "    Returns: (should_refine, basin_center, basin_members)\n",
    "    \n",
    "    Trigger when:\n",
    "    - Have 3+ samples\n",
    "    - Dominant cluster exists but not unanimous\n",
    "    - Time remaining for one more call\n",
    "    - MEDIUM or HARD difficulty\n",
    "    \"\"\"\n",
    "    if len(samples) < 3:\n",
    "        return False, None, []\n",
    "    \n",
    "    if budget - elapsed < 20:\n",
    "        return False, None, []\n",
    "    \n",
    "    if difficulty.level == Difficulty.EASY:\n",
    "        return False, None, []\n",
    "    \n",
    "    # Check for dominant cluster\n",
    "    counter = Counter(samples)\n",
    "    top_answer, top_count = counter.most_common(1)[0]\n",
    "    \n",
    "    # If already unanimous, no need to refine\n",
    "    if top_count == len(samples):\n",
    "        return False, None, []\n",
    "    \n",
    "    # Need at least 50% agreement to have a \"dominant\" cluster\n",
    "    if top_count < len(samples) * 0.5:\n",
    "        # Try value clustering to find basin\n",
    "        result = value_clustering(samples, threshold=0.05)\n",
    "        if result[\"best\"] is None or result[\"best\"].size < 2:\n",
    "            return False, None, []\n",
    "        \n",
    "        basin = result[\"best\"]\n",
    "        basin_center = basin.center\n",
    "        basin_members = basin.members\n",
    "    else:\n",
    "        basin_center = top_answer\n",
    "        basin_members = [s for s in samples if s == top_answer]\n",
    "    \n",
    "    # Only refine if there's disagreement worth resolving\n",
    "    # (i.e., not already 80%+ agreement)\n",
    "    if top_count >= len(samples) * 0.8:\n",
    "        return False, None, []\n",
    "    \n",
    "    return True, basin_center, basin_members\n",
    "\n",
    "\n",
    "def run_basin_refinement(\n",
    "    question_text: str,\n",
    "    basin_center: int,\n",
    "    basin_members: List[int],\n",
    "    question_id: str,\n",
    "    timeout: float = 25.0,\n",
    ") -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Re-prompt within dominant basin to get refined answer.\n",
    "    \n",
    "    Nudges model toward the attractor while allowing correction.\n",
    "    \"\"\"\n",
    "    if TIME_MANAGER.is_expired():\n",
    "        return None\n",
    "    \n",
    "    # Format candidates for prompt\n",
    "    candidates_str = \", \".join(str(m) for m in sorted(set(basin_members))[:5])\n",
    "    \n",
    "    prompt = REFINEMENT_PROMPT.format(\n",
    "        basin_center=basin_center,\n",
    "        candidates=candidates_str\n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are refining a mathematical solution. Be precise and verify arithmetic carefully.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Problem: {question_text[:1500]}\\n\\n{prompt}\"},\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"vllm-model\",\n",
    "            messages=messages,\n",
    "            temperature=0.4,  # Slightly higher than Phase B for exploration\n",
    "            max_tokens=512,   # More room for verification\n",
    "            extra_body=dict(min_p=0.02, stop_token_ids=stop_token_ids),\n",
    "            timeout=timeout,\n",
    "        )\n",
    "        \n",
    "        response_text = resp.choices[0].message.content or \"\"\n",
    "        refined = extract_any_answer(response_text)\n",
    "        \n",
    "        if refined is not None and 0 <= refined <= 99999:\n",
    "            # Check if refinement is close to basin or a correction\n",
    "            if abs(refined - basin_center) < basin_center * 0.1 or refined in basin_members:\n",
    "                print(f\"[REFINE] Basin confirmed: {refined}\")\n",
    "            else:\n",
    "                print(f\"[REFINE] Correction: {basin_center} -> {refined}\")\n",
    "            return refined\n",
    "        else:\n",
    "            print(f\"[REFINE] No valid answer, using basin center: {basin_center}\")\n",
    "            return basin_center\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[REFINE] Error: {e}, using basin center: {basin_center}\")\n",
    "        return basin_center\n",
    "\n",
    "\n",
    "print(\"[BANSHEEV6] Self-Consistency Refinement: Basin-aware re-prompting enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CONTROL POLICY (Tier 5)\n",
    "# =========================\n",
    "# The missing 15-20 points: WHEN to spend compute.\n",
    "#\n",
    "# Core insight: Spend compute only when it buys probability mass.\n",
    "# Two-stage loop:\n",
    "#   Stage A: Cheap consensus (2-4 samples, short)\n",
    "#   Stage B: Targeted repair/escalation (1-2 extra calls when flagged)\n",
    "# =========================\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class ControlDecision(Enum):\n",
    "    ACCEPT = \"accept\"           # High confidence, stop sampling\n",
    "    ESCALATE = \"escalate\"       # Low confidence, spend more compute\n",
    "    FALLBACK = \"fallback\"       # Give up, use best guess\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ControlState:\n",
    "    \"\"\"State for control policy decisions.\"\"\"\n",
    "    cluster_support: float      # Fraction of samples in best cluster\n",
    "    cluster_tightness: float    # Normalized tightness (0-1)\n",
    "    decision_reject: bool       # Hard reject (mod/bounds impossible)\n",
    "    warnings_count: int         # Number of soft warnings\n",
    "    samples_so_far: int         # How many samples collected\n",
    "    time_left: float            # Remaining time budget\n",
    "    difficulty: Difficulty      # Problem difficulty\n",
    "\n",
    "\n",
    "# === CONTROL THRESHOLDS ===\n",
    "# These are the knobs that move you from 25-35 to 40-50+\n",
    "\n",
    "# Accept immediately if:\n",
    "ACCEPT_HIGH_SUPPORT = 0.67      # cluster_support threshold\n",
    "ACCEPT_HIGH_TIGHTNESS = 0.70   # cluster_tightness threshold\n",
    "\n",
    "ACCEPT_MED_SUPPORT = 0.50      # Alternative: lower support but...\n",
    "ACCEPT_MED_TIGHTNESS = 0.85    # ...higher tightness and no warnings\n",
    "\n",
    "# Escalate if:\n",
    "ESCALATE_LOW_SUPPORT = 0.50    # Below this = need more samples\n",
    "ESCALATE_LOW_TIGHTNESS = 0.55  # Below this = disagreement\n",
    "\n",
    "# Budget caps by difficulty\n",
    "BUDGET_CAPS = {\n",
    "    Difficulty.EASY: 2,    # Max samples for easy\n",
    "    Difficulty.MEDIUM: 5,  # H100: +1 for medium problems\n",
    "    Difficulty.HARD: 7,    # H100: +1 for hard problems (if near-miss signals)\n",
    "}\n",
    "\n",
    "# Minimum time to justify another sample (seconds)\n",
    "MIN_TIME_FOR_SAMPLE = 8.0\n",
    "\n",
    "\n",
    "def compute_control_state(\n",
    "    samples: List[int],\n",
    "    verifications: Dict[int, VerificationResult],\n",
    "    difficulty: DifficultyAssessment,\n",
    "    elapsed: float,\n",
    "    budget: float,\n",
    ") -> ControlState:\n",
    "    \"\"\"Compute current control state from samples.\"\"\"\n",
    "    \n",
    "    if not samples:\n",
    "        return ControlState(\n",
    "            cluster_support=0.0,\n",
    "            cluster_tightness=0.0,\n",
    "            decision_reject=False,\n",
    "            warnings_count=0,\n",
    "            samples_so_far=0,\n",
    "            time_left=budget - elapsed,\n",
    "            difficulty=difficulty.level,\n",
    "        )\n",
    "    \n",
    "    # Cluster analysis\n",
    "    counter = Counter(samples)\n",
    "    top_answer, top_count = counter.most_common(1)[0]\n",
    "    cluster_support = top_count / len(samples)\n",
    "    \n",
    "    # Tightness from value clustering\n",
    "    if RUNTIME.ENABLE_VALUE_CLUSTERING and len(samples) >= 2:\n",
    "        result = value_clustering(samples, threshold=0.05)\n",
    "        if result[\"best\"] is not None:\n",
    "            cluster_tightness = result[\"best\"].tightness\n",
    "        else:\n",
    "            cluster_tightness = 0.0\n",
    "    else:\n",
    "        # Simple tightness: 1.0 if all same, lower if spread\n",
    "        if len(set(samples)) == 1:\n",
    "            cluster_tightness = 1.0\n",
    "        else:\n",
    "            cluster_tightness = cluster_support  # Proxy\n",
    "    \n",
    "    # Check for hard rejects\n",
    "    decision_reject = False\n",
    "    for ans, vr in verifications.items():\n",
    "        if vr.failed_checks:\n",
    "            decision_reject = True\n",
    "            break\n",
    "    \n",
    "    # Count warnings\n",
    "    warnings_count = sum(\n",
    "        len(vr.flags) for vr in verifications.values()\n",
    "    )\n",
    "    \n",
    "    return ControlState(\n",
    "        cluster_support=cluster_support,\n",
    "        cluster_tightness=cluster_tightness,\n",
    "        decision_reject=decision_reject,\n",
    "        warnings_count=warnings_count,\n",
    "        samples_so_far=len(samples),\n",
    "        time_left=budget - elapsed,\n",
    "        difficulty=difficulty.level,\n",
    "    )\n",
    "\n",
    "\n",
    "def control_decision(state: ControlState) -> ControlDecision:\n",
    "    \"\"\"\n",
    "    The core control policy.\n",
    "    \n",
    "    Returns: ACCEPT, ESCALATE, or FALLBACK\n",
    "    \"\"\"\n",
    "    # Hard fallback conditions\n",
    "    if state.time_left < MIN_TIME_FOR_SAMPLE:\n",
    "        return ControlDecision.FALLBACK\n",
    "    \n",
    "    # Budget exhausted for this difficulty\n",
    "    max_samples = BUDGET_CAPS.get(state.difficulty, 4)\n",
    "    if state.samples_so_far >= max_samples:\n",
    "        return ControlDecision.ACCEPT  # Accept best guess\n",
    "    \n",
    "    # Accept immediately if high confidence\n",
    "    if (state.cluster_support >= ACCEPT_HIGH_SUPPORT and \n",
    "        state.cluster_tightness >= ACCEPT_HIGH_TIGHTNESS and\n",
    "        not state.decision_reject):\n",
    "        return ControlDecision.ACCEPT\n",
    "    \n",
    "    # Accept with medium support if very tight and no warnings\n",
    "    if (state.cluster_support >= ACCEPT_MED_SUPPORT and\n",
    "        state.cluster_tightness >= ACCEPT_MED_TIGHTNESS and\n",
    "        state.warnings_count == 0):\n",
    "        return ControlDecision.ACCEPT\n",
    "    \n",
    "    # Escalate if low confidence and budget remains\n",
    "    if (state.cluster_support < ESCALATE_LOW_SUPPORT or\n",
    "        state.cluster_tightness < ESCALATE_LOW_TIGHTNESS or\n",
    "        state.warnings_count >= 1):\n",
    "        if state.samples_so_far < max_samples:\n",
    "            return ControlDecision.ESCALATE\n",
    "    \n",
    "    # Default: accept what we have\n",
    "    return ControlDecision.ACCEPT\n",
    "\n",
    "\n",
    "print(\"[BANSHEEV6] ControlPolicy: ACCEPT/ESCALATE/FALLBACK thresholds active\")\n",
    "print(f\"[BANSHEEV6] Accept: support>={ACCEPT_HIGH_SUPPORT}, tight>={ACCEPT_HIGH_TIGHTNESS}\")\n",
    "print(f\"[BANSHEEV6] Escalate: support<{ESCALATE_LOW_SUPPORT} OR tight<{ESCALATE_LOW_TIGHTNESS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ARCHETYPE ROUTER (Tier 5)\n",
    "# =========================\n",
    "# 10-15 problem archetypes with tailored policies.\n",
    "# Fast regex/keyword detection - no LLM needed.\n",
    "# =========================\n",
    "\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class Archetype(Enum):\n",
    "    MOD_ARITHMETIC = \"mod\"           # High yield\n",
    "    COUNTING = \"counting\"            # Medium-hard, fragile\n",
    "    OPTIMIZATION = \"optimization\"    # Trick-laden\n",
    "    GEOMETRY = \"geometry\"            # Prone to arithmetic slips\n",
    "    NUMBER_THEORY = \"number_theory\"  # Can be hard, many medium\n",
    "    ALGEBRA = \"algebra\"              # Equations, polynomials\n",
    "    INEQUALITY = \"inequality\"        # Time sink\n",
    "    SEQUENCE = \"sequence\"            # Medium, often solvable\n",
    "    PROBABILITY = \"probability\"      # Fragile with fractions\n",
    "    SIMPLE_COMPUTE = \"simple\"        # Easy wins\n",
    "    PROOF = \"proof\"                  # Often impossible under time\n",
    "    GENERAL = \"general\"              # Default\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ArchetypePolicy:\n",
    "    \"\"\"Policy for a specific archetype.\"\"\"\n",
    "    min_samples: int\n",
    "    max_samples: int\n",
    "    phase_b_prompt: str  # Specialized Phase B prompt\n",
    "    escalate_on_split: bool  # Extra sample if disagreement\n",
    "\n",
    "\n",
    "# === ARCHETYPE DETECTION ===\n",
    "\n",
    "ARCHETYPE_PATTERNS = {\n",
    "    Archetype.MOD_ARITHMETIC: [\n",
    "        r\"\\bremainder\\b\", r\"\\bmod\\b\", r\"\\bmodulo\\b\", \n",
    "        r\"divided by.*remainder\", r\"last.*digits?\\b\",\n",
    "        r\"\\bmod\\s*\\d+\", r\"congruent\",\n",
    "    ],\n",
    "    Archetype.COUNTING: [\n",
    "        r\"number of ways\", r\"how many\", r\"\\barrangements?\\b\",\n",
    "        r\"\\bpermutations?\\b\", r\"\\bcombinations?\\b\", \n",
    "        r\"count.*(?:ways|numbers|integers)\", r\"in how many\",\n",
    "    ],\n",
    "    Archetype.OPTIMIZATION: [\n",
    "        r\"\\bminimum\\b\", r\"\\bmaximum\\b\", r\"\\bleast\\b\", \n",
    "        r\"\\bgreatest\\b\", r\"\\boptimize\\b\", r\"\\bsmallest\\b\",\n",
    "        r\"\\blargest\\b\", r\"minimize\", r\"maximize\",\n",
    "    ],\n",
    "    Archetype.GEOMETRY: [\n",
    "        r\"\\bcircle\\b\", r\"\\btriangle\\b\", r\"\\bradius\\b\",\n",
    "        r\"\\barea\\b\", r\"\\bperimeter\\b\", r\"\\bangle\\b\",\n",
    "        r\"\\bdistance\\b\", r\"\\bpolygon\\b\", r\"\\bsquare\\b\",\n",
    "        r\"\\brectangle\\b\", r\"inscribed\", r\"circumscribed\",\n",
    "    ],\n",
    "    Archetype.NUMBER_THEORY: [\n",
    "        r\"integer solutions?\", r\"\\bdivisible\\b\", r\"\\bgcd\\b\",\n",
    "        r\"\\blcm\\b\", r\"\\bprime\\b\", r\"\\bfactors?\\b\",\n",
    "        r\"coprime\", r\"euler\", r\"fermat\",\n",
    "    ],\n",
    "    Archetype.ALGEBRA: [\n",
    "        r\"solve for\", r\"\\bequation\\b\", r\"\\bsystem\\b\",\n",
    "        r\"\\broots?\\b\", r\"\\bpolynomial\\b\", r\"\\bquadratic\\b\",\n",
    "        r\"find.*(?:value|x|y)\", r\"\\bcoefficients?\\b\",\n",
    "    ],\n",
    "    Archetype.INEQUALITY: [\n",
    "        r\"for all real\", r\"\\binequality\\b\", r\"function satisfies\",\n",
    "        r\"\\bfor all\\b.*>\", r\"\\bprove.*inequality\",\n",
    "    ],\n",
    "    Archetype.SEQUENCE: [\n",
    "        r\"\\bsequence\\b\", r\"\\brecurrence\\b\", r\"a_n\\b\", r\"a_\\{n\",\n",
    "        r\"f\\(n\\+1\\)\", r\"\\bterm\\b.*sequence\", r\"\\bfibonacci\\b\",\n",
    "    ],\n",
    "    Archetype.PROBABILITY: [\n",
    "        r\"\\bprobability\\b\", r\"expected value\", r\"\\brandom\\b\",\n",
    "        r\"\\bchance\\b\", r\"\\blikelihood\\b\", r\"fair.*(?:die|coin)\",\n",
    "    ],\n",
    "    Archetype.PROOF: [\n",
    "        r\"\\bprove\\b\", r\"\\bshow that\\b\", r\"\\bdemonstrate\\b\",\n",
    "        r\"\\bestablish\\b\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# === ARCHETYPE POLICIES ===\n",
    "\n",
    "ARCHETYPE_POLICIES = {\n",
    "    Archetype.MOD_ARITHMETIC: ArchetypePolicy(\n",
    "        min_samples=2, max_samples=3,\n",
    "        phase_b_prompt=\"Recompute the final modular arithmetic. Verify remainder is in [0, M-1].\",\n",
    "        escalate_on_split=True,\n",
    "    ),\n",
    "    Archetype.COUNTING: ArchetypePolicy(\n",
    "        min_samples=3, max_samples=5,  # H100\n",
    "        phase_b_prompt=\"Count again using an alternative method (bijection, generating function, or direct).\",\n",
    "        escalate_on_split=True,\n",
    "    ),\n",
    "    Archetype.OPTIMIZATION: ArchetypePolicy(\n",
    "        min_samples=3, max_samples=5,  # H100\n",
    "        phase_b_prompt=\"Check boundary cases and equality conditions for the optimum.\",\n",
    "        escalate_on_split=True,\n",
    "    ),\n",
    "    Archetype.GEOMETRY: ArchetypePolicy(\n",
    "        min_samples=2, max_samples=4,\n",
    "        phase_b_prompt=\"Recompute the final numeric value from the derived formula.\",\n",
    "        escalate_on_split=True,\n",
    "    ),\n",
    "    Archetype.NUMBER_THEORY: ArchetypePolicy(\n",
    "        min_samples=3, max_samples=6,  # H100\n",
    "        phase_b_prompt=\"Validate by plugging the answer back into the original constraints.\",\n",
    "        escalate_on_split=True,\n",
    "    ),\n",
    "    Archetype.ALGEBRA: ArchetypePolicy(\n",
    "        min_samples=2, max_samples=3,\n",
    "        phase_b_prompt=\"Substitute the answer to verify it satisfies the equation.\",\n",
    "        escalate_on_split=False,\n",
    "    ),\n",
    "    Archetype.INEQUALITY: ArchetypePolicy(\n",
    "        min_samples=3, max_samples=4,\n",
    "        phase_b_prompt=\"Verify with the equality case.\",\n",
    "        escalate_on_split=False,  # Time sink, don't over-invest\n",
    "    ),\n",
    "    Archetype.SEQUENCE: ArchetypePolicy(\n",
    "        min_samples=3, max_samples=4,\n",
    "        phase_b_prompt=\"Compute small n values to confirm the pattern matches.\",\n",
    "        escalate_on_split=True,\n",
    "    ),\n",
    "    Archetype.PROBABILITY: ArchetypePolicy(\n",
    "        min_samples=3, max_samples=4,\n",
    "        phase_b_prompt=\"Sanity check: probability must be in [0,1], then verify scaling.\",\n",
    "        escalate_on_split=True,\n",
    "    ),\n",
    "    Archetype.SIMPLE_COMPUTE: ArchetypePolicy(\n",
    "        min_samples=1, max_samples=2,\n",
    "        phase_b_prompt=\"Double-check the arithmetic.\",\n",
    "        escalate_on_split=False,  # Don't overspend on easy\n",
    "    ),\n",
    "    Archetype.PROOF: ArchetypePolicy(\n",
    "        min_samples=2, max_samples=4,\n",
    "        phase_b_prompt=\"If a numeric answer is expected, verify it.\",\n",
    "        escalate_on_split=False,  # Hard to escalate effectively\n",
    "    ),\n",
    "    Archetype.GENERAL: ArchetypePolicy(\n",
    "        min_samples=2, max_samples=4,\n",
    "        phase_b_prompt=\"Verify the final calculation step by step.\",\n",
    "        escalate_on_split=True,\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "def detect_archetype(problem_text: str) -> Tuple[Archetype, float]:\n",
    "    \"\"\"\n",
    "    Detect problem archetype from text.\n",
    "    Returns (archetype, confidence).\n",
    "    \"\"\"\n",
    "    t = problem_text.lower()\n",
    "    \n",
    "    # Check for simple/short problems first\n",
    "    if len(problem_text) < 150 and not any(\n",
    "        kw in t for kw in [\"prove\", \"show that\", \"for all\"]\n",
    "    ):\n",
    "        return Archetype.SIMPLE_COMPUTE, 0.8\n",
    "    \n",
    "    # Score each archetype\n",
    "    scores = {}\n",
    "    for archetype, patterns in ARCHETYPE_PATTERNS.items():\n",
    "        score = 0\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, t):\n",
    "                score += 1\n",
    "        scores[archetype] = score\n",
    "    \n",
    "    if not scores or max(scores.values()) == 0:\n",
    "        return Archetype.GENERAL, 0.3\n",
    "    \n",
    "    best = max(scores, key=scores.get)\n",
    "    total = sum(scores.values())\n",
    "    confidence = scores[best] / total if total > 0 else 0.3\n",
    "    \n",
    "    return best, confidence\n",
    "\n",
    "\n",
    "def get_archetype_policy(archetype: Archetype) -> ArchetypePolicy:\n",
    "    \"\"\"Get policy for archetype.\"\"\"\n",
    "    return ARCHETYPE_POLICIES.get(archetype, ARCHETYPE_POLICIES[Archetype.GENERAL])\n",
    "\n",
    "\n",
    "print(\"[BANSHEEV6] ArchetypeRouter: 11 problem types with tailored policies\")\n",
    "print(f\"[BANSHEEV6] Archetypes: {[a.value for a in Archetype]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# A/B SYMBOLIC AUTO-SOLVER\n",
    "# =========================\n",
    "# Deterministic solvers for easy A/B patterns\n",
    "# Runs BEFORE LLM pipeline - instant points with zero variance\n",
    "# =========================\n",
    "\n",
    "# Utility: safe eval of pure arithmetic expressions\n",
    "_ALLOWED_ARITH = set(\"0123456789+-*/()% ^\")\n",
    "\n",
    "def _safe_arith_eval(expr: str) -> Optional[int]:\n",
    "    \"\"\"Evaluate simple integer arithmetic safely.\"\"\"\n",
    "    if not expr:\n",
    "        return None\n",
    "    expr = expr.strip()\n",
    "\n",
    "    # normalize ^ to **\n",
    "    expr = expr.replace(\"^\", \"**\")\n",
    "    # quick filter - no letters allowed\n",
    "    if any(ch.isalpha() for ch in expr):\n",
    "        return None\n",
    "    if any(ch not in _ALLOWED_ARITH and ch != \"*\" for ch in expr):\n",
    "        return None\n",
    "    try:\n",
    "        val = eval(expr, {\"__builtins__\": {}}, {})\n",
    "    except Exception:\n",
    "        return None\n",
    "    try:\n",
    "        if isinstance(val, bool):\n",
    "            return None\n",
    "        if isinstance(val, int):\n",
    "            return int(val)\n",
    "        if isinstance(val, float) and abs(val - round(val)) < 1e-9:\n",
    "            return int(round(val))\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# PATTERN SOLVERS\n",
    "# =========================\n",
    "\n",
    "def solve_direct_arithmetic(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Catch classic A problems:\n",
    "    - \"Compute 2+2\"\n",
    "    - \"Evaluate ( ... )\"\n",
    "    - \"Find the value of <expr>\"\n",
    "    \"\"\"\n",
    "    t = text.strip()\n",
    "    # Look for math expression after keywords\n",
    "    m = re.search(r\"(?:compute|evaluate|find the value of)\\s*[:\\-]?\\s*([0-9\\(\\)\\+\\-\\*\\/\\%\\^\\s]+)\", t, re.I)\n",
    "    if not m:\n",
    "        # Sometimes the whole prompt IS the expression\n",
    "        m2 = re.search(r\"^\\s*([0-9\\(\\)\\+\\-\\*\\/\\%\\^\\s]+)\\s*[\\.\\?]?\\s*$\", t)\n",
    "        if not m2:\n",
    "            return None\n",
    "        expr = m2.group(1)\n",
    "    else:\n",
    "        expr = m.group(1)\n",
    "\n",
    "    expr = expr.strip()\n",
    "    if len(expr) > 80:\n",
    "        return None\n",
    "\n",
    "    ans = _safe_arith_eval(expr)\n",
    "    if ans is None:\n",
    "        return None\n",
    "\n",
    "    if 0 <= ans <= 99999:\n",
    "        return ans, {\"method\": \"direct_arithmetic\", \"expr\": expr}\n",
    "    return None\n",
    "\n",
    "\n",
    "def solve_mod_remainder(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Solve easy remainder problems:\n",
    "    - \"Find the remainder when <expr> is divided by <m>\"\n",
    "    - \"Compute <expr> mod <m>\"\n",
    "    - \"a^b mod m\" (modular exponentiation)\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "\n",
    "    # Find modulus\n",
    "    mm = re.search(r\"\\bmod(?:ulo)?\\s*(\\d{1,7})\\b\", t)\n",
    "    if not mm:\n",
    "        mm = re.search(r\"remainder\\s+when.*divided\\s+by\\s+(\\d{1,7})\", t)\n",
    "    if not mm:\n",
    "        return None\n",
    "    mod = int(mm.group(1))\n",
    "    if mod <= 0 or mod > 10**7:\n",
    "        return None\n",
    "\n",
    "    # Try exponent form a^b first\n",
    "    expm = re.search(r\"(\\d{1,9})\\s*\\^\\s*(\\d{1,9})\", t)\n",
    "    if expm:\n",
    "        a = int(expm.group(1))\n",
    "        b = int(expm.group(2))\n",
    "        ans = pow(a, b, mod)\n",
    "        if 0 <= ans <= 99999:\n",
    "            return ans, {\"method\": \"pow_mod\", \"a\": a, \"b\": b, \"mod\": mod}\n",
    "        return None\n",
    "\n",
    "    # Try plain arithmetic expression\n",
    "    expr = None\n",
    "    mexpr = re.search(r\"(?:compute|find|evaluate)\\s+(.+?)\\s+\\bmod\\b\\s*\\d{1,7}\", text, re.I)\n",
    "    if mexpr:\n",
    "        expr = mexpr.group(1).strip()\n",
    "    if expr is None:\n",
    "        mexpr2 = re.search(r\"([0-9\\(\\)\\+\\-\\*\\/\\%\\^\\s]{3,80})\\s+\\bmod\\b\\s*\\d{1,7}\", text, re.I)\n",
    "        if mexpr2:\n",
    "            expr = mexpr2.group(1).strip()\n",
    "\n",
    "    if not expr:\n",
    "        return None\n",
    "\n",
    "    val = _safe_arith_eval(expr)\n",
    "    if val is None:\n",
    "        return None\n",
    "    ans = val % mod\n",
    "    if 0 <= ans <= 99999:\n",
    "        return ans, {\"method\": \"arith_mod\", \"expr\": expr, \"mod\": mod}\n",
    "    return None\n",
    "\n",
    "\n",
    "def solve_gcd_lcm(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Solve direct GCD/LCM:\n",
    "    - \"gcd(123, 456)\"\n",
    "    - \"lcm of 12 and 30\"\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "    \n",
    "    # GCD\n",
    "    mg = re.search(r\"\\bgcd\\s*\\(\\s*(\\d{1,9})\\s*,\\s*(\\d{1,9})\\s*\\)\", t)\n",
    "    if mg:\n",
    "        a = int(mg.group(1))\n",
    "        b = int(mg.group(2))\n",
    "        ans = math.gcd(a, b)\n",
    "        if 0 <= ans <= 99999:\n",
    "            return ans, {\"method\": \"gcd\", \"a\": a, \"b\": b}\n",
    "        return None\n",
    "\n",
    "    mg2 = re.search(r\"\\bgcd\\b.*?\\b(\\d{1,9})\\b.*?\\b(\\d{1,9})\\b\", t)\n",
    "    if \"gcd\" in t and mg2:\n",
    "        a = int(mg2.group(1))\n",
    "        b = int(mg2.group(2))\n",
    "        ans = math.gcd(a, b)\n",
    "        if 0 <= ans <= 99999:\n",
    "            return ans, {\"method\": \"gcd\", \"a\": a, \"b\": b}\n",
    "        return None\n",
    "\n",
    "    # LCM\n",
    "    if \"lcm\" in t:\n",
    "        ml = re.search(r\"\\b(\\d{1,9})\\b.*?\\b(\\d{1,9})\\b\", t)\n",
    "        if ml:\n",
    "            a = int(ml.group(1))\n",
    "            b = int(ml.group(2))\n",
    "            ans = abs(a // math.gcd(a, b) * b)\n",
    "            if 0 <= ans <= 99999:\n",
    "                return ans, {\"method\": \"lcm\", \"a\": a, \"b\": b}\n",
    "    return None\n",
    "\n",
    "\n",
    "def solve_small_diophantine_count(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Count integer solutions in a tiny box:\n",
    "    - \"How many pairs (x,y) with 0<=x,y<=N satisfy x+y=k\"\n",
    "    - \"How many integer solutions satisfy x*y=k with bounds\"\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "\n",
    "    # x+y=k with bounds\n",
    "    m = re.search(r\"\\bx\\s*\\+\\s*y\\s*=\\s*(\\d{1,6})\", t)\n",
    "    if m:\n",
    "        k = int(m.group(1))\n",
    "        b = re.search(r\"0\\s*<=\\s*x\\s*,?\\s*y\\s*<=\\s*(\\d{1,5})\", t)\n",
    "        if b:\n",
    "            N = int(b.group(1))\n",
    "            cnt = 0\n",
    "            for x in range(0, N + 1):\n",
    "                y = k - x\n",
    "                if 0 <= y <= N:\n",
    "                    cnt += 1\n",
    "            if 0 <= cnt <= 99999:\n",
    "                return cnt, {\"method\": \"count_xy_sum\", \"k\": k, \"N\": N}\n",
    "\n",
    "    # x*y = k with bounds\n",
    "    m2 = re.search(r\"\\bx\\s*\\*\\s*y\\s*=\\s*(\\d{1,6})\", t)\n",
    "    if m2:\n",
    "        k = int(m2.group(1))\n",
    "        b = re.search(r\"0\\s*<=\\s*x\\s*,?\\s*y\\s*<=\\s*(\\d{1,5})\", t)\n",
    "        if b:\n",
    "            N = int(b.group(1))\n",
    "            cnt = 0\n",
    "            for x in range(0, N + 1):\n",
    "                if x == 0:\n",
    "                    if k == 0:\n",
    "                        cnt += (N + 1)\n",
    "                    continue\n",
    "                if k % x == 0:\n",
    "                    y = k // x\n",
    "                    if 0 <= y <= N:\n",
    "                        cnt += 1\n",
    "            if 0 <= cnt <= 99999:\n",
    "                return cnt, {\"method\": \"count_xy_prod\", \"k\": k, \"N\": N}\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def solve_sum_formula(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Sum of first n integers/squares/cubes:\n",
    "    - \"sum of first n integers\"\n",
    "    - \"1+2+3+...+n\"\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "    \n",
    "    # Sum of first n integers\n",
    "    m = re.search(r\"sum\\s+of\\s+(?:the\\s+)?first\\s+(\\d{1,6})\\s+(?:positive\\s+)?integers\", t)\n",
    "    if m:\n",
    "        n = int(m.group(1))\n",
    "        ans = n * (n + 1) // 2\n",
    "        if 0 <= ans <= 99999:\n",
    "            return ans, {\"method\": \"sum_n\", \"n\": n}\n",
    "    \n",
    "    # 1+2+...+n pattern\n",
    "    m2 = re.search(r\"1\\s*\\+\\s*2\\s*\\+\\s*(?:3\\s*\\+\\s*)?(?:\\.\\.\\.|\u2026)\\s*\\+?\\s*(\\d{1,6})\", t)\n",
    "    if m2:\n",
    "        n = int(m2.group(1))\n",
    "        ans = n * (n + 1) // 2\n",
    "        if 0 <= ans <= 99999:\n",
    "            return ans, {\"method\": \"sum_n\", \"n\": n}\n",
    "    \n",
    "    # Sum of squares\n",
    "    m3 = re.search(r\"sum\\s+of\\s+(?:the\\s+)?(?:first\\s+)?(\\d{1,4})\\s+(?:perfect\\s+)?squares\", t)\n",
    "    if m3:\n",
    "        n = int(m3.group(1))\n",
    "        ans = n * (n + 1) * (2 * n + 1) // 6\n",
    "        if 0 <= ans <= 99999:\n",
    "            return ans, {\"method\": \"sum_squares\", \"n\": n}\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def solve_factorial_binomial(text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Small factorial/binomial:\n",
    "    - \"n!\"\n",
    "    - \"C(n,k)\" or \"n choose k\"\n",
    "    \"\"\"\n",
    "    t = text.lower()\n",
    "    \n",
    "    # Factorial\n",
    "    m = re.search(r\"(\\d{1,2})\\s*!\", t)\n",
    "    if m:\n",
    "        n = int(m.group(1))\n",
    "        if n <= 12:  # 12! = 479001600, fits in 99999 check\n",
    "            ans = math.factorial(n)\n",
    "            if 0 <= ans <= 99999:\n",
    "                return ans, {\"method\": \"factorial\", \"n\": n}\n",
    "    \n",
    "    # Binomial C(n,k)\n",
    "    m2 = re.search(r\"c\\s*\\(\\s*(\\d{1,3})\\s*,\\s*(\\d{1,3})\\s*\\)\", t)\n",
    "    if m2:\n",
    "        n = int(m2.group(1))\n",
    "        k = int(m2.group(2))\n",
    "        if n <= 30 and k <= n:\n",
    "            ans = math.comb(n, k)\n",
    "            if 0 <= ans <= 99999:\n",
    "                return ans, {\"method\": \"binomial\", \"n\": n, \"k\": k}\n",
    "    \n",
    "    # \"n choose k\"\n",
    "    m3 = re.search(r\"(\\d{1,3})\\s+choose\\s+(\\d{1,3})\", t)\n",
    "    if m3:\n",
    "        n = int(m3.group(1))\n",
    "        k = int(m3.group(2))\n",
    "        if n <= 30 and k <= n:\n",
    "            ans = math.comb(n, k)\n",
    "            if 0 <= ans <= 99999:\n",
    "                return ans, {\"method\": \"binomial\", \"n\": n, \"k\": k}\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================\n",
    "# DISPATCHER\n",
    "# =========================\n",
    "\n",
    "AUTO_SOLVERS = [\n",
    "    solve_direct_arithmetic,\n",
    "    solve_mod_remainder,\n",
    "    solve_gcd_lcm,\n",
    "    solve_small_diophantine_count,\n",
    "    solve_sum_formula,\n",
    "    solve_factorial_binomial,\n",
    "]\n",
    "\n",
    "\n",
    "def try_autosolve_AB(question_text: str) -> Optional[Tuple[int, Dict[str, Any]]]:\n",
    "    \"\"\"Returns (answer, meta) if solved deterministically, else None.\"\"\"\n",
    "    for f in AUTO_SOLVERS:\n",
    "        try:\n",
    "            out = f(question_text)\n",
    "            if out is not None:\n",
    "                ans, meta = out\n",
    "                if isinstance(ans, int) and 0 <= ans <= 99999:\n",
    "                    return ans, meta\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "print(\"[BANSHEEV6] A/B Auto-Solver: OK\")\n",
    "print(f\"[BANSHEEV6] AUTO_SOLVERS: {len(AUTO_SOLVERS)} pattern solvers loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ADAPTIVE SAMPLE CONTROLLER (Tier 1)\n",
    "# =========================\n",
    "# Early-exit when confidence is high.\n",
    "# Key insight: AIMO problems are bimodal -\n",
    "# many solved in 1-2 tries, few need multiple.\n",
    "# =========================\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SampleState:\n",
    "    \"\"\"Real-time state of sampling for a problem.\"\"\"\n",
    "    samples: List[int]\n",
    "    verifications: Dict[int, VerificationResult]\n",
    "    traces: List[str]\n",
    "    \n",
    "    # Thresholds (tunable)\n",
    "    EARLY_EXIT_CONFIDENCE: float = 0.85\n",
    "    MIN_CLUSTER_SIZE: int = 2\n",
    "    PERFECT_AGREEMENT_EXIT: bool = True\n",
    "    \n",
    "    def add_sample(self, answer: int, vr: VerificationResult, trace: str = \"\"):\n",
    "        \"\"\"Add a new sample and its verification.\"\"\"\n",
    "        self.samples.append(answer)\n",
    "        # Keep best verification per answer\n",
    "        if answer not in self.verifications or vr.score > self.verifications[answer].score:\n",
    "            self.verifications[answer] = vr\n",
    "        if trace:\n",
    "            self.traces.append(trace)\n",
    "    \n",
    "    def should_early_exit(self) -> Tuple[bool, str, Optional[int]]:\n",
    "        \"\"\"\n",
    "        Check if we should stop sampling early.\n",
    "        \n",
    "        Returns: (should_exit, reason, confident_answer)\n",
    "        \"\"\"\n",
    "        if len(self.samples) < 2:\n",
    "            return False, \"need_more_samples\", None\n",
    "        \n",
    "        counter = Counter(self.samples)\n",
    "        top_answer, top_count = counter.most_common(1)[0]\n",
    "        total = len(self.samples)\n",
    "        \n",
    "        # Get verification for top answer\n",
    "        vr = self.verifications.get(top_answer)\n",
    "        verified = vr is not None and vr.score >= 1 and not vr.failed_checks\n",
    "        \n",
    "        # === CONDITION 1: Perfect agreement (2+ identical answers, verified) ===\n",
    "        if self.PERFECT_AGREEMENT_EXIT and top_count >= 2 and verified:\n",
    "            # All samples so far agree on same answer\n",
    "            if top_count == total:\n",
    "                return True, \"perfect_agreement\", top_answer\n",
    "        \n",
    "        # === CONDITION 2: Strong cluster (>= 2/3 agreement + verified) ===\n",
    "        agreement_ratio = top_count / total\n",
    "        if top_count >= self.MIN_CLUSTER_SIZE and agreement_ratio >= 0.67 and verified:\n",
    "            return True, \"strong_cluster\", top_answer\n",
    "        \n",
    "        # === CONDITION 3: High CIC confidence ===\n",
    "        if len(self.samples) >= 3:\n",
    "            cic = compute_cic_functional(self.samples, self.traces)\n",
    "            if cic.confidence >= self.EARLY_EXIT_CONFIDENCE and verified:\n",
    "                return True, \"high_cic_confidence\", top_answer\n",
    "        \n",
    "        # === CONDITION 4: Cluster tightness (value clustering) ===\n",
    "        if len(self.samples) >= 3 and RUNTIME.ENABLE_VALUE_CLUSTERING:\n",
    "            result = value_clustering(self.samples, threshold=0.05)\n",
    "            if result[\"best\"] is not None:\n",
    "                best = result[\"best\"]\n",
    "                # Tight cluster with good size\n",
    "                if best.size >= 2 and best.tightness >= 0.9:\n",
    "                    cluster_answer = basin_refinement(best)\n",
    "                    cluster_vr = self.verifications.get(cluster_answer)\n",
    "                    if cluster_vr and cluster_vr.score >= 1:\n",
    "                        return True, \"tight_cluster\", cluster_answer\n",
    "        \n",
    "        return False, \"continue\", None\n",
    "    \n",
    "    def get_recommended_samples(self, budget_seconds: float) -> int:\n",
    "        \"\"\"\n",
    "        Recommend how many more samples to try.\n",
    "        \n",
    "        Adaptive based on current state:\n",
    "        - High agreement -> fewer samples needed\n",
    "        - No agreement -> more samples needed\n",
    "        - Time pressure -> cap samples\n",
    "        \"\"\"\n",
    "        if len(self.samples) == 0:\n",
    "            # First sample - always do at least 2-4\n",
    "            if budget_seconds < 60:\n",
    "                return 2\n",
    "            elif budget_seconds < 180:\n",
    "                return 4\n",
    "            else:\n",
    "                return 6\n",
    "        \n",
    "        # Check current agreement\n",
    "        counter = Counter(self.samples)\n",
    "        top_count = counter.most_common(1)[0][1]\n",
    "        total = len(self.samples)\n",
    "        agreement = top_count / total if total > 0 else 0\n",
    "        \n",
    "        # High agreement -> fewer additional samples\n",
    "        if agreement >= 0.8 and total >= 2:\n",
    "            return 1  # Just one more to confirm\n",
    "        elif agreement >= 0.5 and total >= 3:\n",
    "            return 2  # Two more to break tie\n",
    "        else:\n",
    "            # Low agreement - need more but cap it\n",
    "            remaining = max(2, min(4, int(budget_seconds / 30)))\n",
    "            return remaining\n",
    "\n",
    "\n",
    "def create_sample_state() -> SampleState:\n",
    "    \"\"\"Factory for new sample state.\"\"\"\n",
    "    return SampleState(samples=[], verifications={}, traces=[])\n",
    "\n",
    "\n",
    "print(\"[BANSHEEV6] AdaptiveSampleController: EARLY-EXIT enabled\")\n",
    "print(f\"[BANSHEEV6] Exit thresholds: confidence>={SampleState.EARLY_EXIT_CONFIDENCE}, cluster>={SampleState.MIN_CLUSTER_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# SOLVE - FULL COMPETITION ARCHITECTURE\n",
    "# =========================\n",
    "# Tier 1: Adaptive multi-sampling with early-exit\n",
    "# Tier 2: Difficulty-aware routing\n",
    "# Tier 3: Two-phase reasoning (Phase B arithmetic)\n",
    "# Tier 4: Self-consistency refinement (basin re-prompting)\n",
    "# Tier 5: Control policy + Archetype routing (SELECTIVE AGGRESSOR)\n",
    "# =========================\n",
    "\n",
    "def should_skip_fast(*, elapsed, budget, samples, verifs, cic_history, regen_attempts):\n",
    "    if elapsed < 0.3 * budget:\n",
    "        return False\n",
    "    any_verified = any(vr.score >= 1 and \"brute_reject\" not in vr.failed_checks for vr in verifs.values())\n",
    "    if any_verified:\n",
    "        return False\n",
    "    if len(samples) < 4:\n",
    "        return False\n",
    "    if elapsed < 0.5 * budget:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def solve(question_text: str, question_id: str) -> int:\n",
    "    \"\"\"\n",
    "    Main solve: Full 5-tier stack.\n",
    "    \n",
    "    The selective aggressor: spend compute only when it buys probability mass.\n",
    "    \"\"\"\n",
    "    \n",
    "    # === PHASE 0: SYMBOLIC AUTO-SOLVE ===\n",
    "    auto = try_autosolve_AB(question_text)\n",
    "    if auto is not None:\n",
    "        ans, meta = auto\n",
    "        print(f\"[AUTO] Solved: {ans} via {meta.get('method')}\")\n",
    "        completed_question_ids.add(question_id)\n",
    "        return ans\n",
    "    \n",
    "    server_ready = ensure_server()\n",
    "    if not server_ready:\n",
    "        return fallback_solver(question_text)\n",
    "    \n",
    "    if TIME_MANAGER.is_expired():\n",
    "        return fallback_solver(question_text)\n",
    "    \n",
    "    # === TIER 2: DIFFICULTY CLASSIFICATION ===\n",
    "    difficulty = classify_difficulty(question_text)\n",
    "    strategy = get_strategy(difficulty)\n",
    "    \n",
    "    # === TIER 5: ARCHETYPE DETECTION ===\n",
    "    archetype, arch_conf = detect_archetype(question_text)\n",
    "    arch_policy = get_archetype_policy(archetype)\n",
    "    \n",
    "    print(f\"\\n[DIFFICULTY] {difficulty.level.value.upper()} (conf={difficulty.confidence:.2f})\")\n",
    "    print(f\"[ARCHETYPE] {archetype.value} (conf={arch_conf:.2f})\")\n",
    "    print(f\"[POLICY] samples={arch_policy.min_samples}-{arch_policy.max_samples}, escalate_on_split={arch_policy.escalate_on_split}\")\n",
    "    \n",
    "    # Reset state\n",
    "    question_id_to_counter[question_id] = Counter()\n",
    "    question_id_to_samples[question_id] = []\n",
    "    question_id_to_traces[question_id] = []\n",
    "    question_id_to_cic_history[question_id] = []\n",
    "    question_id_to_verification[question_id] = {}\n",
    "    completed_question_ids.discard(question_id)\n",
    "    \n",
    "    budget = TIME_MANAGER.start_problem()\n",
    "    solve_start = time.time()\n",
    "    \n",
    "    sample_state = create_sample_state()\n",
    "    sample_state.EARLY_EXIT_CONFIDENCE = strategy.early_exit_threshold\n",
    "    \n",
    "    # Use archetype policy for sample limits\n",
    "    max_generations = min(arch_policy.max_samples, max(2, int(budget / 25)))\n",
    "    \n",
    "    print(f\"\\n[SOLVE] {question_id}\")\n",
    "    print(f\"[TIME] {TIME_MANAGER.status()}\")\n",
    "    print(f\"[BUDGET] {budget:.0f}s, up to {max_generations} samples\")\n",
    "    \n",
    "    if budget <= 10:\n",
    "        TIME_MANAGER.end_problem(0, budget)\n",
    "        return fallback_solver(question_text)\n",
    "    \n",
    "    prompt_indices = get_routed_prompts(question_text, max_generations)\n",
    "    regen_attempts = 0\n",
    "    early_exit_answer = None\n",
    "    early_exit_reason = None\n",
    "    phase_b_corrections = 0\n",
    "    \n",
    "    for i in range(max_generations):\n",
    "        if not TIME_MANAGER.should_continue(solve_start, budget):\n",
    "            break\n",
    "        if question_id in completed_question_ids:\n",
    "            break\n",
    "        \n",
    "        elapsed = time.time() - solve_start\n",
    "        \n",
    "        # === TIER 5: CONTROL POLICY DECISION ===\n",
    "        if i >= arch_policy.min_samples:\n",
    "            ctrl_state = compute_control_state(\n",
    "                question_id_to_samples[question_id],\n",
    "                question_id_to_verification[question_id],\n",
    "                difficulty,\n",
    "                elapsed,\n",
    "                budget,\n",
    "            )\n",
    "            decision = control_decision(ctrl_state)\n",
    "            \n",
    "            if decision == ControlDecision.ACCEPT:\n",
    "                samples = question_id_to_samples[question_id]\n",
    "                if samples:\n",
    "                    counter = Counter(samples)\n",
    "                    early_exit_answer = counter.most_common(1)[0][0]\n",
    "                    early_exit_reason = f\"control_accept (sup={ctrl_state.cluster_support:.2f}, tight={ctrl_state.cluster_tightness:.2f})\"\n",
    "                    print(f\"[CONTROL] ACCEPT: {early_exit_answer}\")\n",
    "                    TIME_MANAGER.time_banked += 0.4 * (budget - elapsed)\n",
    "                    break\n",
    "            elif decision == ControlDecision.FALLBACK:\n",
    "                print(\"[CONTROL] FALLBACK triggered\")\n",
    "                break\n",
    "            # ESCALATE: continue sampling\n",
    "        \n",
    "        # === TIER 1: EARLY-EXIT CHECK (backup) ===\n",
    "        if i >= 2:\n",
    "            should_exit, reason, confident_answer = sample_state.should_early_exit()\n",
    "            if should_exit and confident_answer is not None:\n",
    "                print(f\"[EARLY-EXIT] {reason}: {confident_answer}\")\n",
    "                early_exit_answer = confident_answer\n",
    "                early_exit_reason = reason\n",
    "                TIME_MANAGER.time_banked += 0.5 * (budget - elapsed)\n",
    "                break\n",
    "        \n",
    "        # === SIMPLE COMPUTE FAST PATH ===\n",
    "        if archetype == Archetype.SIMPLE_COMPUTE and i >= 1:\n",
    "            samples = question_id_to_samples[question_id]\n",
    "            if len(samples) >= 2:\n",
    "                counter = Counter(samples)\n",
    "                top_ans, top_count = counter.most_common(1)[0]\n",
    "                if top_count >= 2:\n",
    "                    print(f\"[SIMPLE-EXIT] 2 agreeing: {top_ans}\")\n",
    "                    early_exit_answer = top_ans\n",
    "                    TIME_MANAGER.time_banked += 0.6 * (budget - elapsed)\n",
    "                    break\n",
    "        \n",
    "        prompt_idx = prompt_indices[i] if i < len(prompt_indices) else i % len(SYSTEM_PROMPTS)\n",
    "        sys_prompt = SYSTEM_PROMPTS[prompt_idx]\n",
    "        \n",
    "        try:\n",
    "            answer = generate_solution(question_text, question_id, i, sys_prompt, budget, max_generations)\n",
    "            \n",
    "            if answer is not None:\n",
    "                gen_elapsed = time.time() - solve_start\n",
    "                \n",
    "                # === TIER 3: PHASE B (archetype-aware) ===\n",
    "                if should_run_phase_b(answer, difficulty, gen_elapsed, budget):\n",
    "                    original = answer\n",
    "                    # Use archetype-specific Phase B prompt if available\n",
    "                    answer = run_phase_b(question_text, answer, question_id, min(20, budget - gen_elapsed - 5))\n",
    "                    if answer != original:\n",
    "                        phase_b_corrections += 1\n",
    "                        if original in question_id_to_samples[question_id]:\n",
    "                            idx = question_id_to_samples[question_id].index(original)\n",
    "                            question_id_to_samples[question_id][idx] = answer\n",
    "                            question_id_to_counter[question_id][original] -= 1\n",
    "                            question_id_to_counter[question_id][answer] += 1\n",
    "                \n",
    "                vr = verify_answer(question_text, answer)\n",
    "                trace = question_id_to_traces[question_id][-1] if question_id_to_traces[question_id] else \"\"\n",
    "                sample_state.add_sample(answer, vr, trace)\n",
    "                \n",
    "                prev = question_id_to_verification[question_id].get(answer)\n",
    "                if prev is None or vr.score > prev.score:\n",
    "                    question_id_to_verification[question_id][answer] = vr\n",
    "                \n",
    "                decision = regeneration_policy(question_id, question_text, answer, vr, i)\n",
    "                print(f\"[VERIFY] ans={answer}, score={vr.score}\")\n",
    "                \n",
    "                if decision == \"reject\":\n",
    "                    regen_attempts += 1\n",
    "                    # Archetype escalation on reject\n",
    "                    if arch_policy.escalate_on_split and i < max_generations - 1:\n",
    "                        print(\"[ESCALATE] Rejected answer, trying again\")\n",
    "                    continue\n",
    "                \n",
    "                if decision == \"regenerate\":\n",
    "                    regen_attempts += 1\n",
    "                \n",
    "                # Crystallization for clustering archetypes\n",
    "                if strategy.use_clustering and len(question_id_to_samples[question_id]) >= 3:\n",
    "                    if detect_safe_crystallization(question_id_to_samples[question_id],\n",
    "                                                  question_id_to_verification[question_id],\n",
    "                                                  question_id_to_cic_history[question_id]):\n",
    "                        completed_question_ids.add(question_id)\n",
    "                        break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"[SOLVE] Gen {i} error: {e}\")\n",
    "            regen_attempts += 1\n",
    "            continue\n",
    "    \n",
    "    # === ANSWER SELECTION ===\n",
    "    elapsed_before_select = time.time() - solve_start\n",
    "    \n",
    "    if early_exit_answer is not None:\n",
    "        final_answer = early_exit_answer\n",
    "        print(f\"[SELECT] Early-exit: {final_answer} ({early_exit_reason})\")\n",
    "    else:\n",
    "        samples = question_id_to_samples[question_id]\n",
    "        print(f\"[SOLVE] {len(samples)} samples, {phase_b_corrections} Phase-B corrections\")\n",
    "        \n",
    "        if not samples:\n",
    "            final_answer = fallback_solver(question_text)\n",
    "        else:\n",
    "            # === TIER 4: SELF-CONSISTENCY REFINEMENT ===\n",
    "            should_refine, basin_center, basin_members = should_refine_with_basin(\n",
    "                samples, difficulty, elapsed_before_select, budget\n",
    "            )\n",
    "            \n",
    "            if should_refine and basin_center is not None:\n",
    "                print(f\"[REFINE] Basin refinement around {basin_center}\")\n",
    "                remaining = budget - elapsed_before_select\n",
    "                refined = run_basin_refinement(\n",
    "                    question_text, basin_center, basin_members, question_id,\n",
    "                    timeout=min(25, remaining - 5)\n",
    "                )\n",
    "                final_answer = refined if refined is not None else basin_center\n",
    "            else:\n",
    "                # Standard selection\n",
    "                try:\n",
    "                    if strategy.use_clustering:\n",
    "                        final_answer, confidence, metadata = select_answer_with_verification(\n",
    "                            candidates=samples, problem_text=question_text, \n",
    "                            fallback=fallback_solver(question_text))\n",
    "                        print(f\"[SELECT] Clustered: {final_answer} (conf={confidence:.2f})\")\n",
    "                    else:\n",
    "                        counter = Counter(samples)\n",
    "                        final_answer = counter.most_common(1)[0][0]\n",
    "                        print(f\"[SELECT] Majority: {final_answer}\")\n",
    "                except:\n",
    "                    final_answer = samples[0] if samples else fallback_solver(question_text)\n",
    "    \n",
    "    # Golden clamp\n",
    "    try:\n",
    "        final_answer = int(final_answer)\n",
    "    except:\n",
    "        final_answer = fallback_solver(question_text)\n",
    "    \n",
    "    final_answer = max(0, min(99999, final_answer))\n",
    "    \n",
    "    actual_time = time.time() - solve_start\n",
    "    TIME_MANAGER.end_problem(actual_time, budget)\n",
    "    \n",
    "    print(f\"[SOLVE] Final: {final_answer} ({actual_time:.1f}s, {difficulty.level.value}, {archetype.value})\")\n",
    "    completed_question_ids.add(question_id)\n",
    "    return final_answer\n",
    "\n",
    "\n",
    "print(\"[BANSHEEV6] solve(): FULL 5-TIER STACK (Selective Aggressor)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# PREDICT - NO UNCONDITIONAL ZEROS\n",
    "# =========================\n",
    "import kaggle_evaluation.aimo_3_inference_server\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Load reference for debugging\n",
    "id_to_answer = {}\n",
    "try:\n",
    "    ref_path = \"/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv\"\n",
    "    if os.path.exists(ref_path):\n",
    "        df = pd.read_csv(ref_path)\n",
    "        id_to_answer = dict(zip(df[\"id\"], df[\"answer\"]))\n",
    "        df.drop(\"answer\", axis=1).to_csv(\"reference.csv\", index=False)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "_problems_processed = 0\n",
    "_correct_count = 0\n",
    "_total_count = 0\n",
    "\n",
    "\n",
    "def golden_clamp(answer: int) -> int:\n",
    "    \"\"\"SINGLE point of clamping. All paths use this.\"\"\"\n",
    "    return max(0, min(99999, int(answer)))\n",
    "\n",
    "\n",
    "def predict(id_: pl.Series, problem: pl.Series) -> pl.DataFrame:\n",
    "    \"\"\"Kaggle API prediction. NEVER returns 0 unconditionally.\"\"\"\n",
    "    global _problems_processed, _correct_count, _total_count\n",
    "    \n",
    "    try:\n",
    "        question_id = str(id_.item(0))\n",
    "    except:\n",
    "        question_id = \"unknown\"\n",
    "    \n",
    "    try:\n",
    "        question_text = str(problem.item(0))\n",
    "    except:\n",
    "        question_text = \"\"\n",
    "    \n",
    "    _problems_processed += 1\n",
    "    \n",
    "    # ChatGPT: \"gate verbose prints to avoid stdout limits\"\n",
    "    _verbose = (_problems_processed <= 3) or (_problems_processed % 50 == 0)\n",
    "    \n",
    "    if _verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"[PREDICT] Problem #{_problems_processed}: {question_id}\")\n",
    "        print(f\"[TIME] {TIME_MANAGER.status()}\")\n",
    "    \n",
    "    # Ensure server is ready (lazy start)\n",
    "    if not ensure_server():\n",
    "        print(\"[PREDICT] Server not ready - using fallback\")\n",
    "        prediction = golden_clamp(fallback_solver(question_text) if question_text else 42)\n",
    "        return pl.DataFrame({\"id\": [question_id], \"answer\": [prediction]})\n",
    "    \n",
    "    # Time expired - use fallback (not 0)\n",
    "    if TIME_MANAGER.is_expired():\n",
    "        print(f\"[PREDICT] TIME EXPIRED - using fallback\")\n",
    "        prediction = golden_clamp(fallback_solver(question_text) if question_text else 42)\n",
    "        return pl.DataFrame({\"id\": [question_id], \"answer\": [prediction]})\n",
    "    \n",
    "    # Empty problem - use fallback\n",
    "    if not question_text.strip():\n",
    "        print(f\"[PREDICT] Empty problem - using fallback\")\n",
    "        return pl.DataFrame({\"id\": [question_id], \"answer\": [golden_clamp(42)]})\n",
    "    \n",
    "    # SOLVE\n",
    "    try:\n",
    "        raw_prediction = solve(question_text, question_id=question_id)\n",
    "        prediction = golden_clamp(int(raw_prediction))\n",
    "    except Exception as e:\n",
    "        print(f\"[PREDICT] Solve error: {e} - using fallback\")\n",
    "        prediction = golden_clamp(fallback_solver(question_text))\n",
    "    \n",
    "    # Score tracking\n",
    "    if id_to_answer:\n",
    "        try:\n",
    "            true_answer = int(id_to_answer.get(question_id, -1))\n",
    "            _total_count += 1\n",
    "            if prediction == true_answer and true_answer != -1:\n",
    "                _correct_count += 1\n",
    "                print(f\"[SCORE] CORRECT: {_correct_count}/{_total_count}\")\n",
    "            elif true_answer != -1:\n",
    "                print(f\"[SCORE] WRONG: pred={prediction}, true={true_answer}\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if _verbose:\n",
    "        print(f\"[PREDICT] Answer: {prediction}\")\n",
    "    return pl.DataFrame({\"id\": [question_id], \"answer\": [prediction]})\n",
    "\n",
    "print(\"[BANSHEEV6] predict(): SINGLE golden_clamp, lazy server start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# RUN SERVER - serve() FIRST\n",
    "# =========================\n",
    "# CRITICAL: serve() MUST be called BEFORE any blocking operations.\n",
    "# vLLM startup is LAZY - happens on first predict() call.\n",
    "# This ensures Kaggle's 15-minute startup limit is satisfied.\n",
    "# =========================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BANSHEEV6: COMPETITION MODE\")\n",
    "print(f\"SERVER_WAIT: {RUNTIME.SERVER_WAIT_TIMEOUT}s\")\n",
    "print(f\"MOCK_ANSWERS: {RUNTIME.DRY_RUN_MOCK_ANSWERS}\")\n",
    "print(f\"CLUSTERING: {RUNTIME.ENABLE_VALUE_CLUSTERING}\")\n",
    "print(f\"CRYSTALLIZATION: {RUNTIME.ENABLE_CRYSTALLIZATION}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "inference_server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n",
    "\n",
    "# serve() FIRST - ALWAYS\n",
    "# vLLM starts lazily on first predict() call\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    print(\"[SERVER] Competition rerun - serve() (vLLM starts on first predict)\")\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # Validation run - use gateway with reference.csv\n",
    "    print(\"[SERVER] Validation - run_local_gateway() (vLLM starts on first predict)\")\n",
    "    inference_server.run_local_gateway((\"reference.csv\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CLEANUP\n",
    "# =========================\n",
    "import atexit\n",
    "\n",
    "def cleanup():\n",
    "    global vllm_process\n",
    "    if vllm_process and vllm_process.poll() is None:\n",
    "        print(\"[CLEANUP] Stopping vLLM...\")\n",
    "        vllm_process.terminate()\n",
    "        try:\n",
    "            vllm_process.wait(timeout=10)\n",
    "        except:\n",
    "            vllm_process.kill()\n",
    "        print(\"[CLEANUP] Done\")\n",
    "\n",
    "atexit.register(cleanup)\n",
    "print(\"[BANSHEEV6] Cleanup registered\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# BANSHEEV6 READY + SELF-TEST\n",
    "# =========================\n",
    "\n",
    "def submission_self_test():\n",
    "    \"\"\"\n",
    "    Run this BEFORE submitting to verify everything works.\n",
    "    ChatGPT: \"one-cell submission readiness self-test\"\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"SUBMISSION SELF-TEST\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    checks = []\n",
    "    \n",
    "    # Check 1: Preflight passed?\n",
    "    try:\n",
    "        checks.append((\"Preflight passed\", _PREFLIGHT_PASSED))\n",
    "    except:\n",
    "        checks.append((\"Preflight passed\", False))\n",
    "    \n",
    "    # Check 2: vLLM available?\n",
    "    try:\n",
    "        checks.append((\"vLLM available\", _VLLM_AVAILABLE))\n",
    "    except:\n",
    "        checks.append((\"vLLM available\", False))\n",
    "    \n",
    "    # Check 3: Model path?\n",
    "    checks.append((\"Model path exists\", os.path.exists(MODEL_PATH)))\n",
    "    \n",
    "    # Check 4: CUDA?\n",
    "    try:\n",
    "        import torch\n",
    "        checks.append((\"CUDA available\", torch.cuda.is_available()))\n",
    "    except:\n",
    "        checks.append((\"CUDA available\", False))\n",
    "    \n",
    "    # Check 5: predict function exists?\n",
    "    checks.append((\"predict() defined\", 'predict' in dir()))\n",
    "    \n",
    "    # Check 6: golden_clamp works?\n",
    "    try:\n",
    "        test = golden_clamp(123456)\n",
    "        checks.append((\"golden_clamp works\", test == 99999))\n",
    "    except:\n",
    "        checks.append((\"golden_clamp works\", False))\n",
    "    \n",
    "    # Results\n",
    "    all_pass = True\n",
    "    for name, passed in checks:\n",
    "        status = \"\u2713\" if passed else \"\u2717\"\n",
    "        print(f\"  [{status}] {name}\")\n",
    "        if not passed:\n",
    "            all_pass = False\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    if all_pass:\n",
    "        print(\"\u2713 ALL CHECKS PASSED - Ready for submission!\")\n",
    "    else:\n",
    "        print(\"\u2717 SOME CHECKS FAILED - Debug before submitting!\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return all_pass\n",
    "\n",
    "print(\"[BANSHEEV6] All cells loaded. Competition mode only.\")\n",
    "print(\"[BANSHEEV6] Run submission_self_test() to verify readiness.\")\n",
    ""
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}