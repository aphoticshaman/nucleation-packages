{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb276a22",
   "metadata": {
    "papermill": {
     "duration": 0.004364,
     "end_time": "2025-05-23T09:37:18.768809",
     "exception": false,
     "start_time": "2025-05-23T09:37:18.764445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"display: flex; justify-content: space-between; align-items: flex-start;\">\n",
    "    <div style=\"text-align: left;\">\n",
    "        <p style=\"color:#FFD700; font-size: 15px; font-weight: bold; margin-bottom: 1px; text-align: left;\">Published on  May 1, 2025</p>\n",
    "        <h4 style=\"color:#4B0082; font-weight: bold; text-align: left; margin-top: 6px;\">Author: Jocelyn C. Dumlao</h4>\n",
    "        <p style=\"font-size: 17px; line-height: 1.7; color: #333; text-align: center; margin-top: 20px;\"></p>\n",
    "        <a href=\"https://www.linkedin.com/in/jocelyn-dumlao-168921a8/\" target=\"_blank\" style=\"display: inline-block; background-color: #003f88; color: #fff; text-decoration: none; padding: 5px 10px; border-radius: 10px; margin: 15px;\">LinkedIn</a>\n",
    "        <a href=\"https://github.com/jcdumlao14\" target=\"_blank\" style=\"display: inline-block; background-color: transparent; color: #059c99; text-decoration: none; padding: 5px 10px; border-radius: 10px; margin: 15px; border: 2px solid #007bff;\">GitHub</a>\n",
    "        <a href=\"https://www.youtube.com/@CogniCraftedMinds\" target=\"_blank\" style=\"display: inline-block; background-color: #ff0054; color: #fff; text-decoration: none; padding: 5px 10px; border-radius: 10px; margin: 15px;\">YouTube</a>\n",
    "        <a href=\"https://www.kaggle.com/jocelyndumlao\" target=\"_blank\" style=\"display: inline-block; background-color: #3a86ff; color: #fff; text-decoration: none; padding: 5px 10px; border-radius: 10px; margin: 15px;\">Kaggle</a>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd49f5e",
   "metadata": {
    "papermill": {
     "duration": 0.003091,
     "end_time": "2025-05-23T09:37:18.775437",
     "exception": false,
     "start_time": "2025-05-23T09:37:18.772346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"padding:10px;background-color:#09abf2;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:12px;font-weight:200;border: 6px outset #f2102e;\">Import Libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddafae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T09:37:18.783025Z",
     "iopub.status.busy": "2025-05-23T09:37:18.782714Z",
     "iopub.status.idle": "2025-05-23T09:37:26.625842Z",
     "shell.execute_reply": "2025-05-23T09:37:26.625032Z"
    },
    "papermill": {
     "duration": 7.848652,
     "end_time": "2025-05-23T09:37:26.627335",
     "exception": false,
     "start_time": "2025-05-23T09:37:18.778683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51124d0e",
   "metadata": {
    "papermill": {
     "duration": 0.003316,
     "end_time": "2025-05-23T09:37:26.634312",
     "exception": false,
     "start_time": "2025-05-23T09:37:26.630996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reference: [Qwen 3 qwen-lm/qwen-3](https://www.kaggle.com/models/qwen-lm/qwen-3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc8773",
   "metadata": {
    "papermill": {
     "duration": 0.003119,
     "end_time": "2025-05-23T09:37:26.640674",
     "exception": false,
     "start_time": "2025-05-23T09:37:26.637555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"padding:10px;background-color:#09abf2;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:12px;font-weight:200;border: 6px outset #f2102e;\">Define paths to the datasets</p>\n",
    "\n",
    "- The code first locates the JSON files containing the ARC (Abstraction and Reasoning Corpus) dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "846f803a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T09:37:26.648952Z",
     "iopub.status.busy": "2025-05-23T09:37:26.648016Z",
     "iopub.status.idle": "2025-05-23T09:37:26.652162Z",
     "shell.execute_reply": "2025-05-23T09:37:26.651461Z"
    },
    "papermill": {
     "duration": 0.009328,
     "end_time": "2025-05-23T09:37:26.653255",
     "exception": false,
     "start_time": "2025-05-23T09:37:26.643927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "def get_path(name):\n",
    "    return f'/kaggle/input/arc-prize-2025/{name}' if os.path.exists(f'/kaggle/input/arc-prize-2025/{name}') else name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3366763",
   "metadata": {
    "papermill": {
     "duration": 0.003102,
     "end_time": "2025-05-23T09:37:26.659607",
     "exception": false,
     "start_time": "2025-05-23T09:37:26.656505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"padding:10px;background-color:#09abf2;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:12px;font-weight:200;border: 6px outset #f2102e;\">Load the Data</p>\n",
    "\n",
    "- It then loads the contents of these JSON files into Python dictionaries. This includes training puzzles, evaluation puzzles, solutions, and a sample submission file.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6283728a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T09:37:26.666690Z",
     "iopub.status.busy": "2025-05-23T09:37:26.666476Z",
     "iopub.status.idle": "2025-05-23T09:37:27.265012Z",
     "shell.execute_reply": "2025-05-23T09:37:27.264192Z"
    },
    "papermill": {
     "duration": 0.60372,
     "end_time": "2025-05-23T09:37:27.266525",
     "exception": false,
     "start_time": "2025-05-23T09:37:26.662805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data files\n",
    "training_solutions = json.load(open(get_path('arc-agi_training_solutions.json')))\n",
    "evaluation_solutions = json.load(open(get_path('arc-agi_evaluation_solutions.json')))\n",
    "evaluation_challenges = json.load(open(get_path('arc-agi_evaluation_challenges.json')))\n",
    "sample_submission = json.load(open(get_path('sample_submission.json')))\n",
    "training_challenges = json.load(open(get_path('arc-agi_training_challenges.json')))\n",
    "test_challenges = json.load(open(get_path('arc-agi_test_challenges.json')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c783c0e2",
   "metadata": {
    "papermill": {
     "duration": 0.003244,
     "end_time": "2025-05-23T09:37:27.278931",
     "exception": false,
     "start_time": "2025-05-23T09:37:27.275687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"padding:10px;background-color:#09abf2;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:12px;font-weight:200;border: 6px outset #f2102e;\">Choose a Model</p>\n",
    "\n",
    "- Download a pre-trained Qwen model from Kaggle Hub (a place to share models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71627411",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T09:37:27.287549Z",
     "iopub.status.busy": "2025-05-23T09:37:27.286868Z",
     "iopub.status.idle": "2025-05-23T09:37:27.881089Z",
     "shell.execute_reply": "2025-05-23T09:37:27.880253Z"
    },
    "papermill": {
     "duration": 0.599886,
     "end_time": "2025-05-23T09:37:27.882253",
     "exception": false,
     "start_time": "2025-05-23T09:37:27.282367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "try:\n",
    "    import kagglehub\n",
    "    model_name = kagglehub.model_download(\"qwen-lm/qwen-3/transformers/0.6b\")\n",
    "except:\n",
    "    model_name = \"Qwen/Qwen-7B\"  # fallback\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe1083f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T09:37:27.890232Z",
     "iopub.status.busy": "2025-05-23T09:37:27.889995Z",
     "iopub.status.idle": "2025-05-23T09:37:28.312864Z",
     "shell.execute_reply": "2025-05-23T09:37:28.312021Z"
    },
    "papermill": {
     "duration": 0.428241,
     "end_time": "2025-05-23T09:37:28.314103",
     "exception": false,
     "start_time": "2025-05-23T09:37:27.885862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded from Kaggle Hub: /kaggle/input/qwen-3/transformers/0.6b/1\n"
     ]
    }
   ],
   "source": [
    "# Model loading and setup\n",
    "try:\n",
    "    import kagglehub\n",
    "    model_name = kagglehub.model_download(\"qwen-lm/qwen-3/transformers/0.6b\")\n",
    "    print(f\"Model downloaded from Kaggle Hub: {model_name}\")\n",
    "except ImportError:\n",
    "    print(\"Kaggle Hub not available.  Make sure you have kaggle installed and are in a kaggle environment with internet access.\")\n",
    "    model_name = \"Qwen/Qwen-7B\"  # or any other appropriate Qwen model you have access to\n",
    "except Exception as e:\n",
    "     print(f\"Error downloading from Kaggle Hub: {e}.  Using a local or alternative model.\")\n",
    "     model_name = \"Qwen/Qwen-7B\" # Replace this if needed to a suitable model\n",
    "     print(f\"Trying model {model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce1b4c8",
   "metadata": {
    "papermill": {
     "duration": 0.003305,
     "end_time": "2025-05-23T09:37:28.321037",
     "exception": false,
     "start_time": "2025-05-23T09:37:28.317732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"padding:10px;background-color:#09abf2;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:12px;font-weight:200;border: 6px outset #f2102e;\">Set Up the Hardware</p>\n",
    "\n",
    "- It determines if a GPU is available (using CUDA) and sets the processing device to either the GPU or the CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "025f3e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T09:37:28.328468Z",
     "iopub.status.busy": "2025-05-23T09:37:28.328249Z",
     "iopub.status.idle": "2025-05-23T09:37:28.331240Z",
     "shell.execute_reply": "2025-05-23T09:37:28.330710Z"
    },
    "papermill": {
     "duration": 0.007818,
     "end_time": "2025-05-23T09:37:28.332185",
     "exception": false,
     "start_time": "2025-05-23T09:37:28.324367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for CUDA availability and set device\n",
    "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b81118",
   "metadata": {
    "papermill": {
     "duration": 0.003098,
     "end_time": "2025-05-23T09:37:28.338564",
     "exception": false,
     "start_time": "2025-05-23T09:37:28.335466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"padding:10px;background-color:#09abf2;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:12px;font-weight:200;border: 6px outset #f2102e;\">Load the Model and Tokenizer</p>\n",
    "\n",
    "- This is the core step. It loads the Qwen model and its corresponding tokenizer. The tokenizer converts text into numbers that the model can understand, and vice versa. The model is also moved to the chosen device (GPU or CPU).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc9ec27c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T09:37:28.346233Z",
     "iopub.status.busy": "2025-05-23T09:37:28.345683Z",
     "iopub.status.idle": "2025-05-23T09:38:05.151598Z",
     "shell.execute_reply": "2025-05-23T09:38:05.150795Z"
    },
    "papermill": {
     "duration": 36.811255,
     "end_time": "2025-05-23T09:38:05.153153",
     "exception": false,
     "start_time": "2025-05-23T09:37:28.341898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-23 09:37:35.936915: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747993056.118585      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747993056.172307      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f3535",
   "metadata": {
    "papermill": {
     "duration": 0.003267,
     "end_time": "2025-05-23T09:38:05.160716",
     "exception": false,
     "start_time": "2025-05-23T09:38:05.157449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"padding:10px;background-color:#09abf2;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:12px;font-weight:200;border: 6px outset #f2102e;\">Create a Chatbot Class</p>\n",
    "\n",
    "- The chatbot will remember the conversation, and it can use that knowledge to make a better prediction.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b23408a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T09:38:05.168557Z",
     "iopub.status.busy": "2025-05-23T09:38:05.168076Z",
     "iopub.status.idle": "2025-05-23T09:38:05.176716Z",
     "shell.execute_reply": "2025-05-23T09:38:05.176179Z"
    },
    "papermill": {
     "duration": 0.01359,
     "end_time": "2025-05-23T09:38:05.177668",
     "exception": false,
     "start_time": "2025-05-23T09:38:05.164078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QwenChatbot:\n",
    "    def __init__(self, model, tokenizer, max_input_tokens=3000):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.model = model\n",
    "        self.history = []\n",
    "        self.max_input_tokens = max_input_tokens\n",
    "\n",
    "    def generate_response(self, user_input, max_tokens=64):\n",
    "        self.history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        # Try generating with the full history, then truncate if necessary\n",
    "        while True:\n",
    "            messages = self.history + [{\"role\": \"user\", \"content\": user_input}]\n",
    "            text = self.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "            inputs = self.tokenizer(text, return_tensors=\"pt\").to(self.model.device)\n",
    "\n",
    "            if inputs.input_ids.shape[-1] <= self.max_input_tokens:\n",
    "                break  # Good to go\n",
    "            elif len(self.history) > 2:\n",
    "                self.history = self.history[2:]  # Truncate oldest user-assistant pair\n",
    "            else:\n",
    "                print(\"⚠️ Unable to fit prompt within token limit even after truncation.\")\n",
    "                return \"\", \"\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generated_ids = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_tokens,\n",
    "                do_sample=False,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        output_ids = generated_ids[0][len(inputs.input_ids[0]):].tolist()\n",
    "\n",
    "        try:\n",
    "            index = len(output_ids) - output_ids[::-1].index(151668)  # Qwen-specific token\n",
    "        except ValueError:\n",
    "            index = 0\n",
    "\n",
    "        thinking_content = self.tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip()\n",
    "        response = self.tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip()\n",
    "\n",
    "        self.history.append({\"role\": \"assistant\", \"content\": response})\n",
    "        return thinking_content, response\n",
    "\n",
    "\n",
    "def is_valid_grid(grid):\n",
    "    if not isinstance(grid, list) or len(grid) == 0:\n",
    "        return False\n",
    "    row_length = len(grid[0])\n",
    "    for row in grid:\n",
    "        if not isinstance(row, list) or len(row) != row_length:\n",
    "            return False\n",
    "        if not all(isinstance(cell, int) for cell in row):\n",
    "            return False\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da8d55",
   "metadata": {
    "papermill": {
     "duration": 0.003274,
     "end_time": "2025-05-23T09:38:05.184354",
     "exception": false,
     "start_time": "2025-05-23T09:38:05.181080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"padding:10px;background-color:#09abf2;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:12px;font-weight:200;border: 6px outset #f2102e;\">Demonstration and Task Integration</p>\n",
    "\n",
    "- The script includes an if __name__ == \"__main__\": block, which is executed when the script is run directly (not imported as a module).\n",
    "- First input (without /think or /no_think tags, thinking mode is enabled by default)\n",
    "- Second input with /no_think\n",
    "- Third input with /think\n",
    "- The script loops through a few challenges from the training set. For each challenge, it constructs a prompt by showing the model some examples (input/output pairs) and asking it to predict the output for a new input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e04400",
   "metadata": {
    "papermill": {
     "duration": 0.003181,
     "end_time": "2025-05-23T09:38:05.190944",
     "exception": false,
     "start_time": "2025-05-23T09:38:05.187763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create a Chatbot object and interact with the model. \n",
    "- The model can respond in two ways: The first way is that it will tell the thought about the answer. The second way is the real answer that users want to know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b28882b6",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-23T09:38:05.198323Z",
     "iopub.status.busy": "2025-05-23T09:38:05.198137Z",
     "iopub.status.idle": "2025-05-23T09:38:05.201225Z",
     "shell.execute_reply": "2025-05-23T09:38:05.200722Z"
    },
    "papermill": {
     "duration": 0.008053,
     "end_time": "2025-05-23T09:38:05.202268",
     "exception": false,
     "start_time": "2025-05-23T09:38:05.194215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Demonstration and ARC Task Integration ---\n",
    "\n",
    "# Initialize chatbot\n",
    "#chatbot = QwenChatbot(model, tokenizer)\n",
    "\n",
    "# Example Usage with the provided test cases.\n",
    "#if __name__ == \"__main__\":\n",
    "\n",
    "    # First input (without /think or /no_think tags, thinking mode is enabled by default)\n",
    "#    user_input_1 = \"How many r's in strawberries?\"\n",
    "#    print(f\"User: {user_input_1}\")\n",
    "#    thinking_content, response_1 = chatbot.generate_response(user_input_1)\n",
    "#    print(f\"Thinking: {thinking_content}\")\n",
    "#    print(f\"Bot: {response_1}\")\n",
    "#    print(\"----------------------\")\n",
    "\n",
    "#    # Second input with /no_think\n",
    "#    user_input_2 = \"Then, how many r's in blueberries? /no_think\"\n",
    "#    print(f\"User: {user_input_2}\")\n",
    "#    thinking_content, response_2 = chatbot.generate_response(user_input_2, enable_thinking=False) # explicitly disable thinking for the demo\n",
    "#    print(f\"Thinking: {thinking_content}\") # should be empty\n",
    "#    print(f\"Bot: {response_2}\")\n",
    "#    print(\"----------------------\")\n",
    "\n",
    "    # Third input with /think\n",
    "#    user_input_3 = \"Really? /think\"\n",
    "#    print(f\"User: {user_input_3}\")\n",
    "#    thinking_content, response_3 = chatbot.generate_response(user_input_3, enable_thinking=True)\n",
    "#    print(f\"Thinking: {thinking_content}\")\n",
    "#    print(f\"Bot: {response_3}\")\n",
    "\n",
    "#   print(\"----------------------\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "213959c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-23T09:38:05.209988Z",
     "iopub.status.busy": "2025-05-23T09:38:05.209775Z",
     "iopub.status.idle": "2025-05-23T09:38:05.215278Z",
     "shell.execute_reply": "2025-05-23T09:38:05.214720Z"
    },
    "papermill": {
     "duration": 0.010566,
     "end_time": "2025-05-23T09:38:05.216373",
     "exception": false,
     "start_time": "2025-05-23T09:38:05.205807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Demonstration and ARC Task Integration ---\n",
    "\n",
    "# Init chatbot\n",
    "chatbot = QwenChatbot(model, tokenizer)\n",
    "\n",
    "# Challenge solving function\n",
    "def solve_arc_challenge(challenge, chatbot):\n",
    "    predictions = []\n",
    "\n",
    "    # Prebuild train prompt\n",
    "    train_prompt = \"Solve the following abstract reasoning challenge:\\n\\n\"\n",
    "    for i, example in enumerate(challenge['train']):\n",
    "        train_prompt += f\"Input {i + 1}:\\n{example['input']}\\nOutput {i + 1}:\\n{example['output']}\\n\\n\"\n",
    "\n",
    "    for test_input in challenge['test']:\n",
    "        prompt = train_prompt + f\"Now, predict the output for the following test input:\\n{test_input['input']}\\nOutput:\\n\"\n",
    "\n",
    "        try:\n",
    "            _, arc_response = chatbot.generate_response(prompt, max_tokens=64)\n",
    "            arc_response = arc_response.replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "            start, end = arc_response.find(\"[[\"), arc_response.rfind(\"]]\")\n",
    "            if start != -1 and end != -1:\n",
    "                predicted_grid = ast.literal_eval(arc_response[start:end + 2])\n",
    "                if not is_valid_grid(predicted_grid):\n",
    "                    raise ValueError(\"Invalid grid structure\")\n",
    "            else:\n",
    "                raise ValueError(\"No valid grid found in response\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to parse output: {e}\")\n",
    "            predicted_grid = [[0]]  # Safer fallback grid\n",
    "\n",
    "        predictions.append(predicted_grid)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381d73f3",
   "metadata": {
    "papermill": {
     "duration": 0.003227,
     "end_time": "2025-05-23T09:38:05.223049",
     "exception": false,
     "start_time": "2025-05-23T09:38:05.219822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"padding:10px;background-color:#09abf2;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:12px;font-weight:200;border: 6px outset #f2102e;\">Solve Challenges - ARC dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9c929bc",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-23T09:38:05.230521Z",
     "iopub.status.busy": "2025-05-23T09:38:05.230344Z",
     "iopub.status.idle": "2025-05-23T09:38:05.233707Z",
     "shell.execute_reply": "2025-05-23T09:38:05.233053Z"
    },
    "papermill": {
     "duration": 0.008466,
     "end_time": "2025-05-23T09:38:05.234897",
     "exception": false,
     "start_time": "2025-05-23T09:38:05.226431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Example of integrating with the ARC dataset ---\n",
    "# Let's try to answer one of the training challenges.\n",
    "# sample_challenge_id = list(training_challenges.keys())[0]  # Get the first challenge ID\n",
    "#challenge = training_challenges[sample_challenge_id]\n",
    "\n",
    "# Construct a prompt that describes the task and provides examples\n",
    "#prompt = f\"Solve the following abstract reasoning challenge.  Here's the challenge:\\n\\n\"\n",
    "#for i, task in enumerate(challenge['train']): # Use examples from the training set to build the prompt\n",
    "#     prompt += f\"Input {i+1}:\\n\"\n",
    "#     prompt += str(task['input']) + \"\\n\"\n",
    "#     prompt += f\"Output {i+1}:\\n\"\n",
    "#     prompt += str(task['output']) + \"\\n\\n\"\n",
    "\n",
    "# Add the test input.  Tell the model to predict this output\n",
    "#prompt += \"Now, predict the output for the following test input:\\n\"\n",
    "#prompt += str(challenge['test'][0]['input']) + \"\\n\"\n",
    "#prompt += \"Output:\\n\"  # Ask the model to generate the output\n",
    "\n",
    "# Generate the response\n",
    "#print(\"----------------------\")\n",
    "#print(\"Solving ARC Challenge:\")\n",
    "#print(f\"Challenge ID: {sample_challenge_id}\")\n",
    "#thinking_content, arc_response = chatbot.generate_response(prompt)\n",
    "#print(f\"Thinking: {thinking_content}\")\n",
    "#print(f\"Model's Prediction:\\n{arc_response}\")\n",
    "#print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25190fda",
   "metadata": {
    "papermill": {
     "duration": 0.003276,
     "end_time": "2025-05-23T09:38:05.241557",
     "exception": false,
     "start_time": "2025-05-23T09:38:05.238281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <p style=\"padding:10px;background-color:#09abf2;font-family:newtimeroman;font-size:100%;text-align:center;border-radius:12px;font-weight:200;border: 6px outset #f2102e;\">Submission</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc04d659",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-23T09:38:05.249377Z",
     "iopub.status.busy": "2025-05-23T09:38:05.248999Z",
     "iopub.status.idle": "2025-05-23T09:38:14.984133Z",
     "shell.execute_reply": "2025-05-23T09:38:14.983140Z"
    },
    "papermill": {
     "duration": 9.740295,
     "end_time": "2025-05-23T09:38:14.985318",
     "exception": false,
     "start_time": "2025-05-23T09:38:05.245023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:   2%|▏         | 2/120 [00:00<00:07, 15.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:   5%|▌         | 6/120 [00:00<00:09, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:   7%|▋         | 8/120 [00:00<00:08, 13.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:   8%|▊         | 10/120 [00:00<00:10, 10.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  10%|█         | 12/120 [00:01<00:10, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  12%|█▏        | 14/120 [00:01<00:10,  9.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  16%|█▌        | 19/120 [00:01<00:07, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  18%|█▊        | 22/120 [00:01<00:06, 15.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  20%|██        | 24/120 [00:01<00:06, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  24%|██▍       | 29/120 [00:02<00:06, 13.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  26%|██▌       | 31/120 [00:02<00:07, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  29%|██▉       | 35/120 [00:02<00:06, 13.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  31%|███       | 37/120 [00:02<00:05, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  32%|███▎      | 39/120 [00:03<00:06, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  38%|███▊      | 45/120 [00:03<00:04, 16.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  39%|███▉      | 47/120 [00:03<00:05, 13.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  41%|████      | 49/120 [00:03<00:05, 12.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  43%|████▎     | 52/120 [00:04<00:05, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  48%|████▊     | 57/120 [00:04<00:03, 16.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  52%|█████▏    | 62/120 [00:04<00:03, 16.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  53%|█████▎    | 64/120 [00:04<00:03, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  55%|█████▌    | 66/120 [00:04<00:03, 15.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  58%|█████▊    | 70/120 [00:05<00:03, 13.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  60%|██████    | 72/120 [00:05<00:04, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  63%|██████▎   | 76/120 [00:05<00:03, 11.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  67%|██████▋   | 80/120 [00:06<00:04,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  68%|██████▊   | 82/120 [00:06<00:03,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  70%|███████   | 84/120 [00:06<00:04,  8.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  73%|███████▎  | 88/120 [00:07<00:03, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  75%|███████▌  | 90/120 [00:07<00:02, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  77%|███████▋  | 92/120 [00:07<00:02, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  80%|████████  | 96/120 [00:07<00:01, 12.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  82%|████████▏ | 98/120 [00:07<00:01, 12.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  83%|████████▎ | 100/120 [00:08<00:01, 10.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  85%|████████▌ | 102/120 [00:08<00:02,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  88%|████████▊ | 105/120 [00:08<00:01, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  92%|█████████▏| 110/120 [00:09<00:00, 12.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  93%|█████████▎| 112/120 [00:09<00:00, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks:  98%|█████████▊| 117/120 [00:09<00:00, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Solving ARC tasks: 100%|██████████| 120/120 [00:09<00:00, 12.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "⚠️ Unable to fit prompt within token limit even after truncation.\n",
      "⚠️ Failed to parse output: No valid grid found in response\n",
      "✅ Submission saved to `submission.json`.\n",
      "\n",
      "=== Sample submission preview ===\n",
      "\n",
      "Task ID: 0934a4d8\n",
      "  Test input #1:\n",
      "    Attempt 1 output: [[0]]\n",
      "    Attempt 2 output: [[0]]\n",
      "\n",
      "Task ID: 135a2760\n",
      "  Test input #1:\n",
      "    Attempt 1 output: [[0]]\n",
      "    Attempt 2 output: [[0]]\n",
      "\n",
      "Task ID: 136b0064\n",
      "  Test input #1:\n",
      "    Attempt 1 output: [[0]]\n",
      "    Attempt 2 output: [[0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop\n",
    "def create_submission(evaluation_challenges, chatbot):\n",
    "    submission = {}\n",
    "    for task_id, challenge in tqdm(evaluation_challenges.items(), desc=\"Solving ARC tasks\"):\n",
    "        predictions = solve_arc_challenge(challenge, chatbot)\n",
    "        \n",
    "        # Validate count matches number of test inputs\n",
    "        assert len(predictions) == len(challenge['test']), f\"Prediction count mismatch in task {task_id}\"\n",
    "        \n",
    "        submission[task_id] = [{\"attempt_1\": p, \"attempt_2\": p} for p in predictions]\n",
    "    return submission\n",
    "\n",
    "\n",
    "# Main\n",
    "if __name__ == \"__main__\":\n",
    "    submission = create_submission(evaluation_challenges, chatbot)\n",
    "\n",
    "    # Final submission validation\n",
    "    for task_id, outputs in submission.items():\n",
    "        assert isinstance(outputs, list), f\"{task_id} outputs not a list\"\n",
    "        for entry in outputs:\n",
    "            assert 'attempt_1' in entry and 'attempt_2' in entry, f\"Missing attempts in {task_id}\"\n",
    "            assert is_valid_grid(entry['attempt_1']), f\"Invalid attempt_1 grid in {task_id}\"\n",
    "            assert is_valid_grid(entry['attempt_2']), f\"Invalid attempt_2 grid in {task_id}\"\n",
    "\n",
    "    with open('submission.json', 'w') as f:\n",
    "        json.dump(submission, f)\n",
    "\n",
    "    print(\"✅ Submission saved to `submission.json`.\\n\")\n",
    "\n",
    "    # Show some results\n",
    "    print(\"=== Sample submission preview ===\")\n",
    "    sample_tasks = list(submission.items())[:3]  # show first 3 tasks only\n",
    "    for task_id, outputs in sample_tasks:\n",
    "        print(f\"\\nTask ID: {task_id}\")\n",
    "        for i, output in enumerate(outputs):\n",
    "            print(f\"  Test input #{i+1}:\")\n",
    "            print(f\"    Attempt 1 output: {output['attempt_1']}\")\n",
    "            print(f\"    Attempt 2 output: {output['attempt_2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4937452e",
   "metadata": {
    "papermill": {
     "duration": 0.007444,
     "end_time": "2025-05-23T09:38:15.000941",
     "exception": false,
     "start_time": "2025-05-23T09:38:14.993497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11802066,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "modelId": 322000,
     "modelInstanceId": 301506,
     "sourceId": 363124,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 63.250363,
   "end_time": "2025-05-23T09:38:17.871848",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-23T09:37:14.621485",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
