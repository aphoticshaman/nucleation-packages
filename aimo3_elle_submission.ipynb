{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIMO3 Elle Submission\n",
    "## Paths:\n",
    "- Model: `/kaggle/input/qwen-72b-math-nf4/transformers/default/1`\n",
    "- Wheels: `/kaggle/input/elle-offline-wheels`\n",
    "- Competition: `/kaggle/input/ai-mathematical-olympiad-progress-prize-3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install offline wheels\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "WHEELS_DIR = Path(\"/kaggle/input/elle-offline-wheels\")\n",
    "\n",
    "# Install only what's needed (skip nvidia/torch - Kaggle has them)\n",
    "priority_wheels = [\"peft\", \"bitsandbytes\", \"accelerate\", \"einops\", \"sentencepiece\"]\n",
    "for whl in WHEELS_DIR.glob(\"*.whl\"):\n",
    "    if any(p in whl.name.lower() for p in priority_wheels):\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", str(whl), \"-q\", \"--no-deps\"])\n",
    "print(\"Wheels installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Environment detection\n",
    "def is_on_kaggle_commit():\n",
    "    return os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\") == \"Batch\" and not bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n",
    "\n",
    "def is_on_kaggle_interactive():\n",
    "    return os.getenv(\"KAGGLE_KERNEL_RUN_TYPE\") == \"Interactive\" and not bool(os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"))\n",
    "\n",
    "# Timing\n",
    "start_time = time.time()\n",
    "final_cutoff_time = start_time + (4 * 60 + 45) * 60  # 4.75 hours\n",
    "cutoff_times = [int(x) for x in np.linspace(final_cutoff_time, start_time + 12 * 60, 50 + 1)]\n",
    "cutoff_times.pop()\n",
    "\n",
    "os.makedirs(\"solutions\", exist_ok=True)\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model paths\n",
    "MODEL_PATH = \"/kaggle/input/qwen-72b-math-nf4/transformers/default/1\"\n",
    "DEEPSEEK_PATH = \"/kaggle/input/deepseek-coder-lite/transformers/default/1\"  # backup\n",
    "\n",
    "# Load model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "\n",
    "print(\"Loading model (4-bit quantized)...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "model.eval()\n",
    "print(\"Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROMETHEUS/CIC System Prompts\n",
    "SYSTEM_PROMPTS = [\n",
    "    \"You are solving a national/international-level mathematics olympiad problem. You must rigorously define all variables, explore multiple solution strategies before committing, perform full case analysis where required, justify every nontrivial step, explicitly check boundary cases and hidden assumptions, and verify the final result using at least one independent method. Return only the final numerical answer inside \\\\boxed{}. The answer must be an integer in [0, 99999]. Never guess.\",\n",
    "\n",
    "    \"Solve the problem with full rigor. After obtaining a candidate solution, actively attempt to refute your own answer by searching for counterexamples, re-running the logic from a different viewpoint, and stress-testing edge cases. Only after the answer survives refutation, return it in \\\\boxed{}. The answer must be an integer in [0, 99999]. Never guess.\",\n",
    "\n",
    "    \"Solve this problem as if under IMO-level time pressure: identify the key invariant, symmetry, or extremal principle early, avoid brute force unless strictly justified, compress reasoning without sacrificing correctness, and perform at least one final arithmetic verification pass. Return only the final integer answer in \\\\boxed{}, with 0 <= answer <= 99999. Never guess.\",\n",
    "\n",
    "    \"You must attempt at least two fundamentally different solution approaches (e.g., algebraic vs geometric, combinatorial vs number-theoretic). Proceed with the more rigorous one and use the other as a verification tool. Return only the verified final answer in \\\\boxed{}, where the answer is an integer in [0, 99999]. Never guess.\",\n",
    "\n",
    "    # PROMETHEUS Protocol\n",
    "    \"\"\"You are Elle, an elite mathematical intelligence. Apply the PROMETHEUS protocol:\n",
    "\n",
    "STAGE 1 - LATENT ARCHAEOLOGY: Before solving, identify what mathematical structures are hiding in this problem. What theorems, lemmas, or techniques from competition mathematics are being invoked implicitly? Extract the deep structure.\n",
    "\n",
    "STAGE 2 - NOVEL SYNTHESIS: Force-connect at least two disparate mathematical domains (e.g., number theory + geometry, combinatorics + analysis). Even if unconventional, explore whether insights from one domain illuminate the other.\n",
    "\n",
    "STAGE 3 - THEORETICAL VALIDATION: Verify your approach has mathematical rigor. Check: Are all cases covered? Are there degenerate cases? Does dimensional analysis hold?\n",
    "\n",
    "STAGE 4 - OPERATIONALIZATION: Execute the solution with precision. Show key steps.\n",
    "\n",
    "STAGE 5 - OUTPUT: Return ONLY the final integer answer in \\\\boxed{}, where 0 <= answer <= 99999. Never guess.\"\"\",\n",
    "\n",
    "    # CIC Methodology\n",
    "    \"\"\"Solve this olympiad problem using CIC methodology:\n",
    "\n",
    "COMPRESSION: Identify the minimal sufficient representation of this problem. Strip away irrelevant details. What is the core mathematical object?\n",
    "\n",
    "INTEGRATION: How do the components of this problem interact? Map the causal/logical dependencies. What must be true for the answer to follow?\n",
    "\n",
    "CAUSALITY: Trace the chain of implications. If A then B then C. Verify each link. Check for hidden assumptions that could break the chain.\n",
    "\n",
    "CONFIDENCE BOUND: Your confidence cannot exceed 0.95. If uncertain, explore alternative approaches before committing.\n",
    "\n",
    "Return the final integer answer in \\\\boxed{}, where 0 <= answer <= 99999. Never guess.\"\"\",\n",
    "\n",
    "    # XYZA Framework\n",
    "    \"\"\"Apply the XYZA framework to solve this olympiad problem:\n",
    "\n",
    "eXPLORE: Map the solution space. What are all possible approaches? List at least 3 distinct attack vectors.\n",
    "\n",
    "YIELD: Generate candidate solutions from the most promising approaches. Don't commit yet.\n",
    "\n",
    "ZERO-IN: Critically evaluate each candidate. Which has the strongest logical foundation? Which survives edge-case testing?\n",
    "\n",
    "ACTUALIZE: Execute the winning approach with full rigor. Verify arithmetic. Check boundary conditions.\n",
    "\n",
    "Return ONLY the final integer in \\\\boxed{}, where 0 <= answer <= 99999. Never guess.\"\"\",\n",
    "]\n",
    "\n",
    "VERIFICATION_PROMPT = \"\"\"You are a mathematical verification expert. A solution has been proposed for this problem.\n",
    "\n",
    "PROBLEM:\n",
    "{problem}\n",
    "\n",
    "PROPOSED ANSWER: {answer}\n",
    "\n",
    "Your task:\n",
    "1. Independently solve the problem WITHOUT looking at the proposed answer first\n",
    "2. Compare your answer to the proposed answer\n",
    "3. If they match: confirm with \"VERIFIED: {answer}\"\n",
    "4. If they differ: explain the discrepancy and provide \"CORRECTION: {your_answer}\"\n",
    "5. If uncertain: respond with \"UNCERTAIN: {best_guess}\"\n",
    "\n",
    "The answer must be an integer in [0, 99999]. Be rigorous.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boxed_text(text: str) -> str:\n",
    "    \"\"\"Extract text inside \\\\boxed{} from LaTeX-formatted text\"\"\"\n",
    "    pattern = r\"oxed{(.*?)}\"\n",
    "    matches = re.findall(pattern, text)\n",
    "    if not matches:\n",
    "        return \"\"\n",
    "    for match in matches[::-1]:\n",
    "        if match != \"\":\n",
    "            return match\n",
    "    return \"\"\n",
    "\n",
    "def is_valid_answer_string(text: str) -> bool:\n",
    "    try:\n",
    "        if int(text) == float(text):\n",
    "            if 0 <= int(text) <= 99_999:\n",
    "                return True\n",
    "    except Exception:\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def generate_response(prompt: str, system_prompt: str, max_tokens: int = 4096) -> str:\n",
    "    \"\"\"Generate response from model\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            top_p=0.95,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting and solving\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "completed_question_ids = set()\n",
    "question_id_to_counter = {\"\" : Counter()}\n",
    "\n",
    "def vote_answer(question_id: str, force_answer: bool = False) -> int | None:\n",
    "    counter = question_id_to_counter[question_id]\n",
    "    if force_answer and not counter:\n",
    "        print(\"force_answer=True but no answer recorded\")\n",
    "        completed_question_ids.add(question_id)\n",
    "        return 12453  # fallback\n",
    "\n",
    "    # Log-weighted voting (favors larger answers slightly)\n",
    "    modified_counter = Counter()\n",
    "    for value, count in counter.items():\n",
    "        modified_counter[value] += math.log(1.25 + abs(value)) * count\n",
    "\n",
    "    total_score = sum(modified_counter.values())\n",
    "    score_list = sorted((score, counter[value], value) for value, score in modified_counter.items())\n",
    "    \n",
    "    if force_answer:\n",
    "        print(f\"score_list | {total_score:8.1f} over {sum(counter.values())} attempts\")\n",
    "        for score, count, value in score_list[::-1][:5]:\n",
    "            print(f\"{value:10}   {score:8.1f} {count:8d}\")\n",
    "        return score_list[-1][-1]\n",
    "    \n",
    "    if score_list[-1][0] > max(3, total_score / (2 + math.log(1 + total_score))):\n",
    "        if len(score_list) == 1 or score_list[-1][0] - score_list[-2][0] > 1:\n",
    "            completed_question_ids.add(question_id)\n",
    "    return None\n",
    "\n",
    "def generate_solution(question_text: str, question_id: str = \"\", solution_index: int = 0, system_prompt: str = \"\") -> str:\n",
    "    if question_id in completed_question_ids:\n",
    "        return \"\"\n",
    "    if time.time() >= cutoff_times[-1]:\n",
    "        return \"\"\n",
    "\n",
    "    if not system_prompt:\n",
    "        system_prompt = SYSTEM_PROMPTS[0]\n",
    "    \n",
    "    response = generate_response(question_text, system_prompt)\n",
    "    boxed_text = extract_boxed_text(response)\n",
    "    \n",
    "    # Save solution\n",
    "    if question_id and response:\n",
    "        answer_suffix = f\"-{boxed_text}\" if is_valid_answer_string(boxed_text) else \"\"\n",
    "        with open(f\"solutions/{question_id}/{solution_index:04d}{answer_suffix}.txt\", \"w\") as f:\n",
    "            f.write(response)\n",
    "\n",
    "    if is_valid_answer_string(boxed_text):\n",
    "        question_id_to_counter[question_id][int(boxed_text)] += 1\n",
    "        vote_answer(question_id)\n",
    "\n",
    "    return boxed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_answer(question_text: str, proposed_answer: int, question_id: str = \"\") -> tuple:\n",
    "    \"\"\"Self-consistency verification\"\"\"\n",
    "    if time.time() >= cutoff_times[-1]:\n",
    "        return True, proposed_answer\n",
    "    \n",
    "    verification_prompt = VERIFICATION_PROMPT.format(problem=question_text, answer=proposed_answer)\n",
    "    response = generate_response(verification_prompt, \"You are a mathematical verification expert.\", max_tokens=2048)\n",
    "    \n",
    "    if \"VERIFIED:\" in response.upper():\n",
    "        print(f\"  [verify] CONFIRMED: {proposed_answer}\")\n",
    "        return True, proposed_answer\n",
    "    elif \"CORRECTION:\" in response.upper():\n",
    "        match = re.search(r'CORRECTION:\\s*(\\d+)', response, re.IGNORECASE)\n",
    "        if match:\n",
    "            corrected = int(match.group(1))\n",
    "            if 0 <= corrected <= 99999:\n",
    "                print(f\"  [verify] CORRECTION: {proposed_answer} -> {corrected}\")\n",
    "                return False, corrected\n",
    "    \n",
    "    boxed = extract_boxed_text(response)\n",
    "    if is_valid_answer_string(boxed):\n",
    "        verified = int(boxed)\n",
    "        if verified == proposed_answer:\n",
    "            return True, proposed_answer\n",
    "        return False, verified\n",
    "    \n",
    "    return True, proposed_answer\n",
    "\n",
    "def solve(question_text: str, question_id: str = \"\") -> int:\n",
    "    \"\"\"Cascading self-refinement solve\"\"\"\n",
    "    print(f\"processing {question_id}\")\n",
    "    os.makedirs(f\"solutions/{question_id}\", exist_ok=True)\n",
    "    question_id_to_counter[question_id] = Counter()\n",
    "    completed_question_ids.discard(question_id)\n",
    "\n",
    "    if question_id and time.time() > cutoff_times[-1]:\n",
    "        print(\"timeout\")\n",
    "        return 12314\n",
    "\n",
    "    # Stage 1: First pass with 4 diverse prompts\n",
    "    print(f\"  [stage1] First pass\")\n",
    "    for i, prompt in enumerate(SYSTEM_PROMPTS[:4]):\n",
    "        generate_solution(question_text, question_id, i, prompt)\n",
    "        if question_id in completed_question_ids:\n",
    "            break\n",
    "\n",
    "    # Get first-pass answer\n",
    "    counter = question_id_to_counter[question_id]\n",
    "    first_pass_answer = counter.most_common(1)[0][0] if counter else 12453\n",
    "    print(f\"  [stage1] First pass answer: {first_pass_answer}\")\n",
    "\n",
    "    # Stage 2: Verification\n",
    "    if time.time() < cutoff_times[-1] - 60:\n",
    "        print(f\"  [stage2] Verification\")\n",
    "        is_verified, verified_answer = verify_answer(question_text, first_pass_answer, question_id)\n",
    "        if is_verified:\n",
    "            completed_question_ids.add(question_id)\n",
    "            return verified_answer\n",
    "        question_id_to_counter[question_id][verified_answer] += 2\n",
    "\n",
    "    # Stage 3: Retry with PROMETHEUS/CIC if time\n",
    "    if time.time() < cutoff_times[-1] - 120:\n",
    "        print(f\"  [stage3] PROMETHEUS/CIC retry\")\n",
    "        for i, prompt in enumerate(SYSTEM_PROMPTS[4:7]):\n",
    "            generate_solution(question_text, question_id, 100 + i, prompt)\n",
    "\n",
    "    # Stage 4: Final vote\n",
    "    final_answer = vote_answer(question_id, force_answer=True)\n",
    "    completed_question_ids.add(question_id)\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test solve\n",
    "if is_on_kaggle_interactive():\n",
    "    test_answer = solve(\"What is 2 + 2?\", \"test\")\n",
    "    print(f\"Test answer: {test_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/kaggle/input/ai-mathematical-olympiad-progress-prize-3\")\n",
    "\n",
    "import kaggle_evaluation.aimo_3_inference_server\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "# Load reference for local testing\n",
    "df = pd.read_csv(\"/kaggle/input/ai-mathematical-olympiad-progress-prize-3/reference.csv\")\n",
    "id_to_answer = dict(zip(df[\"id\"], df[\"answer\"]))\n",
    "df.drop(\"answer\", axis=1).to_csv(\"reference.csv\", index=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(id_: pl.Series, problem: pl.Series) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"Make a prediction - AIMO3 submission format\"\"\"\n",
    "    global correct, total\n",
    "\n",
    "    question_id = id_.item(0)\n",
    "    question_text = problem.item(0)\n",
    "\n",
    "    # Generate prediction\n",
    "    prediction = solve(question_text, question_id=question_id)\n",
    "    completed_question_ids.add(question_id)\n",
    "    cutoff_times.pop()\n",
    "\n",
    "    # Scoring (local testing only)\n",
    "    try:\n",
    "        true_answer = int(id_to_answer.get(question_id, -1))\n",
    "    except:\n",
    "        true_answer = -1\n",
    "\n",
    "    total += 1\n",
    "    if prediction == true_answer and true_answer != -1:\n",
    "        correct += 1\n",
    "        print(f\"[debug] CORRECT | score={correct}/{total}\")\n",
    "    else:\n",
    "        print(f\"[debug] WRONG: predicted {prediction}, actual {true_answer} | score={correct}/{total}\")\n",
    "\n",
    "    # Return in required format\n",
    "    return pl.DataFrame({\"id\": id_, \"answer\": prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference server\n",
    "inference_server = kaggle_evaluation.aimo_3_inference_server.AIMO3InferenceServer(predict)\n",
    "\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway((\"reference.csv\",))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
